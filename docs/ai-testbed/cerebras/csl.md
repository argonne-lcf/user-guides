# Getting Started with Cerebras CSL

Cerebras CSL (Cerebras System Language) is a low-level kernel programming language designed for the Cerebras system. It enables users to write code that runs on individual Processing Elements (PEs) and to define the placement of programs and the routing of data on the Wafer-Scale Engine (WSE).

To develop programs for the Cerebras system, users create two main components:

1. **Device Code:** Written in CSL, this code executes directly on the Cerebras system.
2. **Host Code:** Written in Python, this code leverages Cerebras APIs to facilitate data movement and execute functions on the Cerebras system.
CSL includes libraries for a variety of commonly used primitive operations, such as broadcasting, gathering, and scattering data across rows or columns of PEs.

The Cerebras SDK can be utilized in two primary modes:
1. **Simulator Mode:** For testing and debugging programs without access to physical hardware.
2. **Appliance Mode:** For executing programs on the actual Cerebras hardware.

For a comprehensive overview of the Cerebras SDK, refer to the  [Cerebras SDK Documentation](https://sdk.cerebras.net/).

## SDK with Simulator

The Cerebras SDK relies on a Singularity container and associated scripts to execute CSL code on a simulator.

On a user node, the Cerebras SDK is available at `/software/cerebras/cs_sdk` for your convenience. You can copy it to your `$HOME` directory, add it to your `$PATH`, and youâ€™re ready to get started.

```bash linenums="1"
cp -r /software/cerebras/cs_sdk-1.2.0 ~
export PATH=~/cs_sdk-1.2.0:$PATH
```

To verify that the SDK is installed correctly, execute the command: `cslc --help`


### Examples

We will use examples from the `csl-examples` repository provided by Cerebras. To get these examples, clone the repository into your desired directory:

```bash linenums="1"
export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128
git clone https://github.com/Cerebras/csl-examples.git
cd csl-examples
git checkout rel-sdk-1.2.0
cd ~/csl-examples/benchmarks/gemm-collectives_2d
bash commands.sh
```

Note: to access any external web resources from a Cerebras user node, you will need to have a proxy environment variable set (or equivalent). `wget` needs the lower-case proxy environment variable.
```bash
export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128
export https_proxy=http://proxy.alcf.anl.gov:3128
```

??? note "Sample Output"

	``` { .bash .nocopy }
    $ bash commands.sh
    INFO: Using SIF: /software/cerebras/cs_sdk-1.2.0/sdk-cbcore-202406260214-3-f03c8e31.sif
    INFO: User's specified CSL_IMPORT_PATH=
    NOTE: CSL_IMPORT_PATH accepts colon separated list of paths generated by 'realpath <path>'
    compile successful
    INFO: Using SIF: /software/cerebras/cs_sdk-1.2.0/sdk-cbcore-202406260214-3-f03c8e31.sif
    SUCCESS
	```

### SDK GUI

You can use the SDK Debug GUI to analyze and gain insights into your code execution. For detailed instructions, refer to the [SDK GUI documentation](https://sdk.cerebras.net/debug/sdk-gui).

To launch the SDK Debug GUI, run the following commands:
```bash linenums="1"
cd ~/csl-examples/benchmarks/gemm-collectives_2d
sdk_debug_shell visualize
```

??? note "Sample Output"

	``` { .bash .nocopy }
    > sdk_debug_shell visualize
    INFO: Using SIF: /software/cerebras/cs_sdk-1.2.0/sdk-cbcore-202406260214-3-f03c8e31.sif
    INFO: User's specified CSL_IMPORT_PATH=
    NOTE: CSL_IMPORT_PATH accepts colon separated list of paths generated by 'realpath <path>'
    Click this link to open URL:  http://cer-login-04.ai.alcf.anl.gov:8000/sdk-gui
    Click this link to open URL:  http://140.221.80.28:8000/sdk-gui
    Press Ctrl-C to exit
	```

To access the GUI from your local computer, forward port 8000 from the user node through a login node to your local machine, and open the following URL in your web browser:  `http://localhost:8000/sdk-gui/`

![CS-3 connection diagram](./files/cs_sdk_gui.png)


## SDK with Appliance Mode

Appliance Mode enables running code directly on the Cerebras Wafer-Scale Cluster. In addition to the containerized Singularity build of the Cerebras SDK, the SDK also supports operations on Cerebras Wafer-Scale Clusters running in appliance mode. Please note that the compilation is performed on the worker/management node, hence there might not be enough resourses while compiling a model along with other jobs running. 

### Setup

**Create Virtual Environment:** Follow these steps to set up the virtual environment for the Cerebras SDK:
```bash linenums="1"
rm -r cs_appliance_sdk
deactivate
/usr/bin/python3.11 -m venv cs_appliance_sdk
source cs_appliance_sdk/bin/activate
pip install --upgrade pip
```

**Install SDK Packages:** Install the `cerebras_appliance` and `cerebras_sdk` Python packages in the virtual environment, specifying the appropriate Cerebras Software release:
```bash linenums="1"
pip install cerebras_appliance==2.6.0
pip install cerebras_sdk==2.6.0
```

### Examples

We will use examples from the `csl-examples` repository provided by Cerebras. To access these examples, clone the repository into your desired directory:

```bash linenums="1"
export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128
git clone https://github.com/Cerebras/csl-examples.git
cd csl-examples
git checkout rel-sdk-1.4.0
cd ~/csl-examples/tutorials/gemv-01-complete-program/
```

#### Compile Code

Use the following `appliance_compile.py` script to compile the code in the respective example directory:

```python title="compile.py" linenums="1"
import json
from cerebras.sdk.client import SdkCompiler
import logging
from cerebras.appliance import logger
logging.basicConfig(level=logging.INFO)

# Instantiate copmiler using a context manager
# Disable version check to ignore appliance client and server version differences.
with SdkCompiler(disable_version_check=True) as compiler:

    # Launch compile job
    artifact_path = compiler.compile(
        ".",
        "layout.csl",
        "--fabric-dims=8,3 --fabric-offsets=4,1 --memcpy --channels=1 -o out",
        "."
    )

# Write the artifact_path to a JSON file
with open("artifact_path.json", "w", encoding="utf8") as f:
    json.dump({"artifact_path": artifact_path,}, f)
```

??? note "Sample Output"

``` { .bash .nocopy }
	$ python appliance_compile.py
	INFO:cerebras.cluster.client:Appliance client semantic version: 1.1.0, cluster server semantic version: 1.1.2, job operator semantic version: 1.1.2
	INFO:cerebras.cluster.client:Initiating a new SDK compile job against the cluster server
	INFO:cerebras.cluster.client:Job id: wsjob-4mhdefdzswskmakfcp9hfe, workflow id: wflow-2ullyamqmrdi7nxodyl6f77xbi, namespace: job-operator, remote log path:
	/n1/wsjob/workdir/job-operator/wsjob-4mhdefdzswskmakfcp9hfe
	INFO:cerebras.cluster.client:Poll ingress status: Waiting for all Coordinator pods to be running, current running: 0/1.
	INFO:cerebras.cluster.client:Recording the timestamp when jobs is scheduled.
	WARNING:cerebras.cluster.client:Event 2025-10-23 19:49:54 +0000 UTC reason=InconsistentVersion wsjob=wsjob-4mhdefdzswskmakfcp9hfe message='Warning: client semantic 		version 1.1.0 is inconsistent with cluster server semantic version 1.1.2, there's a risk job could fail due to inconsistent setup.'
	INFO:cerebras.cluster.client:Poll ingress status: Waiting for job ingress readiness.
	INFO:cerebras.cluster.client:Poll ingress status: Job ingress ready, dashboard: https://grafana.anl0.cerebras.internal/d/WebHNShVz/wsjob-dashboard?orgId=1&var-wsjob=wsjob-
	4mhdefdzswskmakfcp9hfe&from=1761248404000&to=now
	INFO:cerebras.cluster.client:Poll ingress success: Job ingress ready, dashboard: https://grafana.anl0.cerebras.internal/d/WebHNShVz/wsjob-dashboard?orgId=1&var-
	wsjob=wsjob-4mhdefdzswskmakfcp9hfe&from=1761248404000&to=now
	2025-10-23 19:50:44,583 INFO     CSL compiler output:
	CSL compiler produced no messages. Compilation successful.
	INFO:cerebras.sdk.client.sdk_appliance_client:CSL compiler output:
	CSL compiler produced no messages. Compilation successful. 
```

The only difference between CS-3 and simuator run is the `fabric_dims`. It should be set to minimum required for simulatored runs.
Above script generates `artifact.json` which is used by the `appliance_run.py` script.

#### Run Code

Use the following `appliance_run.py` script to run the code in the respective example directory:

```python title="run.py" linenums="1"
#!/usr/bin/env cs_python

import argparse
import numpy as np
import json
#from cerebras.sdk.runtime.sdkruntimepybind import SdkRuntime, MemcpyDataType, MemcpyOrder # pylint: disable=no-name-in-module
import logging
from cerebras.appliance import logger
logging.basicConfig(level=logging.INFO)

from cerebras.appliance.pb.sdk.sdk_common_pb2 import MemcpyDataType, MemcpyOrder
from cerebras.sdk.client import SdkRuntime

# Matrix dimensions
M = 4
N = 6

# Construct A, x, b
A = np.arange(M*N, dtype=np.float32).reshape(M, N)
x = np.full(shape=N, fill_value=1.0, dtype=np.float32)
b = np.full(shape=M, fill_value=2.0, dtype=np.float32)

# Calculate expected y
y_expected = A@x + b

# Read the artifact_path from the JSON file
with open("artifact_path.json", "r", encoding="utf8") as f:
    data = json.load(f)
    artifact_path = data["artifact_path"]

with SdkRuntime(artifact_path, simulator=True, disable_version_check=True) as runner:
    # Launch the init_and_compute function on device
    runner.launch('init_and_compute', nonblock=False)

    # Copy y back from device
    y_symbol = runner.get_id('y')
    y_result = np.zeros([1*1*M], dtype=np.float32)
    runner.memcpy_d2h(y_result, y_symbol, 0, 0, 1, 1, M, streaming=False,
    order=MemcpyOrder.ROW_MAJOR, data_type=MemcpyDataType.MEMCPY_32BIT, nonblock=False)
# Ensure that the result matches our expectation
np.testing.assert_allclose(y_result, y_expected, atol=0.01, rtol=0)
print("SUCCESS!")
```

??? note "Sample Output"
```{ .bash .nocopy }
   $ python appliance_run.py
   INFO:cerebras.cluster.client:Appliance client semantic version: 1.1.0, cluster server semantic version: 1.1.2, job operator semantic version: 1.1.2
   INFO:cerebras.cluster.client:Initiating a new SDK compile job against the cluster server
   INFO:cerebras.cluster.client:Job id: wsjob-qqcsg8g5z66nknmk4d48gp, workflow id: wflow-kcrf2anv7zconl7xq2idceztdq, namespace: job-operator, remote log path:
	/n1/wsjob/workdir/job-operator/wsjob-qqcsg8g5z66nknmk4d48gp
   INFO:cerebras.cluster.client:Poll ingress status: Waiting for all Coordinator pods to be running, current running: 0/1.
   INFO:cerebras.cluster.client:Recording the timestamp when jobs is scheduled.
   WARNING:cerebras.cluster.client:Event 2025-10-23 19:54:55 +0000 UTC reason=InconsistentVersion wsjob=wsjob-qqcsg8g5z66nknmk4d48gp message='Warning: client semantic version    1.1.0 is inconsistent with cluster server semantic version 1.1.2, there's a risk job could fail due to inconsistent setup.'
   INFO:cerebras.cluster.client:Poll ingress status: Waiting for job ingress readiness.
   INFO:cerebras.cluster.client:Poll ingress status: Job ingress ready, dashboard: https://grafana.anl0.cerebras.internal/d/WebHNShVz/wsjob-dashboard?orgId=1&var-wsjob=wsjob-    qqcsg8g5z66nknmk4d48gp&from=1761248705000&to=now
   INFO:cerebras.cluster.client:Poll ingress success: Job ingress ready, dashboard: https://grafana.anl0.cerebras.internal/d/WebHNShVz/wsjob-dashboard?orgId=1&var-
	wsjob=wsjob-   qqcsg8g5z66nknmk4d48gp&from=1761248705000&to=now
   SUCCESS!
```

<!--- KGF: no way to disable a tooltip abbreviation from the include/abbreviations.md glossary used by
https://squidfunk.github.io/mkdocs-material/reference/tooltips/#adding-a-glossary , unlike more basic extension https://python-markdown.github.io/extensions/abbreviations/ -->

<!-- *[CSL]: '' -->

<!--- and there is no way to even override a definition, since pymdownx.snippets auto_append option will always be last entry on a page, e.g.: -->

<!-- *[CSL]: test -->

<!-- but you can add more abbreviations (locally, per page) that arent in the shared, auto-appended glossary -->

<!-- *[CS-3]: test -->
