{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ALCF User Guides","text":"<p>The ALCF user-facing documentation source material is hosted on GitHub, in order to facilitate contributions and issue reporting from the community.</p> <p>Our user guides contain information for:</p> <ul> <li>Account and Project Management: Information and instructions on how to manage your ALCF account and awarded project.</li> <li>Data Management: Information on our file systems that are mounted globally across all of our production systems.</li> <li>Aurora: Information on getting your code ready for Aurora, Argonne's exacale supercomputer.</li> <li>AI Testbed: Information on the advanced, non-GPU AI accelerators housed within the ALCF</li> <li>Crux: A 256-node, dual-socket AMD CPU platform</li> <li>Polaris: Our 560-node HPE system with NVIDIA A100 GPUs</li> <li>Sophia: Our 24-node NVIDIA DGX A100 system</li> <li>Services: Information on how to use various services provided across clusters.</li> <li>Facility Policies: Information on our policies and procedures.</li> </ul>"},{"location":"#how-to-get-access","title":"How to Get Access","text":"<p>Researchers interested in using the ALCF systems (including CPU systems, GPU systems, and the AI Testbed\u2019s Cerebras CS-2 and SambaNova DataScale platforms) can now submit project proposals via the ALCF\u2019s Director\u2019s Discretionary program. Calls for proposals for additional allocation programs will be open at a later date.</p> <p>Submit your proposal requests at: Allocation Request Page</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>If you'd like to get started using our ALCF resources, our Getting Started Page provides information on what you need to do in order to get time on our systems, get an account, and how to start running jobs.</p> <p>Please send feedback to support@alcf.anl.gov</p>"},{"location":"acronyms/","title":"Acronyms","text":"Acronym Term ALCC ASCR Leadership Computing Challenge ALCF Argonne Leadership Computing Facility AMD Advanced Micro Devices API Application Programming Interface ASCR Advanced Scientific Computing Research ASIC Application-Specific Integrated Circuit CLI Command Line Interface CPU Central Processing Unit CSL Cerebras System Language CUDA Compute Unified Device Architecture DFT Density Functional Theory DGX Data Center Graphics Accelerator (NVIDIA) DOE Department of Energy DPC Data Parallel C++ DRAM Dynamic Random-Access Memory DTN Data Transfer Node FFT Fast Fourier Transform FIFO First In, First Out FLOPS Floating Point Operations Per Second FPGA Field-Programmable Gate Array GCC GNU Compiler Collection GDB GNU Debugger GEMM General Matrix Multiply GPU Graphics Processing Unit GTL GPU Transfer Library (HPE Cray) HBM High Bandwidth Memory HDR High Data Rate (InfiniBand) HPC High Performance Computing HPCM HPE Performance Cluster Manager HPE Hewlett Packard Enterprise HSI High-Speed Interface I/O Input/Output INCITE Innovative and Novel Computational Impact on Theory and Experiment IPEX Intel Extension for PyTorch IPU Intelligence Processing Unit ITEX Intel Extension for TensorFlow JIT Just-In-Time (compilation) LAPACK Linear Algebra Package LAMMPS Large-scale Atomic/Molecular Massively Parallel Simulator LDAP Lightweight Directory Access Protocol LLM Large Language Model MFA Multi-Factor Authentication MIG Multi-Instance GPU (NVIDIA) MKL Math Kernel Library MPI Message Passing Interface MPS Multi-Process Service (NVIDIA) MTBF Mean Time Between Failures NAMD Nanoscale Molecular Dynamics NCCL NVIDIA Collective Communications Library NFS Network File System NIC Network Interface Card NLP Natural Language Processing NUMA Non-Uniform Memory Access NVME Non-Volatile Memory Express OFI Open Fabric Interface OpenMP Open Multi-Processing OS Operating System OTP One-time Password PALS Parallel Application Launch Service (HPE Cray EX) PBS Portable Batch System PCI Peripheral Component Interconnect PHB PCIe Host Bridge PMIx Process Management Interface for Exascale QMC Quantum Monte Carlo QMCPACK Quantum Monte Carlo Package RAID Redundant Array of Independent Disks RAM Random Access Memory RBC Red Blood Cells RDMA Remote Direct Memory Access RDU Reconfigurable Dataflow Unit RPC Remote Procedure Call SCM Source Control Management SDK Software Development Kit SFTP SSH File Transfer Protocol SIMD Single Instruction, Multiple Data SIMT Single Instruction, Multiple Threads SMT Simultaneous Multithreading SPMD Single Program, Multiple Data SSD Solid State Drive SSH Secure Shell SSO Single Sign-On SYCL Single-source heterogeneous programming using C++ TCP Transmission Control Protocol TDP Thermal Design Power TOPS Tera Operations Per Second UAN User Access Node UCX Unified Communication X UPI Ultra Path Interconnect URL Uniform Resource Locator USM Unified Shared Memory UUID Universally Unique Identifier VASP Vienna Ab initio Simulation Package VCS Version Control System VMC Variational Monte Carlo VNC Virtual Network Computing XALT System tracking of users codes on clusters XLA Accelerated Linear Algebra XPU Any Processing Unit (CPU, GPU, FPGA, ASIC) in Intel's heterogeneous computing strategy"},{"location":"account-project-management/","title":"Account &amp; Project Management","text":"<p>Follow the links below for additional information on the ALCF User Portal, ALCF user account and access, ALCF project management, and project allocations.</p> <ul> <li>MyALCF User Portal</li> <li>Accounts and Access</li> <li>Project Management</li> <li>Allocations</li> </ul>"},{"location":"account-project-management/MyALCF/","title":"Getting Started on MyALCF","text":""},{"location":"account-project-management/MyALCF/#access-myalcf","title":"Access MyALCF","text":"<p>To find MyALCF, either use the myALCF link at the ALCF homepage or visit the MyALCF homepage</p>"},{"location":"account-project-management/MyALCF/#logging-in","title":"Logging In","text":"<p>Log in using your ALCF username and CRYPTOcard passcode. For those who already have an ALCF account, this set of credentials isn\u2019t changed. For those who do not have an ALCF account, you will need to request a new account in the section below the login. For more about accounts and passcodes, see Obtaining a Token</p>"},{"location":"account-project-management/MyALCF/#home-screen-dashboard","title":"Home Screen Dashboard","text":"<p>Once logged in to MyALCF, a home screen is presented with useful information pertaining to an individual's projects and the facility. The navigation menu links to get to more in depth tools and information. Simple icons show the current status of ALCF systems. Up-to-date data about current compute project allocations are shown as a high-level view of current activity (if there are no current allocations, there will be a link to request a new allocation). Links for support help, training event information, and facility news updates complete the home screen dashboard.</p> <p></p> <p>Example appearance of home screen dashboard.</p>"},{"location":"account-project-management/MyALCF/#navigation","title":"Navigation","text":"<p>Navigation menu items link to pages to update account and project information, use the sbank accounting tool, view training and documentation, and use any other tools your role allows you to access.</p>"},{"location":"account-project-management/MyALCF/#system-status","title":"System Status","text":"<p>ALCF machine status is visible with a green up arrow showing a running system and a red down arrow showing a system down for scheduled or unscheduled maintenance. Clicking the system name will take you to the resource status page for that machine if available. Machine usage, active jobs, and more is shown on the resource status page.</p>"},{"location":"account-project-management/MyALCF/#current-allocations","title":"Current Allocations","text":"<p>Collection of data showing status and usage of compute allocations. If there are no current compute allocations, a link to request a new discretionary allocation is visible. Data for each allocation is presented in rows with five columns per row:</p> <ul> <li>Compute Allocation: The project name, system, award type, allocation ID and dates.</li> <li>On-track Trend: Comparison of project activity to a linear usage of hours. Expanding the graph shows a more detailed version of the graph with node hour percentage used and months specified. A second graph shows job sizes needed to use all node hours available in the remaining time. </li> </ul> <p> </p> <p>Screenshot of example expanded on-track graph.</p> <ul> <li>Node Hour Usage: Total node hours available, used, and remaining in the allocation.</li> <li>14 Day Jobs Activity: show a simple graph of the last two weeks of activity. Expanding it gives a more detailed view with node hour counts per day and per month.</li> </ul> <p> </p> <p>Screenshot of example expanded activity graph.</p> <ul> <li>Hours by Size: How the jobs in the allocation are split in terms of machine nodes used. Expanding this graph will give a visualization of how that split has occurred over time.</li> </ul> <p> </p> <p>Screenshot of example expanded jobs by size graph.</p>"},{"location":"account-project-management/MyALCF/#links-training-facility-updates","title":"Links, Training, Facility Updates","text":"<p>The bottom portion of the MyALCF home screen shows quick links to training events, support, and current facility news.</p>"},{"location":"account-project-management/MyALCF/#navigation-menu","title":"Navigation Menu","text":"<p>The navigation menu is personalized and shows sections available based on the user role. As more MyALCF features are developed, this menu will update to keep the site easy to navigate. All active account users will be able to access the following:</p>"},{"location":"account-project-management/MyALCF/#update-account","title":"Update Account","text":"<p>View account details and update necessary fields here. View project memberships and UNIX groups.</p>"},{"location":"account-project-management/MyALCF/#projects-resources","title":"Projects &amp; Resources","text":"<p>View and update project memberships, join projects, view and edit UNIX groups and request an allocation from this section.</p>"},{"location":"account-project-management/MyALCF/#sbank","title":"sbank","text":"<p>sbank is the compute node hour accounting system at ALCF. It has historically been accessed via the command line but this interface allows for accessing information via graphic-based interactions. The basic capabilities and tools within the graphic interface are the following:</p> <ul> <li>Command Builder: The Command Builder is a point-and-click style interface that allows for typing commands into the top command bar and/or selecting options from input boxes and/or dropdowns to create specific sbank commands. The default command is \u2018sbank-list-allocations\u2019. You can switch to sbank-list-jobs, sbank-detail-allocations, etc. under the top command bar and refine the command below via the input fields. Dynamic help is offered when a field is highlighted to explain the command and give examples. The output commands can be altered in the \u2018view options\u2019 panel accessed via the \"View Options\" button.</li> </ul> <p></p> <p>Screenshot of command builder portion of sbank page.</p> <ul> <li>View Options: View Options is shown as a set of three lists with selectable items that affect how the output is presented.<ul> <li>Display Fields: The column titles that will show in the output. The column titles are listed in the order they will be viewed in the output (1 is the column shown to the left extent, followed to the right by 2, 3, etc.) The column titles are selectable/deselectable and can be reordered via the arrow buttons or by dragging and dropping them to the desired order. \"Field Width\" is available if a character limit is desired in the column's output.</li> </ul> </li> <li>Filters: Allows for toggling between different sets of rows available. By default, output is for active allocations.</li> <li> <p>Display Options: Allows for toggling items shown in the output.</p> <p> </p> <p>Screenshot of the view options portion of sbank page.</p> </li> <li> <p>Output: The output can be either text based or an html table that is filterable. This is done by toggling between \u2018text output\u2019 and \u2018html output\u2019 next to the output window. Output can be saved as .csv by clicking the \u2018Save Output\u2019 button next to the output window. Commands can also be saved by clicking the \u2018save command\u2019 button.</p> </li> <li>Popular Commands: Popular commands are a set of preconfigured commands that will output useful information with no modification necessary.  \u2018Popular Commands\u2019 can be accessed by clicking the \u2018Quick Commands\u2019 bar. Each command can be run as is or can be copied to the clipboard for use in the command line or copied to the command builder.</li> <li>Saved Commands: Commands that are likely to be repeated can be saved for later use with the \u2018save command\u2019 feature. \u2018Save command\u2019 buttons can be found next to the command bar or next to the output window. When you want to save a command, enter it via the command bar or by selecting options through the interface, click the save command button, and then enter a name and a brief description of the function. Once saved, the command will be accessible in the saved commands window unless deleted. The saved command can be run as is, copied to either the command builder or clipboard, edited (name and description), or deleted.</li> </ul>"},{"location":"account-project-management/MyALCF/#training","title":"Training","text":"<p>Link to ALCF training events.</p>"},{"location":"account-project-management/MyALCF/#user-guides","title":"User Guides","text":"<p>Link to ALCF User Guides.</p>"},{"location":"account-project-management/accounts-and-access/","title":"ALCF User Account Overview","text":"<p>All computing carried out on the ALCF systems is associated with a user \"account.\" This account is used to log onto the login servers and run jobs on the resources. If someone has a user account, then they have a login name that is recorded in the user database. This web page describes the process that users will need to understand to manage account details, including policies and procedures.</p> <p>If you need an account, visit the Accounts and Project Management website: Request an account</p> <p>If you want to learn how to get started, visit the Get Started Guide</p>"},{"location":"account-project-management/accounts-and-access/#who-can-get-an-account","title":"Who Can Get an Account","text":"<p>Those who are interested in having an account on an ALCF resource must first request an allocation and provide a detailed description of the work, including computational requirements and coding capabilities for the applicable ALCF resources. Alternatively, one may be part of a project team that already has an active allocation. Once an allocation has been granted, new users should complete an account request. A project\u2019s Principal Investigator (PI) must sponsor these accounts\u2014if the PI is the user, an ALCF staff member must serve as sponsor. Sponsors are asked annually to evaluate the accounts they have sponsored to determine whether or not these accounts should be kept active.</p>"},{"location":"account-project-management/accounts-and-access/#account-abilities","title":"Account Abilities","text":"<p>A user with an active account can log in to the ALCF login servers (e.g., polaris.alcf.anl.gov). This account will have some home directory space, where file transfer can occur from that space via the login nodes, and where development activities, such as editing and compiling, can also occur.</p>"},{"location":"account-project-management/accounts-and-access/#account-states","title":"Account States","text":"<p>Accounts are classified in one of the following categories:</p> <ul> <li>Pending: An account that has been requested but has not yet been created.</li> <li>Active: An account that can be used to interact with the ALCF Login Servers. This is the normal state for all accounts.</li> <li>Inactive: An account that still exists on the system (that is, the account continues to be registered in the database and the user's files exist on disk) but the user cannot interact with the ALCF Login Servers. An account might be disabled due to misuse, security concerns, or because it is no longer allocated or the approval period has expired.</li> <li>Deleted: An account that existed on the system and is thus in the records and backups, but whose user no longer has access to the systems or files on disk. Typically, an account that is inactive for 90 days is flagged as deleted.</li> </ul>"},{"location":"account-project-management/accounts-and-access/#more-information","title":"More Information","text":"<ul> <li>Account Policy</li> <li>User Authentication Policy</li> <li>Account Sponsorship and Retention Policy</li> </ul>"},{"location":"account-project-management/accounts-and-access/accounts-and-access-faqs/","title":"Accounts and Access FAQ","text":""},{"location":"account-project-management/accounts-and-access/accounts-and-access-faqs/#i-am-unable-to-sign-in-to-the-myalcf-portal-what-do-i-do","title":"I am unable to sign in to the MyALCF portal. What do I do?","text":"<p>Only users with active ALCF accounts can sign in to the MyALCF user portal. If you have an active account, verify that you are using the correct ALCF username. Note that the username is case-sensitive. If you forgot your username, contact support@alcf.anl.gov. </p> <p>For passcode, this is your ALCF Cryptocard (PIN+passcode string displayed) or Mobilepass+ token (passcode from the app). For passcode token issues, please review the troubleshooting information on this page: Troubleshooting Tokens. </p> <p>If your account is inactive, please submit a reactivation request here.</p> <p>If you never had an ALCF account, please apply for one here. Note that all ALCF accounts must be associated with a project with an active allocation.</p>"},{"location":"account-project-management/accounts-and-access/accounts-and-access-faqs/#how-do-i-request-a-new-projectallocation","title":"How do I request a new project/allocation?","text":"<p>Please see Allocations on ALCF Systems</p>"},{"location":"account-project-management/accounts-and-access/accounts-and-access-faqs/#who-do-i-contact-if-my-discretionary-project-allocation-expires-or-if-i-need-to-request-additional-hours","title":"Who do I contact if my Discretionary Project Allocation expires or if I need to request additional hours?","text":"<p>To renew or request an extension or request additional hours for your existing compute allocations, please fill out the Allocation Request Form. </p> <p>For storage-allocation renewals/extensions/quota increases, email support@alcf.anl.gov with answers to the following: - What have you accomplished with your original allocation?   - Please include a brief description of any publications or major presentations that were (or will be) generated in full or in part because of this allocation. - What will you do with the extra time? - How much additional storage (in TB) do you need? - When should the allocation end?</p>"},{"location":"account-project-management/accounts-and-access/accounts-and-access-faqs/#how-do-i-join-a-project","title":"How do I join a project?","text":"<p>To join a project, please go to MyALCF &gt; Join Project), and login. Then search and scroll down to the project you want to join and click on the project name. At the bottom of the section, click on the \"Request Membership\" button. This sends a reques to the project PI and proxies. Once ALCF Support receives approval from the PI/proxy, we will provide you with access to the necessary resources.</p>"},{"location":"account-project-management/accounts-and-access/accounts-and-access-faqs/#how-do-i-request-a-reservation","title":"How do I request a reservation?","text":"<p>Reservation requests must include information detailed here: Machine Reservations: We will contact you after your request is reviewed by our scheduling committee and once a decision is made.</p>"},{"location":"account-project-management/accounts-and-access/accounts-and-access-faqs/#how-do-i-apply-for-a-new-account","title":"How do I apply for a new account?","text":"<p>Note</p> <p>All ALCF accounts must be associated with an allocated project.</p> <p>Submit an ALCF account requet by filling out this account request form. </p>"},{"location":"account-project-management/accounts-and-access/accounts-and-access-faqs/#what-do-i-do-when-my-alcf-account-expires","title":"What do I do when my ALCF account expires?","text":"<p>Please submit an account reactivation request if your account has expired here.</p>"},{"location":"account-project-management/accounts-and-access/accounts-and-access-faqs/#what-do-i-do-when-i-receive-a-warning-that-my-593-is-about-to-expire","title":"What do I do when I receive a warning that my 593 is about to expire?","text":"<p>If you need to extend your access, follow the instructions in the email to update your USCIS information. After updating your information, forward the email to the PI/proxy listed in the email so they can send their approval to the ALCF Support team. Once we receive the approval, we will process the 593 (Foreign Visit &amp; Assignment Request form) request.  In order to allow sufficient time for processing, it is recommended that your response be submitted as soon as possible. Processing time can range from a few days to a few weeks or months.</p> <p>If you are not planning to extend your account, respond to the email letting us know so that we may close out your records.</p>"},{"location":"account-project-management/accounts-and-access/logging-in-with-tokens/","title":"Logging In with a Token","text":"<p>Once you have obtained a token, you can use it to log in to ALCF systems. </p> <p>You can log in with a Mobile Token using your mobile device. </p> <p>You can log in with a Physical Token if you have received one in the mail.</p>"},{"location":"account-project-management/accounts-and-access/logging-in-with-tokens/#logging-in-to-an-alcf-system-using-a-mobile-token","title":"Logging in to an ALCF System using a Mobile Token","text":"<ol> <li> <p>Open the MobilePASS+ app on your device.     Then initiate an SSH session and type the following:</p> <pre><code>ssh &lt;ALCF username&gt;@&lt;system_name&gt;.alcf.anl.gov\n</code></pre> <p>For example, johnsmith@aurora.alcf.gov</p> </li> <li> <p>When prompted for a password, click the SafeNet MobilePASS+ app on your    phone.</p> <p>Click on the token name listed within the app and enter your PIN.</p> </li> <li> <p>The app will display your passcode immediately.</p> <p>Enter the passcode as the login password for the system within the SSH session.</p> <p>Note</p> <p>You do NOT have to enter the PIN on the SSH screen when logging into a resource. This only needs to be done to access the passcode within the SafeNet MobilePASS+ app.</p> </li> <li> <p>Each generated passcode is valid on the SafeNet MobilePass+ app window until    your mobile device screen times out.</p> </li> </ol>"},{"location":"account-project-management/accounts-and-access/logging-in-with-tokens/#logging-in-to-an-alcf-system-using-a-physical-token","title":"Logging in to an ALCF System using a Physical Token","text":"<p>When the physical token is activated, an initial PIN will be provided.</p> <p>Upon INITIAL login (to one of the ALCF machines), a prompt to change the PIN will appear.</p> <p>PINs must be at least four characters long and must only contain numbers.</p> <ol> <li> <p>Initiate an SSH session using:</p> <pre><code>ssh &lt;ALCF username&gt;@&lt;system_name&gt;.alcf.anl.gov\n</code></pre> </li> <li> <p>A password prompt will be received.    At this point, push the button on the physical token once.</p> </li> <li> <p>An eight-character, one-time password made up of letters and numbers will    appear on the token\u2019s display.    This one-time password is case-sensitive.</p> </li> <li> <p>Type your PIN followed immediately by the one-time password at the SSH    password prompt.</p> </li> </ol> <p>For example, if your PIN is 1234 and you received the one-time password    string ABCD9876, you would type 1234ABCD9876 at the password prompt.</p>"},{"location":"account-project-management/accounts-and-access/obtaining-a-token/","title":"How To Obtain a Token","text":"<p>Users need to acquire a token to log in to ALCF systems. Users can choose between a Mobile or a Physical token.</p> <p>Note: Please contact accounts@alcf.anl.gov to change your token preference.</p> <ul> <li> <p>Mobile Token: Mobile tokens utilize an app that is keyed to your user account   and for which you are responsible on your Android, iPhone, or Windows mobile   device.   Mobile tokens are a fast and easy way to get started quickly.</p> </li> <li> <p>Physical Token: A physical token is a device that will be mailed to you.   Once received, you will need to work with the ALCF support team to enable it.</p> </li> </ul>"},{"location":"account-project-management/accounts-and-access/obtaining-a-token/#mobile-token","title":"Mobile Token","text":"<p>The SafeNet MobilePass+ Mobile Token allows access to ALCF systems. This security mobile token uses one-time passwords combined with your PIN for controlled access to the login systems. The mobile token utilizes an app that is keyed to your user account. This app is maintained on your Android, iPhone, or Windows mobile device.</p> <p>Please safeguard your phone as you would your credit cards or house keys.</p> <p>Do not store your username, PIN, or other account-related records with the token. Sharing mobile tokens is strictly forbidden. A mobile token can be associated with a single device only.</p>"},{"location":"account-project-management/accounts-and-access/obtaining-a-token/#step-1-download-the-safenet-mobilepass-app-for-your-device","title":"Step 1: Download the SafeNet MobilePass+ app for your device","text":"<p>The SafeNet MobilePASS+ app turns your device into a two-factor authentication device, removing the need to carry an additional hardware token.</p> <p>As a SafeNet MobilePASS+ user, you can generate passcodes on your mobile device and use those passcodes to authenticate on ALCF computing resources. For more details, please see the SafeNet MobilePASS app information here.</p>"},{"location":"account-project-management/accounts-and-access/obtaining-a-token/#step-2-enroll-your-mobilepass-mobile-token","title":"Step 2: Enroll your MobilePass+ mobile token","text":"<p>After you've been provisioned a mobile token, you will receive a notification email with the subject line \"ALCF Mobile Token Self-Enrollment\".</p> <p>You must access the enrollment from the device on which you wish to install the token.</p> <p>Users have the choice between auto-enrolling or manually enrolling their MobilePass+ Token.</p>"},{"location":"account-project-management/accounts-and-access/obtaining-a-token/#auto-enrollment-to-enroll-safenet-mobilepass-token-automatically","title":"Auto-Enrollment (to enroll SafeNet MobilePass+ token automatically)","text":"<ol> <li>You will receive a link to enroll in your email.    Click on this link and the SafeNet Authentication Service Self-Enrollment    will open.</li> <li>Click enroll your SafeNet MobilePass+ token.</li> <li>When prompted to open in MobilePass+, tap Open.</li> <li>You will now be prompted to enter a 6-digit all-numeric PIN.</li> <li>Enter your PIN in the Token PIN field and repeat in the Confirm PIN field.</li> <li>You will be taken to the Enrollment Complete screen to name the token.</li> <li>Insert the desired name in the Token Name field or leave it as is.    This name is not utilized by the server; it is for you only.</li> <li>The newly enrolled SafeNet MobilePass+ token is now displayed in the SafeNet    MobilePass+ app.</li> </ol>"},{"location":"account-project-management/accounts-and-access/obtaining-a-token/#manual-enrollment","title":"Manual Enrollment","text":"<ol> <li>Copy the activation string from the SafeNet provision email.</li> <li>Open the SafeNet MobilePass+ app and tap the manual option.</li> <li>Paste the enrollment string into the field provided and tap the Enroll button.</li> <li>You will now be prompted to enter a 6-digit all-numeric PIN.</li> <li>Enter your PIN in the Token PIN field and repeat in the Confirm PIN field.</li> <li>You will be taken to the Enrollment Complete screen to name the token.</li> <li>Insert the desired name in the Token Name field or leave it as is.    This name is not utilized by the server; it is for you only.</li> </ol>"},{"location":"account-project-management/accounts-and-access/obtaining-a-token/#physical-token","title":"Physical Token","text":"<p>The physical token allows access to the ALCF systems.</p> <p>This security token uses one-time passwords combined with your PIN for controlled access to the login systems. The physical token is a tracked asset for which you are responsible and is keyed to your use.</p> <p>Please safeguard your token as you would your credit cards or house keys. Do not store username, PIN, or other account-related records with the token. Sharing of physical tokens is strictly forbidden. Please do not mark on the token or alter it in any way.</p>"},{"location":"account-project-management/accounts-and-access/obtaining-a-token/#activating-your-alcf-physical-token","title":"Activating Your ALCF Physical Token","text":"<p>You will receive your physical token in the mail. Upon receipt of the physical token, contact accounts@alcf.anl.gov to verify your identity and activate the token. If this step is not performed, you will not be able to use the passcode token to log on to the ALCF resource.</p> <ul> <li>ALCF Accounts Service Desk Info:</li> <li>Hours: Monday-Friday 9 a.m. - 5 p.m. Central Time</li> <li>Email: accounts@alcf.anl.gov</li> </ul>"},{"location":"account-project-management/accounts-and-access/obtaining-a-token/#returning-a-physical-token","title":"Returning a Physical Token","text":"<p>If you no longer need your physical token, please return it to this address:</p> <pre><code>ALCF Help Desk\nArgonne National Laboratory\n9700 S. Cass Ave.\nBldg. 240, Rm. 2129\nLemont, IL 60439\n</code></pre>"},{"location":"account-project-management/accounts-and-access/troubleshooting-tokens/","title":"Troubleshooting Tokens","text":"<p>This page offers guidance on common issues users have with their tokens. </p> <p>You can view the common issues and fixes for mobile tokens and for physical tokens below.</p> <p>If your issue is not on this page, please contact support@alcf.anl.gov.</p>"},{"location":"account-project-management/accounts-and-access/troubleshooting-tokens/#troubleshooting-your-mobile-token","title":"Troubleshooting your Mobile Token","text":"<ul> <li>Forgotten PIN: If you enter a PIN for your mobile token and you get an   invalid PIN, you will be asked to re-enter your PIN.   After 6 failed attempts, your token will be deleted.   If your token is deleted, call or send an email to ALCF support to have a new   mobile token provisioned.</li> <li>Account Lockout: If you fail to enter the correct password 6 times, you   will get a permission denied error on the SSH screen.   If you fail to enter the correct password 4 more times, your IP will be   blocked.   You will need to email (?) ALCF support and submit a ticket to have the   IP unblocked. <li>PIN Change: While logged in to the mobile token, click on token settings,   then tap change PIN.   Enter the current PIN followed by the new PIN and confirm.</li> <li>Re-Sync: If you are unable to log in to a resource after entering the   correct PIN and passcode, your token may be out of sync with the server.   Please email ALCF Service Desk at   accounts@alcf.anl.gov for assistance.</li> <li>New Mobile Device: If you have a new mobile device, please email the ALCF   Service Desk at accounts@alcf.anl.gov to have a   new mobile token provisioned.</li>"},{"location":"account-project-management/accounts-and-access/troubleshooting-tokens/#troubleshooting-your-physical-token","title":"Troubleshooting Your Physical Token","text":"<ul> <li>The token says \"locked\": The physical token may be locked due to too many   failed attempts.   Please contact the ALCF Help Desk to return the defective token so a   replacement can be sent.</li> <li>You forgot your PIN: Once a PIN has been set for your physical token, you   will need to prepend your PIN to the token password.   Otherwise, you will not be able to log in.   If you do not remember your PIN, please email us so we can verify your   identity and reset your initial PIN.</li> <li>The physical token does not say \"locked\" but still does not work: It is   likely that your token has fallen out of sync with the server.   If you have pushed the button on your physical token more than 10 times   without successfully logging in, it will fail to authenticate because it has   lost synchronization with the server.   Please try connecting to the system first. If it still fails, please follow   the re-sync instructions below.</li> </ul>"},{"location":"account-project-management/accounts-and-access/troubleshooting-tokens/#re-sync","title":"Re-Sync","text":"<p>If you have pushed the button on your physical token more than 10 times, it will fail to authenticate because it has lost synchronization with the server.</p> <p>You can re-synchronize your token using the following procedure:</p> <ol> <li>Have your physical token ready.</li> <li>Obtain a challenge sequence:</li> <li>Initiate an SSH session to a host that allows token authentication (such      as <code>polaris.alcf.anl.gov</code>).      At the password prompt, just hit \u201cEnter\u201d.      This will cause the physical token to produce a challenge string      consisting of 8 numbers.</li> <li>Hold down the button on your token for a few seconds until the display says    \"Init,\" then let go.</li> <li>The token will scroll through a series of menu options. When it displays    \"ReSync,\" hit the button again.</li> <li>The display will say \u201cResync?0\u201d</li> <li>The number at the end will start cycling from 0 to 9, over and over.</li> <li>Look at the numbers in your challenge string.    When the number displayed on your token changes to the first number of the    challenge string, press the button. The display will now show this number,    and the second digit will start cycling.</li> <li>Enter each of the numbers from your challenge string in the same manner,    until the display on your token matches the entire challenge string.    Choose the \"&lt;\" to backspace and re-enter the previous number if necessary.</li> <li>Once you've entered all 8 digits, re-check to make sure they're accurate.    Then, while all 8 digits are displayed on the token, press the button to    generate a new password.</li> <li>Enter your PIN followed by the new password, and hit 'Enter'.    If successful, you will be logged in to the resource. You're now back in    sync with the authentication server.</li> </ol> <p>If you are unsuccessful, you will be presented with another challenge string. At this point, you may need to perform the re-sync instructions again.</p> <p>Unsuccessful Re-Sync</p> <p>If there are still problems after completing the re-synchronization procedures, please email us at accounts@alcf.anl.gov so we can run a test on the physical token to determine if it is defective. If it is found to be defective, we will promptly replace it.</p>"},{"location":"account-project-management/accounts-and-access/troubleshooting-tokens/#resetting-the-physical-token-pin","title":"Resetting the Physical Token PIN","text":"<p>Please email us at accounts@alcf.anl.gov for PIN resets.</p> <p>Once your identity has been verified, we will provide you with a new PIN for your physical token.</p>"},{"location":"account-project-management/allocation-management/","title":"Allocations on ALCF Computing Resources","text":""},{"location":"account-project-management/allocation-management/#getting-an-allocation-award","title":"Getting an Allocation Award","text":""},{"location":"account-project-management/allocation-management/#incite-and-alcc","title":"INCITE and ALCC","text":"<p>Researchers gain access to ALCF systems for computational science and engineering projects\u2014typically with awards of millions of core-hours\u2014through competitive, peer-reviewed allocation programs supported by the DOE and Argonne. Our peer-reviewed award programs consist of the INCITE, and ALCC programs. More information about the programs, including dates for our CFPs, can be found on their web pages.</p>"},{"location":"account-project-management/allocation-management/#directors-discretionary","title":"Director's Discretionary","text":"<p>ALCF offers a Director's Discretionary allocation award program for leadership computing preparation, INCITE and ALCC scaling, and application performance to maximize scientific application efficiency and productivity on leadership computing platforms. See the Director's Discretionary (DD) Program page for more information.</p>"},{"location":"account-project-management/allocation-management/#nairr","title":"NAIRR","text":"<p>In the NAIRR Pilot program, the US National Science Foundation (NSF), the US Department of Energy (DOE), and numerous private and non-profit sector partners are providing an opportunity for the research community to request access to a set of computing, model, platform and educational resources for projects related to advancing AI research. See NAIRR for more information.</p>"},{"location":"account-project-management/allocation-management/#initializing-your-awarded-allocation","title":"Initializing Your Awarded Allocation","text":"<p>ALCF staff will directly contact INCITE and ALCC awardees with information on creating accounts.</p> <p>Director's Discretionary and NAIRR awardees will receive account creation information in their award confirmation email.</p>"},{"location":"account-project-management/allocation-management/#allocation-resources","title":"Allocation Resources","text":"<p>Depending on the allocation program, users can choose from some or all of the following resources when requesting an allocation:</p> <p>Compute:</p> <p>HPC Systems - Aurora - Polaris - Sophia - Crux</p> <p>AI Accelerators - Groq - Graphcore - SambaNova - Cerebras</p> <p>File Systems: - Eagle/Grand (computer storage) - Flare (Lustre file system)</p>"},{"location":"account-project-management/allocation-management/#policy-information-related-to-allocations","title":"Policy Information Related to Allocations","text":"<ul> <li>Pullback Policy</li> <li>Reports and Penalties</li> <li>Other Facility Policies</li> </ul>"},{"location":"account-project-management/allocation-management/#requesting-additional-allocation-hours","title":"Requesting Additional Allocation Hours","text":"<p>If you are a PI of a Director's Discretionary project that has an active allocation and you need additional hours, please see \u201cGetting More Time\u201d at Managing Your Allocations for more details.</p>"},{"location":"account-project-management/allocation-management/allocation-management/","title":"Managing Your Allocations","text":"<p>Allocations require management \u2013 balance checks, resource allocation, requesting more time, etc. Allocation information is available via the MyALCF user portal or through the command line interface. </p>"},{"location":"account-project-management/allocation-management/allocation-management/#active-allocations-on-myaclf","title":"Active Allocations on MyACLF","text":"<p>Select data for active allocations are shown on the dashboard of the MyALCF portal when signed into an ALCF user account. The dashboard section labeled \"Active Project Allocations\" provides an overview of activity with allocation start and end dates, allocation node hour usage, remaining node hours, usage trend data for future planning, and job sizes run. More detailed queries can be done using the sbank graphic interface in the sbank section of the MyALCF portal. Further information on how to use the sbank graphic interface is available in the MyALCF documentation.</p> <p></p> <p>An active project allocation on the dashboard provides an overview of allocation data.</p>"},{"location":"account-project-management/allocation-management/allocation-management/#active-allocations-through-command-line","title":"Active Allocations Through Command Line","text":"<p>To determine if there is an active allocation, check Job Submission.</p> <p>For information on how to run the query, look at our documentation on our sbank Allocations Accounting System or email support@alcf.anl.gov and ask for all active allocations.</p>"},{"location":"account-project-management/allocation-management/allocation-management/#using-sbank-to-determine-the-balance-of-an-allocation","title":"Using sbank to Determine the Balance of an Allocation","text":"<p>To determine which platforms have an active balance, check our allocation accounting system sbank.</p> <ul> <li>To obtain the allocation balance, check the <code>sbank</code> command sbank-list-allocations.</li> <li>DD projects with a negative balance will not be able to run jobs until they have requested additional time; see the \"Getting More Time\" subsection below.</li> <li>INCITE and ALCC PIs automatically receive an email summary of project usage. If this is a DD project, please email support@alcf.anl.gov.</li> </ul>"},{"location":"account-project-management/allocation-management/allocation-management/#allocation-expiration","title":"Allocation Expiration","text":"<p>Projects and allocations at the ALCF are different. A particular project might have multiple allocations of time. For example, a discretionary project that has been approved more than three times will have three allocations (two are probably expired) but just one project. Projects will not expire -- allocations will. If allocations are expired, or have no hours left, jobs will not be able to run. Consult the two above sections to determine active allocations.</p>"},{"location":"account-project-management/allocation-management/allocation-management/#getting-more-time","title":"Getting More Time","text":"<p>To request an extension of your existing discretionary allocation or to request additional hours, please complete an allocation renewal request here.</p> <p>To renew or extend storage allocations, email support@alcf.anl.gov with answers to the following information:</p> <ul> <li>What have you accomplished with your original allocation?</li> <li>Please include a brief description of any publications or major presentations that were (or will be) generated in full or in part because of this allocation.</li> <li>What will you do with the extra time?</li> <li>How much additional storage (in TB) do you need?</li> <li>When should the allocation end?</li> </ul>"},{"location":"account-project-management/allocation-management/allocation-management/#sub-allocations","title":"Sub-allocations","text":"<p>Tip</p> <p>See <code>sbank new suballocation -h</code> for all the options.</p> <p>Suballocations let PIs control who in their team can run jobs, how much they are allowed to consume (allocation amount), and when they are allowed to run jobs (start and end dates).</p> <p>Note</p> <p>Once submanagement is enabled for a project allocation, all job submissions must specify the suballocationID or the suballocationName. You can no longer submit jobs with just the project name.</p>"},{"location":"account-project-management/allocation-management/allocation-management/#step-1-create-suballocations-project-pi","title":"Step 1: Create Suballocations (Project PI):","text":"<p>PI creates suballocations </p> <pre><code>sbank new sub &lt;allocationid&gt; --name &lt;nameofsuballoc&gt;\n</code></pre>"},{"location":"account-project-management/allocation-management/allocation-management/#step-2-manage-suballocations-project-pi","title":"Step 2: Manage Suballocations (Project PI):","text":""},{"location":"account-project-management/allocation-management/allocation-management/#pi-adds-users-to-suballocations","title":"PI adds users to suballocations","text":"<pre><code>sbank e sub &lt;projectname&gt;::&lt;nameofsuballoc&gt; --add-user=\"&lt;username1&gt; &lt;username2&gt; ...\"\n</code></pre>"},{"location":"account-project-management/allocation-management/allocation-management/#pi-can-change-the-name-of-a-suballocation","title":"PI can change the name of a suballocation","text":"<pre><code>sbank e sub &lt;suballocationID&gt; --name=&lt;new_name_of_suballocation&gt;\n</code></pre> <p>By default, the primary suballocation (which is the default suballocation created when the allocation is created by ALCF) is unrestricted, i.e., enabled for all project members. That means all project members can submit jobs against the primary suballocation by default. All other suballocations are restricted by default, and users have to be added for each of them.</p>"},{"location":"account-project-management/allocation-management/allocation-management/#to-change-the-default-for-the-primary-suballocation-to-restrict-usage-pi-must-first-edit-the-suballocation","title":"To change the default for the primary suballocation to restrict usage, PI must first edit the suballocation:","text":"<pre><code>sbank-edit-suballocation --restrict &lt;primary suballocation id&gt;\n</code></pre>"},{"location":"account-project-management/allocation-management/allocation-management/#then-add-users-with-this-command","title":"Then add users with this command:","text":"<pre><code>sbank e sub &lt;primary suballocation id&gt; --add-user=\"&lt;username1&gt; &lt;username2&gt; ...\"\n</code></pre>"},{"location":"account-project-management/allocation-management/allocation-management/#pi-changes-start-and-end-dates-for-a-suballocation","title":"PI changes start and end dates for a suballocation:","text":"<pre><code>sbank e sub &lt;suballocationID&gt; -S &lt;start_date&gt; -E &lt;end_date&gt;\n</code></pre>"},{"location":"account-project-management/allocation-management/allocation-management/#pi-adds-hours-to-a-suballocation","title":"PI adds hours to a suballocation:","text":"<pre><code>sbank e sub &lt;projectname&gt;::&lt;nameOfSourceSuballoc&gt; --hours-to-move &lt;hours&gt; --to-suballocation &lt;projectname&gt;::&lt;nameOfDestSuballoc&gt;\n</code></pre> <p>Note</p> <p><code>hours</code> must be less than or equal to the available balance for the suballocation <code>nameOfSourceSuballoc</code>.</p> <p>Tip</p> <p>See <code>sbank e suballocation -h</code> for all the options.</p>"},{"location":"account-project-management/allocation-management/allocation-management/#step-3-submit-jobs-project-team","title":"Step 3: Submit Jobs (Project team):","text":"<p>Submit jobs to a suballocation. Note that the user should be on the suballocation\u2019s user list. Once submanagement is enabled for a project allocation, all job submissions must specify the <code>suballocationID</code> or the <code>suballocationName</code>.</p> <p>Example:</p> <p><pre><code># Specify suballocationID\nqsub -l select=10,walltime=30:00,filesystems=eagle:home -A &lt;suballocationID&gt; -q demand test.sh\n</code></pre> or</p> <pre><code># Specify suballocation name\nqsub -l select=10,walltime=30:00,filesystems=eagle:home -A &lt;projectname&gt;::&lt;suballocationName&gt; -q demand test.sh\n</code></pre>"},{"location":"account-project-management/allocation-management/allocation-management/#useful-commands","title":"Useful commands:","text":"<p>List all suballocations for a project that shows the number of jobs run, charges, allocation balance, suballocation name, and list of users:</p> <pre><code>sbank-list-allocations -r polaris -p &lt;projectname&gt; -f \"+subname users_list\"\n</code></pre> <p>Tip</p> <p>See <code>sbank l a -h</code> for all the options and <code>sbank \u2013f\\?</code> for a list of fields that can be displayed.</p>"},{"location":"account-project-management/allocation-management/sbank-allocation-accounting-system/","title":"sbank Allocation Accounting System","text":"<p>sbank is the accounting system used within the ALCF. It tracks project allocations, usage charges, and refunds. sbank allows queries about the balance and expiration of project allocations.</p> <p>The sbank accounting system helps users manage their allocations and usage per job. It gives PIs the ability to monitor their allocation usage by user, job, and machine. It also allows the user to monitor their usage per allocation and provides insight into how many hours are left on the project.</p>"},{"location":"account-project-management/allocation-management/sbank-allocation-accounting-system/#sbank-interface-options","title":"sbank Interface Options","text":"<p>sbank is available through a command line interface (see below for example commands and docs) or through a graphic interface in the MyALCF user portal further explained in MyALCF documentation. </p>"},{"location":"account-project-management/allocation-management/sbank-allocation-accounting-system/#getting-started-with-sbank-command-line","title":"Getting Started with sbank (Command Line)","text":"<p>To view examples of the most common sbank commands, please see sbank Example Commands.</p>"},{"location":"account-project-management/allocation-management/sbank-allocation-accounting-system/#sbank-man-pages","title":"sbank Man Pages","text":"<p>Use these sbank man pages to get information on how to use the commands.</p> <ul> <li>sbank</li> <li>sbank-detail</li> <li>sbank-detail-allocations</li> <li>sbank-detail-jobs</li> <li>sbank-detail-projects</li> <li>sbank-detail-transactions</li> <li>sbank-detail-users</li> <li>sbank-list</li> <li>sbank-list-allocations</li> <li>sbank-list-jobs</li> <li>sbank-list-projects</li> <li>sbank-list-transactions</li> <li>sbank-list-users</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/","title":"Manpage for sbank-detail-allocations","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#sbank-detail-allocations-options","title":"sbank-detail-allocations [options] [ ... ] <p>Detail allocation information.</p> <p>NOTE:  1. The list of <code>&lt;allocation id&gt;</code> arguments is optional. 2. You can also enter <code>&lt;allocation id&gt;</code> list by using the <code>-a</code> option multiple times. 3. Regardless, both are optional, and you can get detailed allocation info using the option filters below.</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#options","title":"OPTIONS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-version","title":"--version","text":"<p>Show the program's version number and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-h-help","title":"-h, --help","text":"<p>Show this help message and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>Filter on allocation id.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-e-event_id-event-idevent_id","title":"-e EVENT_ID, --event-id=EVENT_ID","text":"<p>Filter on event id.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p><code>FIELD_INFO</code> is <code>&lt;FIELD&gt;[:&lt;WIDTH&gt;]</code>. For available fields, enter <code>-f?</code> or <code>-f \"?\"</code>. To add fields, enter <code>-f \"+ &lt;FIELD&gt;[:&lt;WIDTH&gt;] ...\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-j-jobid-jobidjobid","title":"-j JOBID, --jobid=JOBID","text":"<p>Filter on jobid.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>Set the number of fields to display.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>Filter on name or id. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>Filter on name or id. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-t-transaction_id-transaction-idtransaction_id","title":"-t TRANSACTION_ID, --transaction-id=TRANSACTION_ID","text":"<p>Filter on transaction id.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>Filter on name or id. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width=","text":"<p><code>\"FIELD_INFO\"</code> is <code>&lt;FIELD&gt;:&lt;WIDTH&gt;</code>. For available fields, enter <code>-w?</code> or <code>-w \"?\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-e-end-endend","title":"-E END, --end=END","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:</p> <ul> <li><code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</li> </ul> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'ge' for single date entry.</li> <li><code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-h-human-readable","title":"-H, --human-readable","text":"<p>Abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions), ...</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-i-get-inactive","title":"-I, --get-inactive","text":"<p>Also get inactive allocations.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-o-get-only-inactive","title":"-O, --get-only-inactive","text":"<p>Only inactive allocations.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-s-start-startstart","title":"-S START, --start=START","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:</p> <ul> <li><code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</li> </ul> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'ge' for single date entry.</li> <li><code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-t-transaction_type-transaction-typetransaction_type","title":"-T TRANSACTION_TYPE, --transaction-type=TRANSACTION_TYPE","text":"<p>Transaction types: CHARGE, REFUND, PULLBACK, DEPOSIT, VOID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-award-type-nameaward_type_name","title":"--award-type-name=AWARD_TYPE_NAME","text":"<p>Filter on award type name.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-award-categoryaward_category","title":"--award-category=AWARD_CATEGORY","text":"<p>Filter on award category.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-cbank-refcbank_ref","title":"--cbank-ref=CBANK_REF","text":"<p>Filter on Clusterbank reference id.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-createdcreated_timestamp","title":"--created=CREATED_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:</p> <ul> <li><code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</li> </ul> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'ge' for single date entry.</li> <li><code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-get-deleted","title":"--get-deleted","text":"<p>Also get deleted objects.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-get-only-deleted","title":"--get-only-deleted","text":"<p>Only deleted objects.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-all-charges","title":"--all-charges","text":"<p>Only show list info that have charges regardless of project/user relationship.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-history-date-rangeend","title":"--history-date-range=END","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:</p> <ul> <li><code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</li> </ul> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'ge' for single date entry.</li> <li><code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-last-updatedlast_updated_timestamp","title":"--last-updated=LAST_UPDATED_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:</p> <ul> <li><code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</li> </ul> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'ge' for single date entry.</li> <li><code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-no-commas","title":"--no-commas","text":"<p>Remove commas from comma-separated thousands.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-no-header","title":"--no-header","text":"<p>Do not display the header.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-no-history","title":"--no-history","text":"<p>Do not show history information.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-no-rows","title":"--no-rows","text":"<p>Do not display the row data.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-no-sys-msg","title":"--no-sys-msg","text":"<p>Do not display system messages.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-allocations/#-no-totals","title":"--no-totals","text":"<p>Do not display the totals.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-jobs/","title":"sbank-detail-jobs","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-jobs/#sbank-detail-jobs-options","title":"sbank-detail-jobs [options] [  |  ...  | ] <p>Detail job information. NOTE: </p> <ol> <li>The arguments <code>&lt;jobid.resource&gt;</code> or <code>&lt;event_id&gt;</code> are NOT REQUIRED.  </li> <li><code>event_id</code> is the JOB DATABASE ID.  </li> <li><code>&lt;jobid&gt;</code> is the SCHEDULER CREATED ID, such as Cobalt.  </li> <li><code>&lt;jobid&gt;</code> can also be entered using the option <code>-j &lt;jobid&gt;</code>.  </li> <li><code>&lt;event_id&gt;</code> can also be entered using the option <code>-e &lt;event_id&gt;</code>.  </li> <li><code>&lt;resource&gt;</code> can also be entered using the option <code>-r &lt;resource&gt;</code>.  </li> <li>Regardless, you can use options or arguments to get detailed job information.</li> </ol>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-jobs/#options","title":"OPTIONS","text":"<p>--version</p> <p>Show the program's version number and exit.</p> <p>-h, --help</p> <p>Show this help message and exit.</p> <p>-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID</p> <p>Filter on allocation ID.</p> <p>-e EVENT_ID, --event-id=EVENT_ID</p> <p>Filter on event ID.</p> <p>-f FIELD_INFO, --field-to-display=FIELD_INFO</p> <p>FIELD_INFO is <code>&lt;FIELD&gt;[:&lt;WIDTH&gt;]</code>. For available fields, enter <code>-f?</code> or <code>-f \"?\"</code>. To add fields, enter <code>-f \"+ &lt;FIELD&gt;[:&lt;WIDTH&gt;] ...\"</code>.</p> <p>-j JOBID, --jobid=JOBID</p> <p>Filter on job ID.</p> <p>-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY</p> <p>Set the number of fields to display.</p> <p>-p PROJECT, --project=PROJECT</p> <p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p> <p>-r RESOURCE, --resource=RESOURCE</p> <p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p> <p>-t TRANSACTION_ID, --transaction-id=TRANSACTION_ID</p> <p>Filter on transaction ID.</p> <p>-u USER, --user=USER</p> <p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p> <p>-w \"FIELD_INFO\", --field-width</p> <p>\"FIELD_INFO\" is <code>&lt;FIELD&gt;:&lt;WIDTH&gt;</code>. For available fields, enter <code>-w?</code> or <code>-w \"?\"</code>.</p> <p>-E END, --end=END</p> <p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators OPER1 and OPER2 can be one of the following: <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. Operator Defaults: OPER1 is 'lt' for a single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</p> <p>-H, --human-readable</p> <p>Abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p> <p>-S START, --start=START</p> <p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators OPER1 and OPER2 can be one of the following: <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. Operator Defaults: OPER1 is 'ge' for a single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</p> <p>-T TRANSACTION_TYPE, --transaction-type=TRANSACTION_TYPE</p> <p>Transaction types: CHARGE, REFUND, PULLBACK, DEPOSIT, VOID.</p> <p>--created=CREATED_TIMESTAMP</p> <p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators OPER1 and OPER2 can be one of the following: <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. Operator Defaults: OPER1 is 'ge' for a single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</p> <p>--debug=DEBUG_LEVEL</p> <p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2.</p> <p>--eligible=ELIGIBLE_TIMESTAMP</p> <p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators OPER1 and OPER2 can be one of the following: <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. Operator Defaults: OPER1 is 'ge' for a single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</p> <p>--get-not-charged</p> <p>Only un-charged jobs.</p> <p>--history-date-range=END</p> <p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators OPER1 and OPER2 can be one of the following: <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. Operator Defaults: OPER1 is 'ge' for a single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</p> <p>--last-updated=LAST_UPDATED_TIMESTAMP</p> <p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators OPER1 and OPER2 can be one of the following: <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. Operator Defaults: OPER1 is 'gt' for a single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</p> <p>--no-commas</p> <p>Remove commas from comma-separated thousands.</p> <p>--no-header</p> <p>Do not display the header.</p> <p>--no-history</p> <p>Do not show history information.</p> <p>--no-rows</p> <p>Do not display the row data.</p> <p>--no-sys-msg</p> <p>Do not display system messages.</p> <p>--no-totals</p> <p>Do not display the totals.</p> <p>--queued=QUEUED_TIMESTAMP</p> <p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators OPER1 and OPER2 can be one of the following: <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. Operator Defaults: OPER1 is 'ge' for a single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. Date Parsing Precedence: YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/","title":"Manpage for sbank-detail-projects","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#sbank-detail-projects-options","title":"sbank-detail-projects [options] [ ... ] <p>Detail project information. </p> <p>NOTE:    1. The list of  arguments are optional   2. you can also enter  list by using the -p option multiple times   3. regardless, both are optional, and you can get detail project info using the option filters below","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#options","title":"OPTIONS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-version","title":"--version","text":"<p>show program's version number and exit</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-h-help","title":"-h, --help","text":"<p>show this help message and exit</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>filter on allocation id</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p>FIELD_INFO is [:], for available fields enter -f? or -f \"?\", to add fields enter -f \"+ [:] ...\""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>set number of fields to display</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>filter on name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed but only on names</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p>\"FIELD_INFO\" FIELD_INFO is :, for available fields enter -w? or -w \"?\""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-e-end-endend","title":"-E END, --end=END","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults: </p> <ul> <li>OPER1 is 'lt' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence:    - YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-h-human-readable","title":"-H, --human-readable","text":"<p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-i-get-inactive","title":"-I, --get-inactive","text":"<p>get inactive allocations</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-s-start-startstart","title":"-S START, --start=START","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following:  <ul> <li>ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. </li> </ul> <p>Operator Defaults:</p> <ul> <li>OPER1 is 'ge' for single date entry, OPER1 and OPER2 are 'ge' and 'lt', respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-all-charges","title":"--all-charges","text":"<p>only show list info that have charges regardless of project/user relationship</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-no-commas","title":"--no-commas","text":"<p>remove commas from comma separated thousands</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-no-header","title":"--no-header","text":"<p>do not display the header</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-no-rows","title":"--no-rows","text":"<p>do not display the row data</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-no-sys-msg","title":"--no-sys-msg","text":"<p>do not display system message</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-projects/#-no-totals","title":"--no-totals","text":"<p>do not display the totals</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/","title":"Manpage for sbank-detail-transactions","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#sbank-detail-transactions-options","title":"sbank-detail-transactions [options] [ ... ] <p>Detail transaction information.</p>  <p>Note</p> <ol> <li>The list of <code>&lt;transaction id&gt;</code> arguments is optional.</li> <li>You can also enter the <code>&lt;transaction id&gt;</code> list by using the <code>-t</code> option multiple times.</li> <li>Regardless, both are optional, and you can get detailed transaction info using the option filters below.</li> </ol>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#options","title":"OPTIONS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-version","title":"--version","text":"<p>Show the program's version number and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-h-help","title":"-h, --help","text":"<p>Show this help message and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>Filter on allocation id.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-c-comment","title":"-c, --comment","text":"<p>Display comment.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-e-event_id-event-idevent_id","title":"-e EVENT_ID, --event-id=EVENT_ID","text":"<p>Filter on event id.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p><code>FIELD_INFO</code> is <code>&lt;FIELD&gt;[:&lt;WIDTH&gt;]</code>. For available fields, enter <code>-f?</code> or <code>-f \"?\"</code>. To add fields, enter <code>-f \"+ &lt;FIELD&gt;[:&lt;WIDTH&gt;] ...\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-j-jobid-jobidjobid","title":"-j JOBID, --jobid=JOBID","text":"<p>Filter on jobid.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>Set the number of fields to display.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>Filter on name or id. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>Filter on name or id. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-t-transaction_id-transaction-idtransaction_id","title":"-t TRANSACTION_ID, --transaction-id=TRANSACTION_ID","text":"<p>Filter on transaction id.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>Filter on name or id. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width=","text":"<p><code>\"FIELD_INFO\"</code> is <code>&lt;FIELD&gt;:&lt;WIDTH&gt;</code>. For available fields, enter <code>-w?</code> or <code>-w \"?\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-e-job_end-endjob_end","title":"-E JOB_END, --end=JOB_END","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:</p> <ul> <li><code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</li> </ul> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'ge' for a single date entry.</li> <li><code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-h-human-readable","title":"-H, --human-readable","text":"<p>Abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-s-job_start-startjob_start","title":"-S JOB_START, --start=JOB_START","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:</p> <ul> <li><code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</li> </ul> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'ge' for a single date entry.</li> <li><code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-t-transaction_type-transaction-typetransaction_type","title":"-T TRANSACTION_TYPE, --transaction-type=TRANSACTION_TYPE","text":"<p>Transaction types: CHARGE, REFUND, PULLBACK, DEPOSIT, VOID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-attransaction_at_timestamp","title":"--at=TRANSACTION_AT_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:</p> <ul> <li><code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</li> </ul> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'ge' for a single date entry.</li> <li><code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-cbank-refcbank_ref","title":"--cbank-ref=CBANK_REF","text":"<p>Filter on Clusterbank reference id.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-createdjob_created_timestamp","title":"--created=JOB_CREATED_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:</p> <ul> <li><code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</li> </ul> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'ge' for a single date entry.</li> <li><code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-no-commas","title":"--no-commas","text":"<p>Remove commas from comma-separated thousands.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-no-header","title":"--no-header","text":"<p>Do not display the header.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-no-rows","title":"--no-rows","text":"<p>Do not display the row data.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-no-sys-msg","title":"--no-sys-msg","text":"<p>Do not display system messages.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-no-totals","title":"--no-totals","text":"<p>Do not display the totals.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-transactions/#-queuedjob_queued_timestamp","title":"--queued=JOB_QUEUED_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:</p> <ul> <li><code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</li> </ul> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'ge' for a single date entry.</li> <li><code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/","title":"Manpage for sbank-detail-users","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#sbank-detail-users-options","title":"sbank-detail-users [options] [ ... ] <p>Detail user information.</p>  <p>Note</p> <ol> <li>Use <code>-I</code> to include inactive allocations.</li> <li>The list of <code>&lt;user&gt;</code> arguments is optional.</li> <li>You can also enter the <code>&lt;user&gt;</code> list by using the <code>-u</code> option multiple times.</li> <li>Regardless, both are optional, and you can get detailed user info using the option filters below.</li> </ol>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#options","title":"OPTIONS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-version","title":"--version","text":"<p>Show the program's version number and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-h-help","title":"-h, --help","text":"<p>Show this help message and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>Filter on allocation ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p><code>FIELD_INFO</code> is <code>&lt;FIELD&gt;[:&lt;WIDTH&gt;]</code>. For available fields, enter <code>-f?</code> or <code>-f \"?\"</code>. To add fields, enter <code>-f \"+ &lt;FIELD&gt;[:&lt;WIDTH&gt;] ...\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>Set the number of fields to display.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p><code>\"FIELD_INFO\"</code> is <code>&lt;FIELD&gt;:&lt;WIDTH&gt;</code>. For available fields, enter <code>-w?</code> or <code>-w \"?\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-e-end-endend","title":"-E END, --end=END","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following: - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</p> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-h-human-readable","title":"-H, --human-readable","text":"<p>Abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-i-get-inactive","title":"-I, --get-inactive","text":"<p>Get inactive allocations.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-s-start-startstart","title":"-S START, --start=START","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following: - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</p> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p><code>SILENT</code>, <code>MUCH_LESS</code>, <code>LESS</code>, <code>MORE</code>, <code>VERBOSE</code>, <code>DEBUG</code>, <code>DEBUG1</code>, <code>DEBUG2</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-all-charges","title":"--all-charges","text":"<p>Only show list info that has charges regardless of project/user relationship.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-no-commas","title":"--no-commas","text":"<p>Remove commas from comma-separated thousands.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-no-header","title":"--no-header","text":"<p>Do not display the header.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-no-rows","title":"--no-rows","text":"<p>Do not display the row data.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-no-sys-msg","title":"--no-sys-msg","text":"<p>Do not display system messages.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail-users/#-no-totals","title":"--no-totals","text":"<p>Do not display the totals.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/","title":"Manpage for sbank-detail","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#sbank-detail-options","title":"sbank-detail  [options] <p>Detail Meta Command</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#commands","title":"COMMANDS","text":"<ul> <li>allocations [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-I|-O|-S|-T|...] (DEFAULT) </li> <li>categories [-f|-n|-w|...] </li> <li>messages [-f|-n|-w|...] </li> <li>names [-f|-n|-w|...] </li> <li>jobs [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...] </li> <li>projects [-a|-f|-n|-p|-r|-u|-w|-E|-H|-I|-S|...] </li> <li>transactions [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...] </li> <li>users [-a|-f|-n|-p|-r|-u|-w|-E|-H|-S|...]</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#options","title":"OPTIONS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-a-allocation","title":"-a --allocation","text":"<p>Enter allocation ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-c-comment","title":"-c --comment","text":"<p>Enter a comment for new or edit commands, display comment for list commands.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-e-event-id","title":"-e --event-id","text":"<p>Enter event DB ID; event DB ID is an internal ID created by the charging system.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-f-field","title":"-f --field","text":"<p>Enter [:], width is optional; enter -f? or -f \"?\" for available fields, + to add fields."},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-h-help","title":"-h --help","text":"<p>Command line help.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-j-jobid","title":"-j --jobid","text":"<p>Enter job ID; job ID is created by the scheduler and is not unique.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-n-num-field","title":"-n --num-field","text":"<p>Enter the number of fields to display.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-p-project","title":"-p --project","text":"<p>Enter name or ID, DO NOT MIX, enter 'all' to get all, wildcards '*' are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-r-resource","title":"-r --resource","text":"<p>Enter name or ID, DO NOT MIX, enter 'all' to get all, wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-s-suballocation","title":"-s --suballocation","text":"<p>Enter suballocation ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-t-transaction","title":"-t --transaction","text":"<p>Enter transaction ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-u-user","title":"-u --user","text":"<p>Enter name or ID, DO NOT MIX, enter 'all' to get all, wildcards '*' are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-w-field-width","title":"-w --field-width","text":"<p>Enter the field width as follows: :, enter -w? or -w \"?\" for available fields."},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-e-end","title":"-E --end","text":"<p>Enter end datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-h-human-readable","title":"-H --human-readable","text":"<p>Abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions), etc.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-i-get-inactive","title":"-I --get-inactive","text":"<p>Include inactive allocations.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-o-get-only-inactive","title":"-O --get-only-inactive","text":"<p>Get only inactive allocations.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-s-start","title":"-S --start","text":"<p>Enter start datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-t-type","title":"-T --Type","text":"<p>Enter type of transaction.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-all-charges","title":"--all-charges","text":"<p>For list allocations | projects | users, only show info with charges.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-at","title":"--at","text":"<p>Enter transaction created datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-award-category","title":"--award-category","text":"<p>Enter allocation award category.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-award-type-name","title":"--award-type-name","text":"<p>Enter allocation award-type name.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-created","title":"--created","text":"<p>Enter created datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-debug","title":"--debug","text":"<p>Enter debug level.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-get-deleted","title":"--get-deleted","text":"<p>Get deleted objects.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-get-not-charged","title":"--get-not-charged","text":"<p>Get jobs that have not been charged.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-get-only-deleted","title":"--get-only-deleted","text":"<p>Get only deleted objects.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-history-date-range","title":"--history-date-range","text":"<p>Enter history datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-last-updated","title":"--last-updated","text":"<p>Enter last updated datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-no-commas","title":"--no-commas","text":"<p>Remove commas from comma-separated thousands.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-no-header","title":"--no-header","text":"<p>Do not display header.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-no-history","title":"--no-history","text":"<p>Do not display history information.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-no-rows","title":"--no-rows","text":"<p>Do not display rows.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-no-sys-msg","title":"--no-sys-msg","text":"<p>Do not display system message.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-no-totals","title":"--no-totals","text":"<p>Do not display totals.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-detail/#-queued","title":"--queued","text":"<p>Enter queued datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/","title":"sbank Example Commands","text":"<p>Below is a set of helpful commands to help you better manage the projects you have running at the ALCF.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#view-your-projects-allocations","title":"View your project's allocations","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#command-sbank-list-allocations","title":"Command: sbank-list-allocations","text":"<p>Use this command to list all of your active allocations for a specific project [Project-X]. This is useful when you need to provide this information in a report.</p> <pre><code>&gt; sbank-list-allocations -p ProjectX -r all\n Id         Start       End         Resource   Project          Jobs        Charged          Available Balance \n ---------  ----------  ----------  ---------  ---------------  ----------  ---------------  ----------------- \n 2106       2016-01-04  2017-01-01  cooley     ProjectX              1,139          6,032.8           43,967.2 \n 2146       2016-01-14  2017-01-10  theta      ProjectX                983      1,084,770.3       25,483,927.5\n 6438       2020-09-22  2022-01-01  thetagpu   ProjectX                  3              0.0            2,000.0 \n\nTotals:\n  Rows: 3\n  Cooley:\n    Available Balance: 43,967.2 node hours\n    Charged          : 6,032.8 node hours\n    Jobs             : 1,139 \n Theta:\n    Available Balance: 25,483,927.5 node hours \n    Charged          : 1,084,770.3 node hours \n    Jobs             : 983 \n Thetagpu:\n    Available Balance: 2,000.0 node hours\n    Charged          : 0.0 node hours\n    Jobs             : 3 \n</code></pre>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#list-your-projects-quota-on-eagle-file-system","title":"List your project's quota on Eagle File system","text":"<pre><code>&gt; sbank-list-allocations -p ProjectX -r eagle\n Allocation  Suballocation  Start       End         Resource  Project      Quota\n ----------  -------------  ----------  ----------  --------  -----------  -----\n 6687        6555           2020-12-16  2022-01-01  eagle     ProjectX    1.0\n\nTotals:\n  Rows: 1\n   Eagle: \n    Quota: 1.0 TB\n\n&gt; sbank-list-allocations -p ProjectX -r eagle\n Allocation  Suballocation  Start       End         Resource  Project      Quota\n ----------  -------------  ----------  ----------  --------  -----------  -----\n 6688        6556           2020-12-16  2022-01-01  eagle     ProjectX    1.0\n\nTotals:\n  Rows: 1\n  Eagle:\n    Quota: 1.0 TB\n</code></pre>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#list-only-the-created-timestamp-field-for-all-allocations-that-were-created-before-01-01-2015-for-projectx-across-all-resources","title":"List only the created timestamp field for all allocations that were created before 01-01-2015 for ProjectX across all resources","text":"<pre><code>&gt; sbank-list-allocations  --created \"&lt;20150101\" -r all -p ProjectX \"-f created\"\n Created    \n ---------- \n 2016-01-04 \n 2016-01-14 \n 2016-01-15 \n\nTotals:\n  Rows: 3\nDate filters (UTC): created &lt; \"2015-01-01 00:00:00\",  \n</code></pre>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#list-all-active-allocations-for-all-resources-for-project-projectx-and-add-the-field-created-to-the-display-list","title":"List all active allocations for all resources for project ProjectX and add the field Created to the display list","text":"<pre><code>shrubbery~ &gt; sbank-list-allocations -r all  -p ProjectX -f \"+created\"\n Id         Start       End         Resource   Project          Jobs        Charged          Available Balance  Created    \n ---------  ----------  ----------  ---------  ---------------  ----------  ---------------  -----------------  ---------- \n 279        2011-08-30  2020-01-01  theta      ProjectX              6,361     12,332,699.9      -12,332,699.9  2013-02-22 \n 2106       2016-01-04  2017-01-01  cooley     ProjectX              1,150          6,080.9           43,919.1  2016-01-04  \n\nTotals:\n  Rows: 2\n  Theta:\n    Available Balance: -12,332,699.9 node hours\n    Charged          : 12,332,699.9 node hours\n    Jobs             : 6,361 \n  Cooley:\n    Available Balance: 43,919.1 node hours\n    Charged          : 6,080.9 node hours\n    Jobs             : 1,150 \n</code></pre>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#list-all-available-fields-for-the-sbank-list-allocations-command","title":"List all available fields for the sbank-list-allocations command","text":"<pre><code>&gt; sbank-list-allocations  -f \"?\"\navailable fields:\n id\n start_timestamp\n end_timestamp\n resource\n project_name\n jobs_count\n charged_sum\n available_balance_sum\n created_timestamp\n award_category\n award_type_name\n admin_name\n cbank_ref\n comment\n</code></pre>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#view-your-projects-users","title":"View your project's users","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#command-sbank-list-users","title":"Command: sbank-list-users","text":"<p>List all charges for userx on theta on project ProjectX</p> <pre><code>&gt; sbank-list-users -p ProjectX -r theta -u userx\n User             Jobs        Charged         \n ---------------  ----------  --------------- \n userx                 1,814          9,884.5\n\nTotals:\n  Rows: 1\n  Resources: theta\n  Charged: 9,884.5 node hours\n  Jobs   : 1,814 \n</code></pre>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#list-charges-for-all-users-in-projectx-on-cooley","title":"List charges for all users in ProjectX on Cooley.","text":"<p>This works for project leads (i.e., PIs, Co-PIs, Proxies), since they can see everything in their own projects.</p> <pre><code>&gt; sbank-list-users -p ProjectX -r theta\n User             Jobs        Charged         \n ---------------  ----------  --------------- \n user1                   120          4,243.7 \n user2                     0              0.0 \n user3                     0              0.0 \n user4                   181          1,195.5 \n user5                     0              0.0 \n user6                 2,560         10,868.7 \n user7                     0              0.0 \n user8                     0              0.0 \n user9                     0              0.0 \n user10                    7              3.5 \n user11                    0              0.0 \n\nTotals:\n  Rows: 11\n  Resources: theta\n  Charged: 16,311.4 node hours\n  Jobs   : 2,868 \n</code></pre>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#view-your-projects-jobs","title":"View your project's jobs","text":"<p>List jobs for user \"userx\" for jobs that started in the range 2016-02-15 &lt;= started &lt; 2016-02-29 and add the transactions related to the job</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#command-sbank-list-jobs","title":"Command: sbank-list-jobs","text":"<p>Note: The job with the refund <code>transaction_ids_list</code> field can be shortened all the way to \"t\" in the <code>-f \"+ t\"</code></p> <pre><code>shrubbery~ &gt; sbank-list-jobs -u userx -f \"+ t\" -S \"2016-02-15...2016-02-29\"\n Id         Jobid      Resource   Project          Allocation  User       Duration   Charged          Transaction Ids \n ---------  ---------  ---------  ---------------  ----------  ---------  ---------  ---------------  --------------- \n 1013857    730417     theta       ProjectX         1740        userx      1:53:07           61,776.8  CHARGE-1011230  \n 1013860    730558     theta       ProjectX         1740        userx      1:53:07           61,776.8  CHARGE-1011233  \n 1014168    730668     theta       ProjectX         1740        userx      1:53:25           61,940.6  CHARGE-1011541  \n\nTotals:\n  Rows: 3\n  Theta:\n    Charged      : 185,494.2 node hours\n    Duration     : 6:44:00 \nDate filters (UTC): \"2016-02-15 00:00:00\" &lt;= start &lt; \"2016-02-29 00:00:00\",\n</code></pre>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#list-the-nodes-used-runtime-and-start-timestamp-for-cooley-job-744160","title":"List the nodes used, runtime, and start timestamp for Cooley job 744160","text":"<p>Note: To display the date and time, we increased the number of characters of start_timestamp to 19</p> <pre><code>catapult~ &gt; sbank l j -r theta -j 50576 -f \"jobid nodes_used runtime start_timestamp:19\"\n Jobid Nodes Used Runtime Start \n --------- ---------- --------- ------------------- \n 50576 512 1:00:49 2013-01-16 21:49:30 \n\nTotals: \n Rows: 1\n</code></pre>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#view-your-projects-transactions","title":"View your project's transactions","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-examples/#command-sbank-list-transactions","title":"Command: sbank-list-transactions","text":"<p>List of transactions that were at or after 2016-02-29 for ProjectX add fields: job_duration, nodes_used, and hosts</p> <p>Note:  - job_duration, nodes_used, and hosts are shortened, but they are still uniquely identified - host has the left justified width of 20, specified as \"h:-20\"</p> <pre><code>catapult~ &gt; sbank-list-transactions -p ProjectX --at \"ge 2016-02-29\" -f \"+ job_d nodes_u h:-20\" -r theta\n Id         Resource   Project          Allocation  At          User             Transaction Type  Amount           Jobid      Job Duration  Nodes Used  Hosts                \n ---------  ---------  ---------------  ----------  ----------  ---------------  ----------------  ---------------  ---------  ------------  ----------  -------------------- \n 1025426    theta       ProjectX         2147        2016-02-29  userx            CHARGE                   48,005.1  740587     1:27:54       2048        MIR-00800-33BF1-2048 \n 1028046    theta       ProjectX         2147        2016-03-01  userx            CHARGE                  147,647.1  742090     4:30:21       2048        MIR-40000-733F1-2048 \n 1028755    theta       ProjectX         2147        2016-03-02  userx            CHARGE                1,576,068.0  742126     6:00:44       16384       MIR-04000-77FF1-1638 \n\nTotals:\n  Rows: 3\n  Theta:\n    Charges Amount: 1,771,720.2 node hours\n    Job Duration  : 11:58:98 \nDate filters (UTC) : at &gt;= \"2016-02-29 00:00:00\",  \n</code></pre>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/","title":"Manpage for sbank-list-allocations","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#sbank-list-allocations-options","title":"sbank-list-allocations [options]","text":"<p>Generate allocation list report.</p> <p>Notes:  1. Use <code>-I</code> to include inactive allocations. 2. Enter <code>-r all</code> to get information for all resources.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#options","title":"OPTIONS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-version","title":"--version","text":"<p>Show program's version number and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-h-help","title":"-h, --help","text":"<p>Show this help message and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>Filter on allocation ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-c-comment","title":"-c, --comment","text":"<p>Display comment.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-e-event_id-event-idevent_id","title":"-e EVENT_ID, --event-id=EVENT_ID","text":"<p>Filter on event ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p><code>FIELD_INFO</code> is <code>&lt;FIELD&gt;[:&lt;WIDTH&gt;]</code>. For available fields, enter <code>-f?</code> or <code>-f \"?\"</code>. To add fields, enter <code>-f \"+ &lt;FIELD&gt;[:&lt;WIDTH&gt;] ...\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-j-jobid-jobidjobid","title":"-j JOBID, --jobid=JOBID","text":"<p>Filter on job ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>Set number of fields to display.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>Filter on name or ID. DO NOT MIX. Enter <code>all</code> to get all. Wildcards <code>*</code> are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>Filter on name or ID. DO NOT MIX. Enter <code>all</code> to get all. Wildcards <code>*</code> are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-t-transaction_id-transaction-idtransaction_id","title":"-t TRANSACTION_ID, --transaction-id=TRANSACTION_ID","text":"<p>Filter on transaction ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>Filter on name or ID. DO NOT MIX. Enter <code>all</code> to get all. Wildcards <code>*</code> are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p><code>FIELD_INFO</code> is <code>&lt;FIELD&gt;:&lt;WIDTH&gt;</code>. For available fields, enter <code>-w?</code> or <code>-w \"?\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-e-end-endend","title":"-E END, --end=END","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators OPER1 and OPER2 can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li>OPER1 is <code>lt</code> for single date entry. OPER1 and OPER2 are <code>ge</code> and <code>lt</code>, respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-h-human-readable","title":"-H, --human-readable","text":"<p>Abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-i-get-inactive","title":"-I, --get-inactive","text":"<p>Get inactive allocations.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-o-get-only-inactive","title":"-O, --get-only-inactive","text":"<p>Only inactive allocations.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-s-start-startstart","title":"-S START, --start=START","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators OPER1 and OPER2 can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li>OPER1 is <code>lt</code> for single date entry. OPER1 and OPER2 are <code>ge</code> and <code>lt</code>, respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-t-transaction_type-transaction-typetransaction_type","title":"-T TRANSACTION_TYPE, --transaction-type=TRANSACTION_TYPE","text":"<p>Transaction types: CHARGE, REFUND, PULLBACK, DEPOSIT, VOID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-award-type-nameaward_type_name","title":"--award-type-name=AWARD_TYPE_NAME","text":"<p>Filter on award-type name.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-award-categoryaward_category","title":"--award-category=AWARD_CATEGORY","text":"<p>Filter on award category.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-cbank-refcbank_ref","title":"--cbank-ref=CBANK_REF","text":"<p>Filter on Clusterbank reference ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-createdcreated_timestamp","title":"--created=CREATED_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators OPER1 and OPER2 can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li>OPER1 is <code>lt</code> for single date entry. OPER1 and OPER2 are <code>ge</code> and <code>lt</code>, respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-get-deleted","title":"--get-deleted","text":"<p>Get deleted objects.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-get-only-deleted","title":"--get-only-deleted","text":"<p>Get only deleted objects.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-all-charges","title":"--all-charges","text":"<p>Only show list info that have charges regardless of project/user relationship.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-last-updatedlast_updated_timestamp","title":"--last-updated=LAST_UPDATED_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators OPER1 and OPER2 can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li>OPER1 is <code>lt</code> for single date entry. OPER1 and OPER2 are <code>ge</code> and <code>lt</code>, respectively, for range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-no-commas","title":"--no-commas","text":"<p>Remove commas from comma-separated thousands.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-no-header","title":"--no-header","text":"<p>Do not display the header.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-no-rows","title":"--no-rows","text":"<p>Do not display the row data.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-no-sys-msg","title":"--no-sys-msg","text":"<p>Do not display system message.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-allocations/#-no-totals","title":"--no-totals","text":"<p>Do not display the totals.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/","title":"Manpage for sbank-list-jobs","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#sbank-list-jobs-options","title":"sbank-list-jobs [options]","text":"<p>Generate job list report. Note: To get information for all resources, enter \"-r all\".</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#options","title":"OPTIONS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-version","title":"--version","text":"<p>Show the program's version number and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-h-help","title":"-h, --help","text":"<p>Show this help message and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>Filter on allocation ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-e-event_id-event-idevent_id","title":"-e EVENT_ID, --event-id=EVENT_ID","text":"<p>Filter on event ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p><code>FIELD_INFO</code> is <code>&lt;FIELD&gt;[:&lt;WIDTH&gt;]</code>. For available fields, enter <code>-f?</code> or <code>-f \"?\"</code>. To add fields, enter <code>-f \"+ &lt;FIELD&gt;[:&lt;WIDTH&gt;] ...\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-j-jobid-jobidjobid","title":"-j JOBID, --jobid=JOBID","text":"<p>Filter on job ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>Set the number of fields to display.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-t-transaction_id-transaction-idtransaction_id","title":"-t TRANSACTION_ID, --transaction-id=TRANSACTION_ID","text":"<p>Filter on transaction ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p><code>\"FIELD_INFO\"</code> is <code>&lt;FIELD&gt;:&lt;WIDTH&gt;</code>. For available fields, enter <code>-w?</code> or <code>-w \"?\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-e-end-endend","title":"-E END, --end=END","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-h-human-readable","title":"-H, --human-readable","text":"<p>Abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions), etc.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-s-start-startstart","title":"-S START, --start=START","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-t-transaction_type-transaction-typetransaction_type","title":"-T TRANSACTION_TYPE, --transaction-type=TRANSACTION_TYPE","text":"<p>Transaction types: CHARGE, REFUND, PULLBACK, DEPOSIT, VOID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-createdcreated_timestamp","title":"--created=CREATED_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-eligibleeligible_timestamp","title":"--eligible=ELIGIBLE_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-get-not-charged","title":"--get-not-charged","text":"<p>Get only jobs that have not been charged.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-last-updatedlast_updated_timestamp","title":"--last-updated=LAST_UPDATED_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-no-commas","title":"--no-commas","text":"<p>Remove commas from comma-separated thousands.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-no-header","title":"--no-header","text":"<p>Do not display the header.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-no-rows","title":"--no-rows","text":"<p>Do not display the row data.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-no-sys-msg","title":"--no-sys-msg","text":"<p>Do not display system messages.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-no-totals","title":"--no-totals","text":"<p>Do not display the totals.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-jobs/#-queuedqueued_timestamp","title":"--queued=QUEUED_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/","title":"Manpage for sbank-list-projects","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#sbank-list-projects-options","title":"sbank-list-projects [options]","text":"<p>Generate project list report.</p> <p>Notes:</p> <ol> <li>Use <code>-I</code> to include inactive allocations.</li> <li>To get information for all resources, enter <code>-r all</code>.</li> </ol>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#options","title":"OPTIONS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-version","title":"--version","text":"<p>Show the program's version number and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-h-help","title":"-h, --help","text":"<p>Show this help message and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>Filter on allocation ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p><code>FIELD_INFO</code> is <code>&lt;FIELD&gt;[:&lt;WIDTH&gt;]</code>. For available fields, enter <code>-f?</code> or <code>-f \"?\"</code>. To add fields, enter <code>-f \"+ &lt;FIELD&gt;[:&lt;WIDTH&gt;] ...\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>Set the number of fields to display.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p><code>\"FIELD_INFO\"</code> is <code>&lt;FIELD&gt;:&lt;WIDTH&gt;</code>. For available fields, enter <code>-w?</code> or <code>-w \"?\"</code>.</p> <p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following: - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. <p>Operator Defaults:</p> <ul> <li>OPER1 is 'lt' for a single date entry. OPER1 and OPER2 are 'ge' and 'lt', respectively, for a range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-h-human-readable","title":"-H, --human-readable","text":"<p>Abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-i-get-inactive","title":"-I, --get-inactive","text":"<p>Get inactive allocations.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-s-start-startstart","title":"-S START, --start=START","text":"<p>[OPER1][...[OPER2]], where the operators OPER1 and OPER2 can be one of the following: - ge, gt, le, lt, eq or &gt;=, &gt;, &lt;=, &lt;, ==. <p>Operator Defaults:</p> <ul> <li>OPER1 is 'lt' for a single date entry. OPER1 and OPER2 are 'ge' and 'lt', respectively, for a range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-all-charges","title":"--all-charges","text":"<p>Only show list info that has charges regardless of project/user relationship.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-no-commas","title":"--no-commas","text":"<p>Remove commas from comma-separated thousands.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-no-header","title":"--no-header","text":"<p>Do not display the header.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-no-rows","title":"--no-rows","text":"<p>Do not display the row data.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-no-sys-msg","title":"--no-sys-msg","text":"<p>Do not display system messages.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-projects/#-no-totals","title":"--no-totals","text":"<p>Do not display the totals.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/","title":"Manpage for sbank-list-transactions","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#sbank-list-transactions-options","title":"sbank-list-transactions [options]","text":"<p>Generate a transaction list report.</p> <p>Note: To get information for all resources, enter <code>-r all</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#options","title":"OPTIONS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-version","title":"--version","text":"<p>Show the program's version number and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-h-help","title":"-h, --help","text":"<p>Show this help message and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>Filter on allocation ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-c-comment","title":"-c, --comment","text":"<p>Display comment.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-e-event_id-event-idevent_id","title":"-e EVENT_ID, --event-id=EVENT_ID","text":"<p>Filter on event ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p><code>FIELD_INFO</code> is <code>&lt;FIELD&gt;[:&lt;WIDTH&gt;]</code>. For available fields, enter <code>-f?</code> or <code>-f \"?\"</code>. To add fields, enter <code>-f \"+ &lt;FIELD&gt;[:&lt;WIDTH&gt;] ...\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-j-jobid-jobidjobid","title":"-j JOBID, --jobid=JOBID","text":"<p>Filter on job ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>Set the number of fields to display.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>Filter on name or ID. Do not mix. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>Filter on name or ID. Do not mix. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-t-transaction_id-transaction-idtransaction_id","title":"-t TRANSACTION_ID, --transaction-id=TRANSACTION_ID","text":"<p>Filter on transaction ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>Filter on name or ID. Do not mix. Enter 'all' to get all. Wildcards '*' are allowed but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p><code>\"FIELD_INFO\"</code> is <code>&lt;FIELD&gt;:&lt;WIDTH&gt;</code>. For available fields, enter <code>-w?</code> or <code>-w \"?\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-e-job_end-endjob_end","title":"-E JOB_END, --end=JOB_END","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-h-human-readable","title":"-H, --human-readable","text":"<p>Abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-s-job_start-startjob_start","title":"-S JOB_START, --start=JOB_START","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-t-transaction_type-transaction-typetransaction_type","title":"-T TRANSACTION_TYPE, --transaction-type=TRANSACTION_TYPE","text":"<p>Transaction types: CHARGE, REFUND, PULLBACK, DEPOSIT, VOID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-attransaction_at_timestamp","title":"--at=TRANSACTION_AT_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-cbank-refcbank_ref","title":"--cbank-ref=CBANK_REF","text":"<p>Filter on Clusterbank reference ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-createdjob_created_timestamp","title":"--created=JOB_CREATED_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-no-commas","title":"--no-commas","text":"<p>Remove commas from comma-separated thousands.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-no-header","title":"--no-header","text":"<p>Do not display the header.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-no-rows","title":"--no-rows","text":"<p>Do not display the row data.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-no-sys-msg","title":"--no-sys-msg","text":"<p>Do not display system messages.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-no-totals","title":"--no-totals","text":"<p>Do not display the totals.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-transactions/#-queuedjob_queued_timestamp","title":"--queued=JOB_QUEUED_TIMESTAMP","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>. </p> <p>Operator Defaults: </p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry. </li> </ul> <p>Date Parsing Precedence: </p> <ul> <li>YEAR then MONTH then DAY, i.e., 121101 is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/","title":"Manpage for sbank-list-users","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#sbank-list-users-options","title":"sbank-list-users [options]","text":"<p>Generate user list report.</p> <p>Notes:</p> <ol> <li>Use <code>-I</code> to include inactive allocations.</li> <li>For information on all resources, use <code>-r all</code>.</li> </ol>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#options","title":"OPTIONS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-version","title":"--version","text":"<p>Show the program's version number and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-h-help","title":"-h, --help","text":"<p>Show this help message and exit.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-a-allocation_id-allocation-idallocation_id","title":"-a ALLOCATION_ID, --allocation-id=ALLOCATION_ID","text":"<p>Filter on allocation ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-f-field_info-field-to-displayfield_info","title":"-f FIELD_INFO, --field-to-display=FIELD_INFO","text":"<p><code>FIELD_INFO</code> is <code>&lt;FIELD&gt;[:&lt;WIDTH&gt;]</code>. For available fields, enter <code>-f?</code> or <code>-f \"?\"</code>. To add fields, enter <code>-f \"+ &lt;FIELD&gt;[:&lt;WIDTH&gt;] ...\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-n-num_fields_to_display-num-fields-to-displaynum_fields_to_display","title":"-n NUM_FIELDS_TO_DISPLAY, --num-fields-to-display=NUM_FIELDS_TO_DISPLAY","text":"<p>Set the number of fields to display.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-p-project-projectproject","title":"-p PROJECT, --project=PROJECT","text":"<p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-r-resource-resourceresource","title":"-r RESOURCE, --resource=RESOURCE","text":"<p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-u-user-useruser","title":"-u USER, --user=USER","text":"<p>Filter on name or ID. DO NOT MIX. Enter 'all' to get all. Wildcards '*' are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-w-field_info-field-width","title":"-w \"FIELD_INFO\", --field-width","text":"<p><code>\"FIELD_INFO\"</code> is <code>&lt;FIELD&gt;:&lt;WIDTH&gt;</code>. For available fields, enter <code>-w?</code> or <code>-w \"?\"</code>.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-e-end-endend","title":"-E END, --end=END","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</p> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-h-human-readable","title":"-H, --human-readable","text":"<p>Abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-i-get-inactive","title":"-I, --get-inactive","text":"<p>Also get inactive allocations.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-s-start-startstart","title":"-S START, --start=START","text":"<p><code>[OPER1]&lt;UTC_DATE1&gt;[...[OPER2]&lt;UTC_DATE2&gt;]</code>, where the operators <code>OPER1</code> and <code>OPER2</code> can be one of the following:    - <code>ge</code>, <code>gt</code>, <code>le</code>, <code>lt</code>, <code>eq</code> or <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&lt;</code>, <code>==</code>.</p> <p>Operator Defaults:</p> <ul> <li><code>OPER1</code> is 'lt' for a single date entry. <code>OPER1</code> and <code>OPER2</code> are 'ge' and 'lt', respectively, for a range date entry.</li> </ul> <p>Date Parsing Precedence:</p> <ul> <li>YEAR then MONTH then DAY, i.e., <code>121101</code> is parsed as YYMMDD, hence Nov. 1, 2012.</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-debugdebug_level","title":"--debug=DEBUG_LEVEL","text":"<p>SILENT, MUCH_LESS, LESS, MORE, VERBOSE, DEBUG, DEBUG1, DEBUG2</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-all-charges","title":"--all-charges","text":"<p>Only show list info that have charges regardless of project/user relationship.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-no-commas","title":"--no-commas","text":"<p>Remove commas from comma-separated thousands.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-no-header","title":"--no-header","text":"<p>Do not display the header.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-no-rows","title":"--no-rows","text":"<p>Do not display the row data.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-no-sys-msg","title":"--no-sys-msg","text":"<p>Do not display system messages.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list-users/#-no-totals","title":"--no-totals","text":"<p>Do not display the totals.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/","title":"Manpage for sbank-list","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#sbank-list-options","title":"sbank-list  [options] <p>List Meta Command</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#commands","title":"COMMANDS","text":"<ul> <li>allocations [-a|-c|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-I|-O|-S|-T|...] (DEFAULT)</li> <li>categories [-f|-n|-w|...]</li> <li>messages [-f|-n|-w|...]</li> <li>names [-f|-n|-w|...]</li> <li>jobs [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...]</li> <li>projects [-a|-f|-n|-p|-r|-u|-w|-E|-H|-I|-S|...]</li> <li>transactions [-a|-c|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...]</li> <li>users [-a|-f|-n|-p|-r|-u|-w|-E|-H|-S|...]</li> </ul>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#options","title":"OPTIONS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-a-allocation","title":"-a --allocation","text":"<p>Enter allocation ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-c-comment","title":"-c --comment","text":"<p>Enter comment for new or edit commands, display comment for list commands.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-e-event-id","title":"-e --event-id","text":"<p>Enter event DB ID; event DB ID is an internal ID created by the charging system.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-f-field","title":"-f --field","text":"<p>Enter <code>&lt;field&gt;[:&lt;width&gt;]</code>, width is optional; enter <code>-f?</code> or <code>-f \"?\"</code> for available fields, <code>+</code> to add fields.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-h-help","title":"-h --help","text":"<p>Command line help.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-j-jobid","title":"-j --jobid","text":"<p>Enter job ID; job ID is created by the scheduler and is not unique.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-n-num-field","title":"-n --num-field","text":"<p>Enter number of fields to display.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-p-project","title":"-p --project","text":"<p>Enter name or ID, DO NOT MIX, enter 'all' to get all, wildcards '*' are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-r-resource","title":"-r --resource","text":"<p>Enter name or ID, DO NOT MIX, enter 'all' to get all, wildcards '*' are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-s-suballocation","title":"-s --suballocation","text":"<p>Enter suballocation ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-t-transaction","title":"-t --transaction","text":"<p>Enter transaction ID.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-u-user","title":"-u --user","text":"<p>Enter name or ID, DO NOT MIX, enter 'all' to get all, wildcards '*' are allowed, but only on names.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-w-field-width","title":"-w --field-width","text":"<p>Enter the field width as follows: <code>&lt;field&gt;:&lt;width&gt;</code>, enter <code>-w?</code> or <code>-w \"?\"</code> for available fields.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-e-end","title":"-E --end","text":"<p>Enter end datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-h-human-readable","title":"-H --human-readable","text":"<p>Abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions), etc.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-i-get-inactive","title":"-I --get-inactive","text":"<p>Include inactive allocations.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-o-get-only-inactive","title":"-O --get-only-inactive","text":"<p>Include only inactive allocations.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-s-start","title":"-S --start","text":"<p>Enter start datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-t-type","title":"-T --Type","text":"<p>Enter type of transaction.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-all-charges","title":"--all-charges","text":"<p>For list allocations | projects | users, only show info with charges.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-at","title":"--at","text":"<p>Enter transaction-created datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-award-category","title":"--award-category","text":"<p>Enter allocation award category.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-award-type-name","title":"--award-type-name","text":"<p>Enter allocation award-type name.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-created","title":"--created","text":"<p>Enter created datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-debug","title":"--debug","text":"<p>Enter debug level.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-get-deleted","title":"--get-deleted","text":"<p>Get deleted objects.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-get-not-charged","title":"--get-not-charged","text":"<p>Get jobs that have not been charged.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-get-only-deleted","title":"--get-only-deleted","text":"<p>Get only deleted objects.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-history-date-range","title":"--history-date-range","text":"<p>Enter history datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-last-updated","title":"--last-updated","text":"<p>Enter last updated datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-no-commas","title":"--no-commas","text":"<p>Remove commas from comma-separated thousands.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-no-header","title":"--no-header","text":"<p>Do not display header.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-no-history","title":"--no-history","text":"<p>Do not display history information.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-no-rows","title":"--no-rows","text":"<p>Do not display rows.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-no-sys-msg","title":"--no-sys-msg","text":"<p>Do not display system message.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-no-totals","title":"--no-totals","text":"<p>Do not display totals.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-list/#-queued","title":"--queued","text":"<p>Enter queued datetime filter.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/","title":"Manpage for sbank Commands","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#sbank-options","title":"sbank   [options]","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#description","title":"DESCRIPTION","text":"<p>HPC Accounting System Command Line Interface</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#detail-meta-command","title":"detail meta command","text":"<p>\"detail\" meta command displays information in a long format with history updates, where appropriate.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#list-meta-command","title":"list meta command","text":"<p>\"list\" meta command displays information in a table format, but no history updates are displayed.</p> <p>IMPORTANT NOTES   1. All dates entered shall be interpreted as UTC   2. non-admin users will only be able to see their content (jobs, charges, etc.)   3. project admin users will be able to see all of the content for their projects   4. staff admin users will be able to see all the content   5. --help and -h are the help options.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#meta-commands","title":"META COMMANDS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-detail-options","title":"- detail  [options]","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-list-options-default","title":"- list  [options] (DEFAULT) <p>DETAIL COMMANDS   * allocations [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-I|-O|-S|-T|...] [ ... ] (DEFAULT)    * jobs [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...] [ ... ]    * projects [-a|-f|-n|-p|-r|-u|-w|-E|-H|-I|-S|...] [ ... ]    * transactions [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...] [ ... ]    * users [-a|-f|-n|-p|-r|-u|-w|-E|-H|-S|...] [ ... ] <p>LIST COMMANDS   * allocations [-a|-c|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-I|-O|-S|-T|...] (DEFAULT)    * jobs [-a|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...] projects [-a|-f|-n|-p|-r|-u|-w|-E|-H|-I|-S|...]    * transactions [-a|-c|-e|-f|-j|-n|-p|-r|-t|-u|-w|-E|-H|-S|-T|...]    * users [-a|-f|-n|-p|-r|-u|-w|-E|-H|-S|...]</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#options","title":"OPTIONS","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-a-allocation","title":"-a --allocation <p>enter allocation id</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-c-comment","title":"-c --comment <p>enter comment for new or edit commands, display comment for list commands</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-e-event-id","title":"-e --event-id <p>enter event db id; event db id is an internal id created by the charging system</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-f-field","title":"-f --field <p>enter [:], width is optional; enter -f? or -f \"?\" for available fields, + to add fields","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-h-help","title":"-h --help <p>command line help</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-j-jobid","title":"-j --jobid <p>enter jobid; jobid is created by the scheduler and is not unique</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-n-num-field","title":"-n --num-field <p>enter number of fields to display</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-p-project","title":"-p --project <p>enter name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-r-resource","title":"-r --resource <p>enter name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-s-suballocation","title":"-s --suballocation <p>enter suballocation id</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-t-transaction","title":"-t --transaction <p>enter transaction id</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-u-user","title":"-u --user <p>enter name or id, DO NOT MIX, enter 'all' to get all, wild cards '*' is allowed, but only on names</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-w-field-width","title":"-w --field-width <p>enter the field width as follows: :, enter -w? or -w \"?\" for available fields","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-e-end","title":"-E --end <p>enter end datetime filter</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-h-human-readable","title":"-H --human-readable <p>abbreviate numbers and use unit suffixes: K (thousands), M (millions), G (billions), T (trillions) ...</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-i-get-inactive","title":"-I --get-inactive <p>include inactive allocations</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-o-get-only-inactive","title":"-O --get-only-inactive <p>get only inactive allocations</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-s-start","title":"-S --start <p>enter start datetime filter</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-t-type","title":"-T --Type <p>enter type of transaction</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-all-charges","title":"--all-charges <p>for list allocations | projects | users, only show info with charges</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-at","title":"--at <p>enter transaction-created datetime filter</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-award-category","title":"--award-category <p>enter allocation award category</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-award-type-name","title":"--award-type-name <p>enter allocation award-type name</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-created","title":"--created <p>enter created datetime filter</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-debug","title":"--debug <p>enter debug level</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-get-deleted","title":"--get-deleted <p>get deleted objects</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-get-not-charged","title":"--get-not-charged <p>get jobs that have not been charged</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-get-only-deleted","title":"--get-only-deleted <p>get only deleted objects</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-history-date-range","title":"--history-date-range <p>enter history datetime filter</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-home-dir","title":"--home-dir <p>enter the directory to store the pbs meta file</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-ignore-pbs-files","title":"--ignore-pbs-files <p>all new pbs files will be ignored and marked as processed</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-last-updated","title":"--last-updated <p>enter last updated datetime filter</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-no-commas","title":"--no-commas <p>remove commas from comma-separated thousands</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-no-header","title":"--no-header <p>do not display header</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-no-history","title":"--no-history <p>do not display history information</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-no-rows","title":"--no-rows <p>do not display rows</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-no-sys-msg","title":"--no-sys-msg <p>do not display system message</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-no-totals","title":"--no-totals <p>do not display totals</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#-queued","title":"--queued <p>enter queued datetime filter</p>","text":""},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#more-option-explanations","title":"MORE OPTION EXPLANATIONS","text":"<p>For -a, -e, -f, -w, -j, -p, -r, -t, -u, -T, --award-categories, --award_type_names, --cbank_refs options:</p> <p>These options can be entered multiple times for different values or entered once for multiple values. </p> <p>Examples: </p> <ol> <li> <p>sbank-list-allocation -u \"pershey rojas allcock\" or &gt; sbank-list-allocation -u pershey -u rojas -u allcock </p> </li> <li> <p>sbank-list-allocation -f \"id p avail\" or &gt; sbank-list-allocation -f id -f p -f avail For -u, -p and -r the use of wild card \"*\" is allowed, but only on names, not ids: </p> </li> </ol> <p>Examples: </p> <ol> <li>The following command will find allocations for users whose names start with \"pers\" and also users rojas and allcock. &gt; sbank-list-allocation -u \"pers* rojas allcock\" </li> <li>The following command will find allocations for projects that contain \"ratio\" in the name. &gt; sbank-list-allocation -p ratio </li> <li>The following command will find allocations for projects that end with \"tion\" in the name. &gt; sbank-list-allocation -p *tion </li> <li>The following command will find allocations for projects that start with \"ab\" and end with \"ng\" in the name. &gt; sbank-list-allocation -p ab*ng</li> </ol> <p>For -f option: This option is the display field option. </p> <p>To get the available fields enter -f? or -f \"?\". Default fields columns will be displayed if no field option is specified. </p> <p>To replace the current fields to display, enter:  <pre><code>&gt; sbank-list-allocations ... -f \"FIELD[:WIDTH]...FIELD[:WIDTH]\" or &gt; sbank-list-allocations ... -f FIELD[:WIDTH] ... -f FIELD[:WIDTH] \n</code></pre></p> <p>If you wish to add fields to the default fields, enter one + symbol anywhere in the quoted string:  <pre><code>&gt; sbank-list-allocations ... -f \"+ FIELD[:WIDTH]...FIELD[:WIDTH]\", only one + symbol is needed.\n</code></pre></p> <p>The fields will be displayed in table format and in the order entered in the command line. You can specify the field width, where WIDTH can be positive or negative value. Left alignment use -, right alignment use + or nothing.</p> <p>For -w option:</p> <p>FIELD:WIDTH, if the field is displayed it will change the width for the specified field. </p> <p>NOTE: This will not add the field as in -f option, only change the width. To get available fields you can also use -w? or -w \"?\" as in -f option.</p> <p>For -S, -E, --created, --queued, --last-updated, --history-date-range options:</p> <p>These are the date filter options. All dates are treated as UTC. </p> <p>You can use any reasonable date string that resembles a date Ambiguous dates will be parsed with the following parsing precedence: **YEAR then MONTH then DAY **</p> <p>For example, 10-11-12 or 101112 will be the following date: Oct. 11, 2012 Not: Nov. 12, 2010 or Nov. 10, 2012 </p> <p>Or you can specify a single date as follows:  <pre><code>\"[OPER]UTC_DATE\" You can specify a date range as follows: \n\"[OPER1]UTC_DATE1...[OPER2]UTC_DATE2\" Where OPER can be one of the following operators: \"==\", \"&gt;=\", \"&lt;=\", \"&gt;\", \"&lt;\" or \"eq\", \"ge\", \"le\", \"gt\", \"lt\" \n</code></pre></p> <p>Note: The following defaults for OPER, OPER1, OPER2 for the following options:  <pre><code>Options OPER OPER1 OPER2 ------------------------- ---- ----- ----- -E, &lt; &gt;= &lt; -S, &gt;= &gt;= &lt; --at &gt;= &gt;= &lt; --created &gt;= &gt;= &lt; --eligible &gt;= &gt;= &lt; --last-updated &gt;= &gt;= &lt; --queued &gt;= &gt;= &lt; \n</code></pre></p> <p>You can also use the following key letters \"n\", \"t\", \"d\", \"w\", \"y\" as follows:  <pre><code>KEY SYNTAX DEFINITIONS ---------- ----------- n[ow] now, where \"now\" is current-date current-time UTC t[oday] today, where \"today\" is current-date 00:00:00 UTC [+/-]d specified \"number\" of +/- days from \"today\" in UTC [+/-]w specified \"number\" of +/- weeks from \"today\" in UTC [+/-]y specified \"number\" of +/- years from \"today\" in UTC\n</code></pre></p> <p>For -T option:</p> <p>Transaction type option. The following are the valid transaction types and their explanation: CHARGE filter on job charges PULLBACK filter on allocation pullbacks DEPOSIT filter on allocation deposits REFUND filter on job refunds VOID filter on void transactions</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#invocation","title":"INVOCATION","text":"<p>sbank sbank sbank sbank-detail sbank detail sbank d sbank-detail-allocations sbank detail allocations sbank d a sbank-detail-jobs sbank detail jobs sbank d j sbank-detail-projects sbank detail project sbank d p sbank-detail-transactions sbank detail transactions sbank d t sbank-detail-users sbank detail users sbank d u sbank-list sbank list sbank l sbank-list-allocations sbank list allocations sbank l a sbank-list-jobs sbank list jobs sbank l j sbank-list-projects sbank list projects sbank l p sbank-list-transactions sbank list transactions sbank l t sbank-list-users sbank list users sbank l u</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#environment-variables","title":"ENVIRONMENT VARIABLES","text":"<p>Command line default options: Define the following environment variables as you would in the command line. Once the environment variable is defined, it will be used as the default options and arguments for the specific command. Command line options will take precedence.</p> <p>sbank_DETAIL_ALLOCATIONS_ARGS</p> <p>Default arguments and options for sbank-detail-allocations.</p> <p>sbank_DETAIL_CATEGORIES_ARGS</p> <p>Default arguments and options for sbank-detail-categories.</p> <p>sbank_DETAIL_NAMES_ARGS</p> <p>Default arguments and options for sbank-detail-names.</p> <p>sbank_DETAIL_MESSAGES_ARGS</p> <p>Default arguments and options for sbank-detail-messages.</p> <p>sbank_DETAIL_JOBS_ARGS</p> <p>Default arguments and options for sbank-detail-jobs.</p> <p>sbank_DETAIL_PROJECTS_ARGS</p> <p>Default arguments and options for sbank-detail-projects.</p> <p>sbank_DETAIL_TRANSACTIONS_ARGS</p> <p>Default arguments and options for sbank-detail-transactions.</p> <p>sbank_DETAIL_USERS_ARGS</p> <p>Default arguments and options for sbank-detail-users.</p> <p>sbank_LIST_ALLOCATIONS_ARGS</p> <p>Default arguments and options for sbank-list-allocations.</p> <p>sbank_LIST_JOBS_ARGS</p> <p>Default arguments and options for sbank-list-jobs.</p> <p>sbank_LIST_PROJECTS_ARGS</p> <p>Default arguments and options for sbank-list-projects.</p> <p>sbank_LIST_TRANSACTIONS_ARGS</p> <p>Default arguments and options for sbank-list-transactions.</p> <p>sbank_LIST_USERS_ARGS</p> <p>Default arguments and options for sbank-list-users.</p>"},{"location":"account-project-management/allocation-management/not_in_nav/sbank-manpage/#examples","title":"EXAMPLES <p>Example 1: -f, --field <pre><code>&gt; sbank-list-transactions ... -f field1:-20 -f field2:20 -f field3 or &gt; sbank-list-transactions ... -f \"field1:-20 field2:20 field3\" \n</code></pre> Explanation: Fields will be displayed in order of appearance, where field1:-20 means 20 characters long, left align; where field2:20 means 20 characters long, right align; where field3 uses default sizes. Number fields default to right aligned. Text fields default to left aligned.</p> <p>Example 2: -S, -E, --created, --queued, --last-updated, --history-start, --history-end</p> <p>Single date-string examples: </p> <ul> <li>  <p>sbank-list-allocations -S \"&gt;=Oct 11, 2014\" start dates that are &gt;= \"2014-10-11 00:00:00\" </p>  </li> <li>  <p>sbank-list-allocations -S \"&lt;=2014-11-10\" start dates that are &lt;= \"2014-11-10 00:00:00\" </p>  </li> <li>  <p>sbank-list-allocations -E \"&lt;20141110\" end dates that are &lt; \"2014-11-10 00:00:00\" </p>  </li> <li>  <p>sbank-list-allocations -E \"22:30:10\" end dates that are &lt; \" 22:30:10\"    <li>  <p>sbank-list-allocations -S \"&gt;today\" start dates that are &gt; \" 00:00:00\"    <li>  <p>sbank-list-allocations -E t end dates that are &lt; \" 00:00:00\"    <li>  <p>sbank-list-allocations -S gtnow start dates that are &gt; \" \"    <li>  <p>sbank-list-allocations -E len end dates that are &lt;= \" \"    <li>  <p>sbank-list-allocations -S \"1d\" start dates that are &gt;= \"today +1 day\" </p>  </li> <li>  <p>sbank-list-allocations -E \"-2w\" end dates that are &lt; \"today -2 weeks\" </p>  </li> <li>  <p>sbank-list-allocations -S \"&gt;=1y\" start dates that are &gt;= \"today +1 year\" </p>  </li> <li>  <p>sbank-list-allocations -S \"&gt;2012\" start dates that are &gt; \"2012-- 00:00:00\"     <p>Range date-string examples: </p> <ul> <li>  <p>sbank-list-allocations -S \"2013-01-01...2014-01-01\" \"2013-01-01\" &lt;= DATES &lt; \"2014-01-01\" </p>  </li> <li>  <p>sbank-list-allocations -S \"-1y...t\" \"today -1 year\" &lt;= DATES &lt; \"today\" </p>  </li> <li>  <p>sbank-list-allocations -E \"2013...t\"\" \"2013--\" &lt;= DATES &lt; \"today\"    <li>  <p>sbank-list-allocations -E \"&gt;2013...&lt;=t\"\" \"2013--\" &lt; DATES &lt;= \"today\"    <p>Example 3: Command invocation examples</p> <ul> <li>  <p>sbank-list-projects list projects full command invocation </p>  </li> <li>  <p>sbank list projects list projects meta command invocation</p>  </li> <li>  <p>sbank s p list projects partial meta command invocation </p>  </li> <li>  <p>sbank p list projects where \"list\" is the default</p>  </li> <li>  <p>sbank list allocations is the default </p>  </li> <li>  <p>sbank a list allocations \"list\" is the default </p>  </li> <li>  <p>sbank s a list allocations partial meta command invocation</p>  </li> </ul> <p>Example 4: -h, --help</p> <ul> <li>  <p>sbank -h will give you help summary on all of sbank </p>  </li> <li>  <p>sbank list --help will give you help on all the \"list\" commands </p>  </li> <li>  <p>sbank list allocations -h will give you help on the \"list allocations\" command</p>  </li> <li>  <p>sbank-list-allocations -h will give you help on the \"list allocations\" command </p>  </li> <li>  <p>sbank l a --help will give you help on the \"list allocations\" command</p>  </li> </ul>","text":""},{"location":"account-project-management/project-management/project-reports/","title":"Quarterly and Year-End Reporting","text":"<p>The Argonne Leadership Computing Facility (ALCF) is required to report the progress and scientific accomplishments of all peer-reviewed projects.</p> <p>PIs of INCITE, ALCC, and ADSP projects must complete quarterly reports and a final end-of-year (EOY) or end-of-project (EOP) report.</p>"},{"location":"account-project-management/project-management/project-reports/#due-dates","title":"Due dates","text":""},{"location":"account-project-management/project-management/project-reports/#2025-incite-quarterly-eoy-and-eop-reports","title":"2025 INCITE quarterly, EOY, and EOP reports:","text":"<ul> <li>April 1, 2025 (CY2025 - Q1)</li> <li>July 1, 2025 (CY2025 - Q2)</li> <li>October 1, 2025 (CY2025 - Q3)</li> <li>January 1, 2026 (CY2025 - EOY) or February 15, 2026 (entire allocation period - EOP)</li> </ul>"},{"location":"account-project-management/project-management/project-reports/#2024-2025-2025-2026-alcc-eop-report","title":"2024-2025 / 2025-2026 ALCC EOP report:","text":"<ul> <li>August 15, 2025 (CY2025)</li> </ul>"},{"location":"account-project-management/project-management/project-reports/#2025-2026-alcc-quarterly-and-eop-reports","title":"2025-2026 ALCC quarterly and EOP reports:","text":"<ul> <li>October 1, 2025 (CY2025 - Q3)</li> <li>January 1, 2026 (CY2025 - Q4)</li> <li>April 1, 2026 (CY2026 - Q1)</li> <li>August 15, 2026 (CY2026 - EOP)</li> </ul>"},{"location":"account-project-management/project-management/project-reports/#penalties","title":"Penalties","text":"<p>If a quarterly report is more than 30 days late:</p> <ul> <li>The ability to submit jobs for the PI and users of the late project will be disabled.</li> </ul> <p>If a quarterly report is more than 90 days late:</p> <ul> <li>The PI and users of the late project will have their accounts disabled.</li> </ul> <p>These penalties will be removed within three business days after the late quarterly or EOY report is submitted.</p>"},{"location":"account-project-management/project-management/project-reports/#alcc-specific-penalties","title":"ALCC Specific Penalties:","text":"<p>A similar penalty will also be applied to new ALCC projects with the same PI or co-PIs that have failed to submit the EOP report for a previous ALCC project. If the EOP report is more than 15 days late:</p> <ul> <li>The new ALCC project will be blocked.</li> <li>For a currently active ALCC project,the ability to submit jobs for the project and all sub-projects will be disabled.</li> <li>For a project that has not been created yet, the process for new project creation will be halted.</li> </ul>"},{"location":"account-project-management/project-management/project-reports/#appeals","title":"Appeals","text":"<p>A PI or user may appeal a project or account suspension to the ALCF Director by a request to ALCF Support.</p>"},{"location":"account-project-management/project-management/project-reports/#report-templates","title":"Report Templates","text":"<p>Templates for the quarterly and the EOY reports can be found at the links at the bottom of this page.</p> <p>Please modify the filename to reflect your project's details:  - Replace PINAME with the last name of the PI of the INCITE/ALCC project - Replace ALLOCATION with INCITE or ALCC  - Replace YEAR to the corresponding calendar year</p> <p>For example, for a project with PI 'Joe Smith' that is submitting the quarterly report for the first quarter in the 2023-2024 cycle for ALCC, the filename will be Smith_ALCC_Q1.docx.</p> <ul> <li>For an EOY report, replace YEARS with the years associated with your allocation.</li> </ul> <p>For example, an ALCC 2025-2026 project with PI 'Joe Smith' would have a filename of Smith_ALCC_2025-2026_EOY.docx.</p>"},{"location":"account-project-management/project-management/project-reports/#templates-for-incite-and-alcc","title":"Templates for INCITE and ALCC:","text":"<ul> <li>Quarterly Report Template</li> <li>End of Project Report Template</li> <li>End of Year Report Template</li> </ul>"},{"location":"account-project-management/project-management/starting-alcf-award/","title":"Starting Your ALCF Award","text":"<p>The following guide is for PIs and Proxies to get insight into managing projects and teams for ALCF awards. Please submit questions or trouble tickets to support@alcf.anl.gov.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#get-started-with-alcfs-systems","title":"Get Started with ALCF's Systems","text":"<p>To get started using our resources, please visit Connect &amp; Login</p> <p>We also encourage you to take full advantage of ALCF's training programs and user services. Some useful introductory materials and videos are listed below:</p> <ul> <li>Running on Polaris</li> <li>Running on Aurora</li> <li>Lustre File Striping Basics</li> <li>Community Data Sharing with ACDC (using Eagle)</li> </ul>"},{"location":"account-project-management/project-management/starting-alcf-award/#project-terminology","title":"Project Terminology","text":"<p>Before your project begins, you will receive an email with the following project information:</p> <ul> <li>Project Short Name: The assigned, shortened name for your project. This will be the name that you'll use to access your project on the systems.</li> <li>Project Proxies: Project members designated by PIs that are authorized to add or renew project members on your behalf.</li> <li>Allocation System(s) and Allocation Amount: The approved system(s) and amount of your award in node hours.</li> <li>Approved Quota: The approved amount of disk space for your project directory.</li> <li>File System: The file system where your project directory will reside. For information on the Eagle file system, see Storage and Networking.</li> <li>Assigned Catalyst: INCITE projects will have ALCF staff members that are assigned to the projects who are available to assist the team throughout the duration of the INCITE allocation.</li> <li>Allocation Start Date: The start date of your award.</li> <li>Allocation End Date: The end date of your award.</li> </ul>"},{"location":"account-project-management/project-management/starting-alcf-award/#account-setup","title":"Account Setup","text":"<p>If you do not have an ALCF account: You will need to request one at https://my.alcf.anl.gov/accounts/#/accountRequest. When prompted for the project name, please select the project short name you were given in your award email from support@alcf.anl.gov.</p> <p>If you have an active ALCF account: Submit a request to join the newly awarded project at https://my.alcf.anl.gov/.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#information-for-foreign-national-access","title":"Information for Foreign National Access","text":"<p>The U.S. Department of Energy has guidelines and requirements for foreign nationals who access its facilities and sites. This guidance is issued in DOE Order 142.3, which is part of Argonne's contract; therefore, all foreign nationals (non-U.S. Citizens) must obtain authorization prior to using ALCF resources.</p> <p>If you are a foreign national and do not have current authorization credentials, you are required to submit an ANL-593 (Foreign National Access Request) form. It is critical that identity documentation requests sent by ALCF staff are completed as early as possible to facilitate timely processing for your account approval.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#user-agreement-for-incite-alcc-and-adsp","title":"User Agreement for INCITE, ALCC, and ADSP","text":"<p>Note: This does not apply to Director's Discretionary awards.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#institution-master-agreement-for-incite-alcc-and-adsp","title":"Institution Master Agreement for INCITE, ALCC, and ADSP","text":"<p>If you are not an employee of Argonne National Laboratory, a user agreement must be signed by your home institution to perform research at Argonne's user facilities. This policy applies to every member of the project team who will be conducting research on ALCF resources.</p> <p>A list of home institutions that have master agreements in place is located on this webpage: https://www.aps.anl.gov/Users-Information/Legal-Financial/Argonne-User-Facility-Agreements</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#alcf-user-agreement-for-incite-alcc-and-adsp","title":"ALCF User Agreement for INCITE, ALCC, and ADSP","text":"<p>Note: This does not apply to Director's Discretionary awards.</p> <p>Every project team member who requests an ALCF account must sign and return an acknowledgment form, stating that they agree to the terms in the user agreement.</p> <p>The form is located at: https://www.alcf.anl.gov/files/Acknowledgement_Form.pdf. Please print, sign, scan, and email it to accounts@alcf.anl.gov.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#managing-project-team-membership","title":"Managing Project Team Membership","text":"<p>As a PI, you can add members to your project. You can assign proxies who are project members authorized to add or renew project members on your behalf.</p> <p>A project PI or proxy has the authority to:</p> <ul> <li>Approve and renew accounts</li> <li>Add and delete users to/from the project</li> <li>Approve Foreign Assignment/Visit Request form renewals for project members who are foreign nationals</li> </ul> <p>During your project setup, the ALCF Support Team will request the following information to establish your project members:</p> <ul> <li>The names, email addresses, and/or ALCF usernames (if already existing) of up to two proxies and all project members.</li> </ul>"},{"location":"account-project-management/project-management/starting-alcf-award/#about-project-and-unix-group-membership","title":"About Project and UNIX Group Membership","text":"<p>All project members have the ability to run jobs against your allocation. There is no limit to the number of project members you may authorize. Project members are automatically added to the project UNIX group, giving them the ability to write to the project directory and to access project data. When a project member is added or removed from a project, this will automatically be reflected in the project UNIX group membership.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#adding-project-members","title":"Adding Project Members","text":"<p>The PI or a proxy must approve each team member to access ALCF resources and run jobs on their project. PI/proxies can respond to emails from ALCF for account access approval with a \"yes\" or \"no\".</p> <p>PI/proxies with active ALCF accounts can also approve new account requests, project membership requests, account reactivation requests, and add existing active ALCF users to the project by logging into the ALCF Account and Project Management application.</p> <p>Note</p> <p>If PI/proxies need to request an ALCF account, see the section below for instructions on \"how to apply\" for an account.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#accounts-and-access-for-your-project-members","title":"Accounts and Access for your Project Members","text":"<p>All project members will need an ALCF user account to access project data and to run jobs on ALCF systems.</p> <p>Members that do not have an ALCF account should request one at: https://my.alcf.anl.gov/accounts/#/accountRequest. When prompted for the project name, they should select your project short name.</p> <p>Members with ALCF accounts that are no longer active should submit a reactivation request here: https://my.alcf.anl.gov/accounts/#/accountReactivate. When prompted for the project name, they should select your project short name.</p> <p>Members with active ALCF accounts but have not been added to your project should submit a request to join your project by going to this page: https://my.alcf.anl.gov/. They should search for your project and click the \"Request Membership\" button for that project.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#moving-your-data","title":"Moving Your Data","text":"<p>We encourage you to use Globus to move your project data to your ALCF project directory before your allocation begins. For details, see Using Globus.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#project-status-reports-for-incite-alcc-and-adsp","title":"Project Status Reports for INCITE, ALCC, and ADSP","text":"<p>Note: PIs that are awarded a Director's Discretionary will not receive weekly status project reports.</p> <p>Shortly after your allocation begins, we will begin sending you a weekly project status report via support@alcf.anl.gov to keep you informed of your award progress.</p> <p>Look for an email from us with the subject line: ALCF [ALLOCATION PROGRAM] Project Status Report for [PROJECT SHORT NAME]</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#reporting-requirements-for-incite-alcc-and-adsp","title":"Reporting Requirements for INCITE, ALCC, and ADSP","text":"<p>Note</p> <p>PIs that are awarded a Director's Discretionary allocation are not required to submit project reports.</p> <p>If you received an INCITE, ALCC, or ADSP allocation award, quarterly reporting is required to keep DOE informed of progress related to your allocation.</p> <p>The ALCF will send you a report template at the end of each quarter. Please complete the report promptly and submit it via email to support@alcf.anl.gov. For more information, see the Quarterly Report webpage.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#policies","title":"Policies","text":""},{"location":"account-project-management/project-management/starting-alcf-award/#facility-policies","title":"Facility Policies","text":"<p>Facility policies have been established to provide consistent and reliable services. Please read about our ALCF Facility Policies.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#pullback-policy","title":"Pullback Policy","text":"<p>Please be aware that we will periodically monitor, and could potentially adjust, your project allocation if a large portion of it goes unused. You may view: Pullback Policy</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#allocation-overburn-policy","title":"Allocation Overburn Policy","text":"<p>Please see this page for overburn/overuse eligibility for INCITE projects that have exhausted their allocation in the first 11 months of its allocation year: Allocation Overburn</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#acknowledgment-in-publications","title":"Acknowledgment In Publications","text":"<p>Please follow the guidelines provided on the ALCF Acknowledgement Policy page to properly acknowledge the use of ALCF resources in all of your publications, both online and print.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#useful-allocation-and-quota-commands","title":"Useful Allocation and Quota Commands","text":"<p>We have an allocation management tool called sbank, and below are a few helpful sbank commands:</p> <ul> <li><code>myprojectquotas</code>: Log into Polaris and type this command to view the project directory quotas for all your projects.</li> <li><code>myquota</code>: Log into Polaris and type this command to view your home directory quota.</li> </ul> <p>You can use the following command to check your project balance on Polaris: - <code>sbank-list-allocations -p &lt;Project Shortname&gt; -r &lt;system name&gt;</code></p> <p>For more command examples and details, see sbank.</p>"},{"location":"account-project-management/project-management/starting-alcf-award/#how-can-we-help","title":"How Can We Help?","text":"<p>We can also help resolve any issues or needs that may be delaying the start of your scientific campaign. - Are you in need of high-throughput software? - Are you having difficulty compiling your application? - Does your code have limited restart capabilities?</p> <p>If your project allocation usage is being held back for reasons due to one of our systems, please contact us for assistance by emailing support@alcf.anl.gov.</p>"},{"location":"account-project-management/project-management/team-management/","title":"Managing Your Team Members","text":"<p>The PI or Proxy must approve each member of the team to gain access and to run project jobs on the ALCF's resources. If you have an active ALCF account, you can manage your project team by logging into the MyALCF user portal and navigating to https://my.alcf.anl.gov/accounts/#/manageProjects</p> <p>Project members will need to have an active ALCF user account to access project data and to run jobs on ALCF systems. See Accounts and Access for your Project Members for information on how team members can get an account, reactivate an account, or request to join your project.</p>"},{"location":"account-project-management/project-management/team-management/#accessing-your-projects","title":"Accessing your project(s)","text":"<ol> <li>Log in at https://my.alcf.anl.gov/accounts/#/manageProjects using your credentials (ALCF username and Physical/Mobile token passcode one-time passcode).</li> <li>You will see a list of projects of which you are the Primary Investigator (PI).</li> <li>Click on the desired project to view information and management options for the selected project.</li> </ol>"},{"location":"account-project-management/project-management/team-management/#modifying-project-information","title":"Modifying project information","text":"<p>Some project information cannot be modified, but as the PI, you can modify the following: project title, institutions, and associated funding.</p> <p>Your project can be associated with multiple institutions, but you must specify a primary institution, which is usually the PI's home institution.</p>"},{"location":"account-project-management/project-management/team-management/#managing-project-members-with-an-existing-alcf-account","title":"Managing project members with an Existing ALCF Account","text":"<ol> <li>You can manage the membership for your project by clicking on the desired project from the Project Management screen.</li> <li>Add and/or remove proxies and team members by clicking on the red \"Remove\" button to the right of each member or clicking on \"Add new user.\" Note that new team members may be placed in \"Approval Pending\" status until the accounts team can complete the relevant paperwork for the user such as user agreement, user agreement acknowledgement, ANL-593 (Foreign National Cyber Access Form) etc.</li> <li>You can view account information for each user as it relates to the project:</li> <li>Account Status</li> <li>Project Role</li> <li>Proxy Permissions</li> <li> <p>Membership Status</p> </li> <li> <p>Proxies are individuals authorized to add or renew user accounts for the project PI. You have the ability to upgrade a user from a member to a Proxy, by clicking on the \"Proxy\" radio button that corresponds with the desired member.</p> </li> </ol>"},{"location":"ai-testbed/","title":"ALCF AI Testbed","text":"<p>The ALCF AI Testbed houses some of the most advanced AI accelerators for scientific research. </p> <p>The goal of the testbed is to enable explorations into next-generation machine learning applications and workloads, enabling the ALCF and its user community to help define the role of AI accelerators in scientific computing and how to best integrate such technologies with supercomputing resources.</p> <p>The AI accelerators complement the ALCF's current and next-generation supercomputers to provide a state-of-the-art computing environment that supports pioneering research at the intersection of AI, big data, and high performance computing (HPC). </p> <p>The platforms are equipped with architectural features that support AI and data-centric workloads, making them well suited for research tasks involving the growing deluge of scientific data produced by powerful tools, such as supercomputers, light sources, telescopes, particle accelerators, and sensors. In addition, the testbed will allow researchers to explore novel workflows that combine AI methods with simulation and experimental science to accelerate the pace of discovery.</p>"},{"location":"ai-testbed/#how-to-get-access","title":"How to Get Access","text":"<p>Researchers interested in using the AI Testbed\u2019s <code>Cerebras CS-2</code>, <code>SambaNova DataScale SN30</code>, <code>Graphcore Bow Pod64</code> and <code>GroqRack</code> platforms can now submit project proposals via the ALCF\u2019s Director\u2019s Discretionary program. Access to additional testbed resources, including <code>Habana</code> accelerators, will be announced at a later date. </p> <p>Submit your proposal requests at: Allocation Request Page</p>"},{"location":"ai-testbed/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Request a Director's Discretionary project on SambaNova/Cerebras/Graphcore/Groq.</p> </li> <li> <p>Apply for an ALCF account after the project request is approved. Choose the SambaNova/Cerebras/Graphcore/Groq project that your PI has created at ALCF. If you have an active ALCF account, request to join the project after your project is approved.</p> </li> <li> <p>Transfer data to ALCF using Globus after your account has been created.</p> <p>a. The endpoint for your data in ALCF is <code>alcf#ai_testbed_projects</code> with the path to your project being  <code>/&lt;project name&gt;</code>. </p> <p>b. The endpoint for your home directory on the AI Testbeds in ALCF is <code>alcf#ai_testbed_home</code>.</p> </li> <li> <p>Add/invite team members to your ALCF project on SambaNova/Cerebras/Graphcore/Groq. </p> </li> </ol>"},{"location":"ai-testbed/#how-to-contribute-to-documentation","title":"How to Contribute to Documentation","text":"<p>The documentation is based on MkDocs and source files are on GitHub. You can contribute to the documentation by creating a pull request. </p> <p>Learn more on how to contribute to documentation.</p>"},{"location":"ai-testbed/cerebras/","title":"System Overview","text":"<p>The Cerebras CS-3 is a wafer-scale deep learning accelerator comprising 900K processing cores, each providing 48KB of dedicated SRAM memory, with a total of 44GB on-chip memory. Its software platform integrates the popular machine learning framework PyTorch.</p> <p>The ALCF CS-3 Cerebras Wafer-Scale Cluster, is designed to support large-scale models (up to approximatly 200 billion parameters) and large-scale inputs. The cluster contains four CS-3 wafer scale engines (compute nodes), supported by 4 worker nodes, 4 activation servers, 2 sets of 12 MemoryX, and 8 SwarmX nodes. The memoryX nodes(24 in total) are grouped into 2 seperate node groups, 12 nodes, each of 1128Gi configuration used for serving large models up to 200B, and the smaller models use the other set of MemoryX configured with 12 nodes each of 183Gi capacity.</p> <p>The Cerebras Wafer-Scale cluster is run as an appliance: a user submits a job to the appliance, and the appliance manages preprocessing and streaming of the data, IO, and device orchestration within the appliance. It provides programming via PyTorch. This installation supports Weight Streaming execution for models being pre-trained or fine-tuned.</p> <p>The public Cerebras documentation is available here.</p> <p>A typical Cerebras Wafer-Scale Cluster is shown in the figure below. Users connect via SSH to the login node, <code>cerebras.alcf.anl.gov</code> and then ssh to a user node, using either  <code>cer-usn-01</code> or <code>cer-usn-02</code>. </p> <p>The trees <code>/home</code>, <code>/projects</code>, and <code>/software</code> are shared across the login nodes and user nodes, the relevant cluster infrastructure nodes, and all ALCF AI testbed platforms.</p> <p></p> <p>Figure: topology of CS-3 cluster (source)</p> <p>As indicated in the figure, which represent a CS-3 cluster with 4 CS-3 WSE, each of the CS-3 engines (marked at the right end corner of the figure) is responsible only for running and accelerating the computations for training and predictions with the model. The other work, including compilation, is performed on the input nodes, and the MemoryX nodes are used for weight storage and broadcast, and SwarmX nodes are used for gradient accumulation. </p>"},{"location":"ai-testbed/cerebras/csl/","title":"Getting Started with Cerebras CSL","text":"<p>Cerebras CSL (Cerebras System Language) is a low-level kernel programming language designed for the Cerebras system. It enables users to write code that runs on individual Processing Elements (PEs) and to define the placement of programs and the routing of data on the Wafer-Scale Engine (WSE).</p> <p>To develop programs for the Cerebras system, users create two main components:</p> <ol> <li>Device Code: Written in CSL, this code executes directly on the Cerebras system.</li> <li>Host Code: Written in Python, this code leverages Cerebras APIs to facilitate data movement and execute functions on the Cerebras system. CSL includes libraries for a variety of commonly used primitive operations, such as broadcasting, gathering, and scattering data across rows or columns of PEs.</li> </ol> <p>The Cerebras SDK can be utilized in two primary modes: 1. Simulator Mode: For testing and debugging programs without access to physical hardware. 2. Appliance Mode: For executing programs on the actual Cerebras hardware.</p> <p>For a comprehensive overview of the Cerebras SDK, refer to the  Cerebras SDK Documentation.</p>"},{"location":"ai-testbed/cerebras/csl/#sdk-with-simulator","title":"SDK with Simulator","text":"<p>The Cerebras SDK relies on a Singularity container and associated scripts to execute CSL code on a simulator.</p> <p>On a user node, the Cerebras SDK is available at <code>/software/cerebras/cs_sdk</code> for your convenience. You can copy it to your <code>$HOME</code> directory, add it to your <code>$PATH</code>, and you\u2019re ready to get started.</p> <pre><code>cp -r /software/cerebras/cs_sdk-1.4.0 ~\nexport PATH=~/cs_sdk-1.4.0:$PATH\n</code></pre> <p>To verify that the SDK is installed correctly, execute the command: <code>cslc --help</code></p>"},{"location":"ai-testbed/cerebras/csl/#examples","title":"Examples","text":"<p>We will use examples from the <code>csl-examples</code> repository provided by Cerebras. To get these examples, clone the repository into your desired directory:</p> <pre><code>export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\ngit clone https://github.com/Cerebras/csl-examples.git\ncd csl-examples\ngit checkout rel-sdk-1.4.0\ncd ~/csl-examples/benchmarks/gemm-collectives_2d\nbash commands_wse3.sh\n</code></pre> <p>Note: to access any external web resources from a Cerebras user node, you will need to have a proxy environment variable set (or equivalent). <code>wget</code> needs the lower-case proxy environment variable. <pre><code>export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\nexport https_proxy=http://proxy.alcf.anl.gov:3128\n</code></pre></p> Sample output: <pre><code>$ bash commands_wse3.sh\n[INFO] === Beginning compilation ===\n[INFO] Using SIF: ~/cs_sdk-1.4.0/sdk-cbcore-202505010205-2-ef181f81.sif\n[INFO] CSL_IMPORT_PATH is not set\n[INFO] CSL_IMPORT_PATH accepts colon separated list of paths generated by 'realpath &lt;path&gt;'\n[INFO] Compilation successful\n[INFO] === Calling container-hosted python ===\n[INFO] Using SIF: ~/cs_sdk-1.4.0/sdk-cbcore-202505010205-2-ef181f81.sif\nSUCCESS\n</code></pre>"},{"location":"ai-testbed/cerebras/csl/#sdk-gui","title":"SDK GUI","text":"<p>You can use the SDK Debug GUI to analyze and gain insights into your code execution. For detailed instructions, refer to the SDK GUI documentation.</p> <p>To launch the SDK Debug GUI, run the following commands: <pre><code>cd ~/csl-examples/benchmarks/gemm-collectives_2d\nsdk_debug_shell visualize\n</code></pre></p> Sample output: <pre><code>[INFO] Using SIF: /home/vsastry/CS3_system/cs_sdk-1.4.0/sdk-cbcore-202505010205-2-ef181f81.sif\n[INFO] CSL_IMPORT_PATH is not set\n[INFO] CSL_IMPORT_PATH accepts colon separated list of paths generated by 'realpath &lt;path&gt;'\nClick this link to open URL:  http://cer-anl-net001-us-sr01:8000/sdk-gui\nClick this link to open URL:  http://10.125.11.2:8000/sdk-gui\nPress Ctrl-C to exit\n</code></pre> <p>To access the GUI from your local computer, forward port 8000 from the user node through a login node to a local machine port 8008.</p> <p>Adjust one or both port numbers if they are already in use.</p> <p>Example script to forward port 8000 to localhost 8008: <pre><code>export SDK_PORT=8000\nexport LOCAL_PORT=8008\nexport ALCFUserID=&lt;your alcf username&gt;\nssh -L $LOCAL_PORT:localhost:$LOCAL_PORT $ALCFUserID@cer-login-04.ai.alcf.anl.gov -t ssh -L $LOCAL_PORT:localhost:$SDK_PORT -N cer-anl-net001-us-sr01\n</code></pre></p> <p>Then open the following URL in your web browser:  <code>http://localhost:8008/sdk-gui/</code></p> <p></p>"},{"location":"ai-testbed/cerebras/csl/#sdk-with-appliance-mode","title":"SDK with Appliance Mode","text":"<p>Appliance Mode enables running code directly on the Cerebras Wafer-Scale Cluster. In addition to the containerized Singularity build of the Cerebras SDK, the SDK also supports operations on Cerebras Wafer-Scale Clusters running in appliance mode. Please note that the compilation is performed on the worker/management node, hence there might not be enough resourses while compiling a model along with other jobs running. For more information on differences between the simulator code and changes needed to run on appliance, refer to Appliance Mode.</p>"},{"location":"ai-testbed/cerebras/csl/#setup","title":"Setup","text":"<p>Create Virtual Environment: Follow these steps to set up the virtual environment for the Cerebras SDK: <pre><code>rm -r cs_appliance_sdk\ndeactivate\n/usr/bin/python3.11 -m venv cs_appliance_sdk\nsource cs_appliance_sdk/bin/activate\npip install --upgrade pip\n</code></pre></p> <p>Install SDK Packages: Install the <code>cerebras_appliance</code> and <code>cerebras_sdk</code> Python packages in the virtual environment, specifying the appropriate Cerebras Software release: <pre><code>pip install cerebras_appliance==2.6.0\npip install cerebras_sdk==2.6.0\n</code></pre></p>"},{"location":"ai-testbed/cerebras/csl/#examples_1","title":"Examples","text":"<p>We will use examples from the <code>csl-examples</code> repository provided by Cerebras. To access these examples, clone the repository into your desired directory:</p> <pre><code>export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\ngit clone https://github.com/Cerebras/csl-examples.git\ncd csl-examples\ngit checkout rel-sdk-1.4.0\ncd ~/csl-examples/tutorials/gemv-01-complete-program/\n</code></pre>"},{"location":"ai-testbed/cerebras/csl/#compile-code","title":"Compile Code","text":"<p>Use the following <code>appliance_compile.py</code> script to compile the code in the respective example directory:</p> compile.py<pre><code>import json\nfrom cerebras.sdk.client import SdkCompiler\nimport logging\nfrom cerebras.appliance import logger\nlogging.basicConfig(level=logging.INFO)\n\n# Instantiate copmiler using a context manager\n# Disable version check to ignore appliance client and server version differences.\nwith SdkCompiler(disable_version_check=True) as compiler:\n\n    # Launch compile job\n    artifact_path = compiler.compile(\n        \".\",\n        \"layout.csl\",\n        \"--fabric-dims=8,3 --fabric-offsets=4,1 --memcpy --channels=1 -o out\",\n        \".\"\n    )\n\n# Write the artifact_path to a JSON file\nwith open(\"artifact_path.json\", \"w\", encoding=\"utf8\") as f:\n    json.dump({\"artifact_path\": artifact_path,}, f)\n</code></pre> Sample output: <pre><code>$ python appliance_compile.py\nINFO:cerebras.cluster.client:Appliance client semantic version: 1.1.0, cluster server semantic version: 1.1.2, job operator semantic version: 1.1.2\nINFO:cerebras.cluster.client:Initiating a new SDK compile job against the cluster server\nINFO:cerebras.cluster.client:Job id: wsjob-4mhdefdzswskmakfcp9hfe, workflow id: wflow-2ullyamqmrdi7nxodyl6f77xbi, namespace: job-operator, remote log path:\n/n1/wsjob/workdir/job-operator/wsjob-4mhdefdzswskmakfcp9hfe\nINFO:cerebras.cluster.client:Poll ingress status: Waiting for all Coordinator pods to be running, current running: 0/1.\nINFO:cerebras.cluster.client:Recording the timestamp when jobs is scheduled.\nWARNING:cerebras.cluster.client:Event 2025-10-23 19:49:54 +0000 UTC reason=InconsistentVersion wsjob=wsjob-4mhdefdzswskmakfcp9hfe message='Warning: client semantic         version 1.1.0 is inconsistent with cluster server semantic version 1.1.2, there's a risk job could fail due to inconsistent setup.'\nINFO:cerebras.cluster.client:Poll ingress status: Waiting for job ingress readiness.\nINFO:cerebras.cluster.client:Poll ingress status: Job ingress ready, dashboard: https://grafana.anl0.cerebras.internal/d/WebHNShVz/wsjob-dashboard?orgId=1&amp;var-wsjob=wsjob-\n4mhdefdzswskmakfcp9hfe&amp;from=1761248404000&amp;to=now\nINFO:cerebras.cluster.client:Poll ingress success: Job ingress ready, dashboard: https://grafana.anl0.cerebras.internal/d/WebHNShVz/wsjob-dashboard?orgId=1&amp;var-\nwsjob=wsjob-4mhdefdzswskmakfcp9hfe&amp;from=1761248404000&amp;to=now\n2025-10-23 19:50:44,583 INFO     CSL compiler output:\nCSL compiler produced no messages. Compilation successful.\nINFO:cerebras.sdk.client.sdk_appliance_client:CSL compiler output:\nCSL compiler produced no messages. Compilation successful. \n</code></pre> <p>The only difference between CS-3 and simuator run is the <code>fabric_dims</code>. It should be set to minimum required for simulatored runs. Above script generates <code>artifact.json</code> which is used by the <code>appliance_run.py</code> script.</p>"},{"location":"ai-testbed/cerebras/csl/#run-code","title":"Run Code","text":"<p>Use the following <code>appliance_run.py</code> script to run the code in the respective example directory:</p> run.py<pre><code>#!/usr/bin/env cs_python\n\nimport argparse\nimport numpy as np\nimport json\n#from cerebras.sdk.runtime.sdkruntimepybind import SdkRuntime, MemcpyDataType, MemcpyOrder # pylint: disable=no-name-in-module\nimport logging\nfrom cerebras.appliance import logger\nlogging.basicConfig(level=logging.INFO)\n\nfrom cerebras.appliance.pb.sdk.sdk_common_pb2 import MemcpyDataType, MemcpyOrder\nfrom cerebras.sdk.client import SdkRuntime\n\n# Matrix dimensions\nM = 4\nN = 6\n\n# Construct A, x, b\nA = np.arange(M*N, dtype=np.float32).reshape(M, N)\nx = np.full(shape=N, fill_value=1.0, dtype=np.float32)\nb = np.full(shape=M, fill_value=2.0, dtype=np.float32)\n\n# Calculate expected y\ny_expected = A@x + b\n\n# Read the artifact_path from the JSON file\nwith open(\"artifact_path.json\", \"r\", encoding=\"utf8\") as f:\n    data = json.load(f)\n    artifact_path = data[\"artifact_path\"]\n\nwith SdkRuntime(artifact_path, simulator=True, disable_version_check=True) as runner:\n    # Launch the init_and_compute function on device\n    runner.launch('init_and_compute', nonblock=False)\n\n    # Copy y back from device\n    y_symbol = runner.get_id('y')\n    y_result = np.zeros([1*1*M], dtype=np.float32)\n    runner.memcpy_d2h(y_result, y_symbol, 0, 0, 1, 1, M, streaming=False,\n    order=MemcpyOrder.ROW_MAJOR, data_type=MemcpyDataType.MEMCPY_32BIT, nonblock=False)\n# Ensure that the result matches our expectation\nnp.testing.assert_allclose(y_result, y_expected, atol=0.01, rtol=0)\nprint(\"SUCCESS!\")\n</code></pre> Sample output: <pre><code>$ python appliance_run.py\nINFO:cerebras.cluster.client:Appliance client semantic version: 1.1.0, cluster server semantic version: 1.1.2, job operator semantic version: 1.1.2\nINFO:cerebras.cluster.client:Initiating a new SDK compile job against the cluster server\nINFO:cerebras.cluster.client:Job id: wsjob-qqcsg8g5z66nknmk4d48gp, workflow id: wflow-kcrf2anv7zconl7xq2idceztdq, namespace: job-operator, remote log path:\n/n1/wsjob/workdir/job-operator/wsjob-qqcsg8g5z66nknmk4d48gp\nINFO:cerebras.cluster.client:Poll ingress status: Waiting for all Coordinator pods to be running, current running: 0/1.\nINFO:cerebras.cluster.client:Recording the timestamp when jobs is scheduled.\nWARNING:cerebras.cluster.client:Event 2025-10-23 19:54:55 +0000 UTC reason=InconsistentVersion wsjob=wsjob-qqcsg8g5z66nknmk4d48gp message='Warning: client semantic version    1.1.0 is inconsistent with cluster server semantic version 1.1.2, there's a risk job could fail due to inconsistent setup.'\nINFO:cerebras.cluster.client:Poll ingress status: Waiting for job ingress readiness.\nINFO:cerebras.cluster.client:Poll ingress status: Job ingress ready, dashboard: https://grafana.anl0.cerebras.internal/d/WebHNShVz/wsjob-dashboard?orgId=1&amp;var-wsjob=wsjob-    qqcsg8g5z66nknmk4d48gp&amp;from=1761248705000&amp;to=now\nINFO:cerebras.cluster.client:Poll ingress success: Job ingress ready, dashboard: https://grafana.anl0.cerebras.internal/d/WebHNShVz/wsjob-dashboard?orgId=1&amp;var-\nwsjob=wsjob-   qqcsg8g5z66nknmk4d48gp&amp;from=1761248705000&amp;to=now\nSUCCESS!\n</code></pre>"},{"location":"ai-testbed/cerebras/customizing-environment/","title":"Customizing Environments","text":""},{"location":"ai-testbed/cerebras/customizing-environment/#using-virtual-python-environments","title":"Using virtual Python environments","text":""},{"location":"ai-testbed/cerebras/customizing-environment/#to-make-a-pytorch-virtual-environment-for-cerebras","title":"To make a PyTorch virtual environment for Cerebras","text":"<p>Clone the Cerebras modelzoo, if it is not already cloned. Check out the R 2.6.0 release.</p> <p><pre><code>mkdir ~/R_2.6.0\ncd ~/R_2.6.0\nexport HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\ngit clone https://github.com/Cerebras/modelzoo.git\ncd modelzoo\ngit tag\ngit checkout Release_2.6.0\n</code></pre> Note: a <code>git pull</code> will not update the tags; if <code>modelzoo/setup.py</code> does not exist after tag checkout, please re-clone <code>modelzoo</code>.</p> <p>Note: to access any external resources from a Cerebras user node, you will need to have a proxy environment variable set (or equivalent). <code>wget</code> needs the lower-case proxy environment variable. <pre><code>export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\nexport https_proxy=http://proxy.alcf.anl.gov:3128\n</code></pre></p> <p>Then build the virtual environment</p> <pre><code>mkdir ~/R_2.6.0\ncd ~/R_2.6.0\n# Note: \"deactivate\" does not actually work in scripts.\ndeactivate\nrm -r venv_cerebras_pt\n/usr/bin/python3.11 -m venv venv_cerebras_pt\nsource venv_cerebras_pt/bin/activate\npip install --upgrade pip\npip install -e modelzoo\n</code></pre>"},{"location":"ai-testbed/cerebras/customizing-environment/#activation-and-deactivation","title":"Activation and deactivation","text":"<p>To activate a virtual environment</p> <pre><code>source ~/R_2.6.0/venv_cerebras_pt/bin/activate\n</code></pre> <p>To deactivate a virtual environment,</p> <pre><code>deactivate\n</code></pre>"},{"location":"ai-testbed/cerebras/example-programs/","title":"Example Programs","text":""},{"location":"ai-testbed/cerebras/example-programs/#use-a-local-copy-of-the-model-zoo","title":"Use a local copy of the model zoo","text":"<p>Make a working directory and a local copy of the Cerebras modelzoo repository, if not previously done, as follows.</p> <pre><code>mkdir ~/R_2.6.0\ncd ~/R_2.6.0\nexport HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\ngit clone https://github.com/Cerebras/modelzoo.git\ncd modelzoo\ngit tag\ngit checkout Release_2.6.0\n</code></pre> <p>Note: to access any external web resources from a Cerebras user node, you will need to have a proxy environment variable set (or equivalent). <code>wget</code> needs the lower-case proxy environment variable. <pre><code>export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\nexport https_proxy=http://proxy.alcf.anl.gov:3128\n</code></pre></p> <p>For all of these samples, if you want the training to use more than one CS3, either</p> <ul> <li>add <code>--num_csx=2</code> (or 3 or 4) to the <code>cszoo fit</code> command line, or</li> <li>add \"trainer.init.backend.cluster_config.num_csx: 2\" (or 3 or 4) to the config yaml, e.g. <pre><code>trainer:\n  init:\n    backend:\n      backend_type: CSX\n      cluster_config:\n        num_csx: 2\n</code></pre> Switching to the data parallel mode will force a one-time recompile (with compile artifacts cached). </li> </ul> <p>Note : The Cerebras CS3 cluster has 2 sets of MemX. One the larger memory group inteded for larger models (12 nodes of 1128Gi memory) and another smaller memX group ((12 nodes of 183Gi memory). Each memX node group can only be associated to a given job, hence we can have a maximum of 2 training jobs. So we encourage users to use distributed training for better utilization of resources and faster training. </p>"},{"location":"ai-testbed/cerebras/example-programs/#bert-pytorch","title":"BERT - PyTorch","text":"<p>The modelzoo/modelzoo/transformers/pytorch/bert directory is a PyTorch implementation of BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding This BERT-large msl128 example uses a single sample dataset for both training and evaluation. See the README.md in the source directory for details on how to build a dataset from text input. First, source a Cerebras PyTorch virtual environment.</p> <pre><code>source ~/R_2.6.0/venv_cerebras_pt/bin/activate\n</code></pre> <p>Then</p> <pre><code>cd ~/R_2.6.0/modelzoo/src/cerebras/modelzoo/models/nlp/bert\ncp /software/cerebras/dataset/bert_large/bert_large_MSL128_sampleds.yaml configs/bert_large_MSL128_sampleds.yaml\nexport MODEL_DIR=model_dir_bert_large_pytorch\nif [ -d \"$MODEL_DIR\" ]; then rm -Rf $MODEL_DIR; fi\ncszoo fit configs/bert_large_MSL128_sampleds.yaml --job_labels name=bert_pt --model_dir $MODEL_DIR |&amp; tee mytest.log\n</code></pre> <p>Note: the vocabulary file referenced in <code>/software/cerebras/dataset/bert_large/bert_large_MSL128_sampleds.yaml</code> is the same as the one at <code>/home/$(whoami)/R_2.6.0/modelzoo/src/cerebras/modelzoo/models/vocab/google_research_uncased_L-12_H-768_A-12.txt</code>. </p> <p>The last parts of the output should resemble the following, with messages about cuda that should be ignored and are not shown.</p> <pre><code>2025-10-09 18:43:37,688 INFO:   Beginning appliance run\n2025-10-09 18:43:41,110 INFO:   | Eval Device=CSX, GlobalStep=1000, Batch=100, Loss=7.08926, Rate=7796.80 samples/sec, GlobalRate=7499.90 samples/sec, LoopTimeRemaining=0:00:04, TimeRemaining=0:00:04\n2025-10-09 18:43:45,277 INFO:   | Eval Device=CSX, GlobalStep=1000, Batch=200, Loss=7.13253, Rate=5099.83 samples/sec, GlobalRate=6754.66 samples/sec, LoopTimeRemaining=0:00:01, TimeRemaining=0:00:01\n2025-10-09 18:43:46,146 INFO:   | Eval Device=CSX, GlobalStep=1000, Batch=220, Loss=6.98112, Rate=6014.04 samples/sec, GlobalRate=6665.64 samples/sec, LoopTimeRemaining=0:00:00, TimeRemaining=0:00:00\n2025-10-09 18:44:08,969 INFO:   Avg Eval Loss: 6.981118208711798\n2025-10-09 18:44:08,986 INFO:   Evaluation metrics:\n2025-10-09 18:44:08,986 INFO:     - eval/accuracy_cls = 0.7051668763160706\n2025-10-09 18:44:08,986 INFO:     - eval/accuracy_masked_lm = 0.13364547491073608\n2025-10-09 18:44:08,986 INFO:     - eval/mlm_perplexity = 701.6852416992188\n2025-10-09 18:44:08,986 INFO:   Evaluation completed successfully!\n2025-10-09 18:44:08,992 INFO:   Processed 3720000 training sample(s) in 1017.47348681 seconds.\n</code></pre>"},{"location":"ai-testbed/cerebras/example-programs/#gpt-j-pytorch","title":"GPT-J PyTorch","text":"<p>GPT-J [github] is an auto-regressive language model created by EleutherAI. This PyTorch GPT-J 6B parameter pretraining sample uses 1 CS3.</p> <p>First, source a Cerebras PyTorch virtual environment.</p> <pre><code>source ~/R_2.6.0/venv_cerebras_pt/bin/activate\n</code></pre> <p>Then</p> <pre><code>cd ~/R_2.6.0/modelzoo/src/cerebras/modelzoo/models/nlp/gptj\ncp /software/cerebras/dataset/gptj/params_gptj_6B_sampleds.yaml configs/params_gptj_6B_sampleds.yaml\nexport MODEL_DIR=model_dir_gptj\nif [ -d \"$MODEL_DIR\" ]; then rm -Rf $MODEL_DIR; fi\ncszoo fit configs/params_gptj_6B_sampleds.yaml --job_labels name=gptj --model_dir $MODEL_DIR |&amp; tee mytest.log\n</code></pre> <p>Note: the validation has been commented out of the yaml to decrease the run time of this sample. To run validation, uncomment the validation sections at the end of <code>configs/params_gptj_6B_sampleds.yaml</code>. </p> <p>The last parts of the output should resemble the following:</p> <pre><code>2025-10-10 20:03:38,180 INFO:   Beginning appliance run\n2025-10-10 20:05:52,476 INFO:   | Train Device=CSX, Step=50, Loss=9.44598, Rate=44.84 samples/sec, GlobalRate=44.70 samples/sec, LoopTimeRemaining=0:06:42, TimeRemaining&gt;0:06:42\n2025-10-10 20:08:06,526 INFO:   | Train Device=CSX, Step=100, Loss=8.34360, Rate=45.03 samples/sec, GlobalRate=44.73 samples/sec, LoopTimeRemaining=0:04:28, TimeRemaining&gt;0:04:28\n2025-10-10 20:10:20,442 INFO:   | Train Device=CSX, Step=150, Loss=8.21114, Rate=45.11 samples/sec, GlobalRate=44.75 samples/sec, LoopTimeRemaining=0:02:14, TimeRemaining&gt;0:02:14\n2025-10-10 20:12:34,522 INFO:   | Train Device=CSX, Step=200, Loss=8.01509, Rate=44.77 samples/sec, GlobalRate=44.75 samples/sec, LoopTimeRemaining=0:00:00, TimeRemaining&gt;0:00:00\n2025-10-10 20:12:34,527 INFO:   Saving checkpoint at step 200\n2025-10-10 20:20:51,668 INFO:   Saved checkpoint model_dir_gptj/checkpoint_200.mdl\n2025-10-10 20:21:14,280 INFO:   Training completed successfully!\n2025-10-10 20:21:14,286 INFO:   Processed 24000 training sample(s) in 1443.67300221 seconds.\n/home/arnoldw/R_2.6.0/venv_cerebras_pt/lib/python3.8/site-packages/pydantic/_internal/_gener\n</code></pre>"},{"location":"ai-testbed/cerebras/example-programs/#llama2-7b","title":"Llama2-7B","text":"<p>The Cerebras llama2 7B model implementation can be found at modelzoo/modelzoo/transformers/pytorch/llama and its overview at https://github.com/Cerebras/modelzoo/blob/main/src/cerebras/modelzoo/models/nlp/llama/README.md. This set up will use a subset of pile data (preprocessed at path /software/datasets/llama_data_32K/) to train with a 32K vocab size. </p> <p>First, source a Cerebras PyTorch virtual environment. <pre><code>source ~/R_2.6.0/venv_cerebras_pt/bin/activate\n</code></pre> Instructions for training: <pre><code>cd ~/R_2.6.0/modelzoo/src/cerebras/modelzoo/models/nlp/llama\ncp /software/cerebras/dataset/params_llama2_7b.yaml configs/params_llama2_7b.yaml\nexport MODEL_DIR=model_dir_llama2_7b\nif [ -d \"$MODEL_DIR\" ]; then rm -Rf $MODEL_DIR; fi\ncszoo fit configs/params_llama2_7b.yaml --job_labels name=llama2_7b --model_dir model_dir_llama2_7b |&amp; tee mytest.log\n</code></pre></p> <p>Note: the validation has been commented out of the yaml to decrease the run time of this sample. To run validation, uncomment the validation sections at the end of <code>configs/params_llama2_7b.yaml</code>. </p> <p>Please find a sample output <pre><code>2025-10-13 14:47:37,651 INFO:   Found existing cached compile with hash: \"cs_16053036657376785725\"\n2025-10-13 14:47:41,091 INFO:   Compile artifacts successfully written to remote compile directory. Compile hash is: cs_16053036657376785725\n2025-10-13 14:47:46,918 INFO:   Compile was successful!\n2025-10-13 14:47:46,918 INFO:   Waiting for weight initialization to complete\n2025-10-13 14:47:46,918 INFO:   Programming Cerebras Wafer Scale Cluster for execution. This may take a few minutes.\n2025-10-13 14:47:49,008 INFO:   Initiating a new execute wsjob against the cluster server.\n2025-10-13 14:47:49,037 INFO:   Job id: wsjob-kgqvqqxnp9zvpmwulcbxuj, workflow id: wflow-cxj2gwf7idcfanryokatnn, namespace: job-operator, remote log path: /n1/wsjob/workdir/job-operator/wsjob-kgqvqqxnp9zvpmwulcbxuj\n2025-10-13 14:48:09,058 INFO:   Poll ingress status: Waiting for all Activation pods to be running, current running: 0/24.\n2025-10-13 14:48:09,078 WARNING:   Event 2025-10-13 14:47:50 +0000 UTC reason=InconsistentVersion wsjob=wsjob-kgqvqqxnp9zvpmwulcbxuj message='Warning: job image version 2.5.1-202507111115-6-48e76807 is inconsistent with cluster server version 3.0.1-202508200300-150-bba1322a+bba1322aed, there's a risk job could fail due to inconsistent setup.'\n2025-10-13 14:48:19,088 INFO:   Poll ingress status: Waiting for all Weight pods to be running, current running: 17/18.\n2025-10-13 14:48:29,112 INFO:   Poll ingress status: Waiting for job ingress readiness.\n2025-10-13 14:48:39,135 INFO:   Poll ingress status: Job ingress ready, dashboard: https://grafana.anl0.cerebras.internal/d/WebHNShVz/wsjob-dashboard?orgId=1&amp;var-wsjob=wsjob-kgqvqqxnp9zvpmwulcbxuj&amp;from=1760366287000&amp;to=now\n2025-10-13 14:48:39,149 INFO:   Poll ingress success: Job ingress ready, dashboard: https://grafana.anl0.cerebras.internal/d/WebHNShVz/wsjob-dashboard?orgId=1&amp;var-wsjob=wsjob-kgqvqqxnp9zvpmwulcbxuj&amp;from=1760366287000&amp;to=now\n2025-10-13 14:48:39,240 INFO:   Preparing to execute using 1 CSX\n2025-10-13 14:49:14,926 INFO:   About to send initial weights\n2025-10-13 14:49:28,149 INFO:   Finished sending initial weights\n2025-10-13 14:49:28,150 INFO:   Finalizing appliance staging for the run\n2025-10-13 14:49:28,158 INFO:   Waiting for device programming to complete\n2025-10-13 14:53:20,585 INFO:   Device programming is complete\n2025-10-13 14:53:21,628 INFO:   Using network type: ROCE\n2025-10-13 14:53:21,629 INFO:   Waiting for input workers to prime the data pipeline and begin streaming ...\n2025-10-13 14:53:21,637 INFO:   Input workers have begun streaming input data\n2025-10-13 14:53:22,791 INFO:   Appliance staging is complete\n2025-10-13 14:53:22,791 INFO:   Beginning appliance run\n2025-10-13 15:20:04,385 INFO:   | Train Device=CSX, Step=50, Loss=7.67126, Rate=31.97 samples/sec, GlobalRate=31.97 samples/sec, LoopTimeRemaining=1:20:41, TimeRemaining=1:20:41\n2025-10-13 15:46:44,894 INFO:   | Train Device=CSX, Step=100, Loss=7.05889, Rate=31.98 samples/sec, GlobalRate=31.98 samples/sec, LoopTimeRemaining=0:54:01, TimeRemaining=0:54:01\n2025-10-13 16:13:25,156 INFO:   | Train Device=CSX, Step=150, Loss=6.53423, Rate=31.99 samples/sec, GlobalRate=31.98 samples/sec, LoopTimeRemaining=0:27:20, TimeRemaining=0:27:20\n2025-10-13 16:40:05,444 INFO:   | Train Device=CSX, Step=200, Loss=6.09834, Rate=31.97 samples/sec, GlobalRate=31.99 samples/sec, LoopTimeRemaining=0:00:40, TimeRemaining=0:00:40\n2025-10-13 16:40:05,450 INFO:   Saving checkpoint at step 200\n2025-10-13 16:47:49,916 INFO:   Saved checkpoint model_dir_llama2_7b/checkpoint_200.mdl\n2025-10-13 16:48:01,419 INFO:   Training completed successfully!\n2025-10-13 16:48:01,425 INFO:   Processed 204800 training sample(s) in 7303.586917439 seconds.\n</code></pre></p>"},{"location":"ai-testbed/cerebras/example-programs/#esm-2","title":"ESM-2","text":"<p>Evolutionary Scale Modeling (ESM-2) is a transformer protein language models from the Meta Fundamental AI Research Protein Team (FAIR).  The Cerebras ESM-2 model implementation can be found at <code>modelzoo/src/cerebras/modelzoo/models/nlp/esm2</code>. Configs available are listed at https://github.com/Cerebras/modelzoo/tree/main/src/cerebras/modelzoo/models/nlp/esm2. This example will use the Uniref 50 dataset, preprocessed at path /software/datasets/ESM-2/, to train a small 35M parameter model.</p> <p>First, source a Cerebras PyTorch virtual environment. <pre><code>source ~/R_2.6.0/venv_cerebras_pt/bin/activate\n</code></pre> Instructions for training (for 400 steps): <pre><code>cd ~/R_2.6.0/modelzoo/src/cerebras/modelzoo/models/nlp/esm2\ncp /software/cerebras/dataset/ESM-2/params_esm2_t12_35M_UR50D_modified.yaml configs/params_esm2_t12_35M_UR50D_modified.yaml\nexport MODEL_DIR=model_dir_esm2\nif [ -d \"$MODEL_DIR\" ]; then rm -Rf $MODEL_DIR; fi\ncszoo fit configs/params_esm2_t12_35M_UR50D_modified.yaml --job_labels name=esm2_t12_35m --model_dir $MODEL_DIR |&amp; tee mytest.log\n</code></pre></p> <p>Note: the validation has been commented out of the yaml to decrease the run time of this sample. To run validation, uncomment the validation sections at the end of <code>configs/params_esm2_t12_35M_UR50D_modified.yaml</code>. </p> <p>Sample output for the end of a training run: <pre><code>2025-10-10 23:27:10,382 INFO:   Preparing to execute using 1 CSX\n2025-10-10 23:27:38,459 INFO:   About to send initial weights\nSending initial weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1007/1007 [00:02&lt;00:00, 372.15 tensors/s]\n2025-10-10 23:27:41,174 INFO:   Finished sending initial weights\n2025-10-10 23:27:41,174 INFO:   Finalizing appliance staging for the run\n2025-10-10 23:27:51,718 INFO:   Waiting for device programming to complete\n2025-10-10 23:31:56,190 INFO:   Device programming is complete\n2025-10-10 23:31:56,990 INFO:   Using network type: ROCE\n2025-10-10 23:31:56,991 INFO:   Waiting for input workers to prime the data pipeline and begin streaming ...\n2025-10-10 23:31:56,998 INFO:   Input workers have begun streaming input data\n2025-10-10 23:31:58,155 INFO:   Appliance staging is complete\n2025-10-10 23:31:58,155 INFO:   Beginning appliance run\n2025-10-10 23:35:19,797 INFO:   | Train Device=CSX, Step=100, Loss=14.50902, Rate=982.39 samples/sec, GlobalRate=1015.86 samples/sec, LoopTimeRemaining=0:10:25, TimeRemaining=0:10:25\n2025-10-10 23:38:48,278 INFO:   | Train Device=CSX, Step=200, Loss=26.60854, Rate=976.56 samples/sec, GlobalRate=998.82 samples/sec, LoopTimeRemaining=0:07:01, TimeRemaining=0:07:01\n2025-10-10 23:38:48,282 INFO:   Saving checkpoint at step 200\nSaving checkpoint: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1321/1321 [00:09&lt;00:00, 146.24 tensors/s]\n2025-10-10 23:38:57,339 INFO:   Saved checkpoint model_dir_esm2/checkpoint_200.mdl\n2025-10-10 23:42:17,143 INFO:   | Train Device=CSX, Step=300, Loss=7.57249, Rate=999.04 samples/sec, GlobalRate=992.65 samples/sec, LoopTimeRemaining=0:03:36, TimeRemaining=0:03:36\n2025-10-10 23:45:46,409 INFO:   | Train Device=CSX, Step=400, Loss=5.03271, Rate=974.58 samples/sec, GlobalRate=989.11 samples/sec, LoopTimeRemaining=0:00:08, TimeRemaining=0:00:08\n2025-10-10 23:45:46,412 INFO:   Saving checkpoint at step 400\nSaving checkpoint: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1321/1321 [00:08&lt;00:00, 154.35 tensors/s]\n2025-10-10 23:45:54,994 INFO:   Saved checkpoint model_dir_esm2/checkpoint_400.mdl\n2025-10-10 23:46:01,812 INFO:   Training completed successfully!\n2025-10-10 23:46:01,861 INFO:   Processed 819200 training sample(s) in 4049.286902367 seconds.\n</code></pre></p>"},{"location":"ai-testbed/cerebras/example-programs/#vision-transformer","title":"Vision Transformer","text":"<p>The cerebras transformer based vision classifier model implementation can be found at <code>modelzoo/models/vision/vision_transformer</code>. Configs for base and huge model of the vision transformer can be found at <code>modelzoo/models/vision/vision_transformer/configs</code>. This examples uses the ImageNet dataset preprocessed at path <code>/software/datasets/imagenet/</code>. </p> <p>First, source a Cerebras PyTorch virtual environment. <pre><code>source ~/R_2.6.0/venv_cerebras_pt/bin/activate\n</code></pre> Instructions for training (for 400 steps): <pre><code>cd ~/R_2.6.0/modelzoo/src/cerebras/modelzoo/models/vision/vision_transformer\ncp /software/cerebras/dataset/vision_transformer/params_vit_base_patch_16_imagenet_1k.yaml configs/params_vit_base_patch_16_imagenet_1k.yaml\nexport MODEL_DIR=model_dir_vit\nif [ -d \"$MODEL_DIR\" ]; then rm -Rf $MODEL_DIR; fi\ncszoo fit configs/params_vit_base_patch_16_imagenet_1k.yaml --job_labels name=vision_transformer --model_dir $MODEL_DIR |&amp; tee mytest.log\n</code></pre></p> <p>Note: the validation has been commented out of the yaml to decrease the run time of this sample. To run validation, uncomment the validation sections at the end of <code>configs/params_vit_base_patch_16_imagenet_1k.yaml</code>. </p> <p>Sample output <pre><code>2025-10-13 15:06:45,407 INFO:   Preparing to execute using 1 CSX\n2025-10-13 15:07:20,175 INFO:   About to send initial weights\n2025-10-13 15:07:22,937 INFO:   Finished sending initial weights\n2025-10-13 15:07:22,937 INFO:   Finalizing appliance staging for the run\n2025-10-13 15:07:33,129 INFO:   Waiting for device programming to complete\n2025-10-13 15:10:54,091 INFO:   Device programming is complete\n2025-10-13 15:10:54,879 INFO:   Using network type: ROCE\n2025-10-13 15:10:54,880 INFO:   Waiting for input workers to prime the data pipeline and begin streaming ...\n2025-10-13 16:12:33,699 INFO:   Input workers have begun streaming input data\n2025-10-13 16:12:34,880 INFO:   Appliance staging is complete\n2025-10-13 16:12:34,880 INFO:   Beginning appliance run\n2025-10-13 16:13:05,769 INFO:   | Train Device=CSX, Step=10, Loss=7.01967, Rate=3323.47 samples/sec, GlobalRate=923.35 samples/sec, LoopTimeRemaining=0:02:50, TimeRemaining&gt;0:02:50\n2025-10-13 16:13:37,520 INFO:   | Train Device=CSX, Step=20, Loss=7.03421, Rate=4452.76 samples/sec, GlobalRate=910.30 samples/sec, LoopTimeRemaining=0:02:40, TimeRemaining&gt;0:02:40\n2025-10-13 16:14:20,867 INFO:   | Train Device=CSX, Step=30, Loss=6.99693, Rate=3553.07 samples/sec, GlobalRate=806.87 samples/sec, LoopTimeRemaining=0:02:31, TimeRemaining&gt;0:02:31\n2025-10-13 16:14:53,830 INFO:   | Train Device=CSX, Step=40, Loss=6.99418, Rate=3840.05 samples/sec, GlobalRate=820.58 samples/sec, LoopTimeRemaining=0:02:22, TimeRemaining&gt;0:02:22\n2025-10-13 16:15:35,551 INFO:   | Train Device=CSX, Step=50, Loss=6.97215, Rate=3422.33 samples/sec, GlobalRate=788.82 samples/sec, LoopTimeRemaining=0:02:13, TimeRemaining&gt;0:02:13\n2025-10-13 16:16:11,445 INFO:   | Train Device=CSX, Step=60, Loss=6.94876, Rate=3656.17 samples/sec, GlobalRate=789.69 samples/sec, LoopTimeRemaining=0:02:04, TimeRemaining&gt;0:02:04\n2025-10-13 16:16:49,841 INFO:   | Train Device=CSX, Step=70, Loss=6.93128, Rate=3559.48 samples/sec, GlobalRate=782.54 samples/sec, LoopTimeRemaining=0:01:55, TimeRemaining&gt;0:01:55\n2025-10-13 16:17:26,243 INFO:   | Train Device=CSX, Step=80, Loss=6.90232, Rate=3577.28 samples/sec, GlobalRate=782.59 samples/sec, LoopTimeRemaining=0:01:47, TimeRemaining&gt;0:01:47\n2025-10-13 16:18:04,947 INFO:   | Train Device=CSX, Step=90, Loss=6.87604, Rate=3509.24 samples/sec, GlobalRate=777.17 samples/sec, LoopTimeRemaining=0:01:38, TimeRemaining&gt;0:01:38\n2025-10-13 16:18:40,674 INFO:   | Train Device=CSX, Step=100, Loss=6.88127, Rate=3464.33 samples/sec, GlobalRate=779.18 samples/sec, LoopTimeRemaining=0:02:27, TimeRemaining&gt;0:02:27\n2025-10-13 16:18:40,675 INFO:   Saving checkpoint at step 100\n2025-10-13 16:18:50,127 INFO:   Saved checkpoint model_dir_vt/checkpoint_100.mdl\n2025-10-13 16:19:18,509 INFO:   | Train Device=CSX, Step=110, Loss=6.83729, Rate=3563.66 samples/sec, GlobalRate=776.75 samples/sec, LoopTimeRemaining=0:02:24, TimeRemaining=0:02:24\n2025-10-13 16:19:54,432 INFO:   | Train Device=CSX, Step=120, Loss=6.83568, Rate=3391.11 samples/sec, GlobalRate=778.10 samples/sec, LoopTimeRemaining=0:02:11, TimeRemaining=0:02:11\n2025-10-13 16:20:33,376 INFO:   | Train Device=CSX, Step=130, Loss=6.82097, Rate=3353.04 samples/sec, GlobalRate=774.34 samples/sec, LoopTimeRemaining=0:02:31, TimeRemaining=0:02:31\n2025-10-13 16:21:08,460 INFO:   | Train Device=CSX, Step=140, Loss=6.79739, Rate=3460.46 samples/sec, GlobalRate=776.93 samples/sec, LoopTimeRemaining=0:03:17, TimeRemaining=0:03:17\n2025-10-13 16:21:47,396 INFO:   | Train Device=CSX, Step=150, Loss=6.81461, Rate=3506.94 samples/sec, GlobalRate=773.76 samples/sec, LoopTimeRemaining=0:04:04, TimeRemaining=0:04:04\n2025-10-13 16:22:22,052 INFO:   | Train Device=CSX, Step=160, Loss=6.79879, Rate=3682.37 samples/sec, GlobalRate=776.63 samples/sec, LoopTimeRemaining=0:03:18, TimeRemaining=0:03:18\n2025-10-13 16:23:01,143 INFO:   | Train Device=CSX, Step=170, Loss=6.78811, Rate=3508.37 samples/sec, GlobalRate=773.67 samples/sec, LoopTimeRemaining=0:02:32, TimeRemaining=0:02:32\n2025-10-13 16:23:35,510 INFO:   | Train Device=CSX, Step=180, Loss=6.76097, Rate=3724.78 samples/sec, GlobalRate=776.56 samples/sec, LoopTimeRemaining=0:01:44, TimeRemaining=0:01:44\n2025-10-13 16:24:15,017 INFO:   | Train Device=CSX, Step=190, Loss=6.75542, Rate=3495.95 samples/sec, GlobalRate=773.45 samples/sec, LoopTimeRemaining=0:00:58, TimeRemaining=0:00:58\n2025-10-13 16:24:49,239 INFO:   | Train Device=CSX, Step=200, Loss=6.72418, Rate=3690.48 samples/sec, GlobalRate=776.21 samples/sec, LoopTimeRemaining=0:00:14, TimeRemaining=0:00:14\n2025-10-13 16:24:49,240 INFO:   Saving checkpoint at step 200\n2025-10-13 16:24:58,829 INFO:   Saved checkpoint model_dir_vt/checkpoint_200.mdl\n2025-10-13 16:25:08,411 INFO:   Training completed successfully!\n2025-10-13 16:25:08,416 INFO:   Processed 570000 training sample(s) in 5447.945427605 seconds.\n</code></pre></p>"},{"location":"ai-testbed/cerebras/example-programs/#diffusion-transformer","title":"Diffusion Transformer","text":"<p>The Cerebras Diffusion Transformer[1] model implementation can be found at <code>modelzoo/src/cerebras/modelzoo/models/vision/dit</code>. Three configs, for the large and xlarge models in the paper, and for a larger model, can be found in <code>modelzoo/src/cerebras/modelzoo/models/vision/dit/configs</code>. This example uses the ImageNet dataset, preprocessed at path <code>/software/cerebras/dataset/dit/</code>, and the config for the largest model.</p> <p>First, source a Cerebras PyTorch virtual environment. <pre><code>source ~/R_2.6.0/venv_cerebras_pt/bin/activate\n</code></pre></p> <p>Instructions for training (for 400 steps): <pre><code>cd ~/R_2.6.0/modelzoo/src/cerebras/modelzoo/models/vision/dit\ncp /software/cerebras/dataset/params_dit_2B_patchsize_2x2_modified.yaml configs/params_dit_2B_patchsize_2x2_modified.yaml\nexport MODEL_DIR=model_dir_dit\nif [ -d \"$MODEL_DIR\" ]; then rm -Rf $MODEL_DIR; fi\ncszoo fit configs/params_dit_2B_patchsize_2x2_modified.yaml --job_labels name=DiT --model_dir $MODEL_DIR |&amp; tee mytest.log\n</code></pre></p> Example output: <pre><code>2025-10-13 20:54:50,747 INFO:   Preparing to execute using 1 CSX\n2025-10-13 20:55:27,795 INFO:   About to send initial weights\n2025-10-13 20:55:33,946 INFO:   Finished sending initial weights\n2025-10-13 20:55:33,946 INFO:   Finalizing appliance staging for the run\n2025-10-13 20:55:41,002 INFO:   Waiting for device programming to complete\n2025-10-13 20:59:42,391 INFO:   Device programming is complete\n2025-10-13 20:59:43,763 INFO:   Using network type: ROCE\n2025-10-13 20:59:43,763 INFO:   Waiting for input workers to prime the data pipeline and begin streaming ...\n2025-10-13 21:43:07,489 INFO:   Input workers have begun streaming input data\n2025-10-13 21:43:08,633 INFO:   Appliance staging is complete\n2025-10-13 21:43:08,633 INFO:   Beginning appliance run\n2025-10-13 21:43:35,288 INFO:   | Train Device=CSX, Step=20, Loss=0.42919, Rate=869.57 samples/sec, GlobalRate=879.99 samples/sec, LoopTimeRemaining=0:08:41, TimeRemaining=0:08:41\n2025-10-13 21:44:02,004 INFO:   | Train Device=CSX, Step=40, Loss=0.28088, Rate=864.86 samples/sec, GlobalRate=877.18 samples/sec, LoopTimeRemaining=0:08:14, TimeRemaining=0:08:14\n2025-10-13 21:44:28,712 INFO:   | Train Device=CSX, Step=60, Loss=0.22520, Rate=874.51 samples/sec, GlobalRate=876.33 samples/sec, LoopTimeRemaining=0:07:49, TimeRemaining=0:07:49\n2025-10-13 21:44:55,371 INFO:   | Train Device=CSX, Step=80, Loss=0.20647, Rate=867.69 samples/sec, GlobalRate=876.31 samples/sec, LoopTimeRemaining=0:07:22, TimeRemaining=0:07:22\n2025-10-13 21:45:21,917 INFO:   | Train Device=CSX, Step=100, Loss=0.21275, Rate=877.39 samples/sec, GlobalRate=877.04 samples/sec, LoopTimeRemaining=0:06:54, TimeRemaining=0:06:54\n2025-10-13 21:45:48,642 INFO:   | Train Device=CSX, Step=120, Loss=0.19596, Rate=873.47 samples/sec, GlobalRate=876.55 samples/sec, LoopTimeRemaining=0:06:28, TimeRemaining=0:06:28\n2025-10-13 21:46:15,303 INFO:   | Train Device=CSX, Step=140, Loss=0.19837, Rate=871.60 samples/sec, GlobalRate=876.50 samples/sec, LoopTimeRemaining=0:06:01, TimeRemaining=0:06:01\n2025-10-13 21:46:42,043 INFO:   | Train Device=CSX, Step=160, Loss=0.20213, Rate=867.43 samples/sec, GlobalRate=876.13 samples/sec, LoopTimeRemaining=0:05:34, TimeRemaining=0:05:34\n2025-10-13 21:47:08,596 INFO:   | Train Device=CSX, Step=180, Loss=0.20233, Rate=869.68 samples/sec, GlobalRate=876.53 samples/sec, LoopTimeRemaining=0:05:08, TimeRemaining=0:05:08\n2025-10-13 21:47:35,271 INFO:   | Train Device=CSX, Step=200, Loss=0.18922, Rate=865.66 samples/sec, GlobalRate=876.45 samples/sec, LoopTimeRemaining=0:04:41, TimeRemaining=0:04:41\n2025-10-13 21:47:35,276 INFO:   Saving checkpoint at step 200\n2025-10-13 21:50:36,478 INFO:   Saved checkpoint model_dir_dit/checkpoint_200.mdl\n2025-10-13 21:50:40,262 INFO:   | Train Device=CSX, Step=220, Loss=0.19112, Rate=5970.06 samples/sec, GlobalRate=569.10 samples/sec, LoopTimeRemaining=0:04:26, TimeRemaining=0:04:26\n2025-10-13 21:50:44,011 INFO:   | Train Device=CSX, Step=240, Loss=0.18163, Rate=6114.62 samples/sec, GlobalRate=615.72 samples/sec, LoopTimeRemaining=0:04:26, TimeRemaining=0:04:26\n2025-10-13 21:50:47,714 INFO:   | Train Device=CSX, Step=260, Loss=0.18644, Rate=5957.36 samples/sec, GlobalRate=661.65 samples/sec, LoopTimeRemaining=0:04:26, TimeRemaining=0:04:26\n2025-10-13 21:50:51,424 INFO:   | Train Device=CSX, Step=280, Loss=0.17691, Rate=6048.57 samples/sec, GlobalRate=706.83 samples/sec, LoopTimeRemaining=0:04:18, TimeRemaining=0:04:18\n2025-10-13 21:50:55,165 INFO:   | Train Device=CSX, Step=300, Loss=0.18429, Rate=6167.70 samples/sec, GlobalRate=751.25 samples/sec, LoopTimeRemaining=0:03:51, TimeRemaining=0:03:51\n2025-10-13 21:50:58,951 INFO:   | Train Device=CSX, Step=320, Loss=0.18575, Rate=6109.52 samples/sec, GlobalRate=794.88 samples/sec, LoopTimeRemaining=0:03:23, TimeRemaining=0:03:23\n2025-10-13 21:51:02,716 INFO:   | Train Device=CSX, Step=340, Loss=0.17604, Rate=6088.11 samples/sec, GlobalRate=837.85 samples/sec, LoopTimeRemaining=0:01:37, TimeRemaining=0:01:37\n2025-10-13 21:51:09,072 INFO:   | Train Device=CSX, Step=360, Loss=0.19354, Rate=1369.79 samples/sec, GlobalRate=875.40 samples/sec, LoopTimeRemaining=0:01:37, TimeRemaining=0:01:37\n2025-10-13 21:51:35,842 INFO:   | Train Device=CSX, Step=380, Loss=0.16738, Rate=870.69 samples/sec, GlobalRate=875.25 samples/sec, LoopTimeRemaining=0:01:37, TimeRemaining=0:01:37\n2025-10-13 21:52:02,497 INFO:   | Train Device=CSX, Step=400, Loss=0.18182, Rate=896.97 samples/sec, GlobalRate=875.31 samples/sec, LoopTimeRemaining=0:01:37, TimeRemaining=0:01:37\n2025-10-13 21:52:02,502 INFO:   Saving checkpoint at step 400\n2025-10-13 21:55:01,077 INFO:   Saved checkpoint model_dir_dit/checkpoint_400.mdl\n2025-10-13 21:55:18,877 INFO:   Training completed successfully!\n2025-10-13 21:55:18,883 INFO:   Processed 467200 training sample(s) in 4754.503176912 seconds.\n</code></pre>"},{"location":"ai-testbed/cerebras/getting-started/","title":"Getting Started","text":""},{"location":"ai-testbed/cerebras/getting-started/#getting-started","title":"Getting Started","text":""},{"location":"ai-testbed/cerebras/getting-started/#connection-to-a-cs-3-node","title":"Connection to a CS-3 node","text":"<p> Connection to one of the CS-3 cluster login nodes requires an MFA passcode for authentication - an 8-digit passcode generated by an app on your mobile device (MobilePASS+) or Cryptocard. The same passcode system is used to authenticate into other ALCF systems, such as Polaris. In the examples below, replace ALCFUserID with your ALCF user id. To connect to a CS-3 login:</p> <p>ssh to the login node: <pre><code>ssh ALCFUserID@cerebras.alcf.anl.gov\n</code></pre></p> <p>Then ssh to a cerebras user node: <pre><code>ssh cer-usn-01\n</code></pre> or <pre><code>ssh cer-usn-02\n</code></pre></p>"},{"location":"ai-testbed/cerebras/job-queuing-and-submission/","title":"Job Queuing and Submission","text":"<p>The CS-3 cluster has its own Kubernetes-based system for job submission and queuing.</p> <p>Jobs are started automatically through the Python framework in modelzoo.common.pytorch.run_utils Continuous job status for a job is output to stdout/stderr; redirect the output, or consider using a persistent session started with screen, or tmux, or both.</p> <p>Jobs that have not yet completed can be listed as shown.</p> <pre><code>(venv_cerebras_pt) $ csctl get jobs\nSESSION       NAME                          TYPE     PRIORITY  AGE  DURATION  PHASE    SYSTEMS  USER     LABELS          WORKFLOW                      DASHBOARD\njob-operator  wsjob-ewhzngfg6rdjhw3s3k2wbh  compile  P2 (299)  12m  12m       RUNNING           username name=llama2_7b  wflow-wuetecva5mb8riup5swrff  https://grafana.anl0.cerebras.internal/d/WebHNShVz/wsjob-dashboard?orgId=1&amp;var-wsjob=wsjob-ewhzngfg6rdjhw3s3k2wbh&amp;from=1761235733000&amp;to=now\n(venv_cerebras_pt) $\n</code></pre> <p>Jobs can be canceled as shown:</p> <pre><code>(venv_cerebras_pt) $ csctl cancel job wsjob-eyjapwgnycahq9tus4w7id\nJob canceled successfully\n(venv_cerebras_pt) $\n</code></pre> <p>Jobs can be labeled in the command line that launches them, if they are written with Cerebras's Python framework for running appliance jobs, by adding a command line option of this form: <pre><code> --job_labels labelname=labelvalue\n</code></pre></p> <p>Jobs can also be labeled after they have been started as shown: <pre><code>(venv_cerebras_pt) $ csctl label job wsjob-ez6dyfronnsg2rz7f7fqw4 testlabel=test\njob/wsjob-ez6dyfronnsg2rz7f7fqw4 was patched\n(venv_cerebras_pt) $\n</code></pre></p> <p>Jobs with a particular label/label value can be listed as shown: <pre><code>(venv_cerebras_pt) $ csctl get jobs | grep \"testlabel=test\"\nwsjob-ez6dyfronnsg2rz7f7fqw4  19m SUCCEEDED  cer-cs2-02 username testlabel=test,user=username\n(venv_cerebras_pt) $\n</code></pre></p> <p>All jobs run in the past week can be listed as shown <pre><code>csctl get jobs -a\n# or\ncsctl get jobs --all-states\n</code></pre></p> <p>Some state details for each node in the cluster can be listed as shown: <pre><code>csctl get cluster\n</code></pre></p> <p>See <code>csctl -h</code> for more options. Add <code>-h</code> to a command for help for that command, e.g. <code>csctl get -h</code> or <code>csctl cancel -h</code>. </p> <pre><code>$ csctl -h\nCerebras cluster command line tool.\n\nUsage:\n  csctl [command]\n\nAvailable Commands:\n  cancel             Cancel job\n  check-volumes      Check volume validity on this usernode\n  clear-worker-cache Clear the worker cache\n  cluster            Manage cluster resources and information\n  config             View csctl config files\n  debug-artifact     Manage debug artifacts.\n  get                Get resources\n  job                Job management commands\n  label              Label resources\n  log-export         Gather and download logs.\n  session            Session management commands\n  system-maintenance System maintenance commands\n  types              Display resource types\n\nFlags:\n      --csconfig string    config file /opt/cerebras/config_v2 (default \"/opt/cerebras/config_v2\")\n  -d, --debug int          higher debug values will display more fields in output objects\n  -h, --help               help for csctl\n  -n, --namespace string   configure csctl to talk to different user namespaces\n      --version            version for csctl\n\nUse \"csctl [command] --help\" for more information about a command.\n</code></pre>"},{"location":"ai-testbed/cerebras/miscellaneous/","title":"Miscellaneous","text":""},{"location":"ai-testbed/cerebras/miscellaneous/#porting-applications-to-the-cs-3","title":"Porting applications to the CS-3","text":"<p>Cerebras documentation for porting code to run on a Cerebras CS-3 system: Port Pytorch Models to Cerebras</p>"},{"location":"ai-testbed/cerebras/miscellaneous/#finetuning-a-model-using-cs-3s","title":"Finetuning a model using CS-3s","text":"<p>The Cerebras tutorial for finetuning a model: Fine-Tune Your First Model</p> <p>The tutorial covers how to: </p> <ul> <li>Setup your environment</li> <li>Pre-process a small dataset (documents and their summaries)</li> <li>Port a trained model from Hugging Face (Llama3-8B)</li> <li>Fine-tune and evaluate a model</li> <li>Test your model on downstream tasks</li> <li>Port your model to Hugging Face format</li> </ul>"},{"location":"ai-testbed/cerebras/running-a-model-or-program/","title":"Running a Model/Program","text":""},{"location":"ai-testbed/cerebras/running-a-model-or-program/#getting-started","title":"Getting Started","text":""},{"location":"ai-testbed/cerebras/running-a-model-or-program/#job-submission-and-queuing","title":"Job submission and queuing","text":"<p>Cerebras jobs are initiated and tracked automatically within the Python framework in cerebras.modelzoo.common.run_utils. This framework interacts with the Cerebras cluster management node.</p>"},{"location":"ai-testbed/cerebras/running-a-model-or-program/#login-nodes","title":"Login nodes","text":"<p>Jobs are launched from user nodes. If you expect a loss of an internet connection for any reason, for long-running jobs we suggest logging into a specific user node and using either screen or tmux to create persistent command line sessions.  For details use:</p> <pre><code>man screen\n# or\nman tmux\n</code></pre>"},{"location":"ai-testbed/cerebras/running-a-model-or-program/#running-jobs-on-the-wafer","title":"Running jobs on the wafer","text":"<p>Follow these instructions to compile and train a small (111m parameters) GPT3 model.</p>"},{"location":"ai-testbed/cerebras/running-a-model-or-program/#cerebras-virtual-environments","title":"Cerebras virtual environments","text":"<p>First, make a virtual environment for Cerebras for PyTorch. See Customizing Environments for the procedures for making PyTorch virtual environments for Cerebras. If an environment is made in <code>~/R_2.6.0/</code>, it would be activated as follows: <pre><code>source ~/R_2.6.0/venv_cerebras_pt/bin/activate\n</code></pre></p> <p>Note: to access any external web resources from a Cerebras user node, you will need to have a proxy environment variable set (or equivalent). <code>wget</code> needs the lower-case proxy environment variable. <pre><code>export HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\nexport https_proxy=http://proxy.alcf.anl.gov:3128\n</code></pre></p>"},{"location":"ai-testbed/cerebras/running-a-model-or-program/#clone-the-cerebras-modelzoo","title":"Clone the Cerebras modelzoo","text":"<p>If you have not already cloned the Cerebras modelzoo repo and checked out the Release_2.6.0 tag, do so.</p> <pre><code>mkdir ~/R_2.6.0\ncd ~/R_2.6.0\nexport HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\ngit clone https://github.com/Cerebras/modelzoo.git\ncd modelzoo\ngit tag\ngit checkout Release_2.6.0\n</code></pre>"},{"location":"ai-testbed/cerebras/running-a-model-or-program/#running-a-pytorch-sample","title":"Running a Pytorch sample","text":""},{"location":"ai-testbed/cerebras/running-a-model-or-program/#activate-your-pytorch-virtual-environment-and-change-to-the-working-directory","title":"Activate your PyTorch virtual environment, and change to the working directory","text":"<pre><code>source ~/R_2.6.0/venv_cerebras_pt/bin/activate\ncd ~/R_2.6.0/modelzoo/src/cerebras/modelzoo/models/nlp/gpt3\n</code></pre> <p>Next, copy a sample config file. This is for a small GPT3 model, modified to use a preprocessed dataset and to run for fewer steps. </p> <pre><code>cp /software/cerebras/dataset/OWT/Pytorch/111m_modified.yaml configs/Cerebras_GPT/111m_modified.yaml\n</code></pre>"},{"location":"ai-testbed/cerebras/running-a-model-or-program/#running-a-sample-pytorch-trainingvalidation-job","title":"Running a sample PyTorch training/validation job","text":"<p>To run the sample:</p> <pre><code>export MODEL_DIR=model_dir_gpt3_111m\n# deletion of the model_dir is only needed if sample has been previously run\nif [ -d \"$MODEL_DIR\" ]; then rm -Rf $MODEL_DIR; fi\ncszoo fit configs/Cerebras_GPT/111m_modified.yaml --job_labels name=gpt3_111m --model_dir $MODEL_DIR |&amp; tee mytest.log\n</code></pre> <p>A successful GPT3 (111m parameters) PyTorch training/validation run should finish with output resembling the following:</p> <pre><code>2025-10-09 18:19:52,310 INFO:   Beginning appliance run\n2025-10-09 18:19:54,361 INFO:   | Eval Device=CSX, GlobalStep=400, Batch=20, Loss=5.94325, Rate=1163.27 samples/sec, GlobalRate=1173.27 samples/sec, LoopTimeRemaining=0:00:08, TimeRemaining=0:00:08\n2025-10-09 18:19:56,408 INFO:   | Eval Device=CSX, GlobalStep=400, Batch=40, Loss=5.92024, Rate=1174.18 samples/sec, GlobalRate=1172.88 samples/sec, LoopTimeRemaining=0:00:06, TimeRemaining=0:00:06\n2025-10-09 18:19:58,463 INFO:   | Eval Device=CSX, GlobalStep=400, Batch=60, Loss=5.89623, Rate=1171.13 samples/sec, GlobalRate=1171.33 samples/sec, LoopTimeRemaining=0:00:04, TimeRemaining=0:00:04\n2025-10-09 18:20:00,514 INFO:   | Eval Device=CSX, GlobalStep=400, Batch=80, Loss=5.92834, Rate=1164.75 samples/sec, GlobalRate=1170.97 samples/sec, LoopTimeRemaining=0:00:02, TimeRemaining=0:00:02\n2025-10-09 18:20:02,564 INFO:   | Eval Device=CSX, GlobalStep=400, Batch=100, Loss=5.92817, Rate=1172.36 samples/sec, GlobalRate=1170.91 samples/sec, LoopTimeRemaining=0:00:00, TimeRemaining=0:00:00\n2025-10-09 18:20:23,263 INFO:   Avg Eval Loss: 5.928174624443054\n2025-10-09 18:20:23,278 INFO:   Evaluation metrics:\n2025-10-09 18:20:23,278 INFO:     - eval/lm_perplexity = 375.4686584472656\n2025-10-09 18:20:23,278 INFO:     - eval/accuracy = 0.16977091133594513\n2025-10-09 18:20:23,279 INFO:   Evaluation completed successfully!\n2025-10-09 18:20:23,281 INFO:   Processed 48000 training sample(s) in 820.575766695 seconds.\n</code></pre> <p>As the console output shows, for this sample, the run framework starts three jobs (two compiles and one execute) as part of a single workflow: <pre><code>(venv_cerebras_pt) username@cer-anl-net001-us-sr01:~/R_2.6.0/modelzoo/src/cerebras/modelzoo/models/nlp/gpt3$ grep -B1 \"Job id:\" mytest.log \n2025-10-30 18:10:39,460 INFO:   Initiating a new compile wsjob against the cluster server.\n2025-10-30 18:10:39,479 INFO:   Job id: wsjob-acxb4mqan53ppiffvdaafq, workflow id: wflow-ocjyqlrf5szhpecphsq3x8, namespace: job-operator, remote log path: /n1/wsjob/workdir/job-operator/wsjob-acxb4mqan53ppiffvdaafq\n--\n2025-10-30 18:11:51,527 INFO:   Initiating a new execute wsjob against the cluster server.\n2025-10-30 18:11:51,558 INFO:   Job id: wsjob-uttzzftdpppygmvqspykpr, workflow id: wflow-ocjyqlrf5szhpecphsq3x8, namespace: job-operator, remote log path: /n1/wsjob/workdir/job-operator/wsjob-uttzzftdpppygmvqspykpr\n--\n2025-10-30 18:21:33,099 INFO:   Initiating a new compile wsjob against the cluster server.\n2025-10-30 18:21:33,118 INFO:   Job id: wsjob-6mvjwjqovjprbibbpi3w43, workflow id: wflow-ocjyqlrf5szhpecphsq3x8, namespace: job-operator, remote log path: /n1/wsjob/workdir/job-operator/wsjob-6mvjwjqovjprbibbpi3w43\n(venv_cerebras_pt) username@cer-anl-net001-us-sr01:~/R_2.6.0/modelzoo/src/cerebras/modelzoo/models/nlp/gpt3$ \n</code></pre></p> <p>The jobs can be seen with <code>csctl get jobs</code>, from another console session on a user node. See Job Queuing and Submission for more details.</p>"},{"location":"ai-testbed/cerebras/tunneling-and-forwarding-ports/","title":"Tunneling and Forwarding Ports","text":"<p>See ALCF's Jupyter Instructions, and Tunneling and forwarding ports. The Cerebras user nodes are accessed through two steps; tunneling and port forwarding need to be through a login node. An example, that tunnels a user-started service using port 8080 on a user node to localhost:7777 <pre><code>export G_PORT=7777\nexport ALCFUserID=&lt;your alcf username&gt;\nssh -L $G_PORT:localhost:$G_PORT $ALCFUserID@cer-login-04.ai.alcf.anl.gov -t ssh -L $G_PORT:localhost:8080 -N cer-anl-net001-us-sr01\n</code></pre></p>"},{"location":"ai-testbed/data-management/data-management-overview/","title":"Data Management for the AI Testbed","text":""},{"location":"ai-testbed/data-management/data-management-overview/#home-file-system-space","title":"Home File System Space","text":"<p>Users have a shared home filesystem <code>/home</code> shared across the ALCF AI testbed systems, including the login and compute nodes. Default user quota is <code>1 TB</code> storage and <code>1,000,000 files</code>. This space is backed up. </p>"},{"location":"ai-testbed/data-management/data-management-overview/#project-file-system-space","title":"Project File System Space","text":"<p>The team project/campaign file system <code>/projects</code> is intended to facilitate project collaboration and is accessible to the team members of your project that have an ALCF account.  Default group storage quota is <code>2 TB</code> and <code>2,000,000 files</code>. Please note that this space isn't backed up.  Our policy is that data will be purged from disk 6 months after project completion.</p>"},{"location":"ai-testbed/data-management/data-management-overview/#data-transfer","title":"Data Transfer","text":"<p>Users can transfer data to and from the AI testbed using <code>Globus</code> or tools such as <code>scp</code> or <code>rsync</code>.</p>"},{"location":"ai-testbed/data-management/data-management-overview/#using-globus","title":"Using Globus","text":"<p>We have a Globus endpoint each to move data to and from the <code>/projects</code> and <code>/home</code> filesystem respectively.</p> <ul> <li>Use <code>alcf#ai_testbed_projects</code> for the <code>/projects</code> file system</li> <li>Use <code>alcf#ai_testbed_home</code> for the <code>/home</code> files system </li> </ul> <p>Relevant information regarding using globus can be found here</p>"},{"location":"ai-testbed/data-management/data-management-overview/#alcf-storage-policies","title":"ALCF Storage Policies","text":"<p>ALCF data policies is available here </p> <p>Please Note: The basic level of protection provided is UNIX file level permissions; it is the user's responsibility to ensure that file permissions and umasks are set to match their needs.</p>"},{"location":"ai-testbed/graphcore/","title":"System Overview","text":"<p>The Graphcore Bow-Pod64 system is the latest-generation AI accelerator from Graphcore. This is a one-rack system consisting of 64 Bow-class Intelligence Processing Units (IPU) with a custom interconnect. The system provides for an aggregate 22 Petaflops/s of performance in half precision. It has a total of 57.6 GB In-Processor-Memory with a total of 94,208 IPU cores. The system consists of four servers for data-processing. </p> <p>For more details refer to the POD64 spec.</p> <p></p> <p>Figure from Graphcore Poplar)</p> <p>The Graphcore software stack includes support for TensorFlow and PyTorch using the Poplar SDK. The Poplar\u00ae SDK is t is the toolchain specifically designed for creating graph software for ML applications.  It integrates with the traditional ML frameworks like PyTorch and TensorFlow allowing users to port their existing code to the IPU hardware-specific code. The various components of the poplar SDK stack are shown in the figure. It includes the PopTorch framework which is a wrapper over the PyTorch framework optimized to the IPU hardware. It also enlists the different PopLibs libraries supported, which enables to construct graphs, define tensor data and control how the code and data are mapped onto the IPU for execution.</p>"},{"location":"ai-testbed/graphcore/documentation/","title":"Documentation links","text":"<p>Poplar SDK PyTorch for the IPU: User Guide Targetting the IPU from Tensorflow 2 IPU programming guide Examples Examples Github Repo POD systems POD64 specs </p>"},{"location":"ai-testbed/graphcore/example-programs/","title":"Example Programs","text":"<p>Graphcore provides examples of some well-known AI applications in their repository at https://github.com/graphcore/examples.git. Clone the examples repository to your personal directory structure: <pre><code>mkdir ~/graphcore\ncd ~/graphcore\ngit clone https://github.com/graphcore/examples.git\n</code></pre></p>"},{"location":"ai-testbed/graphcore/example-programs/#mnist-poptorch","title":"MNIST - PopTorch","text":""},{"location":"ai-testbed/graphcore/example-programs/#activate-poptorch-environment","title":"Activate PopTorch Environment","text":"<pre><code>source ~/venvs/graphcore/poptorch33_env/bin/activate\n</code></pre>"},{"location":"ai-testbed/graphcore/example-programs/#install-requirements","title":"Install Requirements","text":"<p>Change directory: <pre><code>cd ~/graphcore/examples/tutorials/simple_applications/pytorch/mnist\n</code></pre></p>"},{"location":"ai-testbed/graphcore/example-programs/#run-mnist","title":"Run MNIST","text":"<p>Execute the command: <pre><code>/opt/slurm/bin/srun --ipus=1 python mnist_poptorch.py\n</code></pre></p>"},{"location":"ai-testbed/graphcore/example-programs/#output","title":"Output","text":"<p>The expected output will resemble the following:</p> <pre><code>srun: job 10671 queued and waiting for resources\nsrun: job 10671 has been allocated resources\nTrainingModelWithLoss(\n  (model): Network(\n    (layer1): Block(\n      (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (relu): ReLU()\n    )\n    (layer2): Block(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (relu): ReLU()\n    )\n    (layer3): Linear(in_features=1600, out_features=128, bias=True)\n    (layer3_act): ReLU()\n    (layer3_dropout): Dropout(p=0.5, inplace=False)\n    (layer4): Linear(in_features=128, out_features=10, bias=True)\n    (softmax): Softmax(dim=1)\n  )\n  (loss): CrossEntropyLoss()\n)\nEpochs:   0%|          | 0/10 [00:00&lt;?,[23:27:06.753] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 10\nGraph compilation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00]\nEpochs: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [01:17&lt;00:00,  7.71s/it]\nGraph compilation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00]                          \nAccuracy on test set: 96.85%\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00]\n</code></pre>"},{"location":"ai-testbed/graphcore/example-programs/#mnist-tensorflow2","title":"MNIST - Tensorflow2","text":""},{"location":"ai-testbed/graphcore/example-programs/#activate-tensorflow2-environment","title":"Activate Tensorflow2 Environment","text":"<p>Create a TensorFlow2 environment as explained in the tensorflow-2-environment-setup and activate the same. <pre><code>source ~/venvs/graphcore/tensorflow2_33_env/bin/activate\n</code></pre></p>"},{"location":"ai-testbed/graphcore/example-programs/#install-requirements_1","title":"Install Requirements","text":"<p>Change directory: <pre><code>cd ~/graphcore/examples/tutorials/simple_applications/tensorflow2/mnist/\n</code></pre></p>"},{"location":"ai-testbed/graphcore/example-programs/#run-mnist-tensorflow","title":"Run MNIST - TensorFlow","text":"<p>Execute the command:</p> <pre><code>/opt/slurm/bin/srun --ipus=1 python mnist.py\n</code></pre>"},{"location":"ai-testbed/graphcore/example-programs/#output_1","title":"Output","text":"<p>The expected output will resemble the following:</p> <pre><code>srun: job 10672 queued and waiting for resources\nsrun: job 10672 has been allocated resources\n2023-08-22 23:35:02.925033: I tensorflow/compiler/plugin/poplar/driver/poplar_platform.cc:43] Poplar version: 3.3.0 (de1f8de2a7) Poplar package: b67b751185\n2023-08-22 23:35:06.119772: I tensorflow/compiler/plugin/poplar/driver/poplar_executor.cc:1619] TensorFlow device /device:IPU:0 attached to 1 IPU with Poplar device ID: 0\n2023-08-22 23:35:07.087287: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n2023-08-22 23:35:07.351132: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n2023-08-22T23:35:09.469066Z PL:POPOPS    3545299.3545299 W: createOutputForElementWiseOp 'while/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits/fusion.3/Op/Equal/Out' ({32,10}): No suitable input found, creating new variable with linear tile mapping\n2023-08-22 23:35:18.532415: I tensorflow/compiler/jit/xla_compilation_cache.cc:376] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nEpoch 1/4\n2000/2000 [==============================] - 13s 6ms/step - loss: 0.6220\nEpoch 2/4\n2000/2000 [==============================] - 1s 262us/step - loss: 0.3265\nEpoch 3/4\n2000/2000 [==============================] - 1s 273us/step - loss: 0.2781\nEpoch 4/4\n2000/2000 [==============================] - 1s 289us/step - loss: 0.2482\n</code></pre>"},{"location":"ai-testbed/graphcore/example-programs/#resnet50","title":"ResNet50","text":""},{"location":"ai-testbed/graphcore/example-programs/#activate-poptorch-environment_1","title":"Activate PopTorch Environment","text":"<p>Create and activate a fresh PopTorch environment <code>poptorch33_resnet50_env</code> as outlined in the virtual environment section, then activate it. <pre><code>source ~/venvs/graphcore/poptorch33_resnet50_env/bin/activate\n</code></pre></p>"},{"location":"ai-testbed/graphcore/example-programs/#install-requirements_2","title":"Install Requirements","text":"<p>Change directory <pre><code>cd ~/graphcore/examples/vision/cnns/pytorch\nmake install \nmake install-turbojpeg\n</code></pre></p>"},{"location":"ai-testbed/graphcore/example-programs/#update-configsyml","title":"Update configs.yml","text":"<p>Change directory: <pre><code>cd ~/graphcore/examples/vision/cnns/pytorch/train\n</code></pre> Open configs.yml with your favorite editor. Find in the resnet50 section <pre><code>use_bbox_info: true\n</code></pre> and change it to: <pre><code>use_bbox_info: false\n</code></pre></p>"},{"location":"ai-testbed/graphcore/example-programs/#run-resnet50","title":"Run ResNet50","text":"<p>The scripts to train a ResNet50 PyTorch model on Pod4 is located at https://github.com/graphcore/examples/tree/master/vision/cnns/pytorch/train</p> <p>Set the following environmental variables. <pre><code>mkdir -p ~/graphcore/tmp/pt_cache/\nexport PYTORCH_CACHE_DIR=~/graphcore/tmp/pt_cache/\n</code></pre> To run 4 replicas (a total for 4 IPUs) of the ResNet50 model: Make a script with the following contents, called poprun_unet.sh This script tells poprun to use the partition id of the partition created for the slurm job used to run the script. <pre><code>#!/bin/bash\npoprun -vv --vipu-partition=slurm_${SLURM_JOBID} --num-instances=1 --num-replicas=4 --executable-cache-path=$PYTORCH_CACHE_DIR python3 /home/$USER/graphcore/examples/vision/cnns/pytorch/train/train.py --config resnet50-pod4 --imagenet-data-path /mnt/localdata/datasets/imagenet-raw-dataset --epoch 2 --validation-mode none --dataloader-worker 14 --dataloader-rebatch-size 256\n</code></pre> Then <pre><code>chmod +x poprun_unet.sh\n/opt/slurm/bin/srun --ipus=4 poprun_unet.sh\n</code></pre></p> <p>This model is run with the imagenet dataset.</p>"},{"location":"ai-testbed/graphcore/example-programs/#output_2","title":"Output","text":"<p>The expected output starts with this: <pre><code>srun: job 10675 queued and waiting for resources\nsrun: job 10675 has been allocated resources\n23:48:29.160 3555537 POPRUN [I] V-IPU server address picked up from 'vipu': 10.1.3.101:8090\n23:48:29.160 3555537 POPRUN [D] Connecting to 10.1.3.101:8090\n23:48:29.162 3555537 POPRUN [D] Status for partition slurm_10673: OK (error 0)\n23:48:29.162 3555537 POPRUN [I] Partition slurm_10673 already exists and is in state: PS_ACTIVE\n23:48:29.163 3555537 POPRUN [D] The reconfigurable partition slurm_10673 is OK\n ===========================\n|      poprun topology      |\n|===========================|\n| hosts     | gc-poplar-02  |\n|-----------|---------------|\n| ILDs      |       0       |\n|-----------|---------------|\n| instances |       0       |\n|-----------|---------------|\n| replicas  | 0 | 1 | 2 | 3 |\n ---------------------------\n23:48:29.163 3555537 POPRUN [D] Target options from environment: {}\n23:48:29.163 3555537 POPRUN [D] Target options from V-IPU partition: {\"ipuLinkDomainSize\":\"4\",\"ipuLinkConfiguration\":\"default\",\"ipuLinkTopology\":\"mesh\",\"gatewayMode\":\"true\",\"instanceSize\":\"4\"}\n23:48:29.207 3555537 POPRUN [D] Found 1 devices with 4 IPUs\n23:48:29.777 3555537 POPRUN [D] Attached to device 6\n23:48:29.777 3555537 POPRUN [I] Preparing parent device 6\n23:48:29.777 3555537 POPRUN [D] Device 6 ipuLinkDomainSize=64, ipuLinkConfiguration=Default, ipuLinkTopology=Mesh, gatewayMode=true, instanceSize=4\n23:48:33.631 3555537 POPRUN [D] Target options from Poplar device: {\"ipuLinkDomainSize\":\"64\",\"ipuLinkConfiguration\":\"default\",\"ipuLinkTopology\":\"mesh\",\"gatewayMode\":\"true\",\"instanceSize\":\"4\"}\n23:48:33.631 3555537 POPRUN [D] Using target options: {\"ipuLinkDomainSize\":\"4\",\"ipuLinkConfiguration\":\"default\",\"ipuLinkTopology\":\"mesh\",\"gatewayMode\":\"true\",\"instanceSize\":\"4\"}\n</code></pre> Expected output ends with this: <pre><code>Graph compilation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:04&lt;00:00][1,0]&lt;stderr&gt;:2023-08-22T23:49:40.103248Z PO:ENGINE   3556102.3556102 W: WARNING: The compile time engine option debug.branchRecordTile is set to \"5887\" when creating the Engine. (At compile time it was set to 1471)\n[1,0]&lt;stderr&gt;:\nLoss:6.7539 [1,0]&lt;stdout&gt;:[INFO] Epoch 1\u2588\u2588\u2588\u2588\u258c| 75/78 [02:42&lt;00:06,  2.05s/it][1,0]&lt;stderr&gt;:\n[1,0]&lt;stdout&gt;:[INFO] loss: 6.7462,\n[1,0]&lt;stdout&gt;:[INFO] accuracy: 0.62 %\n[1,0]&lt;stdout&gt;:[INFO] throughput: 7599.7 samples/sec\n[1,0]&lt;stdout&gt;:[INFO] Epoch 2/2\nLoss:6.7462 | Accuracy:0.62%: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 78/78 [02:48&lt;00:00,  2.16s/it][1,0]&lt;stderr&gt;:\nLoss:6.2821 | Accuracy:2.42%:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 75/7[1,0]&lt;stdout&gt;:[INFO] Epoch 2,0]&lt;stderr&gt;:\n[1,0]&lt;stdout&gt;:[INFO] loss: 6.2720,\n[1,0]&lt;stdout&gt;:[INFO] accuracy: 2.48 %\n[1,0]&lt;stdout&gt;:[INFO] throughput: 8125.8 samples/sec\n[1,0]&lt;stdout&gt;:[INFO] Finished training. Time: 2023-08-22 23:54:57.853508. It took: 0:05:26.090631\nLoss:6.2720 | Accuracy:2.48%: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 78/78 [02:37&lt;00:00,  2.02s/it][1,0]&lt;stderr&gt;:\n[1,0]&lt;stderr&gt;:/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 14 leaked semaphore objects to clean up at shutdown\n[1,0]&lt;stderr&gt;:  warnings.warn('resource_tracker: There appear to be %d '\n23:55:02.722 3555537 POPRUN [I] mpirun (PID 3556098) terminated with exit code 0\n</code></pre></p>"},{"location":"ai-testbed/graphcore/example-programs/#gpt-2-pytorch-pod16-run","title":"GPT-2 PyTorch - POD16 run","text":"<p>The scripts to train a GPT-2 pytorch model on the POD16 are located at https://github.com/graphcore/examples/tree/master/nlp/gpt2/pytorch</p> <p>In order to run the GPT-2 Pytorch model, create a new popTorch virtual environment poptorch33_gpt2 as described in the virtual environment section and activate it.</p> <pre><code>source ~/venvs/graphcore/poptorch33_gpt2/bin/activate\n</code></pre>"},{"location":"ai-testbed/graphcore/example-programs/#install-requirements_3","title":"Install Requirements","text":"<p>Change directory: <pre><code>cd ~/graphcore/examples/nlp/gpt2/pytorch\npip3 install -r requirements.txt\n</code></pre></p>"},{"location":"ai-testbed/graphcore/example-programs/#run-gpt2-on-16-ipus","title":"Run GPT2 on 16 IPUs","text":"<p>The command for the GPT2 model is as follows is as follows. <pre><code>/opt/slurm/bin/srun --ipus=16 python /home/$USER/graphcore/examples/nlp/gpt2/pytorch/train_gpt2.py --model gpt2 --ipus-per-replica 4 --replication-factor 4 --gradient-accumulation 2048 --device-iterations 8 --batch-size 1 --layers-per-ipu 0 4 4 4 --matmul-proportion 0.15 0.15 0.15 0.15 --max-len 1024 --optimizer AdamW --learning-rate 0.00015 --lr-schedule cosine --lr-warmup 0.01 --remap-logit True --enable-sequence-serialized True --embedding-serialization-factor 4 --recompute-checkpoint-every-layer True --enable-half-partials True --replicated-tensor-sharding True --dataset 'generated' --epochs 1\n</code></pre> It runs a <code>gpt2</code> model that fits on 4 IPUS indicated by <code>--ipus-per-replica</code>. The <code>--replication-factor</code> indicates how many times the model is replicated in a data parallel manner (4 in the above example). Hence the total number of IPUs used in this example is 16.</p> <p>The effective global batch size in this example is (micro)batch-size * gradient-accumulation * replication-factor = 1 x 2048 x 4 = 8192.  The device iterations indicates the total number samples loaded in 1 training step = global batch size * device iterations = 8192*8 = 65536. To learn more about these parameters and in general batching of IPUs refer IPU batching .</p> <p>The above example is running with <code>generated</code> or <code>synthetic data</code>. To use the same example with a real world dataset, refer to data setup.</p>"},{"location":"ai-testbed/graphcore/example-programs/#output_3","title":"Output","text":"<p>Expected output starts with the following: <pre><code>srun: job 10697 queued and waiting for resources\nsrun: job 10697 has been allocated resources\nBuilding (if necessary) and loading remap_tensor_ce.\nFailed to find compiled extension; rebuilding.\nBuilding (if necessary) and loading residual_add_inplace_pattern.\nModel initializing\n-------------------- Device Allocation --------------------\nEmbedding  --&gt; IPU 0\nLayer 0  --&gt; IPU 1\nLayer 1  --&gt; IPU 1\nLayer 2  --&gt; IPU 1\nLayer 3  --&gt; IPU 1\nLayer 4  --&gt; IPU 2\nLayer 5  --&gt; IPU 2\nLayer 6  --&gt; IPU 2\nLayer 7  --&gt; IPU 2\nLayer 8  --&gt; IPU 3\nLayer 9  --&gt; IPU 3\nLayer 10 --&gt; IPU 3\nLayer 11 --&gt; IPU 3\nLM_head --&gt; IPU 0\n</code></pre> Expected output ends with the following: <pre><code>step 0 of epoch 0, loss: 10.913220405578613, acc: 2.0071864128112793e-05, lr: 0.00012803300858899104, throughput: 646.8439205981404 samples/sec\nstep 1 of epoch 0, loss: 10.836345672607422, acc: 1.9788742065429688e-05, lr: 7.5e-05, throughput: 1058.0979097185766 samples/sec\nstep 2 of epoch 0, loss: 10.831247329711914, acc: 2.0518898963928223e-05, lr: 2.1966991411008938e-05, throughput: 1058.7595523807183 samples/sec\nstep 3 of epoch 0, loss: 10.829034805297852, acc: 1.990795135498047e-05, lr: 0.0, throughput: 1059.6762623043378 samples/sec\n</code></pre></p> <p>Note: The graph compilation for a large model like GPT-2 takes about half an hour. </p>"},{"location":"ai-testbed/graphcore/getting-started/","title":"Getting Started","text":"<p>Connection to a Graphcore node is a two-step process.</p> <p>The first step is to ssh from a local machine to the login node.</p> <p>The second step is to log in to a Graphcore node from the login node.</p> <p></p>"},{"location":"ai-testbed/graphcore/getting-started/#log-in-to-login-node","title":"Log in to Login Node","text":"<p>Login to the Graphcore login node from your local machine using the below command. This uses the ALCF account ID that uses the password generated from the MobilePASS+.</p> <p>Note:  In the examples below, replace ALCFUserID with your ALCF user id.</p> <pre><code>ssh ALCFUserID@gc-login-03.ai.alcf.anl.gov\n# or\nssh ALCFUserID@gc-login-04.ai.alcf.anl.gov\n</code></pre> <p>Note: Use the ssh \"-v\" option in order to debug any ssh problems.</p>"},{"location":"ai-testbed/graphcore/getting-started/#log-in-to-a-graphcore-node","title":"Log in to a Graphcore Node","text":"<p>Once you are on the login node, ssh to one of the Graphcore nodes.</p> <pre><code>ssh gc-poplar-02.ai.alcf.anl.gov\n# or\nssh gc-poplar-03.ai.alcf.anl.gov\n# or\nssh gc-poplar-04.ai.alcf.anl.gov\n</code></pre> <p>**Note: <code>ssh gc-poplar-01.ai.alcf.anl.gov</code> is not accessible to users. However, its IPU resources are assigned by the slurm tasks.</p>"},{"location":"ai-testbed/graphcore/job-queuing-and-submission/","title":"Job Queueing and Submission","text":""},{"location":"ai-testbed/graphcore/job-queuing-and-submission/#introduction","title":"Introduction","text":"<p>ALCF's Graphcore POD64 system uses Slurm for job submission and queueing. Below are some of the important commands for using Slurm. For more information refer to Slurm Documentation.</p> <p>NOTE: Jobs that require IPUs will fail unless launched with <code>srun</code> or <code>sbatch</code>. NOTE: There is a single Slurm scheduler for the Graphcore POD64.</p>"},{"location":"ai-testbed/graphcore/job-queuing-and-submission/#srun","title":"SRun","text":"<p>The Slurm command <code>srun</code> can be used to run individual Python scripts (or other programs) in parallel with other scripts on a cluster managed by Slurm. An example of <code>srun</code> usage is shown below. Use the <code>--ipus=</code> option to specify the number of IPUs required for the run.</p> <p>Example:</p> <pre><code>srun --ipus=1 python mnist_poptorch.py\n</code></pre>"},{"location":"ai-testbed/graphcore/job-queuing-and-submission/#sbatch","title":"SBatch","text":"<p>Alternatively, these jobs can be submitted to the Slurm workload manager through a batch script by using the <code>sbatch</code> command. To do this, create a bash script (submit-mnist-poptorch-job.sh here as an example) with the commands that you want to execute.</p> <pre><code>#!/bin/sh\n\npython mnist_poptorch.py\n</code></pre> <p>Then pass the bash script as an input to the <code>sbatch</code> command as shown below, requesting the number of IPUs required:</p> <pre><code>sbatch --ipus=1 --output=mnist-poptorch-output.log submit-mnist-poptorch-job.sh\n</code></pre>"},{"location":"ai-testbed/graphcore/job-queuing-and-submission/#squeue","title":"SQueue","text":"<p>The <code>squeue</code> command provides information about jobs located in the Slurm scheduling queue.</p> <pre><code>$ squeue\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n              2572       p64 Graphcor username  R       1:12      1 gc-poplar-02\n</code></pre>"},{"location":"ai-testbed/graphcore/job-queuing-and-submission/#sinfo","title":"SInfo","text":"<p>SInfo is used to view partition and node information for a system running Slurm.</p> <pre><code>$ sinfo\nPARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST\np64*         up   infinite      3   idle gc-poplar-[02-04]\n</code></pre> <p>For more information, see SInfo.</p>"},{"location":"ai-testbed/graphcore/job-queuing-and-submission/#scancel","title":"SCancel","text":"<p>SCancel is used to signal or cancel jobs, job arrays, or job steps.</p> <pre><code>scancel job_id\n</code></pre>"},{"location":"ai-testbed/graphcore/miscellaneous/","title":"Miscellaneous","text":""},{"location":"ai-testbed/graphcore/miscellaneous/#status","title":"Status","text":""},{"location":"ai-testbed/graphcore/miscellaneous/#gc-monitor","title":"GC-Monitor","text":"<p>The command <code>gc-monitor</code> is Graphcore's device usage monitor. Run it as follows for ordinary monitoring. See <code>gc-monitor --help</code> for other options.</p> <p><pre><code>export IPUOF_VIPU_API_HOST=10.1.3.101\ngc-monitor --no-card-info --all-partitions\n# or watch gc-monitor --no-card-info --all-partitions\n</code></pre> The IPUOF_VIPU_API_HOST environment variable can conflict with the running of poptorch programs.  The graphcore nodes have a convenience script that temporarily sets this environment variable. <pre><code>wrapped_gc_monitor.sh --no-card-info --all-partitions\n</code></pre></p> <p>Note: if there are no partitions active, gc-monitor will core dump: <code>Segmentation fault (core dumped)</code></p> <p>The output will look something like:</p> <pre><code>+--------------------------------------------------------------+-----------------------+\n|      IPUs in slurm_2616 attached from other namespaces       |         Board         |\n+----+------------------------------+--------------+-----------+-----------+-----------+\n| ID |       Application host       |    Clock     |   Temp    |   Temp    |   Power   |\n+----+------------------------------+--------------+-----------+-----------+-----------+\n| 0  |         gc-poplar-02         |   1850MHz    |  24.2 C   |  21.1 C   |  92.3 W   |\n+----+------------------------------+--------------+-----------+-----------+-----------+\n</code></pre>"},{"location":"ai-testbed/graphcore/miscellaneous/#gc-info","title":"GC-Info","text":"<p>The command <code>gc-info</code> is used to display device information. See <code>gc-info --help</code> for more options.</p> <p>To list devices,  <pre><code>gc-info -l\n</code></pre></p> <p>The command <code>gc-info</code> lists the partition and different IPU Id's along with the multi-IPU configuration IDs.</p> <pre><code>-+- Id:  [0], target: [Fabric], IPU-M host:  [10.1.5.1], IPU#: [3]\n-+- Id:  [1], target: [Fabric], IPU-M host:  [10.1.5.1], IPU#: [2]\n-+- Id:  [2], target: [Fabric], IPU-M host:  [10.1.5.1], IPU#: [1]\n</code></pre> <p>One may also display detailed information for a specific device.  The devices are numbered 0-63.  For example,</p> <pre><code>gc-info --device-id 0 --device-info\n</code></pre> <p>See <code>gc-info --help</code> for more information.</p>"},{"location":"ai-testbed/graphcore/miscellaneous/#how-busy-is-the-system","title":"How busy is the system?","text":"<p>Use one of</p> <pre><code>top\nhtop\n</code></pre>"},{"location":"ai-testbed/graphcore/running-a-model-or-program/","title":"Steps to Run a Model/Program","text":"<p>Note:  Please be mindful of how you are using the system. For example, consider running larger jobs in the evening or on weekends.</p> <p>Running of any model or application includes graph compilation of the model that is then deployed on the IPUs. Below is the description of training a neural network for classification on the MNIST dataset using the PopTorch (pytorch framework optimized for IPU).</p>"},{"location":"ai-testbed/graphcore/running-a-model-or-program/#examples-repo","title":"Examples Repo","text":"<p>Graphcore provides examples of some well-known AI applications in their repository at https://github.com/graphcore/examples.git.</p> <p>Clone the examples repository to your personal directory structure, and checkout the v3.3.0 release:</p> <pre><code>mkdir ~/graphcore\ncd ~/graphcore\ngit clone https://github.com/graphcore/examples.git\ncd examples\ngit checkout v3.3.0\n</code></pre>"},{"location":"ai-testbed/graphcore/running-a-model-or-program/#mnist","title":"MNIST","text":""},{"location":"ai-testbed/graphcore/running-a-model-or-program/#activate-poptorch-environment","title":"Activate PopTorch Environment","text":"<p>Follows the steps at Poptorch environment setup to enable the Poplar SDK.</p> <pre><code>source ~/venvs/graphcore/poptorch33_env/bin/activate\n</code></pre>"},{"location":"ai-testbed/graphcore/running-a-model-or-program/#install-requirements","title":"Install Requirements","text":"<p>Change directory and install packages specific to the MNIST model:</p> <pre><code>cd ~/graphcore/examples/tutorials/simple_applications/pytorch/mnist\n</code></pre>"},{"location":"ai-testbed/graphcore/running-a-model-or-program/#run-mnist","title":"Run MNIST","text":"<p>Execute the command:</p> <pre><code>/opt/slurm/bin/srun --ipus=1 python mnist_poptorch.py\n</code></pre> <p>All models are run using Slurm, with the <code>--ipus</code> indicating how many IPUs are need to be allocated for the model being run. This example uses a batchsize of 8, and run for 10 epochs. It also set the device iteration to 50 which is the number of iterations the device should run over the data before returning to the user.  The dataset used in the example is derived from the TorchVision and the PopTorch dataloader is used to load the data required for the 50 device iterations from the host to the device in a single step.</p> <p>The model used here is a simple CNN based model with an output from a classifier (softmax layer). A simple Pytorch model is translated to a PopTorch model using <code>poptorch.Options()</code>. <code>poptorch.trainingModel</code> is the model wrapping function on the Pytorch model. The first call to <code>trainingModel</code> will compile the model for the IPU. You can observe the compilation process as part of output of the above command.</p> <pre><code>Graph compilation:   3%|\u258e         | 3/100 [00:00&lt;00:03]2023-04-26T16:53:21.225944Z PL:POPLIN    3680893.3680893 W: poplin::preplanMatMuls() is deprecated! Use poplin::preplan() instead\nGraph compilation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:20&lt;00:00]2023-04-26T16:53:38.241395Z popart:session 3680893.3680893\n</code></pre> <p>The artifacts from the graph compilations is cached in the location set by the flag <code>POPTORCH_CACHE_DIR</code>, where the <code>.popef</code> file corresponding to the model under consideration is cached.</p>"},{"location":"ai-testbed/graphcore/running-a-model-or-program/#output","title":"Output","text":"<p>The expected output will start with downloads followed by and we can observe the model used by the model, the progress bar of the compilation process, and the training progress bar.</p> <pre><code>srun: job 10671 queued and waiting for resources\nsrun: job 10671 has been allocated resources\nTrainingModelWithLoss(\n  (model): Network(\n    (layer1): Block(\n      (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (relu): ReLU()\n    )\n    (layer2): Block(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (relu): ReLU()\n    )\n    (layer3): Linear(in_features=1600, out_features=128, bias=True)\n    (layer3_act): ReLU()\n    (layer3_dropout): Dropout(p=0.5, inplace=False)\n    (layer4): Linear(in_features=128, out_features=10, bias=True)\n    (softmax): Softmax(dim=1)\n  )\n  (loss): CrossEntropyLoss()\n)\nEpochs:   0%|          | 0/10 [00:00&lt;?,[23:27:06.753] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 10\nGraph compilation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00]\nEpochs: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [01:17&lt;00:00,  7.71s/it]\nGraph compilation: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00]                          \nAccuracy on test set: 96.85%\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00]\n</code></pre> <p>Refer to the script to learn more about this example.</p> <p>Example Programs lists the different example applications with corresponding commands for each of the above steps.</p>"},{"location":"ai-testbed/graphcore/virtual-environments/","title":"Virtual Environments","text":""},{"location":"ai-testbed/graphcore/virtual-environments/#poplar-sdk-setup","title":"Poplar SDK Setup","text":"<p>The Poplar SDK is downloaded onto the graphcore systems at the <code>/software/graphcore/poplar_sdk/</code> location. The default poplar version (3.3.0) is enabled automatically upon logging into a graphcore node.</p> <p>Check if Poplar is setup correctly:</p> <pre><code>popc --version\n</code></pre> <p>One should see:</p> <pre><code>POPLAR version 3.3.0 (de1f8de2a7)\nclang version 16.0.0 (2fce0648f3c328b23a6cbc664fc0dd0630122212)\n</code></pre> <p>If the Poplar SDK is not enabled, it can be enabled with <pre><code>source /software/graphcore/poplar_sdk/3.3.0/enable\n</code></pre></p> <p>To disable the current Poplar SDK, e.g. if one wants to use a different Poplar SDK, follow the steps below. (Otherwise, skip to section Miscellaneous Environment Variables.) This example assumes that the current installed SDK is 3.1.0 and you want to move to 3.3.0</p> <ol> <li>Check the current version    <pre><code> $ popc --version\n POPLAR version 3.1.0 (e12d5f9f01)\n clang version 15.0.0 (bab932b4fc4cdb58bb009370384b2c41579bd9d9)\n</code></pre></li> <li>Unset the current version    <pre><code>unset POPLAR_SDK_ENABLED\n</code></pre></li> <li>Enable poplar and popart    <pre><code>source /software/graphcore/poplar_sdk/3.3.0/poplar-ubuntu_20_04-3.3.0+7857-b67b751185/enable.sh \nsource /software/graphcore/poplar_sdk/3.3.0/popart-ubuntu_20_04-3.3.0+7857-b67b751185/enable.sh \n</code></pre></li> <li>Recheck for the new version.    <pre><code>$popc --version\nPOPLAR version 3.3.0 (de1f8de2a7)\nclang version 16.0.0 (2fce0648f3c328b23a6cbc664fc0dd0630122212)\n</code></pre></li> <li> <p>Set SDK env variable    <pre><code>POPLAR_SDK_ROOT=/software/graphcore/poplar_sdk/3.3.0/\nexport POPLAR_SDK_ROOT=$POPLAR_SDK_ROOT\n</code></pre></p> </li> <li> <p>Create a new virtual environment with this SDK and install popTorch and or other frameworks as needed.    <pre><code>virtualenv ~/Graphcore/workspace/poptorch33_env\nsource ~/Graphcore/workspace/poptorch33_env/bin/activate\npip install $POPLAR_SDK_ROOT/poptorch-3.3.0+113432_960e9c294b_ubuntu_20_04-cp38-cp38-linux_x86_64.whl\nexport PYTHONPATH=$POPLAR_SDK_ROOT/python:$PYTHONPATH\n</code></pre></p> </li> </ol>"},{"location":"ai-testbed/graphcore/virtual-environments/#miscellaneous-environment-variables","title":"Miscellaneous Environment Variables","text":"<pre><code>mkdir ~/tmp\nexport TF_POPLAR_FLAGS=--executable_cache_path=~/tmp\nexport POPTORCH_CACHE_DIR=~/tmp\n\nexport POPART_LOG_LEVEL=WARN\nexport POPLAR_LOG_LEVEL=WARN\nexport POPLIBS_LOG_LEVEL=WARN\n\nexport PYTHONPATH=/software/graphcore/poplar_sdk/3.3.0/poplar-ubuntu_20_04-3.3.0+7857-b67b751185/python:$PYTHONPATH\n</code></pre>"},{"location":"ai-testbed/graphcore/virtual-environments/#poptorch-environment-setup","title":"PopTorch Environment Setup","text":"<p>PopTorch is an extension of the Pytorch framework that is optimized for the IPU specific functionality. To activate the PopTorch environment, first create a virtual environment and activate it.</p> <pre><code>mkdir -p ~/venvs/graphcore\nvirtualenv ~/venvs/graphcore/poptorch33_env\nsource ~/venvs/graphcore/poptorch33_env/bin/activate\n</code></pre> <p>Use the following commands to install the PopTorch environment.</p> <pre><code>POPLAR_SDK_ROOT=/software/graphcore/poplar_sdk/3.3.0\nexport POPLAR_SDK_ROOT=$POPLAR_SDK_ROOT\npip install $POPLAR_SDK_ROOT/poptorch-3.3.0+113432_960e9c294b_ubuntu_20_04-cp38-cp38-linux_x86_64.whl\n</code></pre>"},{"location":"ai-testbed/graphcore/virtual-environments/#tensorflow-2-environment-setup","title":"TensorFlow 2 Environment Setup","text":"<p>The Poplar SDK provides TensorFlow and Keras wheels built on 2.6 that includes the IPU specific functionality and optimized for the AMD processors. It can be installed as follows.</p> <p>Create virtual environment.</p> <pre><code>virtualenv ~/venvs/graphcore/tensorflow2_33_env\nsource ~/venvs/graphcore/tensorflow2_33_env/bin/activate\n</code></pre> <p>Install the TensorFlow and Keras wheels.</p> <pre><code>POPLAR_SDK_ROOT=/software/graphcore/poplar_sdk/3.3.0\nexport POPLAR_SDK_ROOT=$POPLAR_SDK_ROOT\npip install $POPLAR_SDK_ROOT/tensorflow-2.6.3+gc3.3.0+251580+08d96978c7f+amd_znver1-cp38-cp38-linux_x86_64.whl\npip install $POPLAR_SDK_ROOT/keras-2.6.0+gc3.3.0+251582+a3785372-py2.py3-none-any.whl\n</code></pre>"},{"location":"ai-testbed/graphcore/virtual-environments/#verify-installation","title":"Verify Installation","text":"<pre><code>python -c \"from tensorflow.python import ipu\"\n</code></pre> <p>You should see:</p> <pre><code>2023-08-22 21:53:26.109934: I tensorflow/compiler/plugin/poplar/driver/poplar_platform.cc:43] Poplar version: 3.3.0 (de1f8de2a7) Poplar package: b67b751185\n</code></pre>"},{"location":"ai-testbed/graphcore/virtual-environments/#installing-packages","title":"Installing Packages","text":"<p>Install packages in the normal manner such as:</p> <pre><code>python3 -m pip install \"some_package\"\n</code></pre> <p>For more details see Use pip for installing.</p> <p>To install a different version of a package that is already installed in one's environment, one can use:</p> <pre><code>pip install --ignore-installed  ... # or -I\n</code></pre> <p>Note: Conda is not supported on the Graphcore system.</p>"},{"location":"ai-testbed/groq/","title":"System Overview","text":"<p>ALCF's Groq system consists of a single <code>GroqRackTM compute cluster</code> that provides an extensible accelerator network consisting of 9 <code>GroqNodeTM</code> [ <code>groq-r01-gn-01</code> through <code>groq-r01-gn-09</code> ] nodes with a rotational multi-node network topology. Each of these GroqNodes consists of 8 GroqCardTM accelerators in them with integrated chip-to-chip connections with a dragonfly multi-chip topology.</p> <p><code>GroqCardTM accelerator</code> is a dual-width, full-height, three-quarter length PCI-Express Gen4 x16 adapter that includes a single <code>GroqChipTM processor</code> with 230 MB of on-chip memory. Based on the proprietary Tensor Streaming Processor (TSP) architecture, the GroqChip processor is a low latency and high throughput single core SIMD compute engine capable of 750 TOPS (INT8) and 188 TFLOPS (FP16) @ 900 MHz that includes advanced vector and matrix mathematical acceleration units.  The GroqChip processor is deterministic, providing predictable and repeatable performance. </p> <p>The <code>GroqWare suite SDK</code> uses a API based programming model and enables users to develop, compile, and run models on the GroqCard accelerator in a host server system. The SDK uses a ONNX/MLIR enabled DAG compiler and it consists of Groq Compiler, Groq API, and utility tools like GroqView\u2122 profiler and <code>groq-runtime</code>. </p> <p>For more information refer to the following links<sup>1</sup>:</p> <ul> <li>GroqRack spec sheet</li> <li>GroqNode spec sheet</li> <li>GroqCard spec sheet</li> <li>GroqChip spec sheet</li> </ul> <ol> <li> <p>source \u21a9</p> </li> </ol>"},{"location":"ai-testbed/groq/examples/","title":"Examples","text":""},{"location":"ai-testbed/groq/examples/#running-llama-2-7b-on-the-groqrack","title":"Running Llama-2 7B on the Groqrack","text":"<p>Llama-2 7B requires all 9 nodes in a Groqrack.</p>"},{"location":"ai-testbed/groq/examples/#checking-status","title":"Checking status","text":"<p>First, verify that there are no other PBS jobs using the Groqrack. This can be done from either a Groqrack node or a login node. <pre><code>qstat -wa\n</code></pre> If <code>qstat -wa</code> shows any jobs active, do not attempt to start Llama2.</p> <p>Also, be sure to check if anyone else is connected to any of the nodes: This can be done from a either grokrack node or a login node. Logins on nodes just indicate a potential conflict; this would only be an actual conflict if the user starts a job during the attempt to run the full-rack llama job. <pre><code>for host in groq-r01-gn-0{1..9}; do echo $host; ssh $host /usr/bin/who; done\n</code></pre></p> <p>Also verify that all nodes have eight unlocked cards: <pre><code>for host in groq-r01-gn-0{1..9}; do ssh $host tsp-ctl status | grep -a \"Device Locked\" | sed \"s/ Device Locked/$host Device locked/\" | uniq -c ; done\n</code></pre></p> <p>Also, check tsp status for all cards on all nodes; verify that all cards are \"Up\": <pre><code>for host in groq-r01-gn-0{1..9}; do ssh $host tsp-ctl health-check | grep -v \"Health-check\" | jq .[].Summary.tsp_status | sed \"s/^/$host /\" | uniq -c; done\n</code></pre></p> <p>Also, clear the memory registries of all the cards (LPUs):  <pre><code>for host in groq-r01-gn-0{1..9}; do ssh $host tsp-ctl clear | uniq -c; done\n</code></pre></p>"},{"location":"ai-testbed/groq/examples/#running-llama2-7b","title":"Running Llama2 7B","text":"<p>Connect to <code>groq-r01-gn-01.ai.alcf.anl.gov</code> with <code>ssh</code>: <pre><code>ssh  groq-r01-gn-01.ai.alcf.anl.gov\n</code></pre></p> <p>Copy some example files (about 25k), so that you have write access to them. <pre><code>mkdir ~/groq_llama2-7b-kludge/\ncp /software/groq/examples/llama2-7b-kludge/*.sh ~/groq_llama2-7b-kludge/\ncp /software/groq/examples/llama2-7b-kludge/README.md ~/groq_llama2-7b-kludge/\ncd ~/groq_llama2-7b-kludge/\n</code></pre></p> <p>Note</p> <p>Packages installed (including dependencies) in <code>~/.local/lib</code> will override those in your conda environments. If you have a <code>~/.local/lib/python3.10/site-packages/</code> directory, please remove it or rename it before continuing.</p> <p>Create and activate a <code>groqflow_for_llama2</code>conda environment. <pre><code>conda env remove -n groqflow_for_llama2\nexport PYTHON_VERSION=3.10.12\nconda create -n groqflow_for_llama2 python=$PYTHON_VERSION -y\nconda activate groqflow_for_llama2\n</code></pre></p> <p>Install these packages into the conda environment: <pre><code>pip install --upgrade pip\npip install tqdm torch==2.1.2\n</code></pre></p> <p>Set the <code>PYTHONPATH</code> to include the conda environment: <pre><code>export PYTHONPATH=/home/$(whoami)/miniconda3/envs/groqflow_for_llama2/lib/python3.10/site-packages\n</code></pre></p> <p>Reserve the cluster. This will launch a placeholder PBS job that reserves the entire cluster.  It simply runs <code>sleep 24h</code> on a node. The following example script reserves the cluster via PBS for 2hrs. Adjust the values as needed. <pre><code>./stage1_reserve_cluster_via_pbs.sh\n</code></pre></p> <p>Then run Llama2-7b.  <pre><code>cd ~/groq_llama2-7b-kludge/\n./stage2_build_topology.sh\nexport CONDA_PREFIX=/home/$(whoami)/miniconda3/envs/groqflow_for_llama2\n./stage3_run_llamma-7b.sh\n</code></pre> The script can be modified, or pieces run manually: <pre><code># popd to return to the current directory\npushd .\ncd /software/groq/examples/GROQ_TESTS/llama2-7b\n</code></pre></p> <p>The basic command is  <pre><code>groq-python anl_llama2_7b_launch_helper.py -b -p 'what are the most popular ice cream flavors'\n</code></pre> You only need to run -b ('--bringup') once, e.g. <pre><code>groq-python anl_llama2_7b_launch_helper.py -b'\n</code></pre> then can run multiple queries <pre><code>groq-python anl_llama2_7b_launch_helper.py -p 'what are the most popular ice cream flavors in Egypt'\ngroq-python anl_llama2_7b_launch_helper.py -p 'what are the most popular ice cream flavors in Japan'\n</code></pre></p> <p>Note</p> <p>The <code>-b</code> (<code>--bringup</code>) flag for <code>groq_llama2_7b.py</code> brings up the whole rack c2c links between cards.  It can be \"fragile\".  If another job is running, or if it gets in a abnormal state, the command will fail without any really useful info on why.  If another job is running, you have to wait.  If there is nothing else running, you have to get an admin to reset the cards.</p> <p>When done, clean up. This resets the card topology, resets card memory, and deletes the all-rack PBS reservation. <pre><code># if running manually, go back to the script dir\npopd\n./stage4_cleanup.sh\n</code></pre></p>"},{"location":"ai-testbed/groq/getting-started/","title":"Getting Started","text":""},{"location":"ai-testbed/groq/getting-started/#allocations","title":"Allocations","text":"<p>If you do not already have an allocation, you will need to request one here: Discretionary Allocation Request (New &amp; Renewal)</p>"},{"location":"ai-testbed/groq/getting-started/#accounts","title":"Accounts","text":"<p>If you do not have an ALCF account (but have an allocation), request one here: ALCF Account and Project Management</p>"},{"location":"ai-testbed/groq/getting-started/#setup","title":"Setup","text":"<p>Connection to a GroqRack node is a two-step process.</p> <p>The first step is to ssh from a local machine to a login node. The second, optional step is to ssh from a login node to a GroqRack node. Jobs may also be started and tracked from login nodes.</p> <p></p>"},{"location":"ai-testbed/groq/getting-started/#log-in-to-a-login-node","title":"Log in to a login node","text":"<p>Connect to a groq login node, editing this command line to use your ALCF user id. You will be prompted for a password; use the 8-digit code provided by  MobilePASS+.  <pre><code>ssh ALCFUserID@groq.ai.alcf.anl.gov\n</code></pre> This randomly selects one of the login nodes, namely <code>groq-login-01.ai.alcf.anl.gov</code> or <code>groq-login-02.ai.alcf.anl.gov</code>. You can alternatively ssh to the specific login nodes directly. </p>"},{"location":"ai-testbed/groq/getting-started/#log-in-to-a-groqrack-node","title":"Log in to a GroqRack node","text":"<p>Once you are on a login node, optionally ssh to one of the GroqRack nodes, which are numbered 1-9.</p> <pre><code>ssh groq-r01-gn-01.ai.alcf.anl.gov\n# or\nssh groq-r01-gn-09.ai.alcf.anl.gov\n# or any node with hostname of form groq-r01-gn-0[1-9].ai.alcf.anl.gov\n</code></pre>"},{"location":"ai-testbed/groq/groqview/","title":"GroqView profiler and visualizer tool","text":"<p>This section covers how to remotely use the GroqView profiler and visualizer tool.</p>"},{"location":"ai-testbed/groq/groqview/#groqview-sample","title":"GroqView sample","text":"<p>Groq compiles produce an accurate and detailed model of the performance of a model's execution on groq cards. There is no need to run a model on groqcards to use GroqView. The GroqView example adds the \"groqview=True\" parameter to the <code>groqit</code> call, then calls the <code>groqview()</code> method on the model returned by <code>groqit</code>. This is the relevant code when using GroqFlow. It tries to retrieve the compiled model from the cache, compiles the model on a cache miss, then calls <code>groqview()</code>. From <code>groqflow/examples/pytorch/groqview.py</code>:  <pre><code># Build model\ngmodel = groqit(pytorch_model, inputs, groqview=True)\n# Open GroqView\ngmodel.groqview()\n</code></pre></p>"},{"location":"ai-testbed/groq/groqview/#run-the-sample","title":"Run the sample","text":"<p>On a groq node, run the groqview.py sample (or any script that includes similar code). Note the port number chosen by GroqView. <pre><code>conda activate groqflow\ncd ~/groqflow/examples/pytorch\npython groqview.py\n# You will see something like the following.\n# The port number may be different.\n...\nOpen your web browser:\n    http://localhost:8439\n</code></pre></p>"},{"location":"ai-testbed/groq/groqview/#forward-the-port-to-your-machine-with-a-browser","title":"Forward the port to your machine with a browser","text":"<p>On your laptop/user machine with a display, set up a 2-hop ssh tunnel. Set <code>$GN_HOSTNAME</code> to the name of the host where job is running <pre><code>export GN_HOSTNAME=groq-r01-gn-09\n# Modify the port number if GroqView has chosen a different port.\n# This might happen if another user is also using GroqView.\n# Also, another user may be using the port on the login host.\n# `groq-login-01.ai.alcf.anl.gov` can be used as well.\nssh -L 8439:localhost:8439 arnoldw@groq-login-02.ai.alcf.anl.gov -t ssh -L 8439:localhost:8439 -N $GN_HOSTNAME\n# When complete, \"ctrl-c\" or equivalent in the console where the ssh tunnel\n# was started will terminate both parts of a ssh tunnel set up this way.\n</code></pre></p>"},{"location":"ai-testbed/groq/groqview/#access-the-groqview-server-for-your-application","title":"Access the GroqView server for your application:","text":"<p>Point a Google Chrome-family web browser at this url, adjusting the port number if necessary. (Chrome, Brave, Vivaldi, Opera tested.) <pre><code>http://localhost:8439\n</code></pre></p>"},{"location":"ai-testbed/groq/job-queuing-and-submission/","title":"Job Queueing and Submission","text":"<p>Groq jobs in the AI Testbed's groqrack are managed by the PBS job scheduler. Overview: PBS. For additional information, see Running Jobs using PBS</p> <p>Man pages are available. These are the key commands: <pre><code># qsub - to submit a batch job using a script\nman qsub\n# qstat - to display queue information\nman qstat\n# qdel - to delete (cancel) a job:\nman qdel\n# qhold - to hold a job\nman qhold\n</code></pre></p>"},{"location":"ai-testbed/groq/running-a-model-or-program/","title":"Running a Model/Program","text":"<p>Jobs are launched from any GroqRack node.  If you expect a loss of an internet connection for any reason, for long-running jobs we suggest logging into a specific node and using either screen or tmux to create persistent command line sessions.  For details use:</p> <p><pre><code>man screen\n# or\nman tmux\n</code></pre> or online man pages: screen, tmux</p>"},{"location":"ai-testbed/groq/running-a-model-or-program/#running-jobs-on-groq-nodes","title":"Running jobs on Groq nodes","text":""},{"location":"ai-testbed/groq/running-a-model-or-program/#groqflow","title":"GroqFlow","text":"<p>GroqFlow is the simplest way to port applications running inference to groq. The groqflow github repo includes many sample applications. See GroqFlow.</p>"},{"location":"ai-testbed/groq/running-a-model-or-program/#clone-the-groqflow-github-repo","title":"Clone the GroqFlow github repo","text":"<p>Clone the groqflow github repo and change current directory to the clone: <pre><code>cd ~/\ngit clone https://github.com/groq/groqflow.git\ncd groqflow\n</code></pre></p>"},{"location":"ai-testbed/groq/running-a-model-or-program/#groqflow-conda-environments","title":"GroqFlow conda environments","text":"<p>Create a groqflow conda environment, and activate it. Follow the instructions in the Virtual Environments  section. Note: Similar install instructions are in <code>~/groqflow/docs/install.md</code> or GroqFlow\u2122 Installation Guide The conda enviroment should be reinstalled whenever new groqflow code is pulled from the groqflow github; with a groqflow conda environment activated, redo just the pip install steps.</p>"},{"location":"ai-testbed/groq/running-a-model-or-program/#running-a-groqflow-sample","title":"Running a groqflow sample","text":"<p>Each groqflow sample directory in the <code>~/groqflow/proof_points</code> tree has a README.md describing the sample and how to run it.</p>"},{"location":"ai-testbed/groq/running-a-model-or-program/#optionally-activate-your-groqflow-conda-environment","title":"Optionally activate your GroqFlow conda environment","text":"<pre><code>conda activate groqflow\n</code></pre>"},{"location":"ai-testbed/groq/running-a-model-or-program/#run-a-sample-using-pbs-in-batch-mode","title":"Run a sample using PBS in batch mode","text":"<p>See Job Queueing and Submission for more information about the PBS job scheduler.</p> <p>Create a script <code>run_minilmv2.sh</code> with the following contents. It assumes that conda was installed in the default location. The conda initialize section can also be copied from your .bashrc if the conda installer was allowed to add it. <pre><code>#!/bin/bash\n# &gt;&gt;&gt; conda initialize &gt;&gt;&gt;\n# !! Contents within this block are managed by 'conda init' !!\n__conda_setup=\"$(${HOME}'/miniconda3/bin/conda' 'shell.bash' 'hook' 2&gt; /dev/null)\"\nif [ $? -eq 0 ]; then\n    eval \"$__conda_setup\"\nelse\n    if [ -f \"${HOME}/miniconda3/etc/profile.d/conda.sh\" ]; then\n        . \"${HOME}/miniconda3/etc/profile.d/conda.sh\"\n    else\n        export PATH=\"${HOME}/miniconda3/bin:$PATH\"\n    fi\nfi\nunset __conda_setup\n# &lt;&lt;&lt; conda initialize &lt;&lt;&lt;\nconda activate groqflow\ncd ~/groqflow/proof_points/natural_language_processing/minilm\npip install -r requirements.txt\npython minilmv2.py\n</code></pre></p> <p>Then run the script as a batch job with PBS. This will reserve a full eight-card(chip) node. <pre><code>qsub -l  select=1,place=excl run_minilmv2.sh\n</code></pre></p> <p>Note: the number of chips used by a model can be found in the compile cache dir for the model after it is compiled. E.g. <pre><code>$ grep num_chips_used ~/.cache/groqflow/minilmv2/minilmv2_state.yaml\nnum_chips_used: 1\n</code></pre> The groqflow proofpoints models use 1, 2 or 4 chips. </p> <p>If your <code>~/.bashrc</code> initializes conda, an alternative to copying the conda initilization script into your execution scripts is to comment out this section in your \"~/.bashrc\": <pre><code># If not running interactively, don't do anything\ncase $- in\n    *i*) ;;\n      *) return;;\nesac\n</code></pre> to <pre><code>## If not running interactively, don't do anything\n#case $- in\n#    *i*) ;;\n#      *) return;;\n#esac\n</code></pre> Then the execution script becomes: <pre><code>#!/bin/bash\nconda activate groqflow\ncd ~/groqflow/proof_points/natural_language_processing/minilm\npip install -r requirements.txt\npython minilmv2.py\n</code></pre> Job status can  be tracked with qstat: <pre><code>$ qstat\nJob id            Name             User              Time Use S Queue\n----------------  ---------------- ----------------  -------- - -----\n3084.groq-r01-co* run_minilmv2     user              0 R workq           \n$ \n</code></pre></p> <p>Output will by default go to two files with names like the following, where the suffix is the job id. One standard output for the job. The other is the standard error for the job. <pre><code>$ ls -la run_minilmv2.sh.*\n-rw------- 1 user users   448 Oct 16 18:40 run_minilmv2.sh.e3082\n-rw------- 1 user users 50473 Oct 16 18:42 run_minilmv2.sh.o3082\n</code></pre></p>"},{"location":"ai-testbed/groq/running-a-model-or-program/#run-a-sample-using-pbs-in-interactive-mode","title":"Run a sample using PBS in interactive mode","text":"<p>An alternative is to use an interactive PBS job. This may be useful when debugging new or changed code. Here is an example that starts a 24 hour interactive job. It reserves a full eight-card(chip) node.  <pre><code>qsub -IV -l walltime=24:00:00 -l select=1,place=excl\n</code></pre> Then activate your groqflow environment, and run python scripts with <pre><code>conda activate groqflow\npython scriptname.py\n</code></pre></p>"},{"location":"ai-testbed/groq/virtual-environments/","title":"Virtual Environments","text":""},{"location":"ai-testbed/groq/virtual-environments/#install-conda","title":"Install conda","text":"<p>If conda is not already installed: <pre><code>rm Miniconda3-latest-Linux-x86_64.sh*\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh\n# answer y/yes to all prompts\n# exit ssh session, then start a new ssh session\nexit\n</code></pre></p>"},{"location":"ai-testbed/groq/virtual-environments/#groqflow-conda-environment-setup","title":"GroqFlow conda environment setup","text":""},{"location":"ai-testbed/groq/virtual-environments/#create-and-activate-a-groqflow-conda-environment","title":"Create and activate a groqflow conda environment","text":"<p>Create a groqflow conda environment and activate it <pre><code>export PYTHON_VERSION=3.10.12\nconda create -n groqflow python=$PYTHON_VERSION -y\nconda activate groqflow\n</code></pre></p>"},{"location":"ai-testbed/groq/virtual-environments/#install-groqflow-into-the-groqflow-conda-environment","title":"Install groqflow into the groqflow conda environment","text":"<p>Execute the following commands to install groqflow into the activated groqflow conda environment</p> <pre><code># Alter this if you have cloned groqflow to some other location.\ncd ~/groqflow\nif [ -d \"groqflow.egg-info\" ]; then rm -r groqflow.egg-info; fi\npip install --upgrade pip\npip list --format=freeze &gt; frozen.txt\npip install -r frozen.txt -e .\npushd . \ncd demo_helpers\nif [ -d \"groqflow_demo_helpers.egg-info\" ]; then rm -r groqflow_demo_helpers.egg-info; fi\npip install -e .\npopd\npip install soundfile\npip install datasets==2.21.0\n</code></pre> <p>Note: if you encounter problems trying to update an existing groqflow conda environment, consider removing the existing environment with the following command, and recreating it. Make sure you deactivate the environment before removing it.      <pre><code>  conda remove --name groqflow --all -y\n</code></pre></p>"},{"location":"ai-testbed/groq/virtual-environments/#use-groqflow","title":"Use Groqflow","text":"<p>To use groqfloq, <pre><code>conda activate groqflow\n</code></pre> Note: Always use a personal conda environment when installing packages on groq nodes; otherwise they can get installed into <code>~/.local</code> and can cause problems when your shared home directory is used on other systems. If you encounter mysterious package dependency/version issues, check your <code>~/.local/lib</code> and <code>~/.local/bin</code> for mistakenly installed packages.</p> <p>Note: The conda enviroment should be reinstalled whenever new groqflow code is pulled from the groqflow github; with a groqflow conda environment activated, redo just the pip install steps, including the removal of the egg-info directories.</p>"},{"location":"ai-testbed/sambanova/","title":"System Overview","text":""},{"location":"ai-testbed/sambanova/#introduction","title":"Introduction","text":"<p>The SambaNova DataScale SN30 system is architected around the next-generation Reconfigurable Dataflow Unit (RDU) processor for optimal dataflow processing and acceleration. The AI Testbed's SambaNova SN30 system consists of eight nodes in 4 full racks, each node featuring eight RDUs interconnected to enable model and data parallelism. SambaFlow, Sambanova's software stack, extracts, optimizes, and maps the dataflow graphs to the RDUs from standard machine learning frameworks like PyTorch.</p> <p>Below are some of the links to SambaNova documentation.</p> <p>SambaNova white paper: Accelerated Computing with a Reconfigurable Dataflow Architecture</p> <p>SN30 documentation: SambaNova Documentation</p>"},{"location":"ai-testbed/sambanova/documentation/","title":"Documentation","text":"<p>The SambaNova documentation is now available online SambaNova Documentation.</p> <p>The documentation for the SambaTune (a profiling and performance tuning tool for SambaNova systems) is now available at SambaTune Documentation.</p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/","title":"SambaNova Model Zoo samples","text":"<p>The SambaNova Model Zoo is SambaNova's new github repository for delivering RDU-compatible source code, including example applications for compiling and running models on SambaNova hardware.</p> <p>In the ALCF SN30 cluster, the Model Zoo samples run inside of Singularity containers. The Singularity image includes support for compiling and running models.</p> <p>The procedures in this section are drawn from Walkthrough\u2014\u200bInference and Fine-tuning with Llama2 7B for Chat.  The Model Zoo inference sample used as an example in this section is described in more detail here About the Generation Example Apps. This readme (on GitHub) also describes the changes made to a CPU mode sample to run on an RDU. The original python scripts and scripts converted to run on an RDU are also supplied in the modelzoo. cpu_generate_text.py rdu_generate_text.py and cpu_train_llm.py rdu_train_llm.py rdu_train_llm_dp.py </p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#setup","title":"Setup","text":""},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#cloning-the-model-zoo-repository","title":"Cloning the Model Zoo Repository","text":"<p>Clone the repo in your usual location.  <pre><code>mkdir ~/sambanova\ncd ~/sambanova\ngit clone https://github.com/sambanova/modelzoo.git\n</code></pre> Note: your home directory is mounted by default in the singularity containers.</p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#starting-a-container","title":"Starting a container:","text":"<p>Change directory to your Model Zoo clone, and set an environment variable to be host SambaNova runts version, then start the container. This example binds a directory containing an OpenWebText dataset.  <pre><code>cd ~/sambanova/modelzoo\nexport TARGET_SAMBAFLOW_VERSION=$((rpm -q sambanova-runtime 2&gt;/dev/null || dpkg -s sambanova-runtime 2&gt;/dev/null) | egrep -m 1 -o \"[0-9]+\\.[0-9]+\\.[0-9]+\")\necho $TARGET_SAMBAFLOW_VERSION\n# should be of the form 1.19.1\n./start_container.sh -b /data/ANL/openwebtext/hdf5/hdf5:/opt/datasets/openweb_hdf54096/ -b  /software:/software / /software/sambanova/singularity/images/llm-modelzoo/Modelzoo/ModelzooDevbox_0.2.0.sif \n</code></pre> Container startup output should look like: <pre><code>APP_ROOT: /home/arnoldw/sambanova/modelzoo\nUsing singularity with image /software/sambanova/singularity/images/llm-modelzoo/Modelzoo/ModelzooDevbox_1.sif\n\nRunning singularity instance with name: devbox_arnoldw_1724873417\nSingularity start command: singularity instance start --writable-tmpfs --bind /home/arnoldw/github.com/sambanova/modelzoo:/opt/modelzoo --bind /tmp:/tmp --bind /data/ANL/openwebtext/hdf5/hdf5:/opt/datasets/openweb_hdf54096/ --bind /software/models/:/opt/ckpts/ --bind /dev/hugepages:/dev/hugepages --bind /opt/sambaflow/pef/:/opt/sambaflow/pef/ --bind /opt/sambaflow/runtime/:/opt/sambaflow/runtime/ --bind /var/lib/sambaflow/ccl/ccl_config.db:/var/lib/sambaflow/ccl/ccl_config.db --bind /var/snml.sock:/var/snml.sock --bind /opt/sambanova/lib/python3.8/site-packages/pysnml:/opt/sambanova/lib/python3.8/site-packages/pysnml --bind /opt/sambanova/lib/python3.8/site-packages/pysnrdureset:/opt/sambanova/lib/python3.8/site-packages/pysnrdureset --bind /opt/sambanova/lib/python3.8/site-packages/pysnrdutools:/opt/sambanova/lib/python3.8/site-packages/pysnrdutools --bind /opt/sambanova/lib/python3.8/site-packages/sambaruntime:/opt/sambanova/lib/python3.8/site-packages/sambaruntime /software/sambanova/singularity/images/llm-modelzoo/Modelzoo/ModelzooDevbox_1.sif devbox_arnoldw_1724873417\nINFO:    instance started successfully\nSingularity instance devbox_arnoldw_1724873417 started\nRun command: singularity exec instance://devbox_arnoldw_1724873417 /bin/bash\nSingularity&gt; \n</code></pre></p> <p>To list all running containers (while outside a container, e.g. a different SSH session): <pre><code>$ singularity instance list\nINSTANCE NAME                PID        IP    IMAGE\ndevbox_arnoldw_1724873417    1649294          /software/sambanova/singularity/images/llm-modelzoo/Modelzoo/ModelzooDevbox_1.sif\n</code></pre> To re-enter an exited but still-running container (while outside a container): <pre><code>$ singularity exec instance://devbox_arnoldw_1724873417 /bin/bash\nSingularity&gt; \n</code></pre></p> <p>To stop all your running containers (while outside a container): <pre><code>$ singularity instance stop devbox_&lt;youruserid&gt;_*\n</code></pre></p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#set-up-the-python-environment-in-the-container","title":"Set up the Python environment in the container","text":"<pre><code>cd ~/sambanova/modelzoo/\npip install -r requirements/requirements.txt \npip install --upgrade pip\npip install -e . \n</code></pre>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#optionally-download-the-hugging-face-model-for-llama-2-7b","title":"Optionally, download the Hugging Face model for Llama-2-7b","text":"<p>This model is also avaiable in <code>/software/models/Llama-2-7b-hf/</code> First, create a Hugging Face account at https://huggingface.co/join if you do not already have one. Go to meta-llama/Llama-2-7b-hf and accept the terms of use for Llama2 7B. You will need to wait (minutes at least) until the request is proccessed. In your Hugging Face account settings, generate a user access token. A read-only token works. Record the token such that it can easily be copy-pasted in the future. <pre><code># if working in an environment (e.g. laptop) where git-lfs is not installed, \n# sudo apt install git-lfs \ngit lfs install # Only needs to be done once \ncd ~/sambanova\ngit clone https://huggingface.co/meta-llama/Llama-2-7b-hf\n# Enter your HF user name and user access token (copy;paste) when prompted.\n</code></pre></p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#text-generation-sample","title":"Text generation sample","text":""},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#compile-a-text-generation-sample-that-uses-the-hf-model","title":"Compile a text generation sample that uses the HF model","text":"<p>Compile a LLaMA-7b text generation sample (using the Hugging Face model). This will take 20 minutes</p> <pre><code>cd ~/sambanova\n# or ./Llama-2-7b-hf if downloaded\npython ./modelzoo/examples/nlp/text_generation/rdu_generate_text.py \\\ncommand=compile \\\ncheckpoint.model_name_or_path=/software/models/Llama-2-7b-hf/ \\\nsamba_compile.output_folder=/home/$(whoami)/sambanova/out_generation \\\n+samba_compile.target_sambaflow_version=LATEST\n</code></pre> <p>Note: each compile will add a new subdirectory to the ouput folder (<code>/home/$(whoami)/sambanova/out_generation</code>), containing compile artifacts. The folder can be deleted when testing is complete;</p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#run-the-text-generation-sample","title":"Run the text generation sample","text":"<p>Run the sample, using the <code>.pef</code> binary created by the compile. Note: The expression in the command line finds the most recent pef file.</p> <pre><code>cd ~/sambanova\nexport PEF=$(find /home/$(whoami)/sambanova/out_generation -type f -name \"*.pef\" -printf \"%T@ %p\\n\" | sort -n | tail -n1 | awk '{print $2}')\n# or ./Llama-2-7b-hf if downloaded\npython ./modelzoo/examples/nlp/text_generation/rdu_generate_text.py \\\n  command=run \\\n  checkpoint.model_name_or_path=/software/models/Llama-2-7b-hf/ \\\n  samba_run.pef=${PEF}\n</code></pre> <p>The end of the console output should resemble the following: <pre><code>Generating 32 tokens ...\nDecoding ...\nCompletion:\n[', there was a little boy who lived in a small town.\\nHe was a good boy, but sometimes he had a hard time following the rules.\\n']\n\nlatencies\n    time to first token 1.1981s\n    tokens,  excluding first token 0.3330s\n    tokens,  overall 0.3600s\n    Total Latency 1.5310s\nthroughputs\n    tokens/second excluding first token 3.0032\n    tokens/second overall 2.7777\nSingularity&gt; \n</code></pre></p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#model-finetuning-sample","title":"Model Finetuning Sample","text":"<p>Fine-tune the Llama2 7B model using a chat dataset.</p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#data-preparation","title":"Data preparation","text":"<p>NOTE: These data preparation steps should be performed on a SambaNova node, and not in a singularity container.</p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#install-the-generative-data-prep-package-in-a-virtualenv","title":"Install the Generative Data Prep package in a virtualenv","text":"<pre><code>cd ~/sambanova\ngit clone https://github.com/sambanova/generative_data_prep.git\ncd generative_data_prep\npython -m venv gdp_venv\nsource gdp_venv/bin/activate\npip install .\ncd ~/sambanova\n</code></pre>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#download-ultrachat-from-its-hugging-face-page","title":"Download UltraChat from its Hugging Face page","text":"<p>Make sure that you have git lfs installed, with <code>git lfs install</code> <pre><code>cd ~/sambanova\ngit clone https://huggingface.co/datasets/stingning/ultrachat\n</code></pre></p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#convert-the-dataset-to-the-jsonl-format","title":"Convert the dataset to the <code>.jsonl</code> format","text":"<pre><code>cd ~/sambanova\nsource generative_data_prep/gdp_venv/bin/activate\n# This step makes a single jsonl file\npython ./modelzoo/examples/nlp/training/utils/convert_ultrachat.py -src ultrachat/ -dest ultrachat_processed.jsonl\n# get a small subset to keep the 1 epoch runtime down.\nmv ~/sambanova/ultrachat_processed.jsonl ~/sambanova/ultrachat_processed_full.jsonl\nhead -1000 ~/sambanova/ultrachat_processed_full.jsonl &gt; ~/sambanova/ultrachat_processed.jsonl\n# This step makes a directory of hdf5 files from the single jsonl file\nexport TOKENIZER=\"meta-llama/Llama-2-7b-hf\"\nexport MAX_SEQ_LENGTH=4096\npython -m generative_data_prep pipeline --input_file_path=./ultrachat_processed.jsonl --output_path=./ultrachat_dialogue --pretrained_tokenizer=${TOKENIZER} --max_seq_length=${MAX_SEQ_LENGTH}\ndeactivate\n</code></pre>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#compile-a-sample-that-finetunes-the-hf-model","title":"Compile a sample that finetunes the HF model","text":""},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#start-container","title":"Start container","text":"<p>If you are not already in a Singularity container (with the pre-reqs installed), start a new Model Zoo Singularity container with <pre><code>cd ~/sambanova/modelzoo\nexport TARGET_SAMBAFLOW_VERSION=$((rpm -q sambanova-runtime 2&gt;/dev/null || dpkg -s sambanova-runtime 2&gt;/dev/null) | egrep -m 1 -o \"[0-9]+\\.[0-9]+\\.[0-9]+\")\necho $TARGET_SAMBAFLOW_VERSION\n# should be of the form 1.19.1\n./start_container.sh -b /data/ANL/openwebtext/hdf5/hdf5:/opt/datasets/openweb_hdf54096/ -b  /software:/software /software/sambanova/singularity/images/llm-modelzoo/Modelzoo/ModelzooDevbox_1.sif\n</code></pre> or use an existing container with instructions at starting a container</p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#install-pre-reqs","title":"Install pre-reqs","text":"<p>Then install the pre-reqs into the container with <pre><code>cd ~/sambanova/modelzoo/\npip install -r requirements/requirements.txt \npip install --upgrade pip\npip install -e . \n</code></pre></p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#compile-the-sample-for-fine-tuning","title":"Compile the sample for fine tuning","text":"<pre><code>cd ~/sambanova\nexport CHECKPOINT=/software/models/Llama-2-7b-hf/ # or ./Llama-2-7b-hf\nexport MAX_SEQ_LENGTH=4096\nexport BATCH_SIZE=8\nexport ARCH=sn30\npython modelzoo/examples/nlp/training/rdu_train_llm.py \\\n    command=compile \\\n    checkpoint.config_name=${CHECKPOINT} \\\n    model.max_seq_length=${MAX_SEQ_LENGTH} \\\n    training.batch_size=${BATCH_SIZE} \\\n    samba_compile.arch=${ARCH} \\\n    samba_compile.output_folder=/home/$(whoami)/sambanova/out_train \\\n    +samba_compile.target_sambaflow_version=LATEST\n</code></pre> <p>Note: each compile will add a new subdirectory to the ouput folder (<code>/home/$(whoami)/sambanova/out_train</code>), containing compile artifacts. The folder can be deleted when testing is complete;</p>"},{"location":"ai-testbed/sambanova/example-modelzoo-programs/#run-finetuning-using-generated-pef-file","title":"Run finetuning using generated pef file","text":"<p>This will run for 1 full epoch and takes 1 hour to execute, using a single RDU. It uses the config file <code>modelzoo/examples/nlp/training/config/base_config_rdu.yaml</code></p> <pre><code>cd ~/sambanova\nexport CHECKPOINT=/software/models/Llama-2-7b-hf/ # or ./Llama-2-7b-hf\nexport MAX_SEQ_LENGTH=4096\nexport DATASET=./ultrachat_dialogue;  # or container path to dataset\n# Finds most recent pef file in tree\nexport PEF=$(find /home/$(whoami)/sambanova/out_train -type f -name \"*.pef\" -printf \"%T@ %p\\n\" | sort -n | tail -n1 | awk '{print $2}')\npython -u modelzoo/examples/nlp/training/rdu_train_llm.py \\\n    command=run \\\n    checkpoint.model_name_or_path=${CHECKPOINT} \\\n    model.max_seq_length=${MAX_SEQ_LENGTH} \\\n    samba_run.pef=${PEF} \\\n    training.dataset=${DATASET}\n</code></pre> <p>The end of the console output should resemble the following if run for a full epoch: <pre><code>Targeting samba-runtime v4.2.5. Samba is running with --target-runtime-version=1.3.10 on a system with installed runtime None.\n\nLog ID initialized to: [arnoldw][python][1003] at /var/log/sambaflow/runtime/sn.log\nLoading dataset for epoch 1...\n\nNumber of epochs: 1\nBatch size: 8\nNumber of batches (steps): 1,143\n\nStarting training for epoch 1...\nEpoch [1/1], Step [1/1143], Loss: 0.8184\nEpoch [1/1], Step [2/1143], Loss: 0.2452\nEpoch [1/1], Step [3/1143], Loss: 0.3727\nEpoch [1/1], Step [4/1143], Loss: 0.2945\n...\nEpoch [1/1], Step [1134/1143], Loss: 0.2529\nEpoch [1/1], Step [1135/1143], Loss: 0.2713\nEpoch [1/1], Step [1136/1143], Loss: 0.2669\nEpoch [1/1], Step [1137/1143], Loss: 0.2144\nEpoch [1/1], Step [1138/1143], Loss: 0.2129\nEpoch [1/1], Step [1139/1143], Loss: 0.2229\nEpoch [1/1], Step [1140/1143], Loss: 0.2263\nEpoch [1/1], Step [1141/1143], Loss: 0.2434\nEpoch [1/1], Step [1142/1143], Loss: 0.2131\nEpoch [1/1], Step [1143/1143], Loss: 0.1626\nFinished training.\nSaving checkpoint...\nCheckpoint saved at finetuned_model/\nSaving summary...\nSummary saved at finetuned_model/summary.txt\nSingularity&gt; \n</code></pre></p>"},{"location":"ai-testbed/sambanova/example-multi-node-programs/","title":"Example Multi-Node Programs","text":"<p>In this section we will learn how to extend the UNet2d and Gpt1.5B applications scripts that we introduced in the Example Programs to compile and run multiple instances of the model in a data parallel fashion across multiple tiles or across multiple nodes.</p>"},{"location":"ai-testbed/sambanova/example-multi-node-programs/#unet2d","title":"UNet2d","text":""},{"location":"ai-testbed/sambanova/example-multi-node-programs/#set-up","title":"Set Up","text":"<p>Create the following directory and change to it if you have not already done so.</p> <pre><code>mkdir -p ~/apps/image/unet\ncd ~/apps/image/unet\n</code></pre>"},{"location":"ai-testbed/sambanova/example-multi-node-programs/#create-unet2dsh-and-unet_batchsh","title":"Create Unet2d.sh and unet_batch.sh","text":"<p>Create the file Unet2d.sh and unet_batch.sh in the current directory using your favorite editor. Copy and paste the contents of Unet2d.sh and unet_batch.sh to files with the same name into the current directory using your favorite editor.</p> <pre><code>chmod +x Unet2d.sh\nchmod +x unet_batch.sh\n</code></pre>"},{"location":"ai-testbed/sambanova/example-multi-node-programs/#compile-and-run","title":"Compile and run","text":"<p>Run these commands for training (compile + train): The compile and run scripts have the following input arguments.</p> <ol> <li> <p>image size:  The images are square.  Valid sizes include 256, 512, and 1024.</p> </li> <li> <p>Batch size: local batch size.  The global batch size is local batch size * Num of instances.</p> </li> <li> <p>num of instances: Total number of instances of Unet2d run in data parallel framework.</p> </li> <li> <p>RunID: A unique Id for the compile or run process.</p> </li> </ol> <p>The script uses the arguments <code>pcompile</code> and <code>prun</code> for the data parallel compile and run.</p> <pre><code>./Unet2d.sh pcompile &lt;image size&gt; &lt;batch_size&gt; &lt;num of instances&gt; &lt;RunID&gt;\n./Unet2d.sh prun &lt;image size&gt; &lt;batch_size&gt; &lt;num of instances&gt; &lt;RunID&gt;\n</code></pre> <p>If you have already compiled for a previous version of the sambaflow stack, delete existing pef file, if it exists. <pre><code>rm /data/scratch/$(whoami)/GPT_RUN/gpt15/gpt15.pef\n</code></pre></p> <p>For a image size of 256x256 and local batch size of 256 when running 8 instance, the commands are provided as follows.</p> <pre><code>./Unet2d.sh pcompile 256 256 8 unet2d_8inst_pcompile\n./Unet2d.sh prun 256 256 8 unet2d_8inst_prun\n</code></pre> <p>The above commands displays the file that contains the output for the execution of the above scripts, usually <code>/data/ANL/results/&lt;hostname&gt;/&lt;userId&gt;/&lt;RunID&gt;/Unet2d.out</code></p> <p>You can inspect the compile command that contains <code>--data-parallel -ws 2</code> arguments to ensure that the <code>pef</code> file is compatible for data parallel runs. The pef generated from the compilation process for the above compile command is placed under out/Unet2d/unet_train_256_256_NP_4 inside the current working directory.</p> <pre><code>python /opt/sambaflow/apps/image/segmentation/compile.py compile --mac-v2 --in-channels=3 --in-width=${2} --in-height=${2} --batch-size=${BS} --enable-conv-tiling --num-tiles=4 --pef-name=unet_train_${BS}_${2}_NP_${NUM_TILES}  --data-parallel -ws 2 --output-folder=${OUTDIR}\n</code></pre> <p>Once the model is compiled, sbatch is used to launch the multiple instances. The below example shows that a total of 8 tasks or instances are launched over the host on which the script is launched.</p> <pre><code>sbatch --gres=rdu:1 --tasks-per-node ${NP} --nodes 1 --nodelist $(hostname) --cpus-per-task=${cpus} $(pwd)/unet_batch.sh ${NP} ${NUM_WORKERS} ${BS} ${2} ${5}\n</code></pre> <p>The <code>run</code> command has <code>--data-parallel --reduce-on-rdu</code> arguments that is compatible with data parallel run.</p> <pre><code>srun --mpi=pmi2 python /opt/sambaflow/apps/image/segmentation//hook.py run --data-cache=${CACHE_DIR}  --data-in-memory --num-workers=${NUM_WORKERS} --enable-tiling  --min-throughput 395 --in-channels=3 --in-width=${IM} --in-height=${IM} --init-features 32 --batch-size=${BS} --epochs 10 --data-dir ${DS} --log-dir log_dir_unet_${IM}_${BS}_${NP} --data-parallel --reduce-on-rdu --pef=${OUTDIR}/unet_train_${BS}_${IM}_NP_4/unet_train_${BS}_${IM}_NP_4.pef\n</code></pre> <p>The throughput is calculated by averaging the <code>e2e samples_per_sec</code> over the different instances.</p> <pre><code>inner train loop time : 36.314290046691895 for 10 epochs, number of global steps: 10, e2e samples_per_sec: 563.9653143065\ninner train loop time : 33.36756229400635 for 10 epochs, number of global steps: 10, e2e samples_per_sec: 613.7697389922524\ninner train loop time : 33.94625234603882 for 10 epochs, number of global steps: 10, e2e samples_per_sec: 603.3066563941279\ninner train loop time : 32.309499979019165 for 10 epochs, number of global steps: 10, e2e samples_per_sec: 633.8692958200872\ninner train loop time : 31.418426036834717 for 10 epochs, number of global steps: 10, e2e samples_per_sec: 651.8467849404489\ninner train loop time : 28.164129495620728 for 10 epochs, number of global steps: 10, e2e samples_per_sec: 727.1660927132315\ninner train loop time : 30.29698896408081 for 10 epochs, number of global steps: 10, e2e samples_per_sec: 675.9747651583616\ninner train loop time : 25.332663536071777 for 10 epochs, number of global steps: 10, e2e samples_per_sec: 808.442427336472\n</code></pre>"},{"location":"ai-testbed/sambanova/example-multi-node-programs/#gpt-15b","title":"Gpt 1.5B","text":""},{"location":"ai-testbed/sambanova/example-multi-node-programs/#set-up_1","title":"Set up","text":"<pre><code>mkdir ~/nlp-multiNodetest\ncd ~/nlp-multiNodetest\n</code></pre>"},{"location":"ai-testbed/sambanova/example-multi-node-programs/#create-and-run-gpt15b_compilesh-and-gpt15b_runsh","title":"Create and run Gpt1.5B_compile.sh and Gpt1.5B_run.sh","text":"<p>Create the files Gpt1.5B_compile.sh and Gpt1.5B_run.sh in the current directory. Copy the contents of Gpt1.5B_compile.sh and Gpt1.5B_run.sh. Alternatively, the files can be accessed at <code>/data/ANL/scripts/1.24.1/legacy_models/Gpt1.5B_compile.sh</code> and <code>/data/ANL/scripts/1.24.1/legacy_models/Gpt1.5B_run.sh</code> on any of the compute node and can be copied over to the working directory.</p>"},{"location":"ai-testbed/sambanova/example-multi-node-programs/#compile-and-run_1","title":"Compile and Run","text":"<p>This script consists of commands to <code>compile</code> and <code>run</code> multiple instances of Gpt1.5B model across multiple nodes. Run the Gpt1.5B_compile.sh to first compile and generate the <code>pef</code> file for the model and it in turn launches the <code>Gpt1.5B_run.sh</code> script to run multiple instances of the model over the different nodes.</p> <pre><code>chmod +x Gpt1.5B_compile.sh\nchmod +x Gpt1.5B_run.sh\n./Gpt1.5B_compile.sh\n</code></pre> <p>You can see the log file path displayed on the screen as seen in the example below. You can use the <code>tail</code> command to check the progress of the run.</p> <pre><code>vsastry@sn30-r1-h1:~/nlp-multiNodetest$ ./Gpt1.5B_compile.sh\nUsing /data/ANL/results/sn30-r1-h1/vsastry/041823.19/GPT1.5B.out for output\n</code></pre> <p>The artifacts of the compile process is produced in the path : <code>/data/scratch/&lt;userId&gt;</code>.</p> <p>Inspect the <code>compile</code> command in the script to see that it includes additional arguments <code>--data-parallel</code> and <code>-ws 2</code> to generate a <code>pef</code> that is compatible for data parallel runs.</p> <pre><code>python /opt/sambaflow/apps/nlp/transformers_on_rdu/transformers_hook.py compile --module_name gpt2_pretrain --task_name clm --max_seq_length 1024 -b 16 --output_dir=${OUTDIR}/hf_output --overwrite_output_dir --do_train  --per_device_train_batch_size 16 --cache ${OUTDIR}/cache/ --tokenizer_name gpt2 --model_name gpt2 --mac-v2 --non_split_head --mac-human-decision /opt/sambaflow/apps/nlp/transformers_on_rdu/human_decisions_gm/mac_v2_overrides/gpt2_48_enc_full_recompute_training_spatialmapping_tiling16_clmerge_gm_nonpardp_lnsd.json --compiler-configs-file /opt/sambaflow/apps/nlp/transformers_on_rdu/human_decisions_gm/compiler_configs/compiler_configs_gpt2_sc_recompute_spatialmapping_tiling16_clsmerge_withcls_nonpardp_norc_e2e.json --skip_broadcast_patch --config_name /opt/sambaflow/apps/nlp/transformers_on_rdu/customer_specific/mv/configs/gpt2_config_xl_50260.json --no_index_select_patch --data-parallel -ws 2 --weight_decay 0.1  --max_grad_norm_clip 1.0 --num-tiles 4 --pef-name=gpt15 --output-folder=${OUTDIR}\n</code></pre> <p>Once the model is compiled, <code>sbatch</code> is used to launch the multiple instances across the nodes. The below example shows that a total of <code>32 tasks</code> or instances are launched over <code>2 nodes</code> with each node having a maximum of <code>16 tasks</code>. Slurm allocates any 2 of the available nodes in this example.</p> <pre><code>/usr/local/bin/sbatch --output=${HOME}/slurm-%A.out --ntasks 32 --gres=rdu:1 --ntasks-per-node 16  --nodes 2 --cpus-per-task=8  Gpt1.5B_run.sh ${1} &gt;&gt; ${OUTPUT_PATH} 2&gt;&amp;1\n</code></pre> <p>The <code>run</code> command for each of this instance is present in the <code>Gpt1.5B_run.sh</code> script. You can inspect the command in the script to see that <code>--data-parallel --reduce-on-rdu</code> arguments are present to ensure that the model is run in a data parallel fashion and that the gradient accumulation takes place on the RDU.</p> <pre><code>/usr/local/bin/srun --mpi=pmi2 python /opt/sambaflow/apps/nlp/transformers_on_rdu/transformers_hook.py run  -b 16  --module_name gpt2_pretrain --task_name clm --max_seq_length 1024  --overwrite_output_dir --do_train  --per_device_train_batch_size 16 --cache ${OUTDIR}/cache/  --tokenizer_name gpt2 --model_name gpt2 --non_split_head --skip_broadcast_patch --no_index_select_patch --output_dir=${OUTDIR}/hf_output --config_name /opt/sambaflow/apps/nlp/transformers_on_rdu/customer_specific/mv/configs/gpt2_config_xl_50260.json --max_grad_norm_clip 1.0 --skip_checkpoint --data-parallel --reduce-on-rdu --data_dir /data/ANL/ss1024 --data_dir /data/ANL/ss1024  --logging_steps 1 --max_steps 900000 --learning_rate 0.00025 --steps_this_run 800 --min_throughput 299000 --max_throughput 600000 --pef=${OUTDIR}/gpt15/gpt15.pef &gt;&gt; ${OUTPUT_PATH} 2&gt;&amp;1\n</code></pre> <p><code>squeue</code> shows that the model is run on 2 nodes <code>sn30-r1-h1</code> and <code>sn30-r2-h2</code>.</p> <pre><code>JOBID PARTITION                      NAME     USER ST       TIME  NODES NODELIST(REASON)\n10191 sambanova            Gpt1.5B_run.sh  vsastry  R      23:18      2 sn30-r1-h1,sn30-r2-h2\n</code></pre> <p><code>sntilestat</code> can also be used to check the total numbers of tiles used for the runs.</p> <pre><code>TILE                 %idle %exec %pload %aload %chkpt %quiesce    PID     USER COMMAND\n/XRDU_0/RDU_0/TILE_0   8.0  91.6    0.3    0.1    0.0      0.0 2750333  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_0/TILE_1   8.0  91.6    0.3    0.1    0.0      0.0 2750333  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_0/TILE_2   7.9  91.6    0.3    0.3    0.0      0.0 2750333  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_0/TILE_3   7.7  91.8    0.3    0.3    0.0      0.0 2750333  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_0/TILE_4   7.6  91.9    0.4    0.1    0.0      0.0 2750339  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_0/TILE_5   7.5  91.9    0.5    0.1    0.0      0.0 2750339  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_0/TILE_6   7.5  91.8    0.5    0.3    0.0      0.0 2750339  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_0/TILE_7   7.3  92.0    0.6    0.0    0.0      0.0 2750339  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_1/TILE_0   8.9  89.9    1.0    0.1    0.0      0.0 2750338  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_1/TILE_1   9.0  89.9    0.9    0.1    0.0      0.0 2750338  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_1/TILE_2   8.6  89.8    1.4    0.1    0.0      0.0 2750338  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_1/TILE_3   8.5  89.9    1.4    0.1    0.0      0.0 2750338  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_1/TILE_4   7.9  90.9    0.9    0.4    0.0      0.0 2750343  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_1/TILE_5   7.7  90.9    0.9    0.5    0.0      0.0 2750343  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_1/TILE_6   7.7  91.0    0.9    0.4    0.0      0.0 2750343  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_0/RDU_1/TILE_7   8.0  91.0    0.6    0.4    0.0      0.0 2750343  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_0/TILE_0   7.6  92.0    0.3    0.1    0.0      0.0 2750345  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_0/TILE_1   7.6  92.0    0.3    0.1    0.0      0.0 2750345  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_0/TILE_2   7.5  92.1    0.3    0.1    0.0      0.0 2750345  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_0/TILE_3   7.5  92.1    0.3    0.1    0.0      0.0 2750345  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_0/TILE_4   7.5  92.1    0.3    0.1    0.0      0.0 2750335  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_0/TILE_5   7.5  92.1    0.3    0.1    0.0      0.0 2750335  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_0/TILE_6   7.5  92.1    0.3    0.1    0.0      0.0 2750335  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_0/TILE_7   7.5  92.1    0.3    0.1    0.0      0.0 2750335  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_1/TILE_0   7.7  91.5    0.4    0.4    0.0      0.0 2750330  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_1/TILE_1   7.9  91.5    0.3    0.4    0.0      0.0 2750330  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_1/TILE_2   7.9  91.5    0.3    0.4    0.0      0.0 2750330  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_1/TILE_3   7.6  91.8    0.4    0.3    0.0      0.0 2750330  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_1/TILE_4   7.7  91.9    0.4    0.0    0.0      0.0 2750334  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_1/TILE_5   7.7  91.9    0.4    0.0    0.0      0.0 2750334  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_1/TILE_6   7.9  91.9    0.3    0.0    0.0      0.0 2750334  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_1/RDU_1/TILE_7   7.9  91.9    0.3    0.0    0.0      0.0 2750334  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_0/TILE_0   8.0  91.8    0.1    0.1    0.0      0.0 2750346  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_0/TILE_1   8.0  91.8    0.1    0.1    0.0      0.0 2750346  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_0/TILE_2   8.0  91.8    0.1    0.1    0.0      0.0 2750346  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_0/TILE_3   7.7  91.9    0.1    0.3    0.0      0.0 2750346  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_0/TILE_4   7.5  92.0    0.5    0.0    0.0      0.0 2750336  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_0/TILE_5   7.6  91.9    0.5    0.0    0.0      0.0 2750336  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_0/TILE_6   7.6  91.9    0.4    0.1    0.0      0.0 2750336  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_0/TILE_7   7.5  91.9    0.4    0.3    0.0      0.0 2750336  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_1/TILE_0   7.5  91.8    0.6    0.1    0.0      0.0 2750331  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_1/TILE_1   7.5  91.8    0.6    0.1    0.0      0.0 2750331  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_1/TILE_2   7.7  91.6    0.5    0.1    0.0      0.0 2750331  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_1/TILE_3   7.7  91.6    0.5    0.1    0.0      0.0 2750331  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_1/TILE_4   7.9  91.4    0.8    0.0    0.0      0.0 2750329  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_1/TILE_5   7.9  91.4    0.8    0.0    0.0      0.0 2750329  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_1/TILE_6   8.1  91.4    0.5    0.0    0.0      0.0 2750329  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_2/RDU_1/TILE_7   8.2  91.4    0.4    0.0    0.0      0.0 2750329  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_0/TILE_0   7.5  91.8    0.4    0.4    0.0      0.0 2750344  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_0/TILE_1   7.5  91.8    0.4    0.4    0.0      0.0 2750344  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_0/TILE_2   7.5  91.8    0.4    0.4    0.0      0.0 2750344  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_0/TILE_3   7.5  91.8    0.4    0.4    0.0      0.0 2750344  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_0/TILE_4   7.6  91.8    0.3    0.4    0.0      0.0 2750337  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_0/TILE_5   7.7  91.8    0.1    0.4    0.0      0.0 2750337  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_0/TILE_6   7.7  91.8    0.3    0.3    0.0      0.0 2750337  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_0/TILE_7   7.7  91.9    0.3    0.1    0.0      0.0 2750337  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_1/TILE_0   7.7  92.0    0.1    0.1    0.0      0.0 2750347  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_1/TILE_1   7.7  92.0    0.1    0.1    0.0      0.0 2750347  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_1/TILE_2   7.7  92.1    0.1    0.0    0.0      0.0 2750347  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_1/TILE_3   7.7  92.1    0.1    0.0    0.0      0.0 2750347  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_1/TILE_4   7.3  91.9    0.5    0.3    0.0      0.0 2750332  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_1/TILE_5   7.3  91.9    0.5    0.3    0.0      0.0 2750332  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_1/TILE_6   7.3  91.9    0.5    0.3    0.0      0.0 2750332  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n/XRDU_3/RDU_1/TILE_7   7.3  92.0    0.5    0.1    0.0      0.0 2750332  vsastry /opt/sambaflow/apps/nlp/transformers_on_rdu/venv/b\n</code></pre> <p>The Slurm log associated with the JOBID (10191 in the above example) is located in the home directory. You can use the <code>tail</code> command to check the progress of the training.</p> <pre><code>vsastry@sn30-r1-h1:~$ tail -f ~/slurm-10191.out\nUsing /data/ANL/results/sn30-r1-h1/vsastry/041823.03/Gpt1.5B.out for output\n</code></pre> <pre><code>vsastry@sn30-r1-h1:~$ tail -f /data/ANL/results/sn30-r1-h1/vsastry/041823.03/Gpt1.5B.out\n</code></pre> <p>Once the run is completed, check the log file for the performance results.</p> <pre><code>{'e2e_train_time': 2179.2292835712433, 'training_sequences_per_second': 192467.31088004305, 'final_loss': 4.781678199768066}\n247/3247 [01:03&lt;00:00, 50.76it/s]\n</code></pre>"},{"location":"ai-testbed/sambanova/example-programs/","title":"Example Programs","text":"<p>You can use the link to the tutorials on the SambaNova GitHub site or the examples on the compute node (as explained below).</p> <ul> <li>Find the tutorials on the SambaNova GitHub site. If you use those instructions, ensure that you still use the steps for accessing the SN compute node, setting the required environment and compiling and running the applications as described in this documentation. </li> <li>Use the examples of well-known simple AI applications under the path: <code>/opt/sambaflow/apps/starters</code>, on all SambaNova compute nodes, as discussed on this page.  </li> </ul> <p>Make a copy of this to your home directory:</p> <pre><code>cd ~/\nmkdir apps\ncp -r /opt/sambaflow/apps/starters apps/starters\n</code></pre> <p>Deactivate any active conda environment. If you have conda installed and a conda environment is active, you will see something like <code>(base)</code> at the beginning of the command prompt. If so, you will need to deactivate it with <code>conda deactivate</code>. Conda is not used on the SambaNova SN30 cluster. </p>"},{"location":"ai-testbed/sambanova/example-programs/#lenet","title":"LeNet","text":"<p>Change directory</p> <pre><code>cd ~/apps/starters/lenet\n</code></pre>"},{"location":"ai-testbed/sambanova/example-programs/#common-arguments","title":"Common Arguments","text":"<p>Below are some of the common arguments used across most of the models in the example code.</p> Argument Default Help -b 1 Batch size for training -n, 100 Number of iterations to run --num-iterations the pef for -e, 1 Number epochs for training --num-epochs --log-path 'check Log path points' --num-workers 0 Number of workers --measure-train- None Measure training performance performance"},{"location":"ai-testbed/sambanova/example-programs/#lenet-arguments","title":"LeNet Arguments","text":"Argument Default Help --lr 0.01 Learning rate for training --momentum 0.0 Momentum value for training --weight-decay 0.01 Weight decay for training --data-path './data' Data path --data-folder 'mnist_ Folder containing mnist data data' <p>Note:  If you receive an \\\"HTTP error\\\" message on any of the following commands, run the command again. Such errors (e.g 503) are commonly an intermittent failure to download a dataset.</p> <p>Run these commands to compile and train the LeNet model:</p> <pre><code>srun python lenet.py compile -b=1 --pef-name=\"lenet\" --output-folder=\"pef\"\nsrun python lenet.py run --pef=\"pef/lenet/lenet.pef\"\n</code></pre> <p>Alternatively to use Slurm sbatch, create submit-lenet-job.sh with the following contents:</p> <pre><code>#!/bin/sh\n\npython lenet.py compile -b=1 --pef-name=\"lenet\" --output-folder=\"pef\"\npython lenet.py run --pef=\"pef/lenet/lenet.pef\"\n</code></pre> <p>Then</p> <pre><code>mkdir -p pef/lenet\nsbatch --output=pef/lenet/output.log submit-lenet-job.sh\n</code></pre> <p>Squeue will give you the queue status.</p> <pre><code>squeue\n# One may also...\nwatch squeue\n</code></pre> <p>One may see the run log using:</p> <pre><code>cat pef/lenet/output.log\n</code></pre>"},{"location":"ai-testbed/sambanova/example-programs/#mnist-feed-forward-network","title":"MNIST - Feed Forward Network","text":"<p>Change directory</p> <pre><code>cd ~/apps/starters/ffn_mnist/\n</code></pre> <p>Commands to run MNIST example:</p> <pre><code>srun python ffn_mnist.py  compile -b 1 --pef-name=\"ffn_mnist\" --mac-v2\nsrun python ffn_mnist.py  run -b 1 -p out/ffn_mnist/ffn_mnist.pef\n</code></pre> <p>To run the same using Slurm sbatch, create and run the submit-ffn_mnist-job.sh with the following contents.</p> <pre><code>#!/bin/sh\npython ffn_mnist.py  compile -b 1 --pef-name=\"ffn_mnist\" --mac-v2\npython ffn_mnist.py  run -b 1 -p out/ffn_mnist/ffn_mnist.pef\n</code></pre> <pre><code>mkdir -p pef/ffn_mnist\nsbatch --output=pef/ffn_mnist/output.log submit-ffn_mnist-job.sh\n</code></pre>"},{"location":"ai-testbed/sambanova/example-programs/#logistic-regression","title":"Logistic Regression","text":"<p>Change directory</p> <pre><code>cd ~/apps/starters/logreg\n</code></pre>"},{"location":"ai-testbed/sambanova/example-programs/#logistic-regression-arguments","title":"Logistic Regression Arguments","text":"<p>This is not an exhaustive list of arguments.</p> <p>Arguments</p> Argument Default Help Step --lr 0.001 Learning rate for training Compile --momentum 0.0 Momentum value for training Compile --weight-decay 1e-4 Weight decay for training Compile --num-features 784 Number features for training Compile --num-classes 10 Number classes for training Compile --weight-norm na Enable weight normalization Compile <p>Run these commands:</p> <pre><code>srun python logreg.py compile --pef-name=\"logreg\" --output-folder=\"pef\"\nsrun python logreg.py run --pef=\"pef/logreg/logreg.pef\"\n</code></pre> <p>To use Slurm, create submit-logreg-job.sh with the following contents:</p> <pre><code>#!/bin/sh\npython logreg.py compile --pef-name=\"logreg\" --output-folder=\"pef\"\npython logreg.py run --pef=\"pef/logreg/logreg.pef\"\n</code></pre> <p>Then</p> <pre><code>mkdir -p pef/logreg\nsbatch --output=pef/logreg/output.log submit-logreg-job.sh\n</code></pre> <p>The output, pef/logreg/output.log, will look something like this:</p> <pre><code>2023-03-08 21:18:25.168190: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-03-08 21:18:25.334389: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2023-03-08 21:18:25.334430: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-03-08 21:18:26.422458: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2023-03-08 21:18:26.422701: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2023-03-08 21:18:26.422709: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n[Info][SAMBA]# Placing log files in /home/wilsonb/apps/starters/logreg/pef/logreg/logreg.samba.log\n[Info][MAC]# Placing log files in /home/wilsonb/apps/starters/logreg/pef/logreg/logreg.mac.log\n...\n\nEpoch [1/1], Step [10000/60000], Loss: 0.4642\nEpoch [1/1], Step [20000/60000], Loss: 0.4090\nEpoch [1/1], Step [30000/60000], Loss: 0.3863\nEpoch [1/1], Step [40000/60000], Loss: 0.3703\nEpoch [1/1], Step [50000/60000], Loss: 0.3633\nEpoch [1/1], Step [60000/60000], Loss: 0.3553\nTest Accuracy: 91.40  Loss: 0.3014\n2023-03-08T21:19:08 : [INFO][LIB][2688517]: sn_create_session: PEF File: pef/logreg/logreg.pef\n</code></pre>"},{"location":"ai-testbed/sambanova/example-programs/#unet2d","title":"UNet2D","text":"<p>The UNet application example is provided in the the path : <code>/opt/sambaflow/apps/image/segmentation/</code>. As any other application, we first compile and then train the model using compile and run arguments respectively. The scripts containing the compile and run commands for UNet2D model can be accessed at Unet2d.sh or at <code>/data/ANL/scripts/Unet2d.sh</code> on any SN30 compute node.</p> <p>Change directory and copy files.</p> <pre><code>mkdir -p ~/apps/image/unet\ncd ~/apps/image/unet\n</code></pre> <p>Copy and paste the contents of Unet2d.sh to a file with the same name into the current directory using your favorite editor.</p> <pre><code>chmod +x Unet2d.sh\n</code></pre> <p>Run these commands for training (compile + train):</p> <pre><code>./Unet2d.sh compile &lt;image size&gt; &lt;batch_size&gt; &lt;num of instances&gt; &lt;RunID&gt;\n./Unet2d.sh run &lt;image size&gt; &lt;batch_size&gt; &lt;num of instances&gt; &lt;RunID&gt;\n</code></pre> <p>The <code>compile</code> and <code>run</code> arguments of the script can only be run with number of instances equal to 1, indicating that this is a simple 4 tile run without data parallel framework. For a image size of 256x256 and batch size 256 when running just 1 instance, the commands are provided as follows.</p> <p>Note</p> <p>The compilation runs for over 30 minutes.</p> <pre><code>./Unet2d.sh compile 256 256 1 unet2d_single_compile\n./Unet2d.sh run 256 256 1 unet2d_single_run\n</code></pre> <p>The above commands displays the file that contains the output for the execution of the above scripts, usually <code>/data/ANL/results/&lt;hostname&gt;/&lt;userid&gt;/&lt;RunID&gt;/Unet2d.out</code></p> <p>If we inspect the compile and run commands for the UNet application provided in the script, we see that the application is compiled with <code>--num-tiles 4</code>, which means that the entire application fits on 4 tiles or half of a RDU. The pef generated from the compilation process of the above command is placed under <code>out/Unet2d/unet_train_256_256_single_4</code> inside the current working directory.</p> <pre><code>python ${UNET}/compile.py compile --mac-v2 --in-channels=3 --in-width=${2} --in-height=${2} --batch-size=${BS} --enable-conv-tiling --num-tiles=4 --pef-name=unet_train_${BS}_${2}_single_${NUM_TILES} --output-folder=${OUTDIR}\n</code></pre> <pre><code>srun --nodelist $(hostname) python /opt/sambaflow/apps/image/segmentation//hook.py run --data-cache=${CACHE_DIR}  --data-in-memory --num-workers=${NUM_WORKERS} --enable-tiling  --min-throughput 395 --in-channels=3 --in-width=${2} --in-height=${2} --init-features 32 --batch-size=${BS} --epochs 10 --data-dir ${DS} --log-dir log_dir_unet_${2}_${BS}_single_${NUM_TILES} --pef=${OUTDIR}/unet_train_${BS}_${2}_single_${NUM_TILES}/unet_train_${BS}_${2}_single_${NUM_TILES}.pef\n</code></pre> <p>The performance data is located at the bottom of log file.</p> <pre><code>inner train loop time : 374.6789753437042 for 10 epochs, number of global steps: 130, e2e samples_per_sec: 88.82270474202953\n</code></pre>"},{"location":"ai-testbed/sambanova/example-programs/#gpt-15b","title":"GPT 1.5B","text":"<p>The GPT 1.5B application example is provided in the the path : <code>/opt/sambaflow/apps/nlp/transformers_on_rdu/</code>. The scripts containing the <code>compile</code> and <code>run</code> commands for the GPT 1.5B model can be accessed at the path <code>/data/ANL/scripts/1.24.1/legacy_models/Gpt1.5B_base_single_compile.sh</code> and <code>/data/ANL/scripts/1.24.1/legacy_models/Gpt1.5B_base_single_run.sh</code> on any SN30 compute node. This script is compiled and run for only 1 instance and the model fits on 4 tiles or half of a RDU. The scripts are provided for reference. </p> <p>Change directory and copy files.</p> <pre><code>mkdir -p ~/apps/nlp/Gpt1.5B_single\ncd ~/apps/nlp/Gpt1.5B_single\n</code></pre> <p>Copy and paste the contents of Gpt1.5B_base_single_compile.sh and Gpt1.5B_base_single_run.sh  to a file with the same names into the current directory using your favorite editor.</p> <p>or copy the contents from <code>/data/ANL/scripts/Gpt1.5B_base_single_compile.sh</code> and <code>/data/ANL/scripts/Gpt1.5B_base_single_run.sh</code>.</p> <p><pre><code>cp /data/ANL/scripts/1.24.1/legacy_models/Gpt1.5B_base_single_compile.sh ~/apps/nlp/Gpt1.5B_single/\ncp /data/ANL/scripts/1.24.1/legacy_models/Gpt1.5B_base_single_run.sh ~/apps/nlp/Gpt1.5B_single/\n</code></pre> If you have already compiled for a previous version of the sambaflow stack, delete existing pef file, if it exists. <pre><code>rm /data/scratch/$(whoami)/GPT1.5B_base_single_32/GPT1.5B_base_single_32/GPT1.5B_base_single_32.pef\n</code></pre></p> <p>Run the script with batch size as an argument(shown below with an example of 32).</p> <pre><code>chmod +x Gpt1.5B_base_single_compile.sh \n./Gpt1.5B_base_single_compile.sh 32\n</code></pre> <p>The Gpt1.5B_base_single_compile.sh  script will internally call the Gpt1.5B_base_single_run.sh to perform the training. You can inspect the <code>compile</code> and <code>run</code> commands in the scripts to learn that this model trains with a batch size of 32 for 1 instance over 4 tiles. The human decision file and the compiler config file helps to optimize the compute and memory resources specific to this Gpt 1.5B model run.</p> <pre><code>python /opt/sambaflow/apps/nlp/transformers_on_rdu/transformers_hook.py compile --pef-name=GPT1.5B_base_single_32 --output-folder=/data/scratch/user/GPT1.5B_base_single_32 --module_name gpt2_pretrain --task_name clm --max_seq_length 1024 -b 32  --output_dir=/data/scratch/user/GPT1.5B_base_single_32/hf_gpt1dot5b_ss1k_gas_1_bs32  --overwrite_output_dir --do_train  --per_device_train_batch_size 32   --tokenizer_name gpt2 --model_name gpt2 --mac-v2 --non_split_head --mac-human-decision /opt/sambaflow/apps/nlp/transformers_on_rdu/human_decisions_gm/mac_v2_overrides/gpt2_48_enc_full_recompute_training_spatialmapping_tiling16_clmerge_gm_pardp2_lnsd.json --compiler-configs-file /opt/sambaflow/apps/nlp/transformers_on_rdu/human_decisions_gm/compiler_configs/compiler_configs_gpt1dot5b_perf.json --skip_broadcast_patch --config_name /opt/sambaflow/apps/nlp/transformers_on_rdu/customer_specific/mv/configs/gpt2_config_xl_50260.json --no_index_select_patch --weight_decay 0.1  --max_grad_norm_clip 1.0 --num-tiles 4 --enable-stochastic-rounding\n</code></pre> <pre><code>COMMAND= /usr/local/bin/srun --mpi=pmi2 python /opt/sambaflow/apps/nlp/transformers_on_rdu/transformers_hook.py run  -b 32  --data_dir /data/ANL/ss1024 --pef=/data/scratch/user/GPT1.5B_base_single_32/GPT1.5B_base_single_32/GPT1.5B_base_single_32.pef --output_dir=/data/scratch/user/GPT1.5B_base_single_32/hf_gpt1dot5b_ss1k_gas_1_bs16 --module_name gpt2_pretrain --task_name clm --max_seq_length 1024  --overwrite_output_dir --do_train  --per_device_train_batch_size 32 --tokenizer_name gpt2 --model_name gpt2 --non_split_head --skip_broadcast_patch --no_index_select_patch --config_name /opt/sambaflow/apps/nlp/transformers_on_rdu/customer_specific/mv/configs/gpt2_config_xl_50260.json --max_grad_norm_clip 1.0 --skip_checkpoint --logging_steps 1 --max_steps 75000 --learning_rate 0.00025 --steps_this_run 100\n</code></pre> <p>The <code>sntilestat</code> command shows that the application runs on 4 tiles as shown below.</p> <pre><code>/XRDU_0/RDU_0/TILE_0   2.1  96.9    0.8    0.1    0.0      0.0 796481  user python /opt/sambaflow/apps/nlp/transformers_on_rdu/\n/XRDU_0/RDU_0/TILE_1   2.1  96.9    0.8    0.1    0.0      0.0 796481  user python /opt/sambaflow/apps/nlp/transformers_on_rdu/\n/XRDU_0/RDU_0/TILE_2   2.5  96.9    0.4    0.1    0.0      0.0 796481  user python /opt/sambaflow/apps/nlp/transformers_on_rdu/\n/XRDU_0/RDU_0/TILE_3   2.5  96.9    0.4    0.1    0.0      0.0 796481  user python /opt/sambaflow/apps/nlp/transformers_on_rdu/\n/XRDU_0/RDU_0/TILE_4 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_0/TILE_5 100.0   0.0    0.0    0.0    0.0      0.0\n...\n</code></pre>"},{"location":"ai-testbed/sambanova/getting-started/","title":"Getting Started","text":""},{"location":"ai-testbed/sambanova/getting-started/#on-boarding","title":"On-Boarding","text":"<p>SambaNova SN30 can be accessed using your ALCF account. See Get Started to request an account and for additional information.</p>"},{"location":"ai-testbed/sambanova/getting-started/#setup","title":"Setup","text":""},{"location":"ai-testbed/sambanova/getting-started/#system-view","title":"System View","text":"<p>Connection to a SambaNova node is a two-step process. The first step is to ssh to the login node. This step requires an MFA passcode for authentication - an eight-digit passcode generated by an app on your mobile device, e.g., MobilePASS+. The second step is to log in to a SambaNova node from the login node.</p> <p></p>"},{"location":"ai-testbed/sambanova/getting-started/#log-in-to-login-node","title":"Log in to Login Node","text":"<p>Log in to the SambaNova login node from your local machine using the below command. This uses the MobilePASS+ token generated every time you log in to the system. This is the same passcode used to authenticate into other ALCF systems, such as Polaris.</p> <p>In the examples below, replace ALCFUserID with your ALCF user id.</p> <pre><code>ssh ALCFUserID@sambanova.alcf.anl.gov\nPassword: &lt; MobilePASS+ code &gt;\n</code></pre> <p>Note: Use the ssh \"-v\" option in order to debug any ssh problems.</p>"},{"location":"ai-testbed/sambanova/getting-started/#log-in-to-a-sambanova-node","title":"Log in to a SambaNova Node","text":"<p>Once you are on the login node, a SambaNova node can be accessed using an alias, sn30-r[1-4]-h[1-2] where 'r' stands for the rack number, and 'h' stands for host. sn30-r1-h1 is the first host of the first rack.</p> <p>The 8 nodes are aliased as : sn30-r1-h1 , sn30-r1-h2, sn30-r2-h1, sn30-r2-h2, sn30-r3-h1, sn30-r3-h2, sn30-r4-h1, sn30-r4-h2.</p> <p>sn30-r1-h1 can be accessed as below.</p> <pre><code>ssh sn30-r1-h1\n</code></pre>"},{"location":"ai-testbed/sambanova/getting-started/#sdk-setup","title":"SDK setup","text":"<p>The required software environment (SambaFlow software stack and the associated environmental variables) for a SN30 node is set up automatically at login. This is unlike the SN10 where the environment had to be set up by each user.</p>"},{"location":"ai-testbed/sambanova/job-queuing-and-submission/","title":"Job Queueing and Submission","text":""},{"location":"ai-testbed/sambanova/job-queuing-and-submission/#introduction","title":"Introduction","text":"<p>SambaNova uses Slurm for job submission and queueing. Below are some of the important commands for using Slurm. For more information refer to Slurm Documentation.</p> <p>Note: Run the Python scripts using 'srun' or 'sbatch', to ensure that concurrent jobs do not interfere with each other.</p> <p>Note: There is just one scheduler for all of the SambaNova nodes.</p>"},{"location":"ai-testbed/sambanova/job-queuing-and-submission/#srun","title":"SRun","text":"<p>The Slurm command <code>srun</code> can be used to run individual Python scripts in parallel with other scripts on a cluster managed by Slurm. Examples of <code>srun</code> usage are shown below.</p> <p>Slurm will assign a nodelist/host to run a job if a host is not specified.</p> <p>Example:</p> <pre><code>srun python lenet.py compile -b=1 --pef-name=\"lenet\" --output-folder=\"pef\"\nsrun python lenet.py run --pef=\"pef/lenet/lenet.pef\"\n</code></pre> <p>You may specify which node/host on which to run a job.</p> <p>Reasons to specify a node list:</p> <ul> <li>One wants to test a specific node to verify the function of the HW and SW  (daily smoke tests do this)</li> <li>The nodes are at different software levels and one wants to use a node that has the needed software level for one's application.</li> </ul> <p>Example:</p> <pre><code>srun --nodelist=sn30-r1-h1 python lenet.py compile -b=1 --pef-name=\"lenet\" --output-folder=\"pef\"\n</code></pre>"},{"location":"ai-testbed/sambanova/job-queuing-and-submission/#sbatch","title":"SBatch","text":"<p>Alternatively, these jobs can be submitted to the Slurm workload manager through a batch script by using the <code>sbatch</code> command. To do this, create a bash script (submit-lenet-job.sh here as an example) with the commands that you want to execute.</p> <pre><code>#!/bin/sh\n\npython lenet.py compile -b=1 --pef-name=\"lenet\" --output-folder=\"pef\"\npython lenet.py run --pef=\"pef/lenet/lenet.pef\"\n</code></pre> <p>Then pass the bash script as an input to the <code>sbatch</code> command as shown below.</p> <pre><code>sbatch --output=pef/lenet/output.log submit-lenet-job.sh\n</code></pre> <p>In case of the need to use multiple RDUs (2 in the example shown below), the <code>sbatch</code> command would be altered as:</p> <pre><code>sbatch --gres=rdu:2 &lt;your_script.sh&gt;\n</code></pre>"},{"location":"ai-testbed/sambanova/job-queuing-and-submission/#squeue","title":"SQueue","text":"<p>The <code>squeue</code> command provides information about jobs located in the Slurm scheduling queue.</p> <pre><code>squeue\n</code></pre>"},{"location":"ai-testbed/sambanova/job-queuing-and-submission/#sinfo","title":"SInfo","text":"<p>SInfo is used to view partition and node information for a system running Slurm.</p> <p>Here is a suggested command:</p> <pre><code>sinfo -O AllocNodes, GresUsed, Gres, NodeList\n</code></pre> <p>For more information, see SInfo.</p>"},{"location":"ai-testbed/sambanova/job-queuing-and-submission/#scancel","title":"SCancel","text":"<p>SCancel is used to signal or cancel jobs, job arrays, or job steps.</p> <pre><code>scancel job_id\n</code></pre>"},{"location":"ai-testbed/sambanova/miscellaneous/","title":"Miscellaneous","text":""},{"location":"ai-testbed/sambanova/miscellaneous/#sdk-version","title":"SDK Version","text":"<p>To find the SDK version, run the following commands</p> <pre><code># TODO\n(venv) ALCFUserID@sn30-r1-h1:~$ python\nPython 3.7.6 (default, Feb 18 2020, 21:28:31)\n[GCC 9.3.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import sambaflow\n&gt;&gt;&gt; sambaflow.__version__\n'1.11.5'\n&gt;&gt;&gt;\n</code></pre>"},{"location":"ai-testbed/sambanova/miscellaneous/#omp_num_threads","title":"OMP_NUM_THREADS","text":"<p>The OMP_NUM_THREADS environment variable sets the number of threads to use for parallel regions.</p> <p>The value of this environment variable must be a list of positive integer values. The values of the list set the number of threads to use for parallel regions at the corresponding nested levels.</p> <p>For the SambaNova system it, is usually set to one.</p> <pre><code>export OMP_NUM_THREADS=16\n</code></pre>"},{"location":"ai-testbed/sambanova/miscellaneous/#where-is-the-model","title":"Where is the Model?","text":"<p>Two copies of the model are maintained.  One in host CPU memory and one in RDU memory. They do not interfere with each other unless you explicitly sync the model/parameter in between using:</p> <pre><code>SambaTensor.rdu() # Moves the CPU model to the RDU\nSambaTensor.cpu() # Moves the RDU model to the CPU\n</code></pre> <p>In order to run the model on the CPU, you can simply use the PyTorch model as if there is no RDU. In order to run the model on RDU, you would need to use session.run().</p>"},{"location":"ai-testbed/sambanova/miscellaneous/#useful-commands","title":"Useful Commands","text":""},{"location":"ai-testbed/sambanova/miscellaneous/#sn-configuration","title":"SN Configuration","text":"<pre><code>snconfig show Node static\n</code></pre> <p>The snconfig utility shows the static configuration of the system. The configuration for the first node is as follows:</p> <pre><code>======================================================\n=======                NODE Info               =======\n======================================================\n=======                Static Info             =======\nTimestamp: 2023-03-16 17:00:04\nPlatform Name: DataScale SN30-8\nNode Name: NODE\n    Number of XRDUS: 4\n    XRDU Name: XRDU_0\n        Number of RDUS: 2\n        RDU name: RDU_0\n            Serial Number     : 205057B469B35895\n            Number of TILES: 8\n            TILE Name: TILE_0\n                Serial Number     : N/A\n            TILE Name: TILE_1\n                Serial Number     : N/A\n\n\n...\n\n\n                    Size              : 128.0 GB\n                    Serial Number     : 1F5BC22\n            DDR CH Name: DDRCH_6\n                Number of DIMMS: 1\n                DIMM Name: DIMM_L0\n                    Size              : 128.0 GB\n                    Serial Number     : 1F5BC99\n            DDR CH Name: DDRCH_7\n                Number of DIMMS: 1\n                DIMM Name: DIMM_M0\n                    Size              : 128.0 GB\n                    Serial Number     : 1F5BB68\n        Total XRDU_3 memory size (GB): 2048.0\n</code></pre>"},{"location":"ai-testbed/sambanova/miscellaneous/#sambanova-daemon-service","title":"SambaNova Daemon Service","text":"<p>The following command checks if the SambaNova daemon service is running.</p> <pre><code>systemctl status snd\n</code></pre> <p>The output should look something like this:</p> <pre><code>\u25cf snd.service - SN Devices Service\n     Loaded: loaded (/lib/systemd/system/snd.service; enabled; vendor preset: enabled)\n    Drop-In: /etc/systemd/system/snd.service.d\n             \u2514\u2500override.conf\n     Active: active (running) since Fri 2023-01-27 04:03:14 UTC; 1 months 18 days ago\n   Main PID: 5635 (snd)\n      Tasks: 9 (limit: 629145)\n     Memory: 156.8M\n     CGroup: /system.slice/snd.service\n             \u2514\u25005635 /opt/sambaflow/bin/snd\n\nWarning: some journal files were not opened due to insufficient permissions.\n</code></pre>"},{"location":"ai-testbed/sambanova/miscellaneous/#tile-status","title":"Tile status","text":"<pre><code>sntilestat\nwatch sntilestat\n</code></pre> <p>The output shown below is when the system is completely idle.</p> <pre><code>TILE                 %idle %exec %pload %aload %chkpt %quiesce    PID     USER COMMAND\n/XRDU_0/RDU_0/TILE_0 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_0/TILE_1 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_0/TILE_2 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_0/TILE_3 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_0/TILE_4 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_0/TILE_5 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_0/TILE_6 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_0/TILE_7 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_1/TILE_0 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_1/TILE_1 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_1/TILE_2 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_1/TILE_3 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_1/TILE_4 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_1/TILE_5 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_1/TILE_6 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_0/RDU_1/TILE_7 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_0/TILE_0 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_0/TILE_1 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_0/TILE_2 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_0/TILE_3 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_0/TILE_4 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_0/TILE_5 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_0/TILE_6 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_0/TILE_7 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_1/TILE_0 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_1/TILE_1 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_1/TILE_2 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_1/TILE_3 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_1/TILE_4 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_1/TILE_5 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_1/TILE_6 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_1/RDU_1/TILE_7 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_0/TILE_0 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_0/TILE_1 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_0/TILE_2 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_0/TILE_3 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_0/TILE_4 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_0/TILE_5 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_0/TILE_6 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_0/TILE_7 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_1/TILE_0 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_1/TILE_1 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_1/TILE_2 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_1/TILE_3 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_1/TILE_4 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_1/TILE_5 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_1/TILE_6 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_2/RDU_1/TILE_7 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_0/TILE_0 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_0/TILE_1 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_0/TILE_2 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_0/TILE_3 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_0/TILE_4 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_0/TILE_5 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_0/TILE_6 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_0/TILE_7 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_1/TILE_0 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_1/TILE_1 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_1/TILE_2 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_1/TILE_3 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_1/TILE_4 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_1/TILE_5 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_1/TILE_6 100.0   0.0    0.0    0.0    0.0      0.0\n/XRDU_3/RDU_1/TILE_7 100.0   0.0    0.0    0.0    0.0      0.0\n</code></pre>"},{"location":"ai-testbed/sambanova/miscellaneous/#finding-hung-tiles","title":"Finding Hung Tiles","text":"<pre><code>snconfig show Node dynamic | grep perfect\n</code></pre>"},{"location":"ai-testbed/sambanova/miscellaneous/#how-busy-is-the-system","title":"How busy is the system?","text":"<p>Use one of</p> <pre><code>top\nhtop\n</code></pre>"},{"location":"ai-testbed/sambanova/running-a-model-or-program/","title":"Running a Model/Program","text":"<p>Note:  Please be mindful of how you are using the system. For example, consider running larger jobs in the evening or on weekends</p> <p>Note: Please use only Slurm commands, i.e., srun and sbatch, to run your code. If you run your code directly using the 'python' command, it may cause conflicts on the system.</p> <p>Note: If you have conda installed and a conda environment is active, you will see something like <code>(base)</code> at the beginning of the command prompt. If so, you will need to deactivate it with <code>conda deactivate</code>. Conda is not used on the SambaNova SN30 cluster.</p>"},{"location":"ai-testbed/sambanova/running-a-model-or-program/#introduction","title":"Introduction","text":"<p>The SambaNova workflow includes the following main steps to run a model.</p> <ol> <li>Compile</li> <li>Run</li> <li>Test (optional)</li> </ol> <p>The system uses the Slurm job scheduler to schedule the jobs and manage the workload on the system. For more information on Slurm, see Job Queueing and Submission.</p> <p>Example Programs lists the different example applications with corresponding commands for each of the above steps.</p>"},{"location":"ai-testbed/sambanova/running-a-model-or-program/#compile","title":"Compile","text":"<p>Compiles the model and generates a .pef file. This file contains information on how to reconfigure the hardware, and map the compute and memory resources required to run an application on RDUs. The pef files are by default saved in the 'out' directory; the SambaNova documentation advises saving pef files in separate directories with the '--output-folder' option.</p> <p>It is necessary to re-compile only when the model changes, or parameters specific to the model graph change, including the batch size.</p> <p>Compile times can be significant. Compiling the UNet sample, for example, when using images of size 32x32 pixels, takes 358(s), and 1844(s) for images of size 256x256.</p> <p>The entire compile process is executed on the host and no RDUs are involved in the compile step.</p> <p>Example of compiling the LeNet application:</p> <pre><code>srun python lenet.py compile -b=1 --pef-name=\"lenet\" --output-folder=\"pef\"\n</code></pre> <p>where</p> Argument Default Help -b 1 Batch size for training"},{"location":"ai-testbed/sambanova/running-a-model-or-program/#run","title":"Run","text":"<p>As part of this step, the model is trained on the RDUs by passing in the PEF file and the training dataset. The location of the pef file generated in the compile step is passed as an argument to the run command. Below is the example of the <code>run</code> command that trains a LeNet model.</p> <pre><code>srun python lenet.py run --pef=\"pef/lenet/lenet.pef\"\n</code></pre> <p>The location of the pef file generated in the compile step is passed as an argument to the run command.</p>"},{"location":"ai-testbed/sambanova/running-a-model-or-program/#test-optional","title":"Test (Optional)","text":"<p>This command is used to run the model on both the host CPU and a SambaNova RDU.  It compares the results from the CPU and RDU and will report if any discrepancies are found. Pass the pef file generated as part of the compile step as the input to this command.</p> <pre><code>srun python lenet.py test --pef=\"pef/lenet/lenet.pef\"\n</code></pre>"},{"location":"ai-testbed/sambanova/sambatune/","title":"Profiling and performance tuning with SambaTune","text":"<p>This section covers how to use the SambaTune profiling performance tuning tool, and the SambaTune UI for viewing the results.</p>"},{"location":"ai-testbed/sambanova/sambatune/#_1","title":"SambaTune for profiling and performance tuning","text":"<p>SambaTune uses a yaml file that describes how to profile an application. There are samples in <code>/opt/sambaflow/sambatune/configs</code>.  This section shows how to run the simplest sample, a linear net.</p> <p>First, ssh into one of the nodes in the SN30 cluster.  Next, start a slurm interative job reserving a full node (8 RDUs), for 8 hours (480 minutes): <pre><code>$ /usr/local/bin/srun --time=480 --gres=rdu:8 --pty bash\n</code></pre> Record the hostname: <pre><code>$ hostname\nsn30-r1-h1\n</code></pre></p> <p>Next, set an environment variable indicating where the profiling information should be stored: <pre><code>export DUMP_ROOT=~/Sambatune\n</code></pre></p> <p>If running a large model, the profiling information can be hundreds of gigabytes or more, and the DUMP_ROOT should be set to some location with more storage than your home directory (which has a quota). E.g. somewhere that you have write access to in <code>/projects</code></p> <p>Optionally, examine the sample yaml file. You will see that it has 5 top-level sections: <code>app:</code>, <code>model-args:</code>, <code>compile-args:</code>, <code>run-args:</code>, <code>env:</code></p> <p>Next, run sambatune using a sample sambatune yaml configuration file. This sample command line requests profiling with the <code>benchmark</code>, <code>instrument</code>, and <code>run</code> modes. <pre><code>$ sambatune --modes benchmark instrument run -- /opt/sambaflow/sambatune/configs/linear_net.yaml\n</code></pre></p> <p>This will take a while to run, particularly if the yaml for a larger model is used.</p> <p>Then, run <code>sambatune_ui</code>: <pre><code>$ export ST_PORT=8576\n$ sambatune_ui --directory $DUMP_ROOT/artifact_root/sambatune_gen --port $ST_PORT\n</code></pre></p> <p>Copy the password shown (e.g. to your clipboard). The userid is always admin. The password is different for every sambatune_ui run. </p> <p>In a fresh console on your working machine where you will run the browser, set up a two-hop ssh tunnel to the target node. Replace the <code>ALCFUserID</code> in the ssh command line with your ALCF userid. <pre><code>$ export ST_PORT=8576\n$ ssh -L $ST_PORT:localhost:$ST_PORT ALCFUserID@sambanova.alcf.anl.gov  -t ssh -L $ST_PORT:localhost:$ST_PORT -N sn30-r1-h1\n</code></pre></p> <p>Put localhost:8576 in the url bar of a Chrome-family browser. (Chrome, Brave, Vivaldi, Opera tested.) A login prompt for the sambatune ui should show. Enter admin and the password copied previously. You should now see the SambaTune UI. </p> <p>If the browser does not show a login prompt, or if any previous step complains about a port conflict, try another value for ST_PORT on both the target node and for the ssh tunnel command, e.g. 8577.</p> <p>See SambaNova's SambaTune documentation for more information about using SambaTune and the SambaTune UI. This section is a good starting point: Workflow overview</p> <p>When finished: - Break the ssh tunnel with Ctrl+C (SIGINT) or equivalent. - Stop the sambatune_ui server on the target node with Ctrl+C or equivalent. - Exit the interactive slurm job to release the reserved resources.</p> <p>A disconnected job can be canceled by determining its job id with <code>squeue -a</code> and canceling the job with <code>scancel &lt;jobid&gt;</code></p>"},{"location":"ai-testbed/sambanova/tunneling-and-forwarding-ports/","title":"Tunneling and Forwarding Ports","text":"<p>Port forwarding is covered here.  This is specifically for TensorBoard.</p>"},{"location":"ai-testbed/sambanova/tunneling-and-forwarding-ports/#tensorboard-port-forwarding","title":"TensorBoard Port Forwarding","text":"<p>This section describes the steps to be followed to set up port forwarding for applications, like TensorBoard, which runs on the SambaNova system and binds to one or more ports. This example uses 6006 and 16006 as port numbers. Using port numbers other than these may avoid collisions with other users.</p>"},{"location":"ai-testbed/sambanova/tunneling-and-forwarding-ports/#from-your-local-machine","title":"From Your Local Machine","text":"<p>Replace ALCFUserID with your ALCF User ID.</p> <p>Run</p> <pre><code># Forward a port number from sambanova.alcf.anl.gov to your local machine.\nssh -v -N -f -L localhost:16006:localhost:16006 ALCFUserID@sambanova.alcf.anl.gov\n...\nPassword: &lt; MobilePass+ code &gt;\n\n# Connect to sambanova.alcf.anl.gov\nssh ALCFUserID@sambanova.alcf.anl.gov\n...\nPassword: &lt; MobilePass+ code &gt;\n</code></pre>"},{"location":"ai-testbed/sambanova/tunneling-and-forwarding-ports/#from-sambanovaalcfanlgov","title":"From sambanova.alcf.anl.gov","text":"<p>Below are the commands specific to sn30-r1-h1. You may replace sn30-r1-h1 with any other node when using the appropriate system.</p> <p>Run</p> <p>Note:  The full name is sn30-r1-h1.ai.alcf.anl.gov and it may also be used.</p> <pre><code># Forward the port.\nssh -N -f -L localhost:16006:localhost:6006 ALCFUserID@sn30-r1-h1\n# Connect to the system.\nssh ALCFUserID@sn30-r1-h1\n</code></pre>"},{"location":"ai-testbed/sambanova/tunneling-and-forwarding-ports/#on-sn30-r1-h1","title":"On sn30-r1-h1","text":"<p>Activate the venv appropriate to your project.</p> <p>Navigate to the appropriate directory for your model. Launch your model using srun or sbatch.</p> <pre><code>cd /path/to/your/project\nsbatch --output=pef/my_model/output.log submit-my_model-job.sh\n</code></pre>"},{"location":"ai-testbed/sambanova/tunneling-and-forwarding-ports/#on-another-sn30-r1-h1-terminal-window","title":"On Another sn30-r1-h1 Terminal Window","text":"<p>The SambaNova system has a bash shell script to setup the required software environment. This sets up the SambaFlow software stack, the associated environmental variables and activates a pre-configured virtual environment.</p> <p>Use the command appropriate for your environment.</p> <p>For example, if you are using LogReg:</p> <pre><code>ALCFUserID@sn30-r1-h1:~$ source /opt/sambaflow/apps/starters/logreg/venv/bin/activate\n(venv) ALCFUserID@sn30-r1-h1:~$\n</code></pre> <p>Navigate to the appropriate directory for your model.</p> <pre><code>cd /path/to/your/project\ntensorboard --logdir /logs --port 6006\n</code></pre>"},{"location":"ai-testbed/sambanova/tunneling-and-forwarding-ports/#browser-on-local-machine","title":"Browser on Local Machine","text":"<p>Then, navigate in your browser to, in this example, http://localhost:16006 on your local machine.</p>"},{"location":"ai-testbed/sambanova/tunneling-and-forwarding-ports/#notes","title":"Notes","text":"<p>Explanation of ssh command:</p> <pre><code>-N : no remote commands\n\n-f : put ssh in the background\n\n-L &lt;machine1&gt;:&lt;portA&gt;:&lt;machine2&gt;:&lt;portB&gt; :\n\nThe full command line will forward &lt;machine2&gt;:&lt;portB&gt; (remote scope) to &lt;machine1&gt;:&lt;portA&gt; (local scope)\n</code></pre> <p>Adapted from:  How can I run Tensorboard on a remote server?</p>"},{"location":"ai-testbed/sambanova/virtual-environment/","title":"Virtual Environments","text":""},{"location":"ai-testbed/sambanova/virtual-environment/#using-a-venv","title":"Using a Venv","text":"<p>To create a virtual environment, one can use the --system-site-packages flag:</p> <pre><code>python -m venv --system-site-packages my_env\nsource my_env/bin/activate\n</code></pre>"},{"location":"ai-testbed/sambanova/virtual-environment/#installing-packages","title":"Installing Packages","text":"<p>Install packages in the normal manner such as:</p> <pre><code>python3 -m pip install &lt;package&gt;\n</code></pre> <p>For more details see Use pip for installing.</p> <p>To install a different version of a package that is already installed in one's environment, one can use:</p> <pre><code>pip install --ignore-installed  ... # or -I\n</code></pre>"},{"location":"ai-testbed/sambanova/virtual-environment/#pre-built-sample-venv","title":"Pre-Built Sample Venv","text":"<p>Each of the samples or application examples provided by SambaNova has its own pre-built virtual environment which can be readily used. They are present in the <code>/opt/sambaflow/apps/</code> directory tree within each of the applications.</p> <p>Note: Conda is not supported on the SambaNova system.</p>"},{"location":"ai-testbed/sn40l_inference/","title":"System Overview","text":""},{"location":"ai-testbed/sn40l_inference/#introduction","title":"Introduction","text":"<p>SambaStack is a purpose-built hardware and software platform optimized for AI inference, powered by SambaNova\u2019s advanced Reconfigurable Dataflow Unit (RDU) processors. At the core of this infrastructure is a SambaNova SN40L cluster, composed of two SambaRacks\u2014each housing 16 SN40L RDU systems. This dedicated setup delivers high-throughput, low-latency performance for machine learning workloads. Models running on the cluster are exposed through OpenAI-compatible API endpoints, with each endpoint capable of hosting multiple independently accessible models.</p> <p>Below are some of the links to SambaNova documentation.</p> <p>SambaRack information: SambaRack</p> <p>RDUs: Reconfigurable Dataflow Units (RDUs) \u2014 purpose-built for AI</p> <p>More on RDUs (pdf): Accelerated Computing with a Reconfigurable Dataflow Architecture</p>"},{"location":"ai-testbed/sn40l_inference/using_an_inference_endpoint/","title":"Accessing the Metis inference endpoint","text":"<p>The Sambanova SN40L cluster (Metis) is integrated as part of the ALCF inference service provided through API access to the models running on the Metis cluster. The models running on Metis can be accessed in two ways. </p> <pre><code>1. Web UI\n2. API Access\n</code></pre>"},{"location":"ai-testbed/sn40l_inference/using_an_inference_endpoint/#accessing-the-endpoints-using-the-web-ui","title":"Accessing the endpoints using the Web UI.","text":"<p>The easiest way to get started is through the web interface, accessible at https://inference.alcf.anl.gov/</p> <p>The UI is based on the popular Open WebUI platform. After logging in with your ANL or ALCF credentials, you can:</p> <ol> <li>Select a model from the dropdown menu at the top of the screen.</li> <li>Start a conversation directly in the chat interface.</li> </ol> <p>In the model selection dropdown, you can see the status of each model:</p> <p></p> <ul> <li>Live: These models are \"hot\" and ready for immediate use.</li> <li>Starting: A node has been acquired and the model is being loaded into memory.</li> <li>Queued: The model is in a queue waiting for resources to become available.</li> <li>Offline: The model is available but not currently loaded. It will be queued for loading when a user sends a request.</li> <li>All: Lists all available models regardless of their status.</li> </ul>"},{"location":"ai-testbed/sn40l_inference/using_an_inference_endpoint/#accessing-the-endpoints-using-the-api","title":"Accessing the endpoints using the API.","text":"<p>For programmatic access, you can use the API endpoints directly.</p>"},{"location":"ai-testbed/sn40l_inference/using_an_inference_endpoint/#1-setup-your-environment","title":"1. Setup Your Environment","text":"<p>You can run the following setup from any internet connected machine (your local machine, or an ALCF machine).</p> <p><pre><code># Create a new Conda environment\nconda create -n globus_env python==3.11.9 --y\nconda activate globus_env\n\n# Install necessary packages\npip install openai globus_sdk\n</code></pre> Note: A python virtual environment may be used as well. <pre><code>virtualenv -p python3.10 globus_env\nsource globus_env/bin/activate\npip install openai globus_sdk\n</code></pre></p>"},{"location":"ai-testbed/sn40l_inference/using_an_inference_endpoint/#2-authenticate","title":"2. Authenticate","text":"<p>To access the endpoints, you need an authentication token.</p> <pre><code># Download the authentication helper script\nwget https://raw.githubusercontent.com/argonne-lcf/inference-endpoints/refs/heads/main/inference_auth_token.py\n\n# Authenticate with your Globus account\npython inference_auth_token.py authenticate\n</code></pre> <p>This will generate and store access and refresh tokens in your home directory. To see how much time you have left before your access token expires, type the following command (<code>units</code> can be seconds, minutes, or hours):</p> <pre><code>python inference_auth_token.py get_time_until_token_expiration --units seconds\n</code></pre> <p>Token Validity</p> <ul> <li>Access tokens are valid for 48 hours. The <code>get_access_token</code> command will automatically refresh your token if it has expired.</li> <li>An internal policy requires re-authentication every 7 days. If you encounter permission errors, logout from Globus at app.globus.org/logout and re-run <code>python inference_auth_token.py authenticate --force</code>.</li> </ul>"},{"location":"ai-testbed/sn40l_inference/using_an_inference_endpoint/#3-make-a-test-call","title":"3. Make a Test Call","text":"<p>Once authenticated, you can make a test call using cURL or Python.</p> cURLPython (OpenAI SDK) <pre><code>#!/bin/bash\n\n# Get your access token\naccess_token=$(python inference_auth_token.py get_access_token)\n\ncurl -X POST \"https://inference-api.alcf.anl.gov/resource_server/metis/api/v1/chat/completions\" \\\n     -H \"Authorization: Bearer ${access_token}\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n            \"model\": \"Meta-Llama-3.1-8B-Instruct\",\n            \"messages\":[{\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms.\"}]\n         }'\n</code></pre> <pre><code>from openai import OpenAI\nfrom inference_auth_token import get_access_token\n\n# Get your access token\naccess_token = get_access_token()\n\nclient = OpenAI(\n    api_key=access_token,\n    base_url=\"https://inference-api.alcf.anl.gov/resource_server/metis/api/v1\"\n)\n\nresponse = client.chat.completions.create(\n    model=\"Meta-Llama-3.1-8B-Instruct\",\n    messages=[{\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms.\"}]\n)\n\nprint(response.choices[0].message.content)\n</code></pre> <p>Discovering Available Models</p> <p>The endpoint information can be accessed using the Metis status page. It provides the status of the endpoints and the models and the associated configurations.</p> <p>The list of currently supported chat-completion models on Metis are :  - Meta-Llama-3.3-70B-Instruct - Meta-Llama-3.1-8B-Instruct -  Qwen2.5-Coder-0.5B-Instruct -  DeepSeek-R1</p> <p>You can programmatically query all available models and endpoints:</p> <p><pre><code>    access_token=$(python inference_auth_token.py get_access_token)\n    curl -X GET \"https://inference-api.alcf.anl.gov/resource_server/list-endpoints\" \\\n         -H \"Authorization: Bearer ${access_token}\" | jq -C '.clusters.metis'\n</code></pre> If you need any other models to be provisioned via these endpoints, please reach out to support[at]alcf.anl.gov.</p> <p>See SambaNova's documentation for additional information to supplement the instructions below: OpenAI compatible API.</p>"},{"location":"aurora/","title":"Aurora Machine Overview","text":"<p>Aurora is a 10,624-node HPE Cray-Ex based system. It has 166 racks with 21,248 CPUs and 63,744 GPUs. Each node consists of 2 Intel Xeon CPU Max Series (codename Sapphire Rapids or SPR) with on-package HBM and 6 Intel Data Center GPU Max Series (codename Ponte Vecchio or PVC). Each Xeon CPU has 52 physical cores supporting 2 hardware threads per core and 64 GB of HBM. Each CPU socket has 512 GB of DDR5 memory. The GPUs are connected all-to-all with Intel X<sup>e</sup> Link interfaces. Each node has 8 HPE Slingshot-11 NICs, and the system is connected in a Dragonfly topology. The GPUs may send messages directly to the NIC via PCIe, without the need to copy into CPU memory.</p> <p></p> <p>Figure 1: Summary of the compute, memory, and communication hardware contained within a single Aurora node.</p> <p>The Intel Data Center GPU Max Series is based on X<sup>e</sup> Core. Each X<sup>e</sup> core consists of 8 vector engines and 8 matrix engines with 512 KB of L1 cache that can be configured as cache or Shared Local Memory (SLM). 16 X<sup>e</sup> cores are grouped together to form a slice. 4 slices are combined along with a large L2 cache and 4 HBM2E memory controllers to form a stack or tile. One or more stacks/tiles can then be combined on a socket to form a GPU. More detailed information about node architecture can be found here.</p>"},{"location":"aurora/#aurora-compute-node","title":"Aurora Compute Node","text":"NODE COMPONENT DESCRIPTION PER NODE AGGREGATE Processor 2000 MHz 2 21,248 Cores/Threads Intel Xeon CPU Max 9470C Series 104/208 1,104,896/2,209,792 CPU HBM HBM2e 64x2 GiB 1.328 PiB CPU DRAM DDR5 512x2 GiB 10.375 PiB GPUs Intel Data Center Max 1550 Series 6 63,744 GPU HBM HBM2e 768 GiB 7.968 PiB"},{"location":"aurora/#aurora-gpu-architecture-summary","title":"Aurora GPU Architecture Summary","text":"GPU COMPONENT DESCRIPTION COUNT CAPABILITY Stack a.k.a. Tile 2 X<sup>e</sup> Vector Engine a.k.a. EU (execution unit) 512 per Stack (448 active) 8 threads, 512b SIMD X<sup>e</sup> Matrix Engine a.k.a. systolic part of EU 512 per Stack (448 active) Register 512-bit register 128 per thread X<sup>e</sup> Core a.k.a. subslice; unit of 8 EUs 64 per Stack 128 per GPU L1 cache 128 KiB Last Level cache a.k.a. RAMBO cache 384 MiB per GPU <p>See Aurora Overview for more information.</p>"},{"location":"aurora/aurora-pe/","title":"Aurora Programming Environment","text":""},{"location":"aurora/aurora-pe/#overview","title":"Overview","text":"<p>The Aurora Programming Environment (Aurora PE) is Aurora's default software environment and consists of the OneAPI SDK, MPICH, and the Spack PE. The Aurora PE is loaded in the user environment through a default module set. Alternative versions of the Aurora PE, as well as Aurora PE components not loaded by default, are available through the module interface. Each version of the PE may have multiple compilers, runtimes, and/or MPICH installations which are interchangeable via modules. In addition to the OneAPI and MPICH installations, the Aurora PE contains the Spack PE, a software stack which includes general-purpose and scientific computing packages. See the Spack PE page for more details.</p>"},{"location":"aurora/aurora-pe/#switching-pe-or-sdk-versions","title":"Switching PE or SDK versions","text":"<p>Aurora PE and OneAPI SDK versions can be viewed with <code>module avail</code> and switched with <code>module load</code> commands. The Aurora PE modules utilize Lmod's hierarchical module system to allow seamless switching between versions of the Aurora PE and its components. For example, if the user loads a different version of the <code>oneapi</code> module, other loaded modules from the Aurora PE, such as <code>intel_compute_runtime</code>, <code>mpich</code>, and packages from the Spack PE, will be reloaded to guarantee compatibility. In short, the hierarchical modulefile system ensures that the module environment is self-consistent with minimal user intervention.</p>"},{"location":"aurora/aurora-pe/#aurora-pe-and-soft","title":"Aurora PE and /soft","text":"<p>The Aurora PE is installed in <code>/opt/aurora</code> and is mounted as a read-only squashfs. <code>/soft</code> is also available to provide software not present in the Aurora PE. However, loading libraries from shared filesystems like <code>/soft</code> can cause performance issues at scale. Modules in <code>/soft/modulefiles</code> are not part of the default environment in order to avoid adverse impacts. Users wishing to use software in <code>/soft</code> will need to first run <code>module use /soft/modulefiles</code> to access the modules.</p> <p>The Aurora PE has a longer-term upgrade cadence (on the order of months), so ad-hoc software requests will be fulfilled through software installations in <code>/soft</code>. <code>/soft</code> installations will be considered for incorporation into the Aurora PE during upgrade cycles.</p> <p>Modules in <code>/soft</code> may conflict with modules in the Aurora PE. Lmod has some limitations in automatically handling module conflicts, so the user may need to manually resolve conflicts arising from modules outside of the Aurora PE. Users are also advised to sanitize module paths that they add from other non-standard locations, such as <code>/home</code>, to avoid conflicts.</p>"},{"location":"aurora/bugs-table/","title":"Bugs table","text":"<p>&lt; Back to Aurora Known Issues page</p> <p>Sync tables now</p>"},{"location":"aurora/bugs-table/#open-issues","title":"Open Issues","text":"Internal ID Description Vendor ID Reproducer Path PoC Priority? ETA Date Opened Last Updated 92 SYCL device info free_memory wrong on 2-stack PVC1550 GPU No response source/reproducers/dpcpp/sycl_free_flat Jakub H No response 2025-10-31 2025-10-31 91 sycl failed malloc_device on GPU takes 20 seconds No response source/reproducers/dpcpp/slow_alloc/ Jakub H No response 2025-10-31 2025-10-31 90 Device Sanitizer + LIBOMPTARGET_DEBUG=1 issues for the GAMESS RI-MP2 mini-app CMPLRLLVM-71455 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/tools/sanitizer_rimp2_test Brian No response 2025-10-31 2025-10-31 89 Device Sanitizer breaks with MKL DGEMM call in GAMESS RI-MP2 mini-app MKLD-19334 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/tools/sanitizer_rimp2_test Brian, JaeHyuk No response 2025-10-31 2025-10-31 88 RPATH issue when mixing and matching SDK and spack packages built by another SDK No response No need. reprdducer attached in this ticket Ye Luo No response 2025-10-30 2025-10-30 87 QUDA compile fail cmplrllvm-70981 source/reproducers/openmp/quda_crash Xiayong Jin / Brian W In progress 2025-10-28 2025-10-29 86 omp_alloc should support pinned memory, or implement proper fallback behavior CMPLRLIBS-35442 /home/kweide/projects/OpenMP_VV/tests/5.1/allocate/test_omp_alloctrait_pinned.c and source/reproducers/openmp/omp_alloctrait_pinned in the test set Klaus Weide In progress 2025-10-28 2025-10-31 85 zeEventQueryKernelTimestampsExt is broken with IMM command lists GSD-11124 source/reproducers/l0/zeEventQueryKernelTimestampsExt_clock Thomas/John Mellor-Crummey No response 2025-10-27 2025-10-29 84 Device Sanitizer is not functional with OpenMP C/Fortran codes /lus/flare/projects/Aurora_deployment/jkwack/JK_AT_Tools/sanitizer and source/reproducers/tools/sanitizer and source/reproducers/tools/sanitizer_rimp2_test  in the test set JaeHyuk Kwack \ud83d\udea8 2025.3 2025-10-22 2025-10-31 83 With ifx, <code>openmp_version</code> is missing from omp_lib CMPLRLIBS-35365 /home/kweide/tests/test_openmp_version.f90  and source/reproducers/openmp/omp_version in the test set Klaus Weide 2025.3 2025-10-20 2025-10-24 82 Symbol missing issue with 1.3 version onwards in SLES and Intel Datacenter Max GPU on Aurora https://github.com/intel/xpumanager/issues/113 https://github.com/intel/xpumanager/issues/113 Servesh In progress. ETA drop after next (github fix in a few weeks, LTS end of year) 2025-10-16 2025-10-29 81 IGC_StackOverflowDetection not working GSD-11763 source/reproducers/openmp/stack_overflow_not_working Brian In progress 2025-10-15 2025-10-29 80 VTune fails with \"Assertion failed: tool_gtpin_support:126: (buffer) \" VASP-32612, GTPIN-1169 /lus/flare/projects/Aurora_deployment/jkwack/JK_AT_Tools/Apps/GAMESS_RI-MP2_MiniApp  source/reproducers/tools/vtune_gtpin_fail in the test set JaeHyuk Kwack \ud83d\udea8 2025.3 2025-10-10 2025-10-30 79 Advisor fail with \"advisor: Warning: The application returned a non-zero exit value.\" ADV-10687 source/reproducers/tools/advisor_gflop JaeHyuk Kwack Fixed with <code>advisor --version == 616302</code>, which should be in 2025.3 2025-10-08 2025-10-30 78 ExchCXX fails to compile with <code>is too large for Clang to process</code> CMPLRLLVM-70962 source/reproducers/dpcpp/jit_too_large_for_Clang Abhi \ud83d\udea8 No response 2025-10-06 2025-10-29 77 [SYCL] Function pointers compilation issue CMPLRLLVM-16317 Reproducer below and <code>source/reproducers/dpcpp/func_pointers</code> Abhi, Patrick Steinbrecher \ud83d\udea8 Under discussion 2025-10-06 2025-10-15 76 Segfaults in MPICH routines in next-eval No response for XGC: /lus/flare/projects/catalyst/world_shared/zippy/xgc Tim Williams \ud83d\udea8 No response 2025-10-01 2025-10-01 74 ZES_ENABLE_SYSMAN should default to 1 in the oneapi module No response see Details Tim Williams No response 2025-09-29 2025-10-15 73 \"error: undefined reference to `old_llvm.umul.with.overflow.i64'\" in newer kokkos CMPLRLLVM-70603 source/reproducers/dpcpp/kokkos_mdspan_umul Daniel Arndt Being worked internally 2025-09-17 2025-10-14 71 RPC launch error tracking 2025-09-15 2025-09-23 70 PALS gpu-bind, composite, envall lead to \"launch failed\" DCE Case 5392152905 applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/mpi/envall Thomas Applencourt patch to test out and that should already be landed for a future release 2025-09-10 2025-10-02 68 warpx segfaults/hangs with OpenPMD enabled No response /lus/flare/projects/catalyst/world_shared/zippy/reproducers/issue52/ Tim Williams No response 2025-08-23 2025-08-23 67 warpx Debug build crashes oneAPI compiler CMPLRLLVM-24314 /lus/flare/projects/catalyst/world_shared/zippy/reproducers/issue52/ Tim Williams No response 2025-08-21 2025-10-29 66 Compiling with \"-g\" leads to a much larger binary than without CMPLRLLVM-69909, CMPLRLLVM-24314 lammps + -g Brian Holland No response 2025-08-20 2025-10-01 65 Clarification requested about ZE_DEVICE_PROPERTY_FLAG_ONDEMANDPAGING on PVC GSD-11510 source/reproducers/l0/ondemand_paging/ Colleen implemented, ETA end of year. 2025-08-20 2025-10-29 64 E3SM fortran compile ICE CMPLRLLVM-69862 source/reproducers/ifx/e3sm_homme_ICE_error Abhi 2025.3.0 2025-08-18 2025-10-09 63 Kokkos kernels fails to build with kokkos built with openmp enabled CMPLRLLVM-69908 source/applications/kokkos-kernels Sean Koyama / Colleen Bertoni gone starting with 4.19 (fixed in 2025.3 branch) 2025-08-18 2025-09-16 62 -ftarget-register-alloc-mode=pvc:large and \"-device 12.60.7\" for AOT GSD-11490 source/reproducers/general/ftarget-register-alloc-mode_flag Steve Rangel Fixed internally, ETA end of year 2025-08-14 2025-10-29 61 Failing unit tests on PVCs with 2025.2 oneAPI SDK -- is it expected? https://github.com/uxlfoundation/oneMath/issues/703, CMPLRLLVM-69572, ONSAM-1930, GSD-11482 https://github.com/uxlfoundation/oneMath/issues/703 todo: need to check with 2025.3 Colleen Bertoni CMPLRLLVM-69572: fixed, other implemented. ETA Oct if cherry-picked 2025-07-30 2025-10-29 60 ext_oneapi_memcpy2d is significantly slower with implicit scaling than explicit and on PVC vs A100 Really depends on GSD-11132 source/reproducers/dpcpp/ext_oneapi_memcpy2d_perf Natalie Beams No response 2025-07-29 2025-10-01 58 kokkos inclusive and exclusive scan giving incorrect answers for 1146.10 CMPLRLLVM-69285, GSD-11736 source/reproducers/dpcpp/kokkos_optimization_scan Daniel Arndt \ud83d\udea8 Fixed internally, LTS2, 1-2 months (early Nov.) (1146.43) 2025-07-23 2025-10-29 57 GPU segfault in gtensor_bench with 2025.2 MKLD-18276, CMPLRLIBS-35326, CMPLRLLVM-68696 source/applications/gtensor_bench Colleen Bertoni 2025.3 2025-07-22 2025-08-11 56 RSBench-SYCL incorrect answers with 1146.10 GSD-11247 source/applications/RSBench/ John Tramm, Colleen Bertoni 1146.31 2025-07-22 2025-09-17 55 Linking in LZ causes changes in signal handling cmplrlibs-35385, GSD-11413 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/l0/signal_handler/ Thomas Applencourt, Colleen Bertoni No response 2025-07-22 2025-07-25 54 oneCCL zeMemGetAddressRange error with alltoallv and zero-sized buffers oneCCL GitHub Issue: https://github.com/uxlfoundation/oneCCL/issues/174, MLSL-3764 See instructions on oneCCL GitHub Issue: https://github.com/uxlfoundation/oneCCL/issues/174 Riccardo Balin \ud83d\udea8 oneCCL 2021.17, oneAPI 2025.3 2025-07-18 2025-08-26 52 compiler segfaults linking warpx binary GSD-11357, GSD-11855 /lus/flare/projects/catalyst/world_shared/zippy/reproducers/issue52/warpx Tim Williams \ud83d\udea8 2025.2 + 1146.10 2025-07-07 2025-10-15 47 Non standard MPI knobs suggested for performance ANL-291 N/A Servesh M No response 2025-06-23 2025-06-27 45 DDT issues since Aurora upgrade No response /lus/flare/projects/catalyst/world_shared/zippy/ddt Tim Williams Linaro Forge 2025.0.1 has the workaround. GDB 2025.3 the root cause will be gone. 2025-06-12 2025-08-05 43 CMake can't find <code>MKL::MKL_SYCL</code> with MPI wrapper compilers No response https://github.com/thilinarmtb/onemkl_cmake_mpi_bug Thilina Ratnayaka, Colleen Bertoni improvements will be part of the next oneMKL release, 2025.3. 2025-06-11 2025-06-25 39 Feature request for Aurora runtime to include debugging symbols ANL-286, HPCS-15374, GSD-11427 feature request Ye Luo No response 2025-05-29 2025-09-17 38 One application in GRID consistently hangs GSD-11441 /lus/flare/projects/Aurora_deployment/xyjin/W/test_grid_g5r5_paboyle Xiao-Yong Jin \ud83d\udea8 Fixed Internally, likely Nov. 1146.43 2025-05-27 2025-10-15 36 (Occasional Interruptible) hangs in applications Possibly related to ANL-215 /lus/flare/projects/Aurora_deployment/xyjin/W/test_example_detar.skel Xiao-Yong Jin \ud83d\udea8 No response 2025-05-15 2025-07-09 33 Crash when calling too many MPI_Probe https://github.com/pmodels/mpich/issues/7427 https://github.com/pmodels/mpich/issues/7427 David--Cl\u00e9ris Timoth\u00e9e No response 2025-05-15 2025-05-15 32 PETSc segfaults in sparse matrix calls IGDB-6516, GSD-10450 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/mkl/csr_gemv_usm/ Junchao Zhang \ud83d\udea8 2025.3 for part malloc_shared in MKL 2025-05-15 2025-06-25 31 GAMESS segfaults with -O0 GSD-10393, CMPLRLIBS-35345,GSD-11035 <code>/lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/openmp/gamess_O0_page_fault</code> Colleen Bertoni \ud83d\udea8 1146.31 (Targeted for LTS2 (1146.12+), contained with the IGC 2.16 series / WW34 (2-3 weeks)) 2025-05-14 2025-09-17 30 Copy 2D/3D are broken (zeCommandListAppendMemoryCopyRegion) NEO-14954, GSD-11132 https://github.com/rpereira-dev/ze-zoo Romain PEREIRA and Thomas APPLENCOURT \ud83d\udea8 No response 2025-05-10 2025-09-17 29 Significant slowdown with LAMMPS in first run, subsequent runs much faster No response /flare/catalyst/proj_shared/knight/projects/ExtremeCarbon/snap-carbon-scaling/1B/ Christopher Knight No response 2025-05-09 2025-08-20 18 Ping failures and hangs with production runs using GPT/GRID ANL-251, RITM0404147, RITM0404148, RITM0405730, GSD-11441 /lus/flare/projects/LatticeFlavor/lehner Xiao-Yong Jin \ud83d\udea8 No response 2025-04-04 2025-08-18 17 hang with MPI pipelining https://github.com/pmodels/mpich/issues/7373 Build and run commands are in the MPICH issue. James Osborn Merged in https://github.com/pmodels/mpich/pull/7622 2025-04-03 2025-10-14 13 XGC hangs at scale CMPLRTST-27836 xgc-es-cpp-gpu app, ES_ITER test case Tim Williams \ud83d\udea8 No response 2025-04-03 2025-09-17 12 CXI alloc failed on cxi1: request exceeds ACs limits No response None Not Thomas No response 2025-04-01 2025-08-04"},{"location":"aurora/bugs-table/#closed-issues","title":"Closed Issues","text":"Internal ID Description Vendor ID Reproducer Path PoC Priority? Date Opened Closed Date 75 \"MPL_gpu_query_is_same_dev(int, int): Assertion `global_dev1 &gt;= 0 &amp;&amp; global_dev1 &lt; known_ze_device_count' failed.\" with mpich.dbg No response https://github.com/pmodels/mpich/issues/7602 Tim, JaeHyuk, Colleen 2025-09-30 2025-10-13 72 MPI_aborts in many applications in next-eval at larger scales No response N/A Brian Holland / Tim Williams 2025-09-16 2025-09-30 59 [ISHMEM] Unit test fails with ishmem 1.4.0 https://github.com/oneapi-src/ishmem/issues/10 https://github.com/oneapi-src/ishmem/issues/10 and source/applications/ishmem_sos Abhi 2025-07-25 2025-07-31 53 IFX Compiler reads and stores floating point values from a text file at single-precision No response /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/ifx/fp_precision Victor Anisimov \ud83d\udea8 2025-07-09 2025-07-10 51 [SYCL] Bug from SYCL peer_access No response /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/dpcpp/sycl_peer_access Abhi 2025-07-02 2025-10-13 50 OpenMP Thread binding No response See bellow Romain PEREIRA 2025-07-02 2025-07-02 49 [E3SM] MPICH bug related to collectives tunning https://github.com/pmodels/mpich/issues/7456 https://github.com/pmodels/mpich/issues/7456 Abhi \ud83d\udea8 2025-06-27 2025-10-09 48 Zombie Processes GSD-11266 none yet Servesh M \ud83d\udea8 2025-06-25 2025-10-29 44 QMCPACK segfault in libomp No response Not yet created Ye Luo \ud83d\udea8 2025-06-12 2025-07-23 42 Linking fails with old build environment No response /lus/flare/projects/PHASTA_aesp_CNDA/jrwrigh/petsc_build_test Kris Rowe 2025-06-06 2025-06-10 41 torch.compile segfaults for &gt;2 tiles MLSL-3728 <code>/flare/Aurora_deployment/vsastry/torch_compile</code> Varuni Sastry 2025-06-06 2025-07-24 40 Need SYSMAN support for all modes in recent releases HPCS-15366, related: GSD-11104 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/l0/leak_zesMemoryGetState Thomas Applencourt \ud83d\udea8 2025-05-30 2025-06-17 37 xpu-smi reports \"N/A\" for GPU Utilization RITM0428460, ANL-279, GSD-11252 any run of xpu-smi Kyle Felker / Colleen Bertoni 2025-05-22 2025-10-29 35 Avoid outputs exceeding few KBs to stdout/stderr from MPI ranks RITM0425437 First issue Large MPI writes to stdout Servesh Muralidharan 2025-05-15 2025-07-23 34 Runtime Error: pytorch DDP with CCL_BCAST=&lt;\"double_tree, direct, naive, maybe others?\"&gt; MLSL-3729 In issue Nathan Nichols 2025-05-15 2025-10-13 28 CMake failures with SYCL No response /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/dpcpp/ Abhishek Bagusetty 2025-05-09 2025-05-09 27 Build failures on PVC with Cutlass GSD-11099, https://github.com/codeplaysoftware/cutlass-sycl/issues/329 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/dpcpp/cutlass-sycl Abhi \ud83d\udea8 2025-05-07 2025-10-13 26 L0 memcpy bug GSD-11142, NEO-14641 I was doing the same run as QMCPACK SOW runs in the reframe Ye Luo \ud83d\udea8 2025-05-06 2025-10-13 25 Compile fail in Lattice App Brian reproduced and confirms fixed in 2025.1 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/dpcpp/bug_cgpt_icpx Xiao-Yong Jin \ud83d\udea8 2025-05-01 2025-10-13 24 Noticeably more \"ping failed\" than before the 2025.1 SDK + 1099.12 UMD/KMD upgrade JIRA is: \u00a0HPCS-15331 N/A Xiao-Yong Jin Colleen Bertoni 2025-05-01 2025-05-16 23 Apps stop running after Apr 29 upgrade due to libstdc++ dependency No response See details Ye Luo 2025-04-30 2025-05-06 22 SYCL In-order queue broken NEO-14641 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/dpcpp/in-order Thomas Applencourt \ud83d\udea8 2025-04-23 2025-10-13 21 Error during write with Quantum ESPRESSO No response see .zip file attached below, also /lus/flare/projects/matml_aesp_CNDA/dir_io_QE_crash Filippo Simini \ud83d\udea8 2025-04-17 2025-04-18 20 Issue with gpu-bind for mpiexec under ZE_FLAT_DEVICE_HIERARCHY=FLAT mode ANL-283/HPE Support Case 5390607860 See below Abhishek, Nathan, Khalid 2025-04-16 2025-10-01 19 Severe CPU memory growth in MPICH No response /flare/catalyst/world_shared/zippy/reproducers/issue19 Tim Williams 2025-04-04 2025-07-31 16 Catastrophic memory error in context lmp_aurora_kokkos No response public LAMMPS Chris Knight 2025-04-03 2025-07-23 9 Multithreaded data-transfer can cause page-fault N/A Full QMCPACK Ye Luo 2025-04-01 2025-05-08 8 Lots of H2D copies produce CPU I9 error and incorrect value N/A Full QMCPACK Ye Luo \ud83d\udea8 2025-04-01 2025-05-28 7 MPI_Bcast gets faster when turning off XPMEM pmodels/mpich#7334 see Issue on MPICH GitHub repo Ye Luo 2025-04-01 2025-04-24 6 MPICH memory allocation slows down at scale pmodels/mpich#7333 see MPICH issue Ye Luo \ud83d\udea8 2025-04-01 2025-04-24 4 Incorrect results in receive buffer in GPU memory MPICH 7312 grid application (lattice QCD) Patrick Steinbrecher, Tim Williams \ud83d\udea8 2025-03-25 2025-04-24 3 Linker error found by XGC CMPLRLLVM-66496 /home/zippy/smalltests/aurora/xgc42/fails Tim Williams 2025-03-19 2025-03-28"},{"location":"aurora/bugs-table/#update-tables","title":"Update tables","text":"<p>Automatically updated nightly. To update now, wait 10-15s after last change to AuroraBugTracking Issues, then run (anywhere on a machine that has authenticated with <code>gh</code>): <pre><code>gh workflow run \"Update Submodules\" --repo \"argonne-lcf/user-guides\" &amp;&amp; GH_FORCE_TTY=100% watch -c -n1 gh run list --repo \"argonne-lcf/user-guides\"\n</code></pre> And wait ~2m until no jobs are running. </p> <p>Or execute aurora-bug-table-sync.sh to automatically run everything step-by-step and know exactly when the changes are live online.</p>"},{"location":"aurora/getting-started-on-aurora/","title":"Getting Started on Aurora","text":""},{"location":"aurora/getting-started-on-aurora/#logging-into-aurora","title":"Logging Into Aurora:","text":"<p>To log into Aurora: <pre><code>ssh &lt;username&gt;@aurora.alcf.anl.gov\n</code></pre> Then, type in the password from your CRYPTOCard/MobilePASS+ token.</p>"},{"location":"aurora/getting-started-on-aurora/#hardware-overview","title":"Hardware Overview","text":"<p>An overview of the Aurora system, including details on the compute node architecture, is available on the Machine Overview page.</p>"},{"location":"aurora/getting-started-on-aurora/#compiling-applications","title":"Compiling Applications","text":"<p>Users are encouraged to read through the Compiling and Linking Overview page and corresponding pages depending on the target compiler and programming model.</p> <p>Autotools and CMake are available in the default Aurora Programming Environment (PE) and can be loaded via Lmod modules:</p> <pre><code>module load autoconf cmake\n</code></pre>"},{"location":"aurora/getting-started-on-aurora/#submitting-and-running-jobs","title":"Submitting and Running Jobs","text":"<p>Users are encouraged to read through the Running Jobs with PBS at the ALCF page for information on using the PBS scheduler and preparing job submission scripts. For Aurora-specific job documentation, refer to Running Jobs on Aurora.</p>"},{"location":"aurora/getting-started-on-aurora/#early-user-notes-and-known-issues","title":"Early User Notes and Known Issues","text":"<ul> <li>Hardware instabilities - possible frequent downtime</li> <li>Software instabilities - non-optimized compilers, libraries, and tools; frequent software updates</li> <li>Non-final configurations (storage, OS versions, etc.)</li> <li>Short notice for downtimes (scheduled downtimes will be with 4-hour notice, but sometimes downtimes may occur with just an email notice). Notices go to the aurora-notify@alcf.anl.gov email list. All users with access are added to the list initially.</li> </ul> <p>See Early User Notes and Known Issues for details.</p>"},{"location":"aurora/getting-started-on-aurora/#python-on-aurora","title":"Python on Aurora","text":"<p>Frameworks on Aurora can be loaded into a user's environment by loading the <code>frameworks</code> module as follows. The conda environment loaded with this module makes available TensorFlow, Horovod, and PyTorch with Intel extensions and optimizations.</p> <pre><code>module load frameworks\n</code></pre> <p>Note that there is a separate Python installation in <code>spack-pe-gcc</code> which is used as a dependency of a number of Spack PE packages. Users will need to exercise caution when loading both <code>frameworks</code> and <code>python</code> from the Spack PE. For more details about Python on Aurora, please review Python on Aurora.</p>"},{"location":"aurora/getting-started-on-aurora/#software-environment","title":"Software Environment","text":"<p>The Aurora Programming Environment (Aurora PE) provides the OneAPI SDK, MPICH, runtime libraries, and a suite of additional tools and libraries. The Aurora PE is available in the default environment and is accessible through modules. For example, tools and libraries like <code>cmake</code>, <code>boost</code>, and <code>hdf5</code> are available in the default environment. <pre><code>module load cmake\n</code></pre></p> <p>More details are on the Aurora PE page.</p> <p>Additional software is installed in <code>/soft</code> and can be accessed by adding <code>/soft/modulefiles</code> to the module search path. <pre><code>module use /soft/modulefiles\n</code></pre></p> <p>This will make available a handful of additional software modules, such as <code>kokkos</code>.</p>"},{"location":"aurora/getting-started-on-aurora/#proxy","title":"Proxy","text":"<p>Compute nodes don't have outbound network connectivity, add the following to your <code>~/.bash_profile</code> file to access the proxy host. These examples will exclude the use of the proxy while on the UANs, where the proxy will not function.</p> <pre><code># proxy settings\nif [[ ! \"${HOSTNAME}\" =~ aurora-uan ]]; then\n  export HTTP_PROXY=\"http://proxy.alcf.anl.gov:3128\"\n  export HTTPS_PROXY=\"http://proxy.alcf.anl.gov:3128\"\n  export http_proxy=\"http://proxy.alcf.anl.gov:3128\"\n  export https_proxy=\"http://proxy.alcf.anl.gov:3128\"\n  export ftp_proxy=\"http://proxy.alcf.anl.gov:3128\"\n  export no_proxy=\"admin,polaris-adminvm-01,localhost,*.cm.polaris.alcf.anl.gov,polaris-*,*.polaris.alcf.anl.gov,*.alcf.anl.gov\"\nfi\n</code></pre> <p>For <code>ssh</code> connection to <code>github</code>, add the following to your <code>~/.ssh/config</code></p> <pre><code>Match originalhost github.com exec \"hostname -s | (grep -qv aurora-uan)\"\nPort 443\nhostname ssh.github.com\nProxyCommand socat - PROXY:proxy.alcf.anl.gov:%h:%p,proxyport=3128\n</code></pre>"},{"location":"aurora/getting-started-on-aurora/#file-systems-and-daos","title":"File Systems and DAOS","text":""},{"location":"aurora/getting-started-on-aurora/#home-and-project-directories","title":"Home and Project Directories","text":"<p>Home directories on Aurora are <code>/home/username</code>, available on login and compute nodes. This is provided from <code>/lus/gecko/home</code>. The default quota is 50 GB. </p> <p>Lustre project directories are under <code>/lus/flare/projects</code>. Default quota is 1 TB. The project PI should email support@alcf.anl.gov if their project requires additional storage.</p>"},{"location":"aurora/getting-started-on-aurora/#daos","title":"DAOS","text":"<p>The primary storage system on Aurora is not a file system, but rather an object store called the Distributed Asynchronous Object Store. This is a key-array based system embedded directly in the Slingshot fabric, which provides much faster I/O than conventional block-based parallel file systems such as Lustre (even those using non-spinning disk and/or burst buffers). Project PIs will have requested a storage pool on DAOS via INCITE/ALCC/DD allocation proposals.</p> <p>Aurora project PIs should email support@alcf.anl.gov to request DAOS storage with the following information:</p> <ul> <li>Project name </li> <li>Storage capacity (if this is different than in the current project proposal, please give brief justification)</li> <li>Who should be the designated owner of the pool (please provide their ALCF username). The owner can be the project PI or any other team member, but they need to have an active ALCF account.</li> <li>Have you used DAOS in the past? Is yes, please provide details.</li> </ul> <p>See DAOS Overview for more on using DAOS for I/O.</p>"},{"location":"aurora/getting-started-on-aurora/#lustre-file-striping","title":"Lustre File Striping","text":"<p>In addition to the content above, here is a document on Lustre File Striping Basics:</p> <ul> <li>Lustre File Striping Basics</li> </ul>"},{"location":"aurora/getting-started-on-aurora/#aurora-center-of-excellence-coe-office-hours","title":"Aurora Center of Excellence (COE) Office Hours","text":"<p>Aurora users are invited to join our Aurora Office Hours with the Intel Center of Excellence (COE) @ ALCF. See Aurora COE Office Hours for details.</p>"},{"location":"aurora/getting-started-on-aurora/#alcf-users-slack","title":"ALCF Users Slack","text":"<p>The ALCF Users Slack workspace is a platform intended for current, active ALCF users where the user community can interact, collaborate, and help one another. See ALCF Users Slack for details.</p>"},{"location":"aurora/getting-started-on-aurora/#getting-assistance","title":"Getting Assistance","text":"<p>For technical user support issues or questions, please direct all questions, requests, and feedback to ALCF Support. See our Support page for more information.</p>"},{"location":"aurora/known-issues/","title":"Early User Notes and Known Issues","text":"<p>Last Updated: 2025-09-05</p>"},{"location":"aurora/known-issues/#early-user-notes","title":"Early User Notes","text":"<p>Please check back here often for updates (indicated by the \"Last Updated\" timestamp above). As early production users encounter new issues and find solutions or workarounds, we will update these notes. As Aurora matures and becomes more stable over the first year of production, this section should become obsolete.</p>"},{"location":"aurora/known-issues/#outages-and-downtime-expectations","title":"Outages and Downtime \u2013 Expectations","text":"<p>Users should expect weekly preventative maintenance (PM) on the system, although  PMs will be deferred where possible. The stability of the Aurora system has improved significantly in the recent past, but there are still a number of improvement efforts ongoing in cooperation with HPE and Intel, to improve the user experience. Users need to be proactive about verifying correctness, watching for hangs, and otherwise adopting work methods that are mindful of and resilient to instability.</p>"},{"location":"aurora/known-issues/#scheduling","title":"Scheduling","text":"<p>The current queue policy for Aurora is set up based on experiences to date to help maximize productive use of the machine by projects.</p> <ul> <li>The initial goal for teams is to start testing at small scales, ensure correct results (and performance), and ramp up to generating scientific results in production campaigns.</li> <li>Focus initially on making good use of the system with &lt;=2048 nodes per job; the key is to validate code and runtime behavior, then start generating science results.</li> </ul>"},{"location":"aurora/known-issues/#storage","title":"Storage","text":""},{"location":"aurora/known-issues/#flare-lustre-file-system","title":"Flare (Lustre File System)","text":"<p>This is the primary and most stable storage filesystem for now. It is still possible that heavy use may trigger significant lags and performance degradations, and possibly lead to compute nodes crashing. We will continue to monitor filesystem stability as production use ramps up. We encourage teams to start out easy on I/O (both amount and job size), if possible, and report issues.</p>"},{"location":"aurora/known-issues/#daos-object-store","title":"DAOS (Object Store)","text":"<p>DAOS is a scratch file system. Please note that data may be removed or unavailable at any time.</p> <p>The initial configuration of DAOS has a smaller number of nodes, resulting in smaller project allocations. We expect DAOS to grow over the year, and when that happens, changes will be announced/posted in user docs. Please email support@alcf.anl.gov if you are hitting limits and need the allocation size to be increased.</p> <p>The performance of DAOS has been impressive, but we continue to experience crashes with large jobs, including loss of data. Projects may use it, but should not consider it stable or safe for long-term storage.</p>"},{"location":"aurora/known-issues/#grandeagle","title":"Grand/Eagle","text":"<p>These won\u2019t be mounted on Aurora initially, but they might be mounted around May 2025, depending on feasibility. Similarly, Flare will not initially be mounted on Polaris. DTNs and Globus are the best means to transfer data between Polaris and Aurora.</p>"},{"location":"aurora/known-issues/#scaling-out-of-flare-lustre-and-soft-nfs","title":"Scaling out of Flare (Lustre) and <code>/soft</code> (NFS)","text":"<p>Applications which dynamically load libraries out of shared filesystems such as Flare or <code>/soft</code> may experience performance impacts when scaling to large numbers of nodes. These guidelines may mitigate some of these scaling impacts:</p> <ul> <li>Use software in the Aurora PE (<code>/opt/aurora</code>) whenever possible, as this avoids dependence on shared filesystems entirely.</li> <li>Statically link application binaries, as this reduces the number of dynamically loaded files.</li> <li>If loading many small (\u2272100MB) shared libraries or Python modules, use Copper.</li> </ul>"},{"location":"aurora/known-issues/#checkpointing","title":"Checkpointing","text":"<p>Checkpointing is absolutely essential. The mean time between application interrupts caused by system instability may be as short as an hour for larger jobs. The frequency of checkpointing is something that needs to be decided for each individual application based on the scale of runs:</p> <ul> <li>If checkpointing has minimal overhead, consider checkpointing once every 15 minutes.</li> <li>If checkpointing has substantial overhead, then consider checkpointing every 30-60 minutes.</li> <li>It may be the case that the highest throughput initially will be with creating job dependency chains where scripts are able to 1) automatically restart from the latest available checkpoint file and 2) confirm that the prior run generated reasonable/correct results.</li> </ul>"},{"location":"aurora/known-issues/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":"<p>As always, INCITE and ALCC projects should report all issues to the Catalyst point of contact.</p>"},{"location":"aurora/known-issues/#ping-failures","title":"Ping Failures","text":"<p>Network and compute node instabilities may lead to inaccessible compute nodes, which will cause MPI ranks on those nodes to become unreachable. If your job output shows an error message like these:</p> <pre><code>ping failed on x4707c6s4b0n0: Couldn't forward RPC ping(24c93b8c-3434-4fb5-a8f0-53cff4cbbe42) to child x4707c7s6b0n0.hostmgmt2707.cm.aurora.alcf.anl.gov: Resource temporarily unavailable\n</code></pre> <pre><code>ping RPC timeout from x4212c7s0b0n0.hostmgmt2212.cm.aurora.alcf.anl.gov after 120s\n</code></pre> <pre><code>ping failed on x4304c1s6b0n0: No reply from x4307c2s6b0n0.hostmgmt2307.cm.aurora.alcf.anl.gov after 87s\n</code></pre> <p>then most likely your application will crash or hang. If you see these, the best action is to kill the job and re-run it (from the last checkpoint, if there has been one). Potential issues can be discovered when the non-responsive node gets brought back online. Users may query PBS for more info. <pre><code>$ pbsnodes x4307c2s6b0n0 |grep comment\n     comment = StabilityDB 2025-02-24T04:38:14: hbm_controller_errors\n</code></pre></p> <p>Email support@alcf.anl.gov to open a ticket if your application experiences ping failures, especially if these failures are frequent and/or involve the same problematic nodes. ALCF Operations may take such nodes offline.</p>"},{"location":"aurora/known-issues/#hangs","title":"Hangs","text":"<p>There are multiple failure modes that can lead to jobs hanging. For known hardware or low-level software issues such as ping failures as discussed above, just restart the job.</p> <p>To avoid a hung job running out all the requested wallclock time on all its nodes, we suggest devising ways to monitor job progress. For example, if your application regularly writes small output to a logfile, then you could launch a \u201cwatcher\u201d script that looks for that expected output and collects a stack trace and kills the job if it's been too long since progress was made. Please engage your Catalyst POC if you are interested in evaluating this for your application.</p>"},{"location":"aurora/known-issues/#gpu-segfaults-aka-page-faults","title":"GPU Segfaults (a.k.a. \"Page Faults\")","text":"<p>Memory errors on the GPUs are caught when illegal accesses exceed a page boundary. When you see an error message indicating <code>Unexpected page fault from GPU at &lt;address&gt;</code></p> <p>The best tools for debugging these are <code>gdb-oneapi</code> and <code>DDT</code>, both of which allow debugging into GPU kernel threads and looking at GPU data structures. You may also dump and step through the PVC assembly code using the debuggers if helpful. It is possible that there remain bugs in the IGC compiler that produces invalid assembly code, though as always the most likely cause of segfaults is memory errors in application code. To use the debuggers effectively in GPU kernels, you should compile and link your application with <code>-g -O0</code>. Keep in mind that the IGC compilation of GPU kernels takes place during the link phase if you're using AoT compilation.</p>"},{"location":"aurora/known-issues/#known-issues","title":"Known Issues","text":"<p>This is a collection of known issues that have been encountered during Aurora's early user phase. Documentation will be updated as issues are resolved. Users are encouraged to email support@alcf.anl.gov to report issues.</p> <p>A known issues page can be found in the CELS Wiki space used for NDA content. Note that this page requires a JLSE Aurora early hardware/softare resource account for access.</p>"},{"location":"aurora/known-issues/#runtime-errors","title":"Runtime Errors","text":""},{"location":"aurora/known-issues/#1-cassini-event-queue-overflow-detected","title":"1. <code>Cassini Event Queue overflow detected</code>","text":"<p><code>Cassini Event Queue overflow detected</code> errors may occur for certain MPI communications and may happen for a variety of reasons - software and hardware, job placement, job routing, and the state of the machine. Simply speaking, it means one of the network interfaces is getting messages too fast and cannot keep up with processing them.</p> <pre><code>libfabric:16642:1701636928::cxi:core:cxip_cq_eq_progress():531&lt;warn&gt; x4204c1s3b0n0: Cassini Event Queue overflow detected.\n</code></pre> <p>As a workaround, the following environment variables can be set to try alleviating the problem.</p> <pre><code>export FI_CXI_DEFAULT_CQ_SIZE=131072\nexport FI_CXI_OFLOW_BUF_SIZE=8388608\nexport FI_CXI_CQ_FILL_PERCENT=20\n</code></pre> <p>The value of <code>FI_CXI_DEFAULT_CQ_SIZE</code> can be set to something larger if issues persist. This is directly impacted by the number of unexpected messages sent and so may need to be increased as the scale of the job increases.</p> <p>It may be useful to use other libfabric environment settings. In particular, the setting below may be useful to try. These are what Cray MPI sets by default Cray MPI libfabric Settings.</p>"},{"location":"aurora/known-issues/#2-failed-to-convert-gotpcrel-relocation","title":"2. <code>failed to convert GOTPCREL relocation</code>","text":"<p>If you see</p> <pre><code>_libm_template.c:(.text+0x7): failed to convert GOTPCREL relocation against '__libm_acos_chosen_core_func_x'; relink with --no-relax\n</code></pre> <p>try linking with <code>-flink-huge-device-code</code></p>"},{"location":"aurora/known-issues/#3-sycl-device-free-memory-query-error","title":"3. SYCL Device Free Memory Query Error","text":"<p>Note that if you are querying the free memory on a device with the Intel SYCL extension <code>get_info&lt;sycl::ext::intel::info::device::free_memory&gt;();</code>, you will need to set <code>export ZES_ENABLE_SYSMAN=1</code>. Otherwise, you may see an error like:</p> <p><pre><code>x1921c1s4b0n0.hostmgmt2000.cm.americas.sgi.com 0: The device does not have the ext_intel_free_memory aspect -33 (PI_ERROR_INVALID_DEVICE)\nx1921c1s4b0n0.hostmgmt2000.cm.americas.sgi.com 0: terminate called after throwing an instance of 'sycl::_V1::invalid_object_error'\n  what():  The device does not have the ext_intel_free_memory aspect -33 (PI_ERROR_INVALID_DEVICE)\n</code></pre> Applications are recommended to improve the error handling by checking <code>aspect::ext_intel_free_memory</code> SYCL device property before making a memory query.</p>"},{"location":"aurora/known-issues/#4-no-vnis-available-in-internal-allocator","title":"4. <code>No VNIs available in internal allocator.</code>","text":"<p>If you see an error like <code>start failed on x4102c5s2b0n0: No VNIs available in internal allocator</code>, pass <code>--no-vni</code> to <code>mpiexec</code></p>"},{"location":"aurora/known-issues/#5-pmix-error-pmix_err_not_found-and-pmix-error-pmix_error","title":"5. <code>PMIX ERROR: PMIX_ERR_NOT_FOUND</code> and <code>PMIX ERROR: PMIX_ERROR</code>","text":"<p>When running on a single node, you may observe this error message:</p> <pre><code>PMIX ERROR: PMIX_ERR_NOT_FOUND in file dstore_base.c at line 1567 \nPMIX ERROR: PMIX_ERROR in file dstore_base.c at line 2334\n</code></pre> <p>These errors can be safely ignored.</p>"},{"location":"aurora/known-issues/#6-incorrect-results-in-receive-buffer-in-gpu-memory","title":"6. Incorrect results in receive buffer in GPU memory","text":"<p>In the default MPICH module on Aurora, it is possible to get incorrect results in GPU buffers passed through MPI calls. More detail are: Issue#7302. This will be fixed in the next MPICH module upgrade. For now, be careful of using GPU buffers in MPI communications as you may get incorrect results. </p>"},{"location":"aurora/known-issues/#7-file-too-large-for-clang-to-processs","title":"7. File too large for Clang to processs","text":"<p>If you see a compile error similar to: <pre><code>error: file '/var/tmp/icpx-85f5cf3735/wrapper-a0fbdc.bc' is too large for Clang to process\n1 error generated.\n</code></pre> when you are compiling with <code>-g</code>, you can decrease the size of the files by compiling with <code>-fno-system-debug -g</code>. See Intel documentation for more details.</p>"},{"location":"aurora/known-issues/#8-set-tmpdir-to-avoid-af_unix-path-too-long-error","title":"8. Set <code>TMPDIR</code> to avoid <code>AF_UNIX path too long</code> error","text":"<p>Software that relies on the setting of <code>TMPDIR</code> to create socket files may encouter the linux error <code>AF_UNIX path too long</code> when running in processes launched with <code>mpiexec</code> on a single node.  This issue has arisen in software using the <code>python</code> <code>multiprocessing</code> library for this purpose, including some use cases of <code>pytorch</code> and <code>parsl</code>.</p> <p>The solution for this error is to manually set <code>TMPDIR</code> before launching the application, e.g.</p> <pre><code>export TMPDIR=/tmp\n</code></pre> <p>Alternatively, it can be set with the <code>mpiexec</code> command, e.g.</p> <pre><code>mpiexec --env TMPDIR=/tmp -n 1 --ppn 1 ...\n</code></pre>"},{"location":"aurora/known-issues/#submitting-jobs","title":"Submitting Jobs","text":"<p>Jobs may fail to successfully start at times (particularly at higher node counts). If no error message is apparent, then one thing to check is the <code>comment</code> field in the full job information for the job using the command <code>qstat -xfw &lt;JOBID&gt; | grep comment</code>. Some example comments follow.</p> <pre><code>comment = Job held by &lt;USER&gt; on Tue Feb 6 05:20:00 2024 and terminated\n</code></pre> <p>The user has placed the job on hold; the user can <code>qrls</code> the job when ready for it to be queued again.</p> <pre><code>comment = Not Running: Queue not started. and terminated\n</code></pre> <p>The user has submitted to a queue that is not currently running; the user should <code>qmove</code> the job to an appropriate queue.</p> <pre><code>comment = job held, too many failed attempts to run\n</code></pre> <p>The job tried and failed to start. In this scenario, the user should find that their job was placed on hold. This does not indicate a problem with the user's job script, but indicates PBS made several attempts to find a set of nodes to run the job and was not able to. Users can <code>qdel</code> the job and resubmit or <code>qrls</code> the job to try running it again.</p> <pre><code>comment = Not Running: Node is in an ineligible state: down and terminated\n</code></pre> <p>There are an insufficient number of nodes online and free for the job to start.</p> <p>In the event of a node going down during a job, users may encounter messages such as <code>ping failed on x4616c0s4b0n0: Application 047a3c9f-fb41-4595-a2ad-4a4d0ec1b6c1 not found</code>. The node will likely have started a reboot and won't be included in jobs again until checks pass.</p> <p>Use of the <code>qsub -V</code> flag (note: upper-case) is discouraged, as it can lead to startup failures. The following message (found via <code>pbsnodes -l</code>):</p> <pre><code>failed to acquire job resources; job startup aborted (jobid: &lt;YOUR JOBID&gt;)\n</code></pre> <p>indicates such a failure. It is recommended to instead use <code>-v</code> (note: lower-case) and explicitly export any environment variables that your job may require.</p> <p>To increase the chances that a large job does not terminate due to a node failure, you may choose to interactively route your MPI job around nodes that fail during your run. See this page on Working Around Node Failures for more information.</p>"},{"location":"aurora/known-issues/#other-issues","title":"Other Issues","text":"<ul> <li>A large number of Machine Check Events from the PVC, which causes nodes to panic and reboot.</li> <li>HBM mode is not automatically validated. Jobs requiring flat memory mode should test by looking at <code>numactl -H</code> for 4 NUMA memory nodes instead of 16 on the nodes.</li> <li>Application failures at the single-node level are tracked in the JLSE Wiki/Confluence page</li> </ul>"},{"location":"aurora/known-issues/#aurora-bug-tracking-repository-and-table","title":"Aurora Bug Tracking repository and table","text":"<p>The repository argonne-lcf/AuroraBugTracking is a public bug tracking system for known issues (and recently resolved bugs) that affect production science on ALCF Aurora. To report an issue, please reach out to ALCF Support.</p> <p>For convenience, nightly (sortable) copies of the summary tables are included here. For the latest versions, see <code>bugs.md</code></p>"},{"location":"aurora/known-issues/#wider-view-of-tables","title":"Wider View of Tables","text":""},{"location":"aurora/known-issues/#open-issues","title":"Open Issues","text":"Internal ID Description Vendor ID Reproducer Path PoC Priority? ETA Date Opened Last Updated 92 SYCL device info free_memory wrong on 2-stack PVC1550 GPU No response source/reproducers/dpcpp/sycl_free_flat Jakub H No response 2025-10-31 2025-10-31 91 sycl failed malloc_device on GPU takes 20 seconds No response source/reproducers/dpcpp/slow_alloc/ Jakub H No response 2025-10-31 2025-10-31 90 Device Sanitizer + LIBOMPTARGET_DEBUG=1 issues for the GAMESS RI-MP2 mini-app CMPLRLLVM-71455 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/tools/sanitizer_rimp2_test Brian No response 2025-10-31 2025-10-31 89 Device Sanitizer breaks with MKL DGEMM call in GAMESS RI-MP2 mini-app MKLD-19334 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/tools/sanitizer_rimp2_test Brian, JaeHyuk No response 2025-10-31 2025-10-31 88 RPATH issue when mixing and matching SDK and spack packages built by another SDK No response No need. reprdducer attached in this ticket Ye Luo No response 2025-10-30 2025-10-30 87 QUDA compile fail cmplrllvm-70981 source/reproducers/openmp/quda_crash Xiayong Jin / Brian W In progress 2025-10-28 2025-10-29 86 omp_alloc should support pinned memory, or implement proper fallback behavior CMPLRLIBS-35442 /home/kweide/projects/OpenMP_VV/tests/5.1/allocate/test_omp_alloctrait_pinned.c and source/reproducers/openmp/omp_alloctrait_pinned in the test set Klaus Weide In progress 2025-10-28 2025-10-31 85 zeEventQueryKernelTimestampsExt is broken with IMM command lists GSD-11124 source/reproducers/l0/zeEventQueryKernelTimestampsExt_clock Thomas/John Mellor-Crummey No response 2025-10-27 2025-10-29 84 Device Sanitizer is not functional with OpenMP C/Fortran codes /lus/flare/projects/Aurora_deployment/jkwack/JK_AT_Tools/sanitizer and source/reproducers/tools/sanitizer and source/reproducers/tools/sanitizer_rimp2_test  in the test set JaeHyuk Kwack \ud83d\udea8 2025.3 2025-10-22 2025-10-31 83 With ifx, <code>openmp_version</code> is missing from omp_lib CMPLRLIBS-35365 /home/kweide/tests/test_openmp_version.f90  and source/reproducers/openmp/omp_version in the test set Klaus Weide 2025.3 2025-10-20 2025-10-24 82 Symbol missing issue with 1.3 version onwards in SLES and Intel Datacenter Max GPU on Aurora https://github.com/intel/xpumanager/issues/113 https://github.com/intel/xpumanager/issues/113 Servesh In progress. ETA drop after next (github fix in a few weeks, LTS end of year) 2025-10-16 2025-10-29 81 IGC_StackOverflowDetection not working GSD-11763 source/reproducers/openmp/stack_overflow_not_working Brian In progress 2025-10-15 2025-10-29 80 VTune fails with \"Assertion failed: tool_gtpin_support:126: (buffer) \" VASP-32612, GTPIN-1169 /lus/flare/projects/Aurora_deployment/jkwack/JK_AT_Tools/Apps/GAMESS_RI-MP2_MiniApp  source/reproducers/tools/vtune_gtpin_fail in the test set JaeHyuk Kwack \ud83d\udea8 2025.3 2025-10-10 2025-10-30 79 Advisor fail with \"advisor: Warning: The application returned a non-zero exit value.\" ADV-10687 source/reproducers/tools/advisor_gflop JaeHyuk Kwack Fixed with <code>advisor --version == 616302</code>, which should be in 2025.3 2025-10-08 2025-10-30 78 ExchCXX fails to compile with <code>is too large for Clang to process</code> CMPLRLLVM-70962 source/reproducers/dpcpp/jit_too_large_for_Clang Abhi \ud83d\udea8 No response 2025-10-06 2025-10-29 77 [SYCL] Function pointers compilation issue CMPLRLLVM-16317 Reproducer below and <code>source/reproducers/dpcpp/func_pointers</code> Abhi, Patrick Steinbrecher \ud83d\udea8 Under discussion 2025-10-06 2025-10-15 76 Segfaults in MPICH routines in next-eval No response for XGC: /lus/flare/projects/catalyst/world_shared/zippy/xgc Tim Williams \ud83d\udea8 No response 2025-10-01 2025-10-01 74 ZES_ENABLE_SYSMAN should default to 1 in the oneapi module No response see Details Tim Williams No response 2025-09-29 2025-10-15 73 \"error: undefined reference to `old_llvm.umul.with.overflow.i64'\" in newer kokkos CMPLRLLVM-70603 source/reproducers/dpcpp/kokkos_mdspan_umul Daniel Arndt Being worked internally 2025-09-17 2025-10-14 71 RPC launch error tracking 2025-09-15 2025-09-23 70 PALS gpu-bind, composite, envall lead to \"launch failed\" DCE Case 5392152905 applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/mpi/envall Thomas Applencourt patch to test out and that should already be landed for a future release 2025-09-10 2025-10-02 68 warpx segfaults/hangs with OpenPMD enabled No response /lus/flare/projects/catalyst/world_shared/zippy/reproducers/issue52/ Tim Williams No response 2025-08-23 2025-08-23 67 warpx Debug build crashes oneAPI compiler CMPLRLLVM-24314 /lus/flare/projects/catalyst/world_shared/zippy/reproducers/issue52/ Tim Williams No response 2025-08-21 2025-10-29 66 Compiling with \"-g\" leads to a much larger binary than without CMPLRLLVM-69909, CMPLRLLVM-24314 lammps + -g Brian Holland No response 2025-08-20 2025-10-01 65 Clarification requested about ZE_DEVICE_PROPERTY_FLAG_ONDEMANDPAGING on PVC GSD-11510 source/reproducers/l0/ondemand_paging/ Colleen implemented, ETA end of year. 2025-08-20 2025-10-29 64 E3SM fortran compile ICE CMPLRLLVM-69862 source/reproducers/ifx/e3sm_homme_ICE_error Abhi 2025.3.0 2025-08-18 2025-10-09 63 Kokkos kernels fails to build with kokkos built with openmp enabled CMPLRLLVM-69908 source/applications/kokkos-kernels Sean Koyama / Colleen Bertoni gone starting with 4.19 (fixed in 2025.3 branch) 2025-08-18 2025-09-16 62 -ftarget-register-alloc-mode=pvc:large and \"-device 12.60.7\" for AOT GSD-11490 source/reproducers/general/ftarget-register-alloc-mode_flag Steve Rangel Fixed internally, ETA end of year 2025-08-14 2025-10-29 61 Failing unit tests on PVCs with 2025.2 oneAPI SDK -- is it expected? https://github.com/uxlfoundation/oneMath/issues/703, CMPLRLLVM-69572, ONSAM-1930, GSD-11482 https://github.com/uxlfoundation/oneMath/issues/703 todo: need to check with 2025.3 Colleen Bertoni CMPLRLLVM-69572: fixed, other implemented. ETA Oct if cherry-picked 2025-07-30 2025-10-29 60 ext_oneapi_memcpy2d is significantly slower with implicit scaling than explicit and on PVC vs A100 Really depends on GSD-11132 source/reproducers/dpcpp/ext_oneapi_memcpy2d_perf Natalie Beams No response 2025-07-29 2025-10-01 58 kokkos inclusive and exclusive scan giving incorrect answers for 1146.10 CMPLRLLVM-69285, GSD-11736 source/reproducers/dpcpp/kokkos_optimization_scan Daniel Arndt \ud83d\udea8 Fixed internally, LTS2, 1-2 months (early Nov.) (1146.43) 2025-07-23 2025-10-29 57 GPU segfault in gtensor_bench with 2025.2 MKLD-18276, CMPLRLIBS-35326, CMPLRLLVM-68696 source/applications/gtensor_bench Colleen Bertoni 2025.3 2025-07-22 2025-08-11 56 RSBench-SYCL incorrect answers with 1146.10 GSD-11247 source/applications/RSBench/ John Tramm, Colleen Bertoni 1146.31 2025-07-22 2025-09-17 55 Linking in LZ causes changes in signal handling cmplrlibs-35385, GSD-11413 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/l0/signal_handler/ Thomas Applencourt, Colleen Bertoni No response 2025-07-22 2025-07-25 54 oneCCL zeMemGetAddressRange error with alltoallv and zero-sized buffers oneCCL GitHub Issue: https://github.com/uxlfoundation/oneCCL/issues/174, MLSL-3764 See instructions on oneCCL GitHub Issue: https://github.com/uxlfoundation/oneCCL/issues/174 Riccardo Balin \ud83d\udea8 oneCCL 2021.17, oneAPI 2025.3 2025-07-18 2025-08-26 52 compiler segfaults linking warpx binary GSD-11357, GSD-11855 /lus/flare/projects/catalyst/world_shared/zippy/reproducers/issue52/warpx Tim Williams \ud83d\udea8 2025.2 + 1146.10 2025-07-07 2025-10-15 47 Non standard MPI knobs suggested for performance ANL-291 N/A Servesh M No response 2025-06-23 2025-06-27 45 DDT issues since Aurora upgrade No response /lus/flare/projects/catalyst/world_shared/zippy/ddt Tim Williams Linaro Forge 2025.0.1 has the workaround. GDB 2025.3 the root cause will be gone. 2025-06-12 2025-08-05 43 CMake can't find <code>MKL::MKL_SYCL</code> with MPI wrapper compilers No response https://github.com/thilinarmtb/onemkl_cmake_mpi_bug Thilina Ratnayaka, Colleen Bertoni improvements will be part of the next oneMKL release, 2025.3. 2025-06-11 2025-06-25 39 Feature request for Aurora runtime to include debugging symbols ANL-286, HPCS-15374, GSD-11427 feature request Ye Luo No response 2025-05-29 2025-09-17 38 One application in GRID consistently hangs GSD-11441 /lus/flare/projects/Aurora_deployment/xyjin/W/test_grid_g5r5_paboyle Xiao-Yong Jin \ud83d\udea8 Fixed Internally, likely Nov. 1146.43 2025-05-27 2025-10-15 36 (Occasional Interruptible) hangs in applications Possibly related to ANL-215 /lus/flare/projects/Aurora_deployment/xyjin/W/test_example_detar.skel Xiao-Yong Jin \ud83d\udea8 No response 2025-05-15 2025-07-09 33 Crash when calling too many MPI_Probe https://github.com/pmodels/mpich/issues/7427 https://github.com/pmodels/mpich/issues/7427 David--Cl\u00e9ris Timoth\u00e9e No response 2025-05-15 2025-05-15 32 PETSc segfaults in sparse matrix calls IGDB-6516, GSD-10450 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/mkl/csr_gemv_usm/ Junchao Zhang \ud83d\udea8 2025.3 for part malloc_shared in MKL 2025-05-15 2025-06-25 31 GAMESS segfaults with -O0 GSD-10393, CMPLRLIBS-35345,GSD-11035 <code>/lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/openmp/gamess_O0_page_fault</code> Colleen Bertoni \ud83d\udea8 1146.31 (Targeted for LTS2 (1146.12+), contained with the IGC 2.16 series / WW34 (2-3 weeks)) 2025-05-14 2025-09-17 30 Copy 2D/3D are broken (zeCommandListAppendMemoryCopyRegion) NEO-14954, GSD-11132 https://github.com/rpereira-dev/ze-zoo Romain PEREIRA and Thomas APPLENCOURT \ud83d\udea8 No response 2025-05-10 2025-09-17 29 Significant slowdown with LAMMPS in first run, subsequent runs much faster No response /flare/catalyst/proj_shared/knight/projects/ExtremeCarbon/snap-carbon-scaling/1B/ Christopher Knight No response 2025-05-09 2025-08-20 18 Ping failures and hangs with production runs using GPT/GRID ANL-251, RITM0404147, RITM0404148, RITM0405730, GSD-11441 /lus/flare/projects/LatticeFlavor/lehner Xiao-Yong Jin \ud83d\udea8 No response 2025-04-04 2025-08-18 17 hang with MPI pipelining https://github.com/pmodels/mpich/issues/7373 Build and run commands are in the MPICH issue. James Osborn Merged in https://github.com/pmodels/mpich/pull/7622 2025-04-03 2025-10-14 13 XGC hangs at scale CMPLRTST-27836 xgc-es-cpp-gpu app, ES_ITER test case Tim Williams \ud83d\udea8 No response 2025-04-03 2025-09-17 12 CXI alloc failed on cxi1: request exceeds ACs limits No response None Not Thomas No response 2025-04-01 2025-08-04"},{"location":"aurora/known-issues/#closed-issues","title":"Closed Issues","text":"Internal ID Description Vendor ID Reproducer Path PoC Priority? Date Opened Closed Date 75 \"MPL_gpu_query_is_same_dev(int, int): Assertion `global_dev1 &gt;= 0 &amp;&amp; global_dev1 &lt; known_ze_device_count' failed.\" with mpich.dbg No response https://github.com/pmodels/mpich/issues/7602 Tim, JaeHyuk, Colleen 2025-09-30 2025-10-13 72 MPI_aborts in many applications in next-eval at larger scales No response N/A Brian Holland / Tim Williams 2025-09-16 2025-09-30 59 [ISHMEM] Unit test fails with ishmem 1.4.0 https://github.com/oneapi-src/ishmem/issues/10 https://github.com/oneapi-src/ishmem/issues/10 and source/applications/ishmem_sos Abhi 2025-07-25 2025-07-31 53 IFX Compiler reads and stores floating point values from a text file at single-precision No response /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/ifx/fp_precision Victor Anisimov \ud83d\udea8 2025-07-09 2025-07-10 51 [SYCL] Bug from SYCL peer_access No response /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/dpcpp/sycl_peer_access Abhi 2025-07-02 2025-10-13 50 OpenMP Thread binding No response See bellow Romain PEREIRA 2025-07-02 2025-07-02 49 [E3SM] MPICH bug related to collectives tunning https://github.com/pmodels/mpich/issues/7456 https://github.com/pmodels/mpich/issues/7456 Abhi \ud83d\udea8 2025-06-27 2025-10-09 48 Zombie Processes GSD-11266 none yet Servesh M \ud83d\udea8 2025-06-25 2025-10-29 44 QMCPACK segfault in libomp No response Not yet created Ye Luo \ud83d\udea8 2025-06-12 2025-07-23 42 Linking fails with old build environment No response /lus/flare/projects/PHASTA_aesp_CNDA/jrwrigh/petsc_build_test Kris Rowe 2025-06-06 2025-06-10 41 torch.compile segfaults for &gt;2 tiles MLSL-3728 <code>/flare/Aurora_deployment/vsastry/torch_compile</code> Varuni Sastry 2025-06-06 2025-07-24 40 Need SYSMAN support for all modes in recent releases HPCS-15366, related: GSD-11104 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/l0/leak_zesMemoryGetState Thomas Applencourt \ud83d\udea8 2025-05-30 2025-06-17 37 xpu-smi reports \"N/A\" for GPU Utilization RITM0428460, ANL-279, GSD-11252 any run of xpu-smi Kyle Felker / Colleen Bertoni 2025-05-22 2025-10-29 35 Avoid outputs exceeding few KBs to stdout/stderr from MPI ranks RITM0425437 First issue Large MPI writes to stdout Servesh Muralidharan 2025-05-15 2025-07-23 34 Runtime Error: pytorch DDP with CCL_BCAST=&lt;\"double_tree, direct, naive, maybe others?\"&gt; MLSL-3729 In issue Nathan Nichols 2025-05-15 2025-10-13 28 CMake failures with SYCL No response /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/dpcpp/ Abhishek Bagusetty 2025-05-09 2025-05-09 27 Build failures on PVC with Cutlass GSD-11099, https://github.com/codeplaysoftware/cutlass-sycl/issues/329 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/dpcpp/cutlass-sycl Abhi \ud83d\udea8 2025-05-07 2025-10-13 26 L0 memcpy bug GSD-11142, NEO-14641 I was doing the same run as QMCPACK SOW runs in the reframe Ye Luo \ud83d\udea8 2025-05-06 2025-10-13 25 Compile fail in Lattice App Brian reproduced and confirms fixed in 2025.1 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/dpcpp/bug_cgpt_icpx Xiao-Yong Jin \ud83d\udea8 2025-05-01 2025-10-13 24 Noticeably more \"ping failed\" than before the 2025.1 SDK + 1099.12 UMD/KMD upgrade JIRA is: \u00a0HPCS-15331 N/A Xiao-Yong Jin Colleen Bertoni 2025-05-01 2025-05-16 23 Apps stop running after Apr 29 upgrade due to libstdc++ dependency No response See details Ye Luo 2025-04-30 2025-05-06 22 SYCL In-order queue broken NEO-14641 /lus/flare/projects/Aurora_deployment/applications.hpc.argonne-national-lab.aurora.anl-testing/source/reproducers/dpcpp/in-order Thomas Applencourt \ud83d\udea8 2025-04-23 2025-10-13 21 Error during write with Quantum ESPRESSO No response see .zip file attached below, also /lus/flare/projects/matml_aesp_CNDA/dir_io_QE_crash Filippo Simini \ud83d\udea8 2025-04-17 2025-04-18 20 Issue with gpu-bind for mpiexec under ZE_FLAT_DEVICE_HIERARCHY=FLAT mode ANL-283/HPE Support Case 5390607860 See below Abhishek, Nathan, Khalid 2025-04-16 2025-10-01 19 Severe CPU memory growth in MPICH No response /flare/catalyst/world_shared/zippy/reproducers/issue19 Tim Williams 2025-04-04 2025-07-31 16 Catastrophic memory error in context lmp_aurora_kokkos No response public LAMMPS Chris Knight 2025-04-03 2025-07-23 9 Multithreaded data-transfer can cause page-fault N/A Full QMCPACK Ye Luo 2025-04-01 2025-05-08 8 Lots of H2D copies produce CPU I9 error and incorrect value N/A Full QMCPACK Ye Luo \ud83d\udea8 2025-04-01 2025-05-28 7 MPI_Bcast gets faster when turning off XPMEM pmodels/mpich#7334 see Issue on MPICH GitHub repo Ye Luo 2025-04-01 2025-04-24 6 MPICH memory allocation slows down at scale pmodels/mpich#7333 see MPICH issue Ye Luo \ud83d\udea8 2025-04-01 2025-04-24 4 Incorrect results in receive buffer in GPU memory MPICH 7312 grid application (lattice QCD) Patrick Steinbrecher, Tim Williams \ud83d\udea8 2025-03-25 2025-04-24 3 Linker error found by XGC CMPLRLLVM-66496 /home/zippy/smalltests/aurora/xgc42/fails Tim Williams 2025-03-19 2025-03-28"},{"location":"aurora/running-jobs-aurora/","title":"Running Jobs on Aurora","text":""},{"location":"aurora/running-jobs-aurora/#queues","title":"Queues","text":"<p>There are four production queues you can target in your qsub (<code>-q &lt;queue name&gt;</code>):</p> Queue Name Node Min Node Max Time Min Time Max Notes debug 1 2 5 min 1 hr 64 nodes (non-exclusive);   Max 1 job running/accruing/queued per-user debug-scaling 2 31 5 min 1 hr Max 1 job running/accruing/queued per-user prod 1 10,624<sup>1</sup> 5 min 24 hrs Routing queue for tiny, small, medium, and large queues;  See table below for min/max limits prod-large 1920 10,624<sup>1</sup> 5 min 24 hrs Routing queue for large jobs; visualization 1 32 5 min 8 hrs By request only; non-exclusive nodes <p><code>prod</code> and <code>prod-large</code> are routing queues and routes your job to one of the following eight execution queues:</p> Queue Name Node Min Node Max Time Min Time Max Notes tiny 1 512 5 min 6 hrs small 513 1024 5 min 12 hrs medium 1025 1919 5 min 18 hrs large 1920 10,624<sup>1</sup> 5 min 24 hrs backfill-tiny 1 512 5 min 6 hrs Low priority, negative project balance backfill-small 513 1024 5 min 12 hrs Low priority, negative project balance backfill-medium 1025 1919 5 min 18 hrs Low priority, negative project balance backfill-large 1920 10,624<sup>1</sup> 5 min 24 hrs Low priority, negative project balance; theoretical max; stable max nodecount may vary; see pbsnodes and pbs-tui for current nodecount. <p>Warning</p> <p>You cannot submit to these queues directly; you can only submit to the routing queue <code>prod</code> or <code>prod-large</code>.</p> <p>Note</p> <p>All of these queues have a limit of ten (10) jobs running/accruing per-project.   All of these queues have a limit of one hundred (100) jobs queued (not accruing score) per-project.</p>"},{"location":"aurora/running-jobs-aurora/#submitting-a-job","title":"Submitting a job","text":"<p>Note: Jobs should be submitted only from your allocated project directory and not from your home directory or from <code>/soft/modulefiles</code>. Submitting an interactive job from <code>/soft/modulefiles</code> will result in your job ending abruptly.</p> <p>For example, a one-node interactive job requiring access to the <code>/flare</code> filesystem can be requested for 30 minutes with the following command, where <code>&lt;your_ProjectName&gt;</code> is replaced with an appropriate project name.</p> <pre><code>qsub -l select=1 -l walltime=30:00 -l filesystems=flare -A &lt;your_ProjectName&gt; -q debug -I\n</code></pre> <p>For DAOS access, users will need to include either <code>daos_user</code> or <code>daos_perf</code> (only for select teams approved by ALCF) as a filesystem option. More information can be found on the DAOS page.</p> <p>Tip</p> <p>To view the available filesystem options, execute the <code>qstat -Bf</code> command and view the <code>resources_available.valid_filesystems</code> entry.</p> <p>Recommended PBSPro options follow.</p> <pre><code>#!/bin/bash -l\n#PBS -A &lt;your_ProjectName&gt;\n#PBS -N &lt;your_JobName&gt;\n#PBS -l walltime=&lt;requested_walltime_value&gt;\n#PBS -l filesystems=&lt;requested_fs1:requested_fs2&gt;\n#PBS -k doe\n#PBS -l place=scatter\n#PBS -q &lt;requested_Queue&gt;\n</code></pre> <p>More information on the PBS options above, as well as other PBS options, can be found here.</p>"},{"location":"aurora/running-jobs-aurora/#working-around-node-failures","title":"Working around node failures","text":"<p>As Aurora is in early production stage, node failures are a fact of life. If you would like to increase the chances that a large job does not terminate due to a node failure, you may choose to interactively route your MPI job around nodes that fail during your run. To do this, you must run interactively and use must manually adjust your run on the fly to remove nodes that have been marked as failed.</p> <p>If you determine a node is bad, please send an email to support@alcf.anl.gov with the node name, reason why you believe it is bad, and a reproducer if one is available.</p>"},{"location":"aurora/running-jobs-aurora/#removing-known-bad-nodes","title":"Removing \"known\" bad nodes","text":"<p>If you're encountering the same problematic node(s) repeatedly in your allocations, you can add the following lines in your noninteractive PBS script to exclude them from the MPICH execution command:</p> <pre><code>cat $PBS_NODEFILE &gt; local.hostfile\n# edit local.hostfile with sed/awk/etc. to remove problem node IDs\nmpiexec --hostfile local.hostfile &lt;other mpiexec arguments&gt;\n</code></pre>"},{"location":"aurora/running-jobs-aurora/#using-tolerate_node_failuresall","title":"Using <code>tolerate_node_failures=all</code>","text":"<p>We recommend against using <code>-W tolerate_node_failures=all</code> in your qsub command, but we acknowledge its use can be helpful. However, you MUST MANUALLY VERIFY your job and remove faulted nodes from your mpiexec command YOURSELF!</p> <ol> <li>Start your interactive job</li> <li>When the job transitions to Running state, run <code>pbsnodes -l | grep &lt;jobid&gt;</code></li> <li> <p>Manually REMOVE all nodes identified in that output from inclusion in your mpiexec</p> <pre><code>cat $PBS_NODEFILE &gt; local.hostfile\n# edit local.hostfile to remove problem nodes\nmpiexec --hostfile local.hostfile &lt;other mpiexec arguments&gt;\n</code></pre> </li> <li> <p>Continue to execute</p> </li> <li>If other nodes go down during your job, it will not be killed, and you can further exclude those nodes from your mpiexec as needed</li> </ol> <p>It is important to note that all nodes marked as faulty by PBS will not be used in subsequent jobs. This mechanism only provides you with a means to execute additional mpiexec commands under the same interactive job after manually removing nodes identified as faulty. Once your PBS job has exited, those faulty nodes will remain offline until further intervention by Aurora staff.</p> <p>See below section for more details on node Placement.</p>"},{"location":"aurora/running-jobs-aurora/#aurora-mpich","title":"Aurora MPICH","text":"<p>The standard version of the MPI (Message Passing Interface) library on Aurora is Aurora MPICH. This resulted from a collaboration between Intel and the Argonne MPICH developer team. The <code>mpiexec</code> and <code>mpirun</code> commands used to launch multi-rank jobs come from the Cray PALS (Parallel Application Launch Service) system.</p> <p>There are many, many configuration and tuning parameters for Aurora MPICH. Simple ASCII text documentation of the environment variables usable to control behavior is in:</p> <pre><code>$MPI_ROOT/share/doc/mpich/README.envvar\n</code></pre> <p>This includes, for example, settings to select different optional sub-algorithms used in MPI collective operations.</p>"},{"location":"aurora/running-jobs-aurora/#running-mpiopenmpsycl-applications","title":"Running MPI+OpenMP+SYCL Applications","text":"<p>A simple MPI+OpenMP+SYCL code snippet (hello_affinity_aurora.out) will be used to clarify the mappings between MPI ranks, CPU logical processors, OpenMP threads, GPU visiblity and GPU-affinity mappings.</p> <pre><code>#include &lt;stdlib.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;iostream&gt;\n#include &lt;iomanip&gt;\n#include &lt;string.h&gt;\n#include &lt;mpi.h&gt;\n#include &lt;sched.h&gt;\n#include &lt;sycl/sycl.hpp&gt;\n#include &lt;sys/syscall.h&gt;\n#include &lt;omp.h&gt;\n#include &lt;sched.h&gt;\n#include &lt;unistd.h&gt;\n\nstd::string get_cpu_affinity_range() {\n  cpu_set_t mask;\n  CPU_ZERO(&amp;mask);\n  pid_t pid = syscall(SYS_gettid); // You could also use 0 for current process\n  if (sched_getaffinity(pid, sizeof(mask), &amp;mask) == -1) {\n    perror(\"sched_getaffinity\");\n    return \"\";\n  }\n\n  std::string result;\n  int i = 0;\n  while (i &lt; CPU_SETSIZE) {\n    if (CPU_ISSET(i, &amp;mask)) {\n      int start = i;\n      while (i + 1 &lt; CPU_SETSIZE &amp;&amp; CPU_ISSET(i + 1, &amp;mask)) ++i;\n      if (!result.empty()) result += \",\";\n      result += (start == i) ? std::to_string(start)\n        : std::to_string(start) + \"-\" + std::to_string(i);\n    }\n    ++i;\n  }\n\n  return result.empty() ? \"No CPUs found in affinity mask.\" : result;\n}\n\nint main(int argc, char *argv[]){\n\n  MPI_Init(&amp;argc, &amp;argv);\n\n  int size;\n  MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n\n  char name[MPI_MAX_PROCESSOR_NAME];\n  int resultlength;\n  MPI_Get_processor_name(name, &amp;resultlength);\n\n  // If ZE_AFFINITY_MASK is set, capture visible GPUs\n  const char* gpu_id_list;\n  const char* ze_affinity_mask = getenv(\"ZE_AFFINITY_MASK\");\n  if(ze_affinity_mask == NULL){\n    gpu_id_list = \"N/A\";\n  }\n  else{\n    gpu_id_list = ze_affinity_mask;\n  }\n\n  // Find how many GPUs L0 runtime says are available\n  int num_devices = 0;\n  std::vector&lt;sycl::device&gt; sycl_all_devs = sycl::device::get_devices(sycl::info::device_type::gpu);\n  num_devices = sycl_all_devs.size();\n\n  std::string hwthread;\n  int thread_id = 0;\n  std::string busid = \"\";\n  std::string busid_list = \"\";\n  std::string rt_gpu_id_list = \"\";\n\n  // Loop over the GPUs available to each MPI rank\n  for(int i=0; i&lt;num_devices; i++) {\n    // Get the PCIBusId for each GPU and use it to query for UUID\n    busid = sycl_all_devs[i].get_info&lt;sycl::ext::intel::info::device::pci_address&gt;();\n\n    // Concatenate per-MPIrank GPU info into strings for print\n    if(i &gt; 0) rt_gpu_id_list.append(\",\");\n    rt_gpu_id_list.append(std::to_string(i));\n\n    std::string temp_busid(busid);\n\n    if(i &gt; 0) busid_list.append(\",\");\n    busid_list.append(temp_busid.substr(5,2));\n\n  }\n\n#pragma omp parallel default(shared) private(hwthread, thread_id)\n  {\n#pragma omp critical\n    {\n      thread_id = omp_get_thread_num();\n      hwthread = get_cpu_affinity_range();\n      int running_cpu = sched_getcpu();  // This gives current logical core ID\n\n      printf(\"MPI %03d - OMP %03d - HWT %s (Running on: %03d) - Node %s - RT_GPU_ID %s - GPU_ID %s - Bus_ID %s\\n\",\n             rank, thread_id, hwthread.c_str(), running_cpu, name, rt_gpu_id_list.c_str(), gpu_id_list, busid_list.c_str());\n    }\n  }\n\n  MPI_Finalize();\n  return 0;\n}\n</code></pre> <p>The above code snippet can be compiled via: <pre><code>mpicxx -fsycl -qopenmp hello_affinity_aurora.cpp -o hello_affinity_aurora.out\n</code></pre></p> <p>Once a submitted job is running calculations can be launched on the compute nodes using <code>mpiexec</code> to start an MPI application. Documentation is accessible via <code>man mpiexec</code> and some helpful options follow.</p> <ul> <li><code>-n</code> total number of MPI ranks</li> <li><code>-ppn</code> number of MPI ranks per node</li> <li><code>--cpu-bind</code> CPU binding for application</li> <li><code>--depth</code> number of cpus per rank (useful with <code>--cpu-bind</code>)</li> <li><code>--env</code> set environment variables (<code>--env OMP_NUM_THREADS=2</code>)</li> <li><code>--hostfile</code> indicate file with hostnames (the default is <code>--hostfile $PBS_NODEFILE</code>)</li> </ul> <p>A sample submission script with directives is below for a 4-node job with 28 MPI ranks on each node and 4 OpenMP threads per rank (1 per CPU core).</p> <pre><code>#!/bin/bash -l\n#PBS -N AFFINITY\n#PBS -l select=4\n#PBS -l place=scatter\n#PBS -l walltime=0:10:00\n#PBS -l filesystems=&lt;fs1:fs2&gt;\n#PBS -q debug-scaling\n#PBS -A &lt;MYPROJECT&gt;\n\nexport TZ='/usr/share/zoneinfo/US/Central'\ncd ${PBS_O_WORKDIR}\n\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS=28 # Number of MPI ranks to spawn per node\nNDEPTH=4 # Number of hardware threads per rank (i.e. spacing between MPI ranks)\nNTHREADS=4 # Number of software threads per rank to launch (i.e. OMP_NUM_THREADS)\n\nNTOTRANKS=$(( NNODES * NRANKS ))\n\necho \"NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS} THREADS_PER_RANK= ${NTHREADS}\"\n\nmpiexec -n ${NTOTRANKS} -ppn ${NRANKS} --depth=${NDEPTH} --cpu-bind depth -env OMP_NUM_THREADS=${NTHREADS} --env OMP_PLACES=cores ./hello_affinity_aurora.out\n</code></pre>"},{"location":"aurora/running-jobs-aurora/#running-gpu-enabled-applications","title":"Running GPU-enabled Applications","text":"<p>GPU-enabled applications will similarly run on the compute nodes using the above templated PBS job-script.</p> <ul> <li>The environment variable <code>MPIR_CVAR_ENABLE_GPU=1</code> enables GPU-aware MPI support whereby the MPI library sends and receives data directly from GPU buffers. Default value is <code>MPIR_CVAR_ENABLE_GPU=1</code>. For applications that doesn't need support for GPU-aware MPI, it is beneficial to disable by setting <code>MPIR_CVAR_ENABLE_GPU=0</code>.</li> <li>If running on a specific GPU or subset of GPUs and/or tiles is desired, then the <code>ZE_AFFINITY_MASK</code> environment variable can be used. For example, if one only wanted an application to access the first two GPUs on a node, then setting <code>ZE_AFFINITY_MASK=0,1</code> could be used.</li> </ul>"},{"location":"aurora/running-jobs-aurora/#mpi-rank-and-thread-binding-to-cores-and-gpus","title":"MPI rank and thread binding to cores and GPUs","text":"<p>Warning</p> <p>Since March 31, 2025, cores 0 (104) and 52 (156)--the first physical cores on each CPU socket\u2014have been reserved for system services, and are no longer available for user applications.</p> <p>Each node on Aurora has 2 sockets, each with 1 CPU and 3 PVC GPUs. Each CPU has 52 physical cores, with 2 logical processors (provided by Intel hyper threading) per physical core, for a total of 104 physical cores and 208 logical processors on the CPUs per Aurora node. Each GPU has two tiles on it, for a total of 6 GPUs and 12 GPU tiles on the GPUs per Aurora node. When a parallel job is run, the job must have some way of mapping MPI ranks or threads to each of the 208 logical processors and 6 GPUs or 12 GPU tiles. Mapping is typically done by an affinity mask, which assigns hardware resources to each MPI rank or thread to use.</p> <p>A visual representation of node in Aurora is shown below. Each socket is represented by a large blue bubble. Inside, each CPU is represented by a red bubble. Inside of CPU, the white boxes represent the physical cores, and the two grey squares in each tile represent the two logical processors. Each GPU is represented by a large white box, with two grey boxes inside to represent the two tiles. As mentioned in the warning above, the cores 0 and 52 are reserved for the OS, and so are crossed out in red.</p> <p> </p> Simplified representation of Aurora node  <p>For the two CPUs, the numbers inside the boxes identify the specific logical processors in the core. That is, logical processor 0 and 104 are the 2 logical processors on the first physical core. Logical processors 1 and 105 are the 2 logical processors that share the second physical core. Since there are 208 logical processors, the numbers run from 0 to 207. For i from 0 to 51, logical processors i and i+104 share a physical core.</p> <p>For the six GPUs, the GPU number identifies the GPU, and the tile numbers identify the tile in the GPU, with tiles from 0 to 5 with each GPU have two tiles each $gpu.0 and $gpu.1.</p>"},{"location":"aurora/running-jobs-aurora/#binding-mpi-ranks-and-threads-to-cores","title":"Binding MPI ranks and threads to cores","text":"<p>Using the <code>--cpu-bind</code> argument to mpiexec, MPI ranks and threads can be assigned to run on specific logical processors on the CPUs. For more information about the flags to <code>mpiexec</code>, see Running MPI+OpenMP+SYCL Applications. Four examples of using <code>mpiexec</code> are given below to show how the <code>cpu-bind=depth</code>, <code>cpu-bind=list</code>, <code>--depth</code> arguments affect where MPI ranks and OpenMP threads are mapped. The sample output provides the range of logical processors (or hardware threads) a given MPI rank is bound to via <code>HWT</code> and the logical processor ID which the thread is running on via <code>(Running on: )</code>.</p> <p>Note: In this section, we intentionally do not bind GPUs to specific MPI ranks. GPU binding logic is deferred to the next section. As a result, each MPI rank will have visibility to all GPUs available on the node as can be seen from the output of <code>hello_affinity_aurora.out</code> executable from the above code snippet <code>hello_affinity_aurora.cpp</code>. <code>RT_GPU_ID</code> refers to runtime GPU ID as seen by the MPI rank and/or OpenMP thread and/or SYCL runtime. <code>GPU_ID</code> refers to the GPU ID as recognized by <code>ZE_AFFINITY_MASK</code>.</p>"},{"location":"aurora/running-jobs-aurora/#example-1-2-nodes-4-ranksnode-1-threadrank","title":"Example 1: 2 nodes, 4 ranks/node, 1 thread/rank","text":"<pre><code>$ export OMP_NUM_THREADS=1\n$ mpiexec -n 8 -ppn 4 --depth 1 --cpu-bind=depth ./hello_affinity_aurora.out | sort\nMPI 000 - OMP 000 - HWT 1 (Running on: 001) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 001 - OMP 000 - HWT 2 (Running on: 002) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 002 - OMP 000 - HWT 3 (Running on: 003) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 003 - OMP 000 - HWT 4 (Running on: 004) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 004 - OMP 000 - HWT 1 (Running on: 001) - Node x4407c6s7b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 005 - OMP 000 - HWT 2 (Running on: 002) - Node x4407c6s7b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 006 - OMP 000 - HWT 3 (Running on: 003) - Node x4407c6s7b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 007 - OMP 000 - HWT 4 (Running on: 004) - Node x4407c6s7b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\n</code></pre> <ul> <li>The <code>-n 8</code> argument says to use 8 MPI ranks in total and <code>-ppn 4</code> places 4 ranks per node.</li> <li>The <code>--depth 1</code> argument says to use 1 logical processor for each MPI rank.</li> <li>The <code>--cpu-bind depth</code> argument says to spread out the ranks in a round robin manner across the logical processors, first putting one rank on the first logical processor of one physical core, and then looping back to put a second one on the second logical processor. This is done such that there's N logical processors for each MPI rank, where N is the value from the --depth argument (so it's 1 in this case).</li> </ul> <p>The same can be achieved with the <code>--cpu-bind=list</code> argument that explicitly lists which logical processor to bind to per node. Each MPI rank is bound to the logical processors that are listed between <code>:</code>. So here, rank 0 is bound to to logical processor 1, rank 1 to logical processor 2, and so on on each node.</p> <p><pre><code>$ export OMP_NUM_THREADS=1\n$ mpiexec -n 8 -ppn 4 --cpu-bind=list:1:2:3:4 ./hello_affinity_aurora.out | sort\nMPI 000 - OMP 000 - HWT 1 (Running on: 001) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 001 - OMP 000 - HWT 2 (Running on: 002) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 002 - OMP 000 - HWT 3 (Running on: 003) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 003 - OMP 000 - HWT 4 (Running on: 004) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 004 - OMP 000 - HWT 1 (Running on: 001) - Node x4407c6s7b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 005 - OMP 000 - HWT 2 (Running on: 002) - Node x4407c6s7b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 006 - OMP 000 - HWT 3 (Running on: 003) - Node x4407c6s7b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 007 - OMP 000 - HWT 4 (Running on: 004) - Node x4407c6s7b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\n</code></pre> The figure below shows the mapping, where the different colors are different MPI ranks.</p> <p> </p> Example 1 Mapping"},{"location":"aurora/running-jobs-aurora/#example-2-2-nodes-2-ranksnode-2-threadrank","title":"Example 2: 2 nodes, 2 ranks/node, 2 thread/rank","text":"<pre><code>$ OMP_PLACES=threads OMP_NUM_THREADS=2 mpiexec -n 4 -ppn 2 --depth=2 --cpu-bind=depth ./hello_affinity_aurora.out | sort\nMPI 000 - OMP 000 - HWT 1 (Running on: 001) - Node x4707c0s0b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 000 - OMP 001 - HWT 2 (Running on: 002) - Node x4707c0s0b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 001 - OMP 000 - HWT 3 (Running on: 003) - Node x4707c0s0b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 001 - OMP 001 - HWT 4 (Running on: 004) - Node x4707c0s0b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 002 - OMP 000 - HWT 1 (Running on: 001) - Node x4707c0s1b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 002 - OMP 001 - HWT 2 (Running on: 002) - Node x4707c0s1b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 003 - OMP 000 - HWT 3 (Running on: 003) - Node x4707c0s1b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 003 - OMP 001 - HWT 4 (Running on: 004) - Node x4707c0s1b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\n</code></pre> <ul> <li>The <code>-n 4</code> argument says to use 4 MPI ranks in total and <code>-ppn 2</code> places 2 ranks per node.</li> <li>The <code>--depth=2</code> argument says to use 2 logical processors for each MPI rank.</li> <li>The <code>--cpu-bind=depth</code> argument says to spread out the ranks in a round robin manner across the logical processors, first putting one rank on the first logical processor of one physical processor, and then looping back to put a second one on the second logical processor. This is done such that there's N logical processors for each MPI rank, where N is the value from the <code>--depth</code> argument (so it's 2 in this case).</li> <li><code>OMP_NUM_THREADS=2</code> launches two threads per MPI rank</li> <li><code>OMP_PLACES=threads</code> says to bind the OpenMP threads to logical processors</li> </ul> <p>This is the same as explictly using the <code>--cpu-bind=list</code> argument. Each MPI rank is bound to the logical processors that are listed between <code>:</code>. Between :, the logical processors to bind to are listed in a comma-separated manner. So here, rank 0 is bound to logical processors 1 and 2, rank 2 to logical processors 3 and 4. <code>OMP_PLACES=threads</code> then binds the specific threads to the logical processors in the list.</p> <p><pre><code>$ OMP_PLACES=threads OMP_NUM_THREADS=2 mpiexec -n 4 -ppn 2 --cpu-bind=list:1,2:3,4 ./hello_affinity_aurora.out | sort\nMPI 000 - OMP 000 - HWT 1 (Running on: 001) - Node x4707c0s0b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 000 - OMP 001 - HWT 2 (Running on: 002) - Node x4707c0s0b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 001 - OMP 000 - HWT 3 (Running on: 003) - Node x4707c0s0b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 001 - OMP 001 - HWT 4 (Running on: 004) - Node x4707c0s0b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 002 - OMP 000 - HWT 1 (Running on: 001) - Node x4707c0s1b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 002 - OMP 001 - HWT 2 (Running on: 002) - Node x4707c0s1b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 003 - OMP 000 - HWT 3 (Running on: 003) - Node x4707c0s1b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 003 - OMP 001 - HWT 4 (Running on: 004) - Node x4707c0s1b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\n</code></pre> The figure below shows the mapping, where the different colors are different MPI ranks.</p> <p> </p> Example 2 Mapping"},{"location":"aurora/running-jobs-aurora/#example-3-2-nodes-2-ranksnode-1-threadrank-compact-fashion","title":"Example 3: 2 nodes, 2 ranks/node, 1 thread/rank, compact fashion","text":"<p><pre><code>$ export OMP_NUM_THREADS=1\n$ mpiexec -n 4 -ppn 2 --cpu-bind=list:1:105 ./hello_affinity_aurora.out | sort\nMPI 000 - OMP 000 - HWT 1 (Running on: 001) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 001 - OMP 000 - HWT 105 (Running on: 105) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 002 - OMP 000 - HWT 1 (Running on: 001) - Node x4407c6s7b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 003 - OMP 000 - HWT 105 (Running on: 105) - Node x4407c6s7b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\n</code></pre> The <code>--cpu-bind=list</code> argument explicitly lists which logical processor to bind to per node. Here, rank 0 is bound to logical processor 0 and rank 1 is bound to logical processor 105, which share the same physical core. The figure below shows the mapping, where the different colors are different MPI ranks.</p> <p> </p> Example 3 Mapping"},{"location":"aurora/running-jobs-aurora/#example-4-1-node-12-ranksnode","title":"Example 4: 1 node, 12 ranks/node","text":"<p>This setup is a common case for applications: 12 ranks/node, where each rank will offload to one of the 12 GPU tiles. Note that explicit list binding to logical processors is needed here to avoid binding a MPI rank to a logical core on different socket than the GPU it might be targetting (as would happen if cpu_bind=depth was used).</p> <pre><code>$ export OMP_NUM_THREADS=1\n$ export CPU_BIND_SCHEME=\"--cpu-bind=list:1-8:9-16:17-24:25-32:33-40:41-48:53-60:61-68:69-76:77-84:85-92:93-100\"\n$ mpiexec -n 12 -ppn 12 ${CPU_BIND_SCHEME} ./hello_affinity_aurora.out | sort\nMPI 000 - OMP 000 - HWT 1-8 (Running on: 008) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 001 - OMP 000 - HWT 9-16 (Running on: 016) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 002 - OMP 000 - HWT 17-24 (Running on: 024) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 003 - OMP 000 - HWT 25-32 (Running on: 032) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 004 - OMP 000 - HWT 33-40 (Running on: 040) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 005 - OMP 000 - HWT 41-48 (Running on: 048) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 006 - OMP 000 - HWT 53-60 (Running on: 060) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 007 - OMP 000 - HWT 61-68 (Running on: 068) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 008 - OMP 000 - HWT 69-76 (Running on: 076) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 009 - OMP 000 - HWT 77-84 (Running on: 084) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 010 - OMP 000 - HWT 85-92 (Running on: 092) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 011 - OMP 000 - HWT 93-100 (Running on: 100) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\n</code></pre> <ul> <li>The <code>--cpu-bind=list:</code> argument explicitly lists which logical processor to bind to per node. Here, rank 0 is bound to to processors 1-8, rank 1 to processors 9-16, etc.</li> </ul> <p>The figure below shows the mapping, where the different colors are different MPI ranks.</p> <p> </p> Example 4 Mapping  <p>The important point here is that with this explicit binding from <code>cpu-bind=list</code>, we are able to ensure socket 0 has 6 ranks and socket 1 has 6 ranks. Note how MPI rank 5 ends at logical processor 48, but MPI rank 6 begins with logical processor 53, so this involves leaving several cores empty. However, it allows the cores to be spread evenly across the two sockets. </p> <p>If instead we used <code>--cpu-bind=depth</code> as below, then the mapping is: <pre><code>$ export OMP_NUM_THREADS=1\n$ mpiexec -n 12 -ppn 12 --depth=8 --cpu-bind=depth ./hello_affinity_aurora.out | sort\nMPI 000 - OMP 000 - HWT 1-8 (Running on: 008) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 001 - OMP 000 - HWT 9-16 (Running on: 016) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 002 - OMP 000 - HWT 17-24 (Running on: 024) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 003 - OMP 000 - HWT 25-32 (Running on: 032) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 004 - OMP 000 - HWT 33-40 (Running on: 040) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 005 - OMP 000 - HWT 41-48 (Running on: 048) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 006 - OMP 000 - HWT 49-51,53-57 (Running on: 057) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 007 - OMP 000 - HWT 58-65 (Running on: 065) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 008 - OMP 000 - HWT 66-73 (Running on: 073) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 009 - OMP 000 - HWT 74-81 (Running on: 081) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 010 - OMP 000 - HWT 82-89 (Running on: 089) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\nMPI 011 - OMP 000 - HWT 90-97 (Running on: 097) - Node x4407c6s2b0n0 - RT_GPU_ID 0,1,2,3,4,5 - GPU_ID N/A - Bus_ID 18,42,6c,18,42,6c\n</code></pre></p> <p>A small misconfiguration of the <code>--depth</code> option for instance, using <code>--depth=8</code> can result in unexpectedly bad performance. Note that the threads of MPI rank 6 are bound on both socket 0 and socket 1, which potentially will lead to worse performance than using cpu-bind=list to explicitly spread out the ranks (as above), since the threads can migrate across sockets. This is shown in the image below. Note that the pink MPI rank (rank 6) is split between socket 0 and socket 1.</p> <p> </p> Example 4 Mapping Which Splits a MPI Rank Across Sockets  <p>Info</p> <p>For a script to help provide cpu-bindings, you can use get_cpu_bind_aurora. Please see User Guide for Aurora CPU Binding Script for documentation.</p>"},{"location":"aurora/running-jobs-aurora/#binding-mpi-ranks-to-gpus","title":"Binding MPI ranks to GPUs","text":"<p>In this section, the above mentioned MPI+OpenMP+SYCL affinity code will be used to show how to map MPI processes with GPUs. The CPU mapping part of this example is very similar to the examples used above, so the focus here will be on the GPU mapping part.</p> <p>In general, GPU mapping can be accomplished in two different ways: 1) with the <code>gpu_tile_compact.sh</code> and <code>gpu_dev_compact.sh</code> scripts and 2) with the <code>--gpu-bind</code> flag to mpiexec.</p>"},{"location":"aurora/running-jobs-aurora/#1-binding-mpi-ranks-to-gpus-using-gpu_tile_compactsh-and-gpu_dev_compactsh-scripts","title":"1) Binding MPI ranks to GPUs using <code>gpu_tile_compact.sh</code> and <code>gpu_dev_compact.sh</code> scripts","text":"<p>Users are encouraged to use the <code>gpu_tile_compact.sh</code> script provided in the Aurora PE. This script binds each MPI rank to a single GPU tile (\"Explicit Scaling\") using a round-robin strategy. Note that <code>gpu_tile_compact.sh</code> requires the environment variable <code>ZE_FLAT_DEVICE_HIERARCHY=COMPOSITE</code>, which is set by default in the Aurora PE. The script can be placed just before the executable in an <code>mpiexec</code> command like so.</p> <pre><code>mpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind=depth gpu_tile_compact.sh &lt;app&gt; &lt;app_args&gt;\n</code></pre> <p>Below is a simplified version of this script, illustrating how the <code>ZE_AFFINITY_MASK</code> is uniquely set for each MPI rank.</p> <p>A simple version of <code>gpu_tile_compact.sh</code> script is below to illustrate how <code>ZE_AFFINITY_MASK</code> is uniquely set for each MPI rank. <pre><code>#!/bin/bash -l\nnum_gpu=6\nnum_tile=2\ngpu_id=$(( (PALS_LOCAL_RANKID / num_tile ) % num_gpu ))\ntile_id=$((PALS_LOCAL_RANKID % num_tile))\nexport ZE_ENABLE_PCI_ID_DEVICE_ORDER=1\nexport ZE_AFFINITY_MASK=$gpu_id.$tile_id\n#echo \u201cRANK= ${PMI_RANK} LOCAL_RANK= ${PMI_LOCAL_RANK} gpu= ${gpu}\u201d\nexec \"$@\"\n</code></pre></p> <p>The <code>frameworks</code> module sets <code>ZE_FLAT_DEVICE_HIERARCHY=FLAT</code>, treating each tile as a device. Our current recommendation is to not use the <code>gpu_tile_compact.sh</code> script during the job submission while using the <code>frameworks</code> module.  If you wish to bind MPI ranks to devices instead of tiles, this can be done the following way:</p> <p><pre><code>#!/bin/bash\nnum_gpus=12\ngpu_id=$((PMIX_RANK % ${num_gpus} ))\nexport ZE_AFFINITY_MASK=$gpu_id\nexec \"$@\"\n</code></pre> Caution: This will narrow the affinity mask down and generate PyTorch warnings. If you want to avoid that, don't use this binding script and do the binding manually inside your apps.  More information on <code>ZE_FLAT_DEVICE_HIERARCHY</code> can be found in Intel's online documentation.</p> <p>If an application prefers to bind MPI ranks to entire GPU devices rather than individual tiles, the <code>gpu_dev_compact.sh</code> script (also available in your default path) can be used. Binding to a full device instead of a tile is refered to as \"Implicit Scaling\". Users with different MPI-GPU affinity needs, such as assigning multiple GPUs/tiles per MPI rank, are encouraged to modify a local copy of <code>gpu_tile_compact.sh</code> (<code>which gpu_tile_compact.sh</code> will show the location of the script) to suit their needs.</p>"},{"location":"aurora/running-jobs-aurora/#example-1-explicit-scaling-1-node-12-ranksnode-1-threadrank-1-rankgpu-tile","title":"Example 1: (Explicit Scaling) 1 node, 12 ranks/node, 1 thread/rank, 1 rank/GPU-tile","text":"<p>This example below shows a common mapping of MPI ranks to cores and GPUs.</p> <pre><code>$ export OMP_NUM_THREADS=1\n$ export CPU_BIND_SCHEME=\"--cpu-bind=list:1-8:9-16:17-24:25-32:33-40:41-48:53-60:61-68:69-76:77-84:85-92:93-100\"\n$ mpiexec -n 12 -ppn 12 ${CPU_BIND_SCHEME} gpu_tile_compact.sh ./hello_affinity_aurora.out | sort\nMPI 000 - OMP 000 - HWT 1-8 (Running on: 008) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 0.0 - Bus_ID 18\nMPI 001 - OMP 000 - HWT 9-16 (Running on: 016) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 0.1 - Bus_ID 18\nMPI 002 - OMP 000 - HWT 17-24 (Running on: 024) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 1.0 - Bus_ID 42\nMPI 003 - OMP 000 - HWT 25-32 (Running on: 032) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 1.1 - Bus_ID 42\nMPI 004 - OMP 000 - HWT 33-40 (Running on: 040) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 2.0 - Bus_ID 6c\nMPI 005 - OMP 000 - HWT 41-48 (Running on: 048) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 2.1 - Bus_ID 6c\nMPI 006 - OMP 000 - HWT 53-60 (Running on: 060) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 3.0 - Bus_ID 18\nMPI 007 - OMP 000 - HWT 61-68 (Running on: 068) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 3.1 - Bus_ID 18\nMPI 008 - OMP 000 - HWT 69-76 (Running on: 076) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 4.0 - Bus_ID 42\nMPI 009 - OMP 000 - HWT 77-84 (Running on: 084) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 4.1 - Bus_ID 42\nMPI 010 - OMP 000 - HWT 85-92 (Running on: 092) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 5.0 - Bus_ID 6c\nMPI 011 - OMP 000 - HWT 93-100 (Running on: 100) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 5.1 - Bus_ID 6c\n</code></pre> <ul> <li>The <code>-n 12</code> argument says to use 12 MPI ranks in total and <code>-ppn 12</code> places 12 ranks per node.</li> <li>The <code>--cpu-bind=list</code> argument gives the mapping of MPI ranks to cores, as described in Binding MPI ranks and threads to cores.</li> <li>The <code>gpu_tile_compact.sh</code> wrapper sets ZE_AFFINITY_MASK for each of the 12 ranks such that rank 0 maps to GPU 0:Tile 0, rank 1 maps to GPU 0:Tile 1, rank 2 maps to GPU 1:Tile 0 etc. in a round-robin compact fashion.</li> </ul> <p> </p> Example 1 GPU Tile Mapping"},{"location":"aurora/running-jobs-aurora/#example-2-implicit-scaling-1-node-6-ranksnode-1-threadrank-1-rankgpu","title":"Example 2: (Implicit Scaling) 1 node, 6 ranks/node, 1 thread/rank, 1 rank/GPU","text":"<pre><code>$ export OMP_NUM_THREADS=1\n$ export CPU_BIND_SCHEME=\"--cpu-bind=list:1-16:17-32:33-48:53-68:69-84:85-100\"\n$ mpiexec -n 6 -ppn 6 ${CPU_BIND_SCHEME} gpu_dev_compact.sh ./hello_affinity_aurora.out | sort\nMPI 000 - OMP 000 - HWT 1-16 (Running on: 016) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 0 - Bus_ID 18\nMPI 001 - OMP 000 - HWT 17-32 (Running on: 032) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 1 - Bus_ID 42\nMPI 002 - OMP 000 - HWT 33-48 (Running on: 048) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 2 - Bus_ID 6c\nMPI 003 - OMP 000 - HWT 53-68 (Running on: 068) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 3 - Bus_ID 18\nMPI 004 - OMP 000 - HWT 69-84 (Running on: 084) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 4 - Bus_ID 42\nMPI 005 - OMP 000 - HWT 85-100 (Running on: 100) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 5 - Bus_ID 6c\n</code></pre> <ul> <li>The <code>-n 6</code> argument says to use 6 MPI ranks in total and <code>-ppn 6</code> places 6 ranks per node.</li> <li>The <code>--cpu-bind=list</code> argument gives the mapping of MPI ranks to cores, as described in Binding MPI ranks and threads to cores.</li> <li>The <code>gpu_dev_compact.sh</code> wrapper sets ZE_AFFINITY_MASK for each of the 6 ranks such that rank 0 maps to GPU 0, rank 1 maps to GPU 1 etc. in a round-robin compact fashion.</li> </ul> Example 1 GPU Device Mapping"},{"location":"aurora/running-jobs-aurora/#2-binding-mpi-ranks-to-gpus-using-gpu-bind-option-from-mpich","title":"2) Binding MPI ranks to GPUs using <code>--gpu-bind</code> option from MPICH","text":"<p>Similar to the <code>--cpu-bind</code> option, which maps MPI ranks to specific CPU cores, the <code>--gpu-bind</code> option enables mapping MPI ranks to GPUs. While this feature is still under active development and has several limitations, a common use case is mapping 12 MPI ranks to the 12 GPU tiles available per node.</p>"},{"location":"aurora/running-jobs-aurora/#example-1-explicit-scaling-1-node-12-ranksnode-1-threadrank-1-rankgpu-tile_1","title":"Example 1: (Explicit Scaling) 1 node, 12 ranks/node, 1 thread/rank, 1 rank/GPU-tile","text":"<pre><code>$ export OMP_NUM_THREADS=1\n$ export CPU_BIND_SCHEME=\"--cpu-bind=list:1-8:9-16:17-24:25-32:33-40:41-48:53-60:61-68:69-76:77-84:85-92:93-100\"\n$ export GPU_BIND_SCHEME=\"--gpu-bind=list:0.0:0.1:1.0:1.1:2.0:2.1:3.0:3.1:4.0:4.1:5.0:5.1\"\n$ mpiexec -n 12 -ppn 12 ${CPU_BIND_SCHEME} ${GPU_BIND_SCHEME} ./hello_affinity_aurora.out | sort\nMPI 000 - OMP 000 - HWT 1-8 (Running on: 008) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 0.0 - Bus_ID 18\nMPI 001 - OMP 000 - HWT 9-16 (Running on: 016) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 0.1 - Bus_ID 18\nMPI 002 - OMP 000 - HWT 17-24 (Running on: 024) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 1.0 - Bus_ID 42\nMPI 003 - OMP 000 - HWT 25-32 (Running on: 032) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 1.1 - Bus_ID 42\nMPI 004 - OMP 000 - HWT 33-40 (Running on: 040) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 2.0 - Bus_ID 6c\nMPI 005 - OMP 000 - HWT 41-48 (Running on: 048) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 2.1 - Bus_ID 6c\nMPI 006 - OMP 000 - HWT 53-60 (Running on: 060) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 3.0 - Bus_ID 18\nMPI 007 - OMP 000 - HWT 61-68 (Running on: 068) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 3.1 - Bus_ID 18\nMPI 008 - OMP 000 - HWT 69-76 (Running on: 076) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 4.0 - Bus_ID 42\nMPI 009 - OMP 000 - HWT 77-84 (Running on: 084) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 4.1 - Bus_ID 42\nMPI 010 - OMP 000 - HWT 85-92 (Running on: 092) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 5.0 - Bus_ID 6c\nMPI 011 - OMP 000 - HWT 93-100 (Running on: 100) - Node x4407c6s2b0n0 - RT_GPU_ID 0 - GPU_ID 5.1 - Bus_ID 6c\n</code></pre> <ul> <li>The <code>-n 12</code> argument says to use 12 MPI ranks in total and <code>-ppn 12</code> places 12 ranks per node.</li> <li>The <code>--cpu-bind=list</code> argument gives the mapping of MPI ranks to cores, as described in Binding MPI ranks and threads to cores.</li> <li>The <code>--gpu-bind=list</code> argument gives the mapping of MPI ranks to GPU-tiles.</li> </ul> <p>Warning</p> <p>There are several limitations with using <code>--gpu-bind=list</code> namely (a) for implict-scaling via <code>--gpu-bind=list:0:1:2:3:4:5</code>, (b) With a different device-discovery hierarchy, <code>ZE_FLAT_DEVICE_HIERARCHY=FLAT</code>. This is mode preferred for AI/ML frameworks.</p> <pre><code>$ export CPU_BIND_SCHEME=\"--cpu-bind=list:1-16:17-32:33-48:53-68:69-84:85-100\"\n$ export GPU_BIND_SCHEME=\"--gpu-bind=list:0:1:2:3:4:5\"\n$ mpiexec -n 6 -ppn 6 ${CPU_BIND_SCHEME} ${GPU_BIND_SCHEME} ./hello_affinity_aurora.out | sort\nlaunch failed on x4520c2s0b0n0: Failed to parse implicit GPU selection\n$\n$\n$ export ZE_FLAT_DEVICE_HIERARCHY=FLAT\n$ export CPU_BIND_SCHEME=\"--cpu-bind=list:1-8:9-16:17-24:25-32:33-40:41-48:53-60:61-68:69-76:77-84:85-92:93-100\"\n$ export GPU_BIND_SCHEME=\"--gpu-bind=list:0:1:2:3:4:5:6:7:8:9:10:11\"\n$ mpiexec -n 12 -ppn 12 ${CPU_BIND_SCHEME} ${GPU_BIND_SCHEME} ./hello_affinity_aurora.out | sort\nlaunch failed on x4520c2s0b0n0: Failed to parse implicit GPU selection\n</code></pre>"},{"location":"aurora/running-jobs-aurora/#interactive-jobs-on-compute-nodes","title":"Interactive Jobs on Compute Nodes","text":"<p>Here is how to submit an interactive job to, for example, edit/build/test an application on Aurora compute nodes:</p> <pre><code>qsub -I -l select=1,walltime=1:00:00,place=scatter -l filesystems=&lt;fs1:fs2&gt; -A &lt;MYPROJECT&gt; -q debug\n</code></pre> <p>This command requests 1 node for a period of 1 hour in the <code>workq</code> queue. After waiting in the queue for a node to become available, a shell prompt on a compute node will appear. You may then start building applications and testing gpu affinity scripts on the compute node.</p> <p>Warning</p> <p>If you want to <code>ssh</code> or <code>scp</code> to one of your assigned compute nodes you will need to make sure your <code>$HOME</code> directory and your <code>$HOME/.ssh</code> directory permissions are both set to <code>700</code>.</p>"},{"location":"aurora/running-jobs-aurora/#running-with-multiple-compute-command-streamers-ccss","title":"Running with Multiple Compute Command Streamers (CCSs)","text":"<p>The Intel PVC GPUs contain 4 Compute Command Streamers (CCSs) on each tile, which can be used to group Execution Units (EUs) into common pools. These pools can then be accessed by separate processes thereby allowing users to bind multiple processes to a single tile and enabling applications to run up to 48 MPI processes per node on the 6 PVC available. Enabling multiple CCSs on Aurora is similar to the MPS capabilities on NVIDIA GPUs. By default, all EUs are assigned to a single CCS, but EUs can be distributed equally into 2 or 4 groups by exposing 2 or 4 CCSs, respectively. This feature is enabled with the <code>ZEX_NUMBER_OF_CCS</code> environment variable, which takes a comma-separated list of device-mode pairs. For example, to enable 4 CCSs on all 6 PVC, execute <pre><code>export ZEX_NUMBER_OF_CCS=0:4,1:4,2:4,3:4,4:4,5:4\n</code></pre></p> <p>Additional notes when running with multiple CCSs</p> <ul> <li>Please be mindful of the device hierarchy selected. When running with <code>ZE_FLAT_DEVICE_HIERARCHY=COMPOSITE</code>, 6 PVC are exposed to the applications and the above command should be used, noting that <code>export ZEX_NUMBER_OF_CCS=0:4</code> exposes 4 CCSs on both tiles of GPU 0. When running with <code>ZE_FLAT_DEVICE_HIERARCHY=FLAT</code>, the 12 PVC tiles are exposed to the applications (tile-as-device), thus <code>export ZEX_NUMBER_OF_CCS=0:4</code> only refers to tile 0 of GPU 0. To expose multiple CCSs on all tiles, users should use <code>export ZEX_NUMBER_OF_CCS=0:4,1:4,2:4,3:4,4:4,5:4,6:4,7:4,8:4,9:4,10:4,11:4</code>.</li> <li>Users should also be mindful of the CPU binding affinity guidelines described above, ensuring that MPI processes are bound to the correct socket and GPU pairs.</li> <li><code>ZE_AFFINITY_MASK</code> is read by the Level Zero driver prior to <code>ZEX_NUMBER_OF_CCS</code>, thus <code>ZEX_NUMBER_OF_CCS</code> should refer to the GPU IDs of the masked devices.</li> <li>Users can expose different number of CCSs on the different GPU and tiles, the desired CCS mode does not need to be uniform across the GPUs on a node.</li> </ul> <p>More information can be found on Intel's documentation and GitHub pages.</p>"},{"location":"aurora/running-jobs-aurora/#running-multiple-mpi-applications-on-a-node","title":"Running Multiple MPI Applications on a node","text":"<p>Multiple applications can be run simultaneously on a node by launching several <code>mpiexec</code> commands and backgrounding them. For performance, it will likely be necessary to ensure that each application runs on a distinct set of CPU resources and/or targets specific GPUs and tiles. One can provide a list of CPUs using the <code>--cpu-bind</code> option, which when combined with <code>ZE_AFFINITY_MASK</code> provides a user with specifying exactly which CPU and GPU resources to run each application on. In the simple example below, twelve instances of the application are simultaneously running on a single node. In the first instance, the application is spawning MPI ranks 0-3 on CPU cores 0-3 and using GPU 0 tile 0.</p> <pre><code>export OMP_NUM_THREADS=1\nexport ZE_ENABLE_PCI_ID_DEVICE_ORDER=1\n\nexport ZE_AFFINITY_MASK=0.0\nmpiexec --np 4 --ppn 4 --cpu-bind=list:1:2:3:4 ./hello_affinity &amp;\n\nexport ZE_AFFINITY_MASK=0.1\nmpiexec -n 4 --ppn 4 --cpu-bind=list:5:6:7:8 ./hello_affinity &amp;\n\nexport ZE_AFFINITY_MASK=1.0\nmpiexec -n 4 --ppn 4 --cpu-bind=list:9:10:11:12 ./hello_affinity &amp;\n\n\nexport ZE_AFFINITY_MASK=5.1\nmpiexec -n 4 --ppn 4 --cpu-bind=list:40:41:42:43 ./hello_affinity &amp;\n\nwait\n</code></pre> <p>Users will likely find it beneficial to launch processes across CPU cores in both sockets of a node.</p>"},{"location":"aurora/running-jobs-aurora/#using-the-hbm-on-the-sapphire-rapids-cpus","title":"Using the HBM on the Sapphire Rapids CPUs","text":"<p>As mentioned about, each node on Aurora has 2 CPUs, each with 52 physical cores. Each CPU has 512 GB DDR memory and 64 GB HBM memory.  Since the CPUs on Aurora are configured in \"flat\" mode, the DDR and HBM are treated as separate memory regions.</p> <p>This configuration can be seen from running <code>numactl -H</code> on an Aurora node:</p> <pre><code>available: 4 nodes (0-3)\nnode 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155\nnode 0 size: 515524 MB\nnode 0 free: 497948 MB\nnode 1 cpus: 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207\nnode 1 size: 514994 MB\nnode 1 free: 497013 MB\nnode 2 cpus:\nnode 2 size: 65536 MB\nnode 2 free: 65424 MB\nnode 3 cpus:\nnode 3 size: 65536 MB\nnode 3 free: 65433 MB\nnode distances:\nnode   0   1   2   3\n  0:  10  21  13  23\n  1:  21  10  23  13\n  2:  13  23  10  23\n  3:  23  13  23  10\n</code></pre> <p>Here we see that the first CPU on the node (hardware threads 0-51 and 104-155) are associated with 512 GB memory in NUMA node 0 (node 0), and the second CPU (hardware threads 52-103 and 156-207) are also associated with 512 GB memory in <code>NUMA node 1 (node 1)</code>. The 64 GB HBM for the first CPU is in <code>node 2</code> and the second is <code>node 3</code>. Note that the \"nodes\" listed here refer to a NUMA domain on one node and not a different physical node.</p> <p>To specify in which memory ranks allocate, you can use several methods:</p> <ol> <li> <p>Use the memkind library with explicit calls like:       <pre><code>void* hbw_malloc(size_t size);\nvoid hbw_free(void *ptr)\n</code></pre> to allocate and free memory in HBM. By default, <code>malloc</code> will be in DDR.</p> </li> <li> <p>Use <code>numactl</code> to specify in which NUMA domain (based on <code>numactl -H</code> output) to allocate memory. For example, you can use <pre><code>mpirun -n 2 --cpu-bind=list:1-51:53-103 numactl -m 2-3 ./app\n</code></pre> This uses the <code>-m</code> flag to allocate memory only in NUMA node 2 and NUMA node 3, which is the HBM associated with the first and second CPUs, respectively. Or you can use the <code>--preferred</code> flag to specify that you would prefer that the memory allocations begin on the HBM, but if memory cannot be allocated there fall back to the DDR. For example, to allocated first in NUMA node 2 and fall back to DDR if needed: <pre><code>mpirun -n 1 --cpu-bind=list:1-51 numactl --preferred 2 ./app\n</code></pre> Note that <code>--preferred</code> takes only one node number, so to set it differently for each MPI rank, a script similar to <code>gpu_tile_compact.sh</code> can be written that sets <code>numactl --preferred</code> based on the MPI rank.</p> </li> <li> <p>Use the <code>--mem-bind</code> flag for <code>mpirun</code> to restrict where the MPI ranks can allocate memory. For example,  to allocate memory for rank 0 in NUMA node 0 (DDR) and rank 1 on NUMA node 1 (DDR): <pre><code>mpirun -n 2 --cpu-bind=list:1-51:53-103 --mem-bind=list:0:1\n</code></pre> To allocate memory for rank 0 in NUMA node 2 (HBM) and rank 1 in NUMA node 3 (HBM): <pre><code>mpirun -n 2 --cpu-bind=list:1-51:53-103 --mem-bind=list:2:3\n</code></pre></p> </li> </ol>"},{"location":"aurora/running-jobs-aurora/#compute-node-access-to-the-internet","title":"Compute Node Access to the Internet","text":"<p>Currently, the only access to the internet is via a proxy.  Here are the proxy environment variables for Aurora:</p> <pre><code>export http_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport https_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport ftp_proxy=\"http://proxy.alcf.anl.gov:3128\"\n</code></pre> <p>In the future, though we don't have a timeline on this because it depends on future features in slingshot and internal software development, we intend to have public IP addresses be a schedulable resource.  For instance, if only your head node needed public access your select statement might looks something like: <code>-l select=1:pubnet=True+63</code>.</p>"},{"location":"aurora/running-jobs-aurora/#controlling-where-your-job-runs","title":"Controlling Where Your Job Runs","text":"<p>If you wish to have your job run on specific nodes form your select like this: <code>-l select=1:vnode=&lt;node name1&gt;+1:vnode=&lt;node name2&gt;...</code> . Obviously, that gets tedious for large jobs.</p> <p>If you want to control the location of a few nodes, for example 2 out of 64, but the rest don't matter, you can do something like this: <code>-l select=1:vnode=&lt;node name1&gt;+1:vnode=&lt;node name2&gt;+62:system=foo</code>.</p>"},{"location":"aurora/running-jobs-aurora/#placement","title":"Placement","text":"<p>On Aurora, racks consist of 8 chassis, each of which holds 8 nodes, for a total of 64 nodes per rack.  The chassis are in a 2-across by 4-high arrangement numbered 0-7, going left to right, bottom to top. Each chassis has switching built in that the nodes plug into, so if you have a job that is 8 nodes or less you can save switch hops if all the nodes are in the same chassis.</p> <p></p> <p>Figure: Liquid Cooled Cabinet Front and Chassis Numbering (Source: HPE Shasta Hardware Architecture documentation</p> <p>As an example, for node <code>x4109c0s0b0n0</code>, this can be decomposed as: <pre><code>x4109c0s0b0n0 == Rack Identifier x4109, Chassis c0, Slot s0, Board b0, Node n0\n</code></pre> Note that the node names will always end in b0n0 (board 0, node 0) since there is only 1 board per blade, and 1 node per board.</p> <p>Every rack is a Dragonfly group, so if your job is 64 nodes or less you can save switch hops if all your nodes are in the same rack.  Every node has a PBS resource called <code>tier0</code> with a rack identifier (like <code>x4519</code>) and <code>tier1</code> with a rack and chassis identifier (like <code>x4519c3</code>).  PBS is configured so that it will preferentially place your jobs in the same chassis or rack if it can without delaying the start of your job.  If you want to guarantee all your nodes are grouped in a rack, you can add the group specifier to the <code>place</code> statement in PBS:</p> <pre><code>qsub -l select=8 -l place=scatter:group=tier0 pbs_submit_script.sh # allocating 8 nodes all in one rack (Dragonfly group)\n</code></pre> <p>If you wanted everything in the same chassis, replace <code>tier0</code> with <code>tier1</code>. Note that you must explicitly specify the <code>place</code> when you use <code>group</code>. If you wanted a specific rack or Dragonfly group instead of any of them, you can use:</p> <pre><code>qsub -l select=10:tier0=x4519 -l place=scatter:group=tier0 pbs_submit_script.sh # allocating 10 nodes in rack x4519\nqsub -l select=2:tier1=x4519c2 -l place=scatter:group=tier1 pbs_submit_script.sh # allocating 2 nodes in rack x4519 chassis c2\n</code></pre> <p>Another example that requests 10 nodes (8 unspecified nodes + 2 specific compute nodes) would use: <pre><code>#PBS -l select=8:tier1=x4000c0+1:host=x4311c1s0b0n0+1:host=x4311c1s1b0n0\n</code></pre></p> <p>You can also easily check what tier a node is a member of before your job submission:</p> <pre><code>&gt; pbsnodes x4000c0s0b0n0 | grep tier\nresources_available.tier0 = x4000\nresources_available.tier1 = x4000c0\n</code></pre> <p>To check if a specific node is available:</p> <pre><code>&gt; pbsnodes -Sv &lt;node&gt;\n</code></pre> <p>Another useful shell function for querying the compute node IDs and statuses available in a given <code>at_queue</code> (use <code>lustre_scaling</code>) and (optionally) matching status type <code>{free, job-exclusive, down}</code>: <pre><code>pbsnodes_queue() {\n  local at_queue=\"${1}\"\n  local state=\"${2:-}\"\n\n  if [ -z \"${state}\" ]; then\n    pbsnodes -avF JSON | jq --arg queue \"${at_queue}\" -r '.nodes[] | select(.resources_available.at_queue|split(\",\")|.[]|contains($queue)) | [.resources_available.vnode,.state,.comment]|join(\",\")'\n  else\n    pbsnodes -avF JSON | jq --arg queue \"${at_queue}\" --arg state \"${state}\" -r '.nodes[] | select(.resources_available.at_queue|split(\",\")|.[]|contains($queue))|select(.state == $state) | [.resources_available.vnode,.state,.comment]|join(\",\")'\n  fi\n}\n</code></pre> If this shell function is defined (e.g. in your local <code>~/.bashrc</code>), you can see the nodes that are currently <code>down</code> for example: <pre><code>\u276f pbsnodes_queue lustre_scaling down\nx4713c3s2b0n0,down,\nx4013c0s7b0n0,down,EXECJOB_BEGIN: RECHECK 1/40 grand mdc disconnect threshold exceeded(3/10min) (job 2471003)\nx4703c6s4b0n0,down,\nx4703c7s4b0n0,down,EXECJOB_END: RECHECK 2/40 grand mdc disconnect threshold exceeded(3/10min) (job 1070810)\nx4210c2s1b0n0,down,node down: communication closed\n</code></pre></p> <ol> <li> <p>Theoretical max node count. The stable max node count may vary; see pbsnodes and pbs-tui for current node count.\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"aurora/system-updates/","title":"Aurora System Updates","text":""},{"location":"aurora/system-updates/#2025-10-13","title":"2025-10-13","text":"<p>The compute image with Intel's User (UMD) and Kernel Mode Drivers (KMD) (Agama 1146.12 / rolling release 2523.12), and oneAPI 2025.2.0, which was previously available in next-eval queue, is rolled out to the majority of nodes across Aurora. 2,126 nodes have the old production image and are available in a queue called <code>legacy</code>, which will be available to all teams that are unable to run against the new image. Some teams will have higher priority to run in the legacy queue. Use aurora-uan-000[7-8] nodes for the <code>legacy</code> queue as they will have the same  user environment. Users will not be able log in directly to aurora-uan-000[7-8] and will need to ssh to them after logging in to aurora.alcf.anl.gov. </p> <p>See https://docs.alcf.anl.gov/aurora/running-jobs-aurora/</p> <p>See sections \"2025-10-07\" and \"2025-09-08\"  below for all the change log details.</p>"},{"location":"aurora/system-updates/#2025-10-07","title":"2025-10-07","text":"<p>The image in <code>next-eval</code> queue, and uan-0014, has been updated to AuroraSDK version 25.190.0 RC4, with the following changes:</p>"},{"location":"aurora/system-updates/#mpich","title":"MPICH","text":"<ul> <li>Roll back default MPICH to mpich/opt/develop-git.6037a7a (5.0.0.aurora_test.06f012a is still available)</li> <li>use internal yaksa build for versions develop-git.6037a7a and 5.0.0.aurora_test.06f012a</li> <li>use yaksa v0.4 for versions 4.2.3 and 4.3.1</li> </ul>"},{"location":"aurora/system-updates/#oneapi","title":"oneAPI","text":"<ul> <li>Fix module environment to match oneAPI install's setvars.sh</li> </ul>"},{"location":"aurora/system-updates/#notable-fixes","title":"Notable Fixes","text":"<p>We had 32 fixes in the new SDK based on the bug reproducer test set. Notable fixes include: - SYCL In-order queue fixed (affecting any application using in-order SYCL queues) - Bug in SYCL peer_access fixed - Runtime error in pytorch with CCL_BCAST fixed - Compile fail in Lattice App fixed - Fails in fortran if compiled with MKL and -fpe0 fixed - Issues with \u201c-fopenmp-target-simd\u201d usage fixed</p> <p>See section \"2025-09-08\"  below for the original change log.</p>"},{"location":"aurora/system-updates/#2025-09-08","title":"2025-09-08","text":"<p>We have a temporary test queue <code>next-eval</code> (open to all users) with 2,688 nodes that has a new compute image. UAN-0014 has the new software image and can be used for compiling. Please prioritize use of <code>next-eval</code> queue for testing and evaluation. See Running jobs on Aurora for queue policies.</p> <p>The new image includes updates to Intel's User (UMD) and Kernel Mode Drivers (KMD) (Agama 1146.12 / rolling release 2523.12), and OneAPI 2025.2.0.</p> <p>Details of the full change log are below (next-eval test queue only):</p>"},{"location":"aurora/system-updates/#os-image-compute_aurora_test_20250905t165210_95b26e6","title":"OS Image - compute_aurora_test_20250905T165210_95b26e6","text":"<ul> <li>Intel KMD/UMD 1146.12 / Rolling Release 2523.12</li> <li>Intel SEPDK KMDs from OneAPI 2025.2.0</li> <li>Cray PALS 1.8.0 - (Built from source on SLES 15 SP4 against PMIX 4.2.9)</li> <li>Cray PE 25.03, drop old Cray PE 23.03</li> <li>Geompm 3.2.0</li> <li>DAOS Agent 2.6.4 RC1</li> <li>Lustre cray-2.15.B21</li> <li>vastnfs 4.0.34 (replaces inbox NFS client so used on OS boot, PE, /soft.)</li> <li>Pin sssd to CPU cores 0,52,104,156</li> <li>Set kernel.hung_task_check_interval_secs = 120</li> <li>Set kernel.softlockup-all-cpu-backtrace = 1</li> <li>Add HWLOC_COMPONENTS=\"-levelzero\" to palsd systemd unit, disabling the level-zero plugin in hwloc for the palsd process itself, as palsd uses level-zero directly for GPU discovery.</li> </ul>"},{"location":"aurora/system-updates/#ecb-firmware","title":"ECB Firmware","text":"<ul> <li>pciesw[0-1] - 4.16.0.0</li> <li>PVC IFWI - 25WW204PSIFWI_14MHzQuadDAMen_CSC201051902_FSP10000735_HBMIO21c0_HSPHY10462011_OOBMSM23WW26A_PCODE18b_ITDa2p75ITDb1p5_IFRv1332PSCv0811</li> <li>BMC - bdk-0.0.2916b-71bfb1c-8bfb67d-51d61d7-eng</li> </ul>"},{"location":"aurora/system-updates/#pe-251900","title":"PE 25.190.0","text":"<ul> <li>OneAPI 2025.2.0</li> <li>Spack<ul> <li>Spack configurations are now available in /opt/aurora/25.190.0/spack/unified/0.10.0/config</li> <li>Compatible with Spack v0.23.1</li> <li>Package additions: subversion, zip, py-parsl, py-mpi4py, py-h5py</li> <li>ML Components added in Spack</li> <li>py-torch: 2.7.1.a0, 2.8.0.a0, 2.9.0.dev20250804</li> <li>py-torchaudio: 2.7.1.a0, 2.8.0.a0, 2.8.0.dev20250807</li> <li>py-torchvision: 0.22.1a0, 0.23.0a0, 0.24.0.dev20250807</li> <li>py-triton-xpu: 3.4.x, git.83367a9</li> <li>py-oneccl-bind-pt: 2.7.0xpu, 2.8.0xpu, master</li> <li>py-deepspeed: 0.17.4, master</li> <li>py-ipex: 2.7.10xpu, 2.8.10xpu, xpu-main</li> <li>GEOPM 3.2.0</li> <li>reframe: include fast polling variant (reframe-compute; please only use this if running directly from a compute node)</li> <li>darshan-runtime: 3.4.7, set MPICH profiles. Applications built with darshan-runtime loaded will be built with automatic instrumentation at runtime.</li> <li>MPICH@aurora</li> <li>Uses aurora branch of upstream mpich - https://github.com/pmodels/mpich/tree/aurora</li> <li>Manually set MPIR_CVAR_CH4_OFI_EAGER_THRESHOLD=1000000 so large message above 1MB will use the new auto rndv mode which includes the pipeline algorithm.</li> <li>Default tuning files</li> <li>petsc: use 64-bit indices</li> <li>numpy: build with GCC to workaround compiler segfault</li> <li>hdf5 +map</li> <li>apptainer: 1.4.1</li> <li>kokkos, kokkos-kernels: 4.7.00</li> <li>hypre@435e042</li> <li>stat@6c83af9</li> <li>minor version updates to several other packages</li> </ul> </li> </ul>"},{"location":"aurora/system-updates/#frameworks-preview","title":"Frameworks-Preview","text":"<ul> <li><code>miniforge</code> based <code>conda</code> environment with source builds of<ul> <li>torch 2.8.0a0+gitba56102</li> <li>torchao 0.12.0+git442232fbf</li> <li>torchdata 0.11.0+377e64c</li> <li>torchtune 0.6.1 -- but the <code>conda/pip</code> list version appears as <code>0.0.0</code></li> <li>torchvision 0.23.0a0+824e8c8</li> <li>intel-extension-for-pytorch 2.8.10+git09505bb</li> <li>pytorch-triton-xpu 3.4.0+gitae324eea</li> <li>deepspeed 0.17.5+047a7599</li> <li>deepspeed-kernels 0.0.1.dev1698255861</li> <li>scikit-learn-intelex 20250822.140259</li> <li>numba_dpex 0.23.0+31.g63ac57378</li> <li>dpnp 0.18.1</li> <li>dpctl 0.20.2</li> <li>vllm 0.10.1rc2.dev189+ge2db1164a.xpu</li> <li>mpi4py 4.1.0</li> <li>h5py 3.14.0</li> </ul> </li> <li>Associated 302 dependency packages coming exclusively from <code>pip</code></li> <li><code>torchtitan==0.1.0</code> dependencies included</li> <li>Major changes:<ul> <li>Dropped <code>JAX</code> for this iteration. Expected to be added back in future updates.</li> <li>Separated <code>TensorFlow</code> and <code>Horovod</code> in favor of a separate ecosystem</li> <li>Removed <code>oneccl-bindings-for-pytorch</code> in favor of the <code>xccl</code> backend of the PyTorch-DDP. This is a breaking change:</li> <li>PyTorch-DDP must be initialized with <code>backend='xccl'</code> instead of <code>backend='ccl'</code></li> <li><code>import oneccl_bindings_for_pytorch</code> must be removed, otherwise <code>ModuleNotFoundError</code></li> <li>Introducing <code>numpy==2.0.2</code></li> <li>All of the PyTorch eco-system has been compiled with <code>numpy==2.0.2</code><ul> <li>Workloads using <code>numpy==1.x.x</code> should work seamlessly, as compilations with numpy&gt;2.0.0 promises backward compatibility. Please report issues to ALCF Support.</li> </ul> </li> </ul> </li> <li>Framework-Preview - Known Issues</li> <li><code>conda list</code> throws a warning about <code>setuptools</code> and freeing file handles.</li> <li><code>DeepSpeed</code> <code>JIT</code> compilation failure</li> <li><code>oneccl</code> collectives requiring explicit synchronization step<ul> <li>Workaround: <code>export CCL_OP_SYNC = 1</code> set in frameworks module</li> </ul> </li> <li><code>oneccl</code> Rabenseifner algorithm for <code>Allreduce</code> failure (potential bug). Recommending <code>direct</code></li> <li><code>vLLM</code> failure to start EngineCore on multiple ranks<ul> <li>Workaround <code>unset CCL_PROCESS_LAUNCHER &amp;&amp; export CCL_PROCESS_LAUNCHER=None &amp;&amp; unset ONEAPI_DEVICE_SELECTOR</code></li> </ul> </li> <li>Potential issues with <code>mlflow</code> -- a <code>torchtune</code> dependency -- used for tracing and hyper-parameter tracking, very similar to <code>wandb</code>. <code>mlflow</code> will be removed in future updates.</li> </ul>"},{"location":"aurora/system-updates/#2025-06-13-lowering-the-memory-limit-on-aurora-compute-nodes-on-june-23-2025","title":"2025-06-13 (Lowering the memory limit on Aurora compute nodes on June 23, 2025)","text":"<p>ALCF is going to reduce user-accessible memory on Aurora compute nodes, by the equivalent of a node's HBM capacity (128GB), on June 23, 2025, to approximately 960GB between DDR5 + HBM, regardless of how applications utilize each memory tier. The 768GB of GPU memory is unaffected and is not being restricted in any way.</p> <p>Note that, currently on Aurora, ALCF enforces a memory limit on compute nodes such that users are allowed between MemTotal - 64GB (soft limit) and MemTotal - 32GB (hard limit), effectively reserving between 32GB and 64GB for system use. MemTotal refers to approximately 1TB of DDR5 plus 128GB of HBM.</p> <p>However, with our current approach due to limitations in cgroup-based enforcement, we are unable to constrain memory usage at the per-NUMA-node level. In other words we can't limit the memory used on DDR5 separately from HBM NUMA nodes. The kernel only gives the capability to limit via overall bytes allocated.</p> <p>This results in often out-of-memory (OOM) conditions in DDR5 NUMA nodes 0 and 1, Reducing our ability to protect system services and prevent node-wide panics triggered by OOMs.</p>"},{"location":"aurora/system-updates/#2025-04-28","title":"2025-04-28","text":"<p>Due to significant changes resulting from the PM,  recompiling codes is strongly recommended.</p>"},{"location":"aurora/system-updates/#release-notes","title":"Release notes","text":"<ul> <li>Intel Agama KMD 1099.12</li> <li>Intel Agama UMD 1099.12<ul> <li>Release notes:\u00a0https://dgpu-docs.intel.com/releases/packages.html?release=Rolling+2507.12&amp;os=SLES+15SP4</li> </ul> </li> <li>Intel Vtune Sepdk KMD from 2025.0.5</li> <li>Slingshot Host Software 11.1</li> <li>libfabric 1.22.0 compiled from HPE SHS-12.0</li> <li>mcelog v204</li> <li>Added named (bind) as local caching DNS resolver</li> <li>Migrate to HPCM 1.10 node packages / filebeat dropping journalbeat</li> <li>Increase somaxconn and tcp_max_syn_backlog to 10624_12_2 to help address Aurora PyTorch init and socket limitations</li> <li>Update libstdc++6-13.2.1+git7813-150000.1.6.1.x86_64 to support Intel UMD 1099.12 release.</li> <li>Add libnuma-devel to UAN and Compute image</li> <li>lmod 8.7.59</li> <li>Pinned telegraf to cores 0,52,104,156</li> <li>Pinned filebeat to cores 0,52,104,156</li> <li>Add udev rule to set the register/bit for the PVC IFWI to unlock VSP credit</li> </ul> <p>FW </p> <ul> <li>BMC - \"2916\" - bdk-0.0.2916-71bfb1c-8bfb67d-51d61d7-eng</li> <li>BIOS (SPR IFWI) - \"113.D55\" - EGSDCRB1.NWM.0113.D55.2501241829</li> <li>PVC IFWI - \"25WW083\" - 24WW083PSIFWI_14MHzQuadDAMen_CSC201051901_FSP10000733_HBMIO21c0_HSPHY10462011_OOBMSM23WW26A_PCODE44C_ITDa2p75ITDb1p5_IFRv1332PSCv0811</li> </ul> <p>PE 24.347.0 </p> <ul> <li>Intel Compiler update in AuroraSDK to 2025.0.5<ul> <li>Compiler/MKL 2025.0.1<ul> <li>basekit-2025.0.1</li> <li>hpckit-2025.0.1</li> <li>mkl-core-2025.0-2025.0.1</li> </ul> </li> <li>Frameworks 2025.0.5<ul> <li>torch==2.5.1+cxx11.abi</li> <li>intel_extension_for_pytorch==2.5.10+xpu</li> <li>oneccl_bind_pt==2.5.0+xpu</li> <li>torchvision==0.20.1+cxx11.abi</li> <li>intel-extension-for-tensorflow[xpu]==2.15.0.2</li> <li>intel-extension-for-openxla==0.5.0\u00a0</li> </ul> </li> </ul> </li> <li>Support libraries<ul> <li>Updated OpenCL headers, loader 2022.05.18 to 2023.12.14<ul> <li>To match\u00a0https://github.com/intel/compute-runtime/tree/master/third_party/opencl_headers</li> </ul> </li> <li>gpu wrapper scripts tile and dev compact revamp with fixes</li> <li>Dropped gpu_check script</li> <li>Added gemm node test</li> <li>Added valgrind suppression config</li> </ul> </li> <li>Fixed mpich-config lua module to load correctly</li> <li>Updated forge 24.1.1 to 24.1.2<ul> <li>Added symlink to latest forge path.</li> <li>Users can now access a default forge install by, /opt/aurora/default/support/tools/forge/latest</li> </ul> </li> <li>PTI GPU tools update d3639de to 0.11.0</li> <li>Updated to Spack PE v0.9.2<ul> <li>apptainer: build git commit 39e5a8f</li> <li>buildah: 1.38.1</li> <li>double-batched-fft-library: fix build flags and deps for +sycl</li> <li>hwloc: v2.11-mpich, add patch, force autoreconf</li> <li>hypre: v2.33.0 +sycl +mixedint</li> <li>kokkos: add 4.5.01</li> <li>kokkos-kernels: add 4.5.01<ul> <li>Dropped 4.5.01 sycl variant: Build failed on OneAPI 2025.0.5</li> </ul> </li> <li>libceed: add sycl variant, track alcf fork</li> <li>mpich: aurora branch (6037a7a); variants: ze, filesystem, daos, misc configuration; add patches from ALCF + Intel; hardcode some configs.</li> <li>petsc: add patches, sycl-arch variant, kokkos dependencies<ul> <li>Dropped sycl variant: Build failed on OneAPI 2025.0.5</li> </ul> </li> <li>reframe: v4.7.4</li> <li>adios2: fix python env location</li> <li>thapi: 9f2ed86b</li> <li>Umpire: Add MPI variant</li> </ul> </li> </ul>"},{"location":"aurora/system-updates/#test-set-results-on-the-new-sdk","title":"Test set results on the new SDK","text":"<p>We ran the test set on the new SDK and overall the results had more fixes than regressions:</p> <p>Regressions and Fixes: - 37 Fixes  - 9 regressions</p> <p>One important note is that kokkos kernels fail to compile in this SDK. If this impacts you, please let us know.</p> <p>The list of all regressions and fixes is below. If you see any new issues with this compute image, let us know.</p> <p>List of regressions:</p> <ul> <li>source/reproducers/openmp/simd_loops [CMPLRLLVM-38420] P0</li> <li>source/reproducers/ifx/CMPLRLLVM-35621</li> <li>source/reproducers/ifx/XDEPS-5191:XDEPS-5191_simd</li> <li>source/reproducers/ifx/phasta_target_simd [CMPLRLLVM-35621,CMPLRLLVM-40195,CMPLRLLVM-52024,GSD-6634] P0</li> <li>source/reproducers/icx/assert_problem [CMPLRLLVM-62420]</li> <li>source/reproducers/dpcpp/catch2_segfault:catch2_segfault_all_at_once_ath_run [CMPLRLLVM-40048,GSD-10857] P0</li> <li>source/reproducers/mkl/sparse_openmp_kokkos_kernels:sparse_openmp_kokkos_kernels_amazon0302_ath_run [MKLD-12835,MKLD-14715,GSD-10930]</li> <li>source/reproducers/mkl/sparse_openmp_kokkos_kernels:sparse_openmp_kokkos_kernels_europe_osm_ath_run [MKLD-12835,MKLD-14715,GSD-10930]</li> <li>source/reproducers/mkl/sparse_openmp_kokkos_kernels:sparse_openmp_kokkos_kernels_wb-edu_ath_run [MKLD-12835,MKLD-14715,GSD-10930]</li> </ul> <p>List of Fixes:</p> <ul> <li>source/reproducers/dpcpp/FMM [CMPLRLLVM-28325] P0</li> <li>source/reproducers/dpcpp/VirtualFunction:VirtualFunction_newminimal_ath_compile [CMPLRLLVM-35295,XDEPS-6157,CMPLRLLVM-48349,CMPLRLLVM-50632] P0</li> <li>source/reproducers/dpcpp/VirtualFunction:VirtualFunction_newminimal_ath_run [CMPLRLLVM-35295,XDEPS-6157,CMPLRLLVM-48349,CMPLRLLVM-50632] P0</li> <li>source/reproducers/dpcpp/device_copyable_dpl [CMPLRLLVM-57788,CMPLRLLVM-58384]</li> <li>source/reproducers/dpcpp/hang_inline_workgroup:hang_inline_workgroup_ath_run [CMPLRLLVM-47914,CMPLRLLVM-54117]</li> <li>source/reproducers/dpcpp/library_jit_main:library_jit_main_aot_shared_jit_main [CMPLRLLVM-41597]</li> <li>source/reproducers/dpcpp/library_jit_main:library_jit_main_aot_static_jit_main [CMPLRLLVM-41597]</li> <li>source/reproducers/dpcpp/madgraph4gpu-SYCL-gg_ttggg-nocompile:madgraph4gpu-SYCL-gg_ttggg-nocompile_gg-ttggg_ath_compile [CMPLRLLVM-35981,XDEPS-3923] P0</li> <li>source/reproducers/dpcpp/ms371-InlineAsm:ms371-InlineAsm_asm_bad_opcode [cmplrllvm-46097,GSD-7606,GSD-7621,CMPLRLLVM-57331,URLZA-308]</li> <li>source/reproducers/dpcpp/ms371-InlineAsm:ms371-InlineAsm_asm_bad_operand_syntax [cmplrllvm-46097,GSD-7606,GSD-7621,CMPLRLLVM-57331,URLZA-308]</li> <li>source/reproducers/dpcpp/ms371-InlineAsm:ms371-InlineAsm_asm_duplicate_label [cmplrllvm-46097,GSD-7606,GSD-7621,CMPLRLLVM-57331,URLZA-308]</li> <li>source/reproducers/dpcpp/ms371-InlineAsm:ms371-InlineAsm_asm_illegal_exec_size [cmplrllvm-46097,GSD-7606,GSD-7621,CMPLRLLVM-57331,URLZA-308]</li> <li>source/reproducers/dpcpp/ms371-InlineAsm:ms371-InlineAsm_asm_missing_label [cmplrllvm-46097,GSD-7606,GSD-7621,CMPLRLLVM-57331,URLZA-308]</li> <li>source/reproducers/dpcpp/ms371-InlineAsm:ms371-InlineAsm_asm_missing_region [cmplrllvm-46097,GSD-7606,GSD-7621,CMPLRLLVM-57331,URLZA-308]</li> <li>source/reproducers/dpcpp/ms371-InlineAsm:ms371-InlineAsm_asm_simple [cmplrllvm-46097,GSD-7606,GSD-7621,CMPLRLLVM-57331,URLZA-308]</li> <li>source/reproducers/dpcpp/ms371-InlineAsm:ms371-InlineAsm_asm_undefined_decl [cmplrllvm-46097,GSD-7606,GSD-7621,CMPLRLLVM-57331,URLZA-308]</li> <li>source/reproducers/dpcpp/ms371-InlineAsm:ms371-InlineAsm_asm_undefined_pred [cmplrllvm-46097,GSD-7606,GSD-7621,CMPLRLLVM-57331,URLZA-308]</li> <li>source/reproducers/dpcpp/ms371-InlineAsm:ms371-InlineAsm_asm_wrong_declare [cmplrllvm-46097,GSD-7606,GSD-7621,CMPLRLLVM-57331,URLZA-308]</li> <li>source/reproducers/dpcpp/sincos source/reproducers/dpcpp_ct/binary [OTFIP-248]</li> <li>source/reproducers/dpcpp_ct/segfault_build source/reproducers/dpcpp_ct/vector_trans [OTFIP-449]</li> <li>source/reproducers/hybrid/oneConcurency:oneConcurency_omp_nowait_ath_run [CMPLRLLVM-34779,CMPLRLLVM-38250,CMPLRLLVM-40729,XDEPS-2202,XDEPS-3493,XDEPS-5689,CMPLRLIBS-35258] P0</li> <li>source/reproducers/icx/global_bool_isoc_binding:global_bool_isoc_binding_read [CMPLRLLVM-57643,CMPLRLLVM-57935]</li> <li>source/reproducers/ifx/bgw_compare_wfns P0 source/reproducers/ifx/fopenmp-target-simd-data:fopenmp-target-simd-data_four [GSD-8346,CMPLRLLVM-63003]</li> <li>source/reproducers/ifx/fopenmp-target-simd-data:fopenmp-target-simd-data_one [GSD-8346,CMPLRLLVM-63003]</li> <li>source/reproducers/ifx/fopenmp-target-simd-data:fopenmp-target-simd-data_three [GSD-8346,CMPLRLLVM-63003]</li> <li>source/reproducers/ifx/fopenmp-target-simd-data:fopenmp-target-simd-data_two [GSD-8346,CMPLRLLVM-63003]</li> <li>source/reproducers/mkl/fft2d_scale [MKLD-13250] source/reproducers/mkl/slow_batch_getrs [MKLD-15079]</li> <li>source/reproducers/mkl/zgetrs_batch_slowdown [MKLD-15212,MKLD-15906,MKLD-16680]</li> <li>source/reproducers/openmp/ddpp_gamess_mini_wrong_answer_fp_precise [CMPLRLLVM-45082,GSD-7772]</li> <li>source/reproducers/openmp/oneapi_device_selector_test:oneapi_device_selector_test_ath_run [CMPLRLLVM-60986]</li> <li>source/reproducers/openmp/performance_increading_kernels source/reproducers/openmp/workshare_performance [CMPLRLLVM-43487]</li> <li>source/reproducers/tools/advisor_length [ADV-10315]</li> </ul>"},{"location":"aurora/applications-and-libraries/libraries/cabana-aurora/","title":"Cabana","text":""},{"location":"aurora/applications-and-libraries/libraries/cabana-aurora/#cabana_1","title":"Cabana","text":"<p>Cabana is built atop Kokkos. It provides class templates useful for implementing particle codes.</p>"},{"location":"aurora/applications-and-libraries/libraries/cabana-aurora/#cabana-documentation","title":"Cabana Documentation","text":"<ul> <li>Cabana Wiki</li> <li>Cabana GitHub</li> </ul>"},{"location":"aurora/applications-and-libraries/libraries/cabana-aurora/#cabana-on-aurora","title":"Cabana on Aurora","text":"<p>Built against the prebuilt Kokkos on Aurora, the prebuilt Cabana includes three backends: Serial and OpenMP for CPU execution and SYCL for GPU execution. To use it, run:</p> <pre><code>module load cabana\n</code></pre> <p>Currently, Cabana is a headers-only installation; there are no libraries per se.</p>"},{"location":"aurora/applications-and-libraries/libraries/onedal/","title":"oneDAL","text":"<p>oneAPI Data Analytics Library (oneDAL) is a library for big data analysis, which includes support for CPUs and GPUs. It includes machine learning algorithms such as k-means clustering and random forests, and it provides support for batch, online, and distributed processing modes. This page is about using the C++ API on Aurora. However, oneDAL can also be used in Python via the Intel Extension for scikit-learn, which we document in the Data Science section. </p> <p>For more information, see the oneDAL Github page, the documentation, or Intel's website. To run on the Intel GPUs, use the oneAPI DPC++ interface. (DPC++, or Data Parallel C++, is oneAPI's implementation of SYCL, so you also see references to options with and without SYCL support in the oneDAL documentation.) </p>"},{"location":"aurora/applications-and-libraries/libraries/onedal/#environment-setup","title":"Environment Setup","text":"<p>oneAPI, including oneDAL, is included in the default environment on Aurora. </p>"},{"location":"aurora/applications-and-libraries/libraries/onedal/#usage","title":"Usage","text":"<p>For a full GPU example, see the oneDAL documentation Quick Start page. However, note that you do not need to set up the environment if you are using the oneDAL installation in the default Aurora environment. </p> <p>For distributed mode, oneDAL offers two communication options: CCL and MPI. We recommend using the MPI option, which is more tested on Aurora. For examples of distributed oneDAL, see the samples/oneapi/dpc/mpi folder in oneDAL's Github repo. </p>"},{"location":"aurora/applications-and-libraries/libraries/spack-pe/","title":"Spack PE","text":"<p>The Spack PE is a software stack that provides various build tools, utilities, and libraries. The Spack PE consists of two parts: <code>spack-pe-gcc</code> and <code>spack-pe-oneapi</code>. <code>spack-pe-gcc</code> contains commonly used software packages compiled for CPU. <code>spack-pe-oneapi</code> is based on the E4S Project and provides performant HPC libraries built with the OneAPI SDK. <code>spack-pe-oneapi</code> depends on both <code>spack-pe-gcc</code> and the OneAPI SDK; in combination, the Spack PE with the OneAPI SDK and MPICH constitute the Aurora PE.</p>"},{"location":"aurora/applications-and-libraries/libraries/spack-pe/#using-software-from-the-spack-pe","title":"Using software from the Spack PE","text":"<p>The Spack PE is loaded into the environment by default as part of the Aurora PE. To view the available modules, run <code>module avail</code>. A full listing of software, including hidden dependencies, can be viewed with <code>module --show-hidden avail</code>. The Spack PE modules will be in paths under <code>/opt/aurora/&lt;AURORA_PE_VERSION&gt;/spack</code>. These can be loaded like any other module, for example, with <code>module load cmake</code>.</p>"},{"location":"aurora/applications-and-libraries/libraries/spack-pe/#inspecting-packages","title":"Inspecting packages","text":"<p>When a module within the Spack PE is loaded, several environment variables are updated to integrate the package into the user's environment. Additionally, the <code>PACKAGE_ROOT</code> variable is set to contain the path to the installation prefix of the package. For example, after loading <code>cmake</code>:</p> <pre><code>$ echo $CMAKE_ROOT\n/opt/aurora/23.275.2/spack/gcc/0.6.1/install/linux-sles15-x86_64/gcc-12.2.0/cmake-3.27.7-mbl7dvgbiblpavhu53h5cheyrmpaikdz\n$ ls -a $CMAKE_ROOT\n.  ..  bin  doc  share  .spack\n</code></pre> <p>This variable can be used to inspect software installations. Additionally, Spack packages have a <code>.spack</code> directory in the installation prefix, which contains build logs and information on configure and build options.</p>"},{"location":"aurora/applications-and-libraries/libraries/spack-pe/#rpath-linking","title":"RPATH linking","text":"<p>Spack PE packages are built with <code>RPATH</code> linking. <code>RPATH</code> hardcodes a default search path for dynamic runtime linking of binaries. By setting <code>RPATH</code>, the loader only needs to search a single path for each library, reducing the number of filesystem calls performed when loading libraries. However, this means <code>LD_LIBRARY_PATH</code> will be ignored when loading binaries installed in the Spack PE. This has been set both to provide a performance benefit and to guarantee proper compatibility of linked libraries.</p> <p>Software installed outside of the Spack PE tree, such as in <code>/soft</code>, will typically be installed with <code>RUNPATH</code> linking or with no runtime search path, both of which respect <code>LD_LIBRARY_PATH</code>. <code>RUNPATH</code> linking, like <code>RPATH</code>, hardcodes a default path, but it does not have precedence over <code>LD_LIBRARY_PATH</code>. Spack PE preview deployments in <code>/soft</code> are installed with <code>RUNPATH</code> linking.</p>"},{"location":"aurora/applications-and-libraries/libraries/spack-pe/#building-software-with-spack","title":"Building software with Spack","text":"<p>Spack is a powerful package manager designed for HPC. The Spack PE is installed and managed with Spack; users can also install Spack in their own home or project directory to manage their software builds. Spack has a steep learning curve, but it may benefit workflows involving frequent builds with complex dependencies.</p> <p>For users who wish to use Spack to install their own software, we provide configuration files corresponding to the Spack PE deployments. These configuration files can be found in <code>/opt/aurora/&lt;AURORA_PE_VERSION&gt;/spack</code> in <code>config</code> directories organized by Spack PE version. Not all of these settings will be useful for all builds, and it is not recommended to adopt these wholesale as global settings. The recommended method is to include these settings ad hoc in a Spack environment to control what information Spack uses for its builds. However, we do recommend using the provided configurations for the compilers, OneAPI SDK components, and MPICH, as these can be difficult to configure properly.</p> <p>Support requests and feedback for ALCF-specific issues should be directed to support@alcf.anl.gov. For general Spack questions, users are encouraged to consult the following resources:</p> <ul> <li>Spack development website</li> <li>Spack documentation</li> <li>Spack tutorial</li> <li>Spack Slack channel</li> </ul>"},{"location":"aurora/build-tools/cmake-aurora/","title":"CMake","text":""},{"location":"aurora/build-tools/cmake-aurora/#cmake_1","title":"CMake","text":"<p>CMake is a build configuration system that uses higher-level description files to automatically generate Makefiles.</p>"},{"location":"aurora/build-tools/cmake-aurora/#cmake-documentation","title":"CMake Documentation","text":"<ul> <li>CMake website</li> </ul>"},{"location":"aurora/build-tools/cmake-aurora/#cmake-on-aurora","title":"CMake on Aurora","text":"<p>To use CMake on Aurora, run:</p> <pre><code>module load cmake\n</code></pre>"},{"location":"aurora/compiling-and-linking/","title":"Compiling and Linking Overview","text":""},{"location":"aurora/compiling-and-linking/#compiling-on-aurora-login-and-compute-nodes","title":"Compiling on Aurora Login and Compute Nodes","text":"<p>If your build system does not require GPUs for the build process, the compilation of GPU-accelerated codes is generally expected to work well on the Aurora login nodes. If your build system does require GPUs, then currently that must be done on the compute nodes either via an interactive or batch job submission. Doing this interactively in a single-node job may be the preferred route as it also provides an opportunity to quickly test the executable.</p>"},{"location":"aurora/compiling-and-linking/#filesystem","title":"Filesystem","text":"<p>It is helpful to realize that the home filesystem is <code>gecko</code> and the <code>project</code> spaces reside on the Lustre filesystem called <code>Flare</code>. The filesystems are not backed up, and users should take care to retain copies of important files (e.g., local resources or ALCF's <code>eagle</code> filesystem).</p>"},{"location":"aurora/compiling-and-linking/#oneapi-programming-environment","title":"OneAPI Programming Environment","text":"<p>The oneAPI programming environment is currently the single environment for building and running software to maximally use the available hardware resources. The oneAPI environment is loaded by default for users and is principally defined by the following set of modules and related variants.</p> <ul> <li>oneapi: Intel oneAPI HPC toolkit.</li> <li>mpich: MPI libraries.</li> </ul> <p>Additional modules loading <code>GNU</code> CPU compilers and parallel application launch support (e.g., libfabric and cray-pals) are also provided in the default environment. The oneAPI environment provides C, C++, and Fortran compilers and associated MPICH MPI wrappers for building applications targeting CPUs and GPUs based on the OpenMP, SYCL, and OpenCL programming models.</p> <ul> <li><code>mpicc</code> - C Compiler</li> <li><code>mpicxx</code> - C++ Compiler (a.k.a <code>mpic++</code>)</li> <li><code>mpifort</code> - Fortran Compiler (a.k.a <code>mpif70</code> &amp; <code>mpif90</code>)</li> </ul>"},{"location":"aurora/compiling-and-linking/#mixed-cc-fortran-applications","title":"Mixed C/C++ &amp; Fortran Applications","text":"<p>For applications consisting of a mix of programming languages that use MPI, it is important to use the same Fortran compiler for building the application as was used to build MPI because of mpi.mod (and similar) incompatibilities.</p>"},{"location":"aurora/compiling-and-linking/#additional-software-and-build-tools","title":"Additional Software and Build Tools","text":"<p>A suite of build tools and libraries are available in the default Aurora PE environment. Users can look at the list of available modules with <code>module avail</code> to find build tools such as <code>cmake</code>.</p> <pre><code>$ module load cmake\n$ cmake --version\ncmake version 3.27.7\n</code></pre>"},{"location":"aurora/compiling-and-linking/aurora-example-program-makefile/","title":"Aurora Example Program Makefile","text":"<p>Several simple examples of building CPU and GPU-enabled codes on Aurora are available in the ALCF GettingStarted repo for supported programming models. If building your application on the login node is problematic for some reason (e.g., absence of a GPU), then users are encouraged to build and test applications directly on one of the Aurora compute nodes via an interactive job. The discussion below makes use of the <code>oneAPI</code> compilers in the default environment as illustrative examples.</p>"},{"location":"aurora/compiling-and-linking/aurora-example-program-makefile/#cpu-mpiopenmp-example","title":"CPU MPI+OpenMP Example","text":"<p>One of the first useful tasks with any new machine, scheduler, and job launcher is to ensure one is binding MPI ranks and OpenMP threads to the host CPU as intended. A simple HelloWorld MPI+OpenMP example is available here to get started with.</p> <p>The Aurora compute nodes are dual-socket with 52 physical cores in each socket for a total of 104 cores. As hyperthreading is enabled, each core will show up as two CPUs for a total of 208. In many of the examples below, only a single process is spawned on each physical core.</p> <p>The application can be straightforwardly compiled using the MPICH compiler wrappers in the default environment.</p> <pre><code>mpicxx -g -fopenmp -O3 main.cpp\n</code></pre> <p>The executable <code>hello_affinity</code> can then be launched in a job script (or directly in the shell of an interactive job) using <code>mpiexec</code> as discussed here.</p> <pre><code>#!/bin/bash -l\n#PBS -l select=1\n#PBS -l place=scatter\n#PBS -l walltime=0:15:00\n#PBS -q &lt;queue&gt;\n#PBS -A &lt;ProjectName&gt;\n#PBS -l filesystems=&lt;fs1:fs2&gt;\n\n#cd ${PBS_O_WORKDIR}\n\n# MPI example w/ MPI ranks and OpenMP threads spread evenly across cores (one process per physical core)\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=26\nNDEPTH=4\nNTHREADS=4\n\nNTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))\necho \"NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}\"\n\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth --env OMP_NUM_THREADS=${NTHREADS} --env OMP_PLACES=cores ./hello_affinity\n</code></pre>"},{"location":"aurora/compiling-and-linking/aurora-example-program-makefile/#gpu-openmp-example","title":"GPU OpenMP Example","text":"<p>A simple OpenMP offload example is available here. Compilation proceeds similarly to the above CPU-only example except for the use of compiler flags to enable GPU offload.</p> <pre><code>mpicxx -fiopenmp -fopenmp-targets=spir64 main.cpp\n</code></pre> <p>Running the example with 12 MPI ranks and no other settings will generate output like the following.</p> <pre><code>$ make\n\n$ mpiexec -n 12 --ppn 12 --depth=1 --cpu-bind depth ./hello_affinity\nNUM_OF_NODES= 1 TOTAL_NUM_RANKS= 12 RANKS_PER_NODE= 12 THREADS_PER_RANK= 1\n\n  Using OPENMP v5.0\n  num_devices=     6\n  Default device=  0\n  Host=            6\n  num_teams=       896\n  num_threads=     1\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 0  list_cores= (0)  num_devices= 6  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 1  list_cores= (1)  num_devices= 6  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 2  list_cores= (2)  num_devices= 6  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 3  list_cores= (3)  num_devices= 6  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 4  list_cores= (4)  num_devices= 6  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 5  list_cores= (5)  num_devices= 6  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 6  list_cores= (6)  num_devices= 6  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 7  list_cores= (7)  num_devices= 6  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 8  list_cores= (8)  num_devices= 6  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 9  list_cores= (9)  num_devices= 6  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 10  list_cores= (10)  num_devices= 6  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 11  list_cores= (11)  num_devices= 6  gpu_id= 0\n</code></pre> <p>This simple application does not handle binding of MPI ranks to GPUs, so each of the 12 MPI ranks detects all six GPUs on the node and by default all will select the first GPU listed. The binding of MPI ranks to GPUs can be handled by <code>mpiexec</code> in the near future, but for the time being a simple helper script is available for those that need it. There is a centrally installed general <code>gpu_tile_compact.sh</code> script available for use, but the examples include the following example script for convenience in case one would like to explore different CPU-GPU bindings (e.g., bind first N MPI ranks to the first GPU).</p> <pre><code>$ cat set_affinity_gpu_aurora.sh \n#!/usr/bin/env bash\n\nnum_gpu=6\nnum_tile=2\n\ngpu_id=$(( (PALS_LOCAL_RANKID / num_tile ) % num_gpu ))\ntile_id=$((PALS_LOCAL_RANKID % num_tile))\n\nunset EnableWalkerPartition\nexport ZE_ENABLE_PCI_ID_DEVICE_ORDER=1\nexport ZE_AFFINITY_MASK=$gpu_id.$tile_id\n\necho \"RANK= ${PALS_RANKID} LOCAL_RANK= ${PALS_LOCAL_RANKID} gpu= ${gpu_id}  tile= ${tile_id}\"\n\n#https://stackoverflow.com/a/28099707/7674852\n\"$@\"\n</code></pre> <p>The <code>ZE_AFFINITY_MASK</code> environment variable sets the devices that will be available to the CPU process and can be a comma-separated list of GPUs and/or GPU tiles. Each Aurora GPU consists of two tiles that can be separately bound to CPU processes. This simple script will set <code>ZE_AFFINITY_MASK</code> for each MPI rank such that GPU tiles on a node are round-robin assigned.</p> <pre><code>$ mpiexec -n 12 --ppn 12 --depth=1 --cpu-bind depth ./set_affinity_gpu_aurora.sh ./hello_affinity\nNUM_OF_NODES= 1 TOTAL_NUM_RANKS= 12 RANKS_PER_NODE= 12 THREADS_PER_RANK= 1\n\n  Using OPENMP v5.0\n  num_devices=     1\n  Default device=  0\n  Host=            1\n  num_teams=       448\n  num_threads=     1\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 0  list_cores= (0)  num_devices= 1  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 1  list_cores= (1)  num_devices= 1  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 2  list_cores= (2)  num_devices= 1  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 3  list_cores= (3)  num_devices= 1  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 4  list_cores= (4)  num_devices= 1  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 5  list_cores= (5)  num_devices= 1  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 6  list_cores= (6)  num_devices= 1  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 7  list_cores= (7)  num_devices= 1  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 8  list_cores= (8)  num_devices= 1  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 9  list_cores= (9)  num_devices= 1  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 10  list_cores= (10)  num_devices= 1  gpu_id= 0\n\nTo affinity and beyond!! nname= x1922c1s1b0n0  rnk= 11  list_cores= (11)  num_devices= 1  gpu_id= 0\n</code></pre>"},{"location":"aurora/compiling-and-linking/aurora-example-program-makefile/#gpu-sycl-example","title":"GPU SYCL Example","text":"<p>A simple SYCL offload example is available here. Compilation proceeds similarly to the above examples except for the compiler flags enabling GPU offload.</p> <pre><code>mpicxx -std=c++17 -fsycl -fsycl-targets=spir64 main.cpp\n</code></pre> <p>Note, this particular example makes use of the Level-Zero API and requires linking with <code>-lze_loader</code>, which is not something required of a typical SYCL application. Running the SYCL example using the affinity script binding MPI ranks to individual GPU tiles results in output like the following.</p> <pre><code>$ make\n\n$ mpiexec -n 12 --ppn 12 --depth=1 --cpu-bind depth ./set_affinity_gpu_aurora.sh ./hello_affinity\n\nNUM_OF_NODES= 1 TOTAL_NUM_RANKS= 12 RANKS_PER_NODE= 12 THREADS_PER_RANK= 1\nCOMMAND= mpiexec -n 12 --ppn 12 --depth=1 --cpu-bind depth ./set_affinity_gpu_aurora.sh ./hello_affinity\n\n\"RANK= 0 LOCAL_RANK= 0 gpu= 0 tile= 0\"\n\"RANK= 1 LOCAL_RANK= 1 gpu= 0 tile= 1\"\n\"RANK= 2 LOCAL_RANK= 2 gpu= 1 tile= 0\"\n\"RANK= 3 LOCAL_RANK= 3 gpu= 1 tile= 1\"\n\"RANK= 4 LOCAL_RANK= 4 gpu= 2 tile= 0\"\n\"RANK= 5 LOCAL_RANK= 5 gpu= 2 tile= 1\"\n\"RANK= 6 LOCAL_RANK= 6 gpu= 3 tile= 0\"\n\"RANK= 7 LOCAL_RANK= 7 gpu= 3 tile= 1\"\n\"RANK= 8 LOCAL_RANK= 8 gpu= 4 tile= 0\"\n\"RANK= 9 LOCAL_RANK= 9 gpu= 4 tile= 1\"\n\"RANK= 10 LOCAL_RANK= 10 gpu= 5 tile= 0\"\n\"RANK= 11 LOCAL_RANK= 11 gpu= 5 tile= 1\"\n\nTo affinity and beyond!! nname= x1922c2s6b0n0  rnk= 0  list_cores= (0)  num_devices= 1  gpu_uuid=  01000000-0000-0000-dbb1-2f985946b0dd\nTo affinity and beyond!! nname= x1922c2s6b0n0  rnk= 1  list_cores= (1)  num_devices= 1  gpu_uuid=  02000000-0000-0000-dbb1-2f985946b0dd\n\nTo affinity and beyond!! nname= x1922c2s6b0n0  rnk= 2  list_cores= (2)  num_devices= 1  gpu_uuid=  01000000-0000-0000-9d4c-a3a038130bd2\nTo affinity and beyond!! nname= x1922c2s6b0n0  rnk= 3  list_cores= (3)  num_devices= 1  gpu_uuid=  02000000-0000-0000-9d4c-a3a038130bd2\n\nTo affinity and beyond!! nname= x1922c2s6b0n0  rnk= 4  list_cores= (4)  num_devices= 1  gpu_uuid=  01000000-0000-0000-f684-455a4554b231\nTo affinity and beyond!! nname= x1922c2s6b0n0  rnk= 5  list_cores= (5)  num_devices= 1  gpu_uuid=  02000000-0000-0000-f684-455a4554b231\n\nTo affinity and beyond!! nname= x1922c2s6b0n0  rnk= 6  list_cores= (6)  num_devices= 1  gpu_uuid=  01000000-0000-0000-d04a-9a289a53274e\nTo affinity and beyond!! nname= x1922c2s6b0n0  rnk= 7  list_cores= (7)  num_devices= 1  gpu_uuid=  02000000-0000-0000-d04a-9a289a53274e\n\nTo affinity and beyond!! nname= x1922c2s6b0n0  rnk= 8  list_cores= (8)  num_devices= 1  gpu_uuid=  01000000-0000-0000-a178-e2f3a2a0df2b\nTo affinity and beyond!! nname= x1922c2s6b0n0  rnk= 9  list_cores= (9)  num_devices= 1  gpu_uuid=  02000000-0000-0000-a178-e2f3a2a0df2b\n\nTo affinity and beyond!! nname= x1922c2s6b0n0  rnk= 10  list_cores= (10)  num_devices= 1  gpu_uuid=  01000000-0000-0000-1b72-105049dfed26\nTo affinity and beyond!! nname= x1922c2s6b0n0  rnk= 11  list_cores= (11)  num_devices= 1  gpu_uuid=  02000000-0000-0000-1b72-105049dfed26\n</code></pre> <p>Upon carefully comparing the UUIDs from each rank, one can see the first field distinguishing the 1st or 2nd tile on a GPU and the last two fields distinguishing the 6 GPUs on a compute node. If the affinity script was not used for binding MPI ranks to GPUs, then each MPI rank would report UUIDs for all GPUs like in the following.</p> <pre><code>To affinity and beyond!! nname= x1922c2s6b0n0  rnk= 0  list_cores= (0)  num_devices= 6  gpu_uuid=  00000000-0000-0000-dbb1-2f985946b0dd 00000000-0000-0000-9d4c-a3a038130bd2 00000000-0000-0000-f684-455a4554b231 00000000-0000-0000-d04a-9a289a53274e 00000000-0000-0000-a178-e2f3a2a0df2b 00000000-0000-0000-1b72-105049dfed26\n</code></pre>"},{"location":"aurora/compiling-and-linking/aurora-example-program-makefile/#gpu-opencl-example","title":"GPU OpenCL Example","text":"<p>A simple OpenCL example is available here. The <code>include</code> and <code>lib</code> directories for the OpenCL headers and libraries are in the default environment. One simply needs to link the application against <code>-lOpenCL</code>.</p> <pre><code>mpicxx main.cpp -lOpenCL\n</code></pre> <p>This simple example can be run on a single tile of an Aurora GPU as follows.</p> <pre><code>$ export XE_AFFINITY_MASK=0.0\n$ ./vecadd\nRunning on GPU!\nUsing double-precision\n\n    CL_DEVICE_NAME: Intel(R) Data Center GPU Max 1550\n    CL_DEVICE_VERSION: OpenCL 3.0 NEO \n    CL_DEVICE_OPENCL_C_VERSION: OpenCL C 1.2 \n    CL_DEVICE_MAX_COMPUTE_UNITS: 896\n    CL_DEVICE_MAX_CLOCK_FREQUENCY: 1600\n    CL_DEVICE_MAX_WORK_GROUP_SIZE: 1024\n\nResult is CORRECT!! :)\n</code></pre>"},{"location":"aurora/compiling-and-linking/aurora-programming-models/","title":"Aurora Programming Models","text":"<p>The software environment on Aurora supports several parallel programming models targeting the CPUs and GPUs.</p>"},{"location":"aurora/compiling-and-linking/aurora-programming-models/#cpu-parallel-programming-models","title":"CPU Parallel Programming Models","text":"<p>The Aurora MPICH compiler wrappers <code>mpicc</code>, <code>mpicxx</code>, and <code>mpifort</code> are recommended for MPI applications to be built using the oneAPI compilers. A summary of available CPU parallel programming models and relevant compiler flags is shown below. Users are encouraged to review the corresponding man pages and documentation.</p> Programming Model oneAPI OpenMP -fiopenmp or -qopenmp <p>Note: <code>-fopenmp</code> uses OpenMP as it is implemented by the LLVM community.</p> <p>Higher-level programming models such as Kokkos and Raja may also be used for CPU programming on Aurora.</p>"},{"location":"aurora/compiling-and-linking/aurora-programming-models/#gpu-programming-models","title":"GPU Programming Models","text":"<p>A summary of available GPU programming models and relevant compiler flags is shown below for compilers that generate offloadable code. Two modes of compilation are currently available with the oneAPI compilers: Just-in-Time (JIT) and Ahead-of-Time (AoT). With AoT compilation, flags for specifying the backend are only needed when linking the application. Users are encouraged to review the corresponding man pages and documentation.</p> Programming Model oneAPI (JIT) oneAPI (AoT) OpenCL -- N/A OpenMP -fiopenmp -fopenmp-targets=spir64 -fiopenmp -fopenmp-targets=spir64_gen -Xopenmp-target-backend=spir64_gen \"-device pvc\" SYCL --intel -fsycl -fsycl-targets=spir64 --intel -fsycl -fsycl-targets=spir64_gen -Xsycl-target-backend \"-device pvc\" <p>For some build systems (e.g., <code>cmake</code>), it may be necessary to use the backslash character to escape the double quotes when specifying the device in AoT builds.</p> <pre><code>-Xopenmp-target-backend=spir64_gen \\\"-device pvc\\\"\n</code></pre> <p>OpenCL is supported, but does not require specific compiler flags per-se as the offloaded kernels are JIT-compiled. One does need to link against the OpenCL library <code>-lOpenCL</code>. Abstraction programming models, such as Kokkos, can be built on top of these programming models.</p>"},{"location":"aurora/containers/containers/","title":"Containers on Aurora","text":"<p>Users of Aurora can benefit from container-based workloads for seamless compatibility across Intel systems. This guide details the use of containers on Aurora, including custom container creation, large-scale execution, and common pitfalls.</p> <p>We support Apptainer and Podman (documentation coming soon) on Aurora.</p>"},{"location":"aurora/containers/containers/#apptainer","title":"Apptainer","text":"<p>Aurora employs Apptainer (formerly known as Singularity) for container management.</p>"},{"location":"aurora/containers/containers/#login-and-queue-a-job","title":"Login and queue a job","text":"<p><pre><code>ssh &lt;username&gt;@aurora.alcf.anl.gov\n</code></pre> Refer to Getting Started on Aurora for additional information. In particular, you need to set the environment variables that provide access to the proxy host.</p> <p>Note</p> <p>The instructions below should be run directly from a compute node.</p> <p>Explicitly, to request an interactive job (from <code>aurora-uan</code>): <pre><code>qsub -I -q &lt;your_Queue&gt; -l select=1,walltime=60:00 -A &lt;your_ProjectName&gt; -l filesystems=&lt;fs1:fs2&gt;\n</code></pre></p> <p>Refer to job scheduling and execution for additional information.</p>"},{"location":"aurora/containers/containers/#load-modules-on-compute-node","title":"Load Modules on Compute Node","text":"<pre><code># load apptainer\nmodule load apptainer\n</code></pre>"},{"location":"aurora/containers/containers/#building-from-docker-or-argonne-github-container-registry","title":"Building from Docker or Argonne GitHub Container Registry","text":"<p>Containers on Aurora can be built by writing Dockerfiles on a local machine and then publishing the container to DockerHub, or by directly building them on an ALCF compute node by writing an Apptainer recipe file. If you prefer to use existing containers, you can pull them from various registries like DockerHub and run them on Aurora.</p> <p>Since Docker requires root privileges, which users do not have on Aurora, existing Docker containers must be converted to Apptainer. To build a Docker-based container on Aurora, use the following as an example:</p> <pre><code>## Build an image\napptainer build --fakeroot intel-optimized-pytorch.sing docker://intel/intel-optimized-pytorch\n</code></pre>"},{"location":"aurora/containers/containers/#example-to-run-hello-world-using-apptainer","title":"Example to run Hello World using Apptainer","text":"<pre><code>apptainer exec --fakeroot docker://ghcr.io/apptainer/lolcow cowsay 'Fresh from the internet'\n</code></pre>"},{"location":"aurora/containers/containers/#example-to-run-postgres-database-using-apptainer","title":"Example to run Postgres Database using Apptainer","text":"<p>To run Postgres on an Aurora compute node, below is a full example.</p> apptainer_aurora_example.sh<pre><code># qsub from a UAN/login node\nqsub -l select=1 -l walltime=60:00 -A &lt;Projectname&gt; -q &lt;Queue&gt; -l filesystems=&lt;fs1:fs2&gt; -I\n\n# Set proxy on compute node\nexport HTTP_PROXY=\"http://proxy.alcf.anl.gov:3128\"\nexport HTTPS_PROXY=\"http://proxy.alcf.anl.gov:3128\"\nexport http_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport https_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport ftp_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport no_proxy=\"admin,*.hostmgmt.cm.aurora.alcf.anl.gov,*.alcf.anl.gov,localhost\"\n\n# Load apptainer\nmodule load apptainer\n\n# Build postgres image\napptainer build --fakeroot postgres.sing docker://postgres # do this once\n\n# Create an environment file\ncat &gt;&gt; pg.env &lt;&lt;EOF\nexport POSTGRES_USER=pguser\nexport POSTGRES_PASSWORD=mypguser123\nexport POSTGRES_DB=mydb\nexport POSTGRES_INITDB_ARGS=\"--encoding=UTF-8\"\nEOF\n\n# Create a data and run directory to bind to the running container\nmkdir -p pgdata pgrun\n\n# Start an instance of the container using nohup\nnohup apptainer run --fakeroot -B pgrun:/var/run/postgresql -B pgdata:/var/lib/postgresql/data --env-file pg.env postgres.sing postgres &amp;\n\n# Save PID\necho $! &gt; pg_pid.txt\necho \"Postgres started with PID $(cat pg_pid.txt)\"\n\n# Interact with running container using psql client\napptainer exec \\\n  --fakeroot \\\n  -B pgrun:/var/run/postgresql \\\n  -B pgdata:/var/lib/postgresql/data \\\n  --env-file pg.env \\\n  postgres.sing psql -h 127.0.0.1 -p 5432 -U pguser -d mydb -c \"SELECT version();\"\n\n# Stop the container and kill the process\nkill \"$(cat pg_pid.txt)\"\nrm pg_pid.txt\n</code></pre>"},{"location":"aurora/data-management/copper/copper/","title":"Copper","text":"<p>Copper is a co-operative caching layer for scalable parallel data movement in Exascale Supercomputers developed at Argonne Leadership Computing Facility.</p>"},{"location":"aurora/data-management/copper/copper/#introduction","title":"Introduction","text":"<ul> <li>Copper is a lightweight library designed to address the I/O bottleneck caused by all compute nodes loading the same files simultaneously.</li> <li>To reduce file system contention and improve efficiency, Copper enables a single designated process to load data from the file system and transfer to other ranks through high-speed interconnects.</li> <li>This approach significantly reduces redundant file access and improves scalability in distributed training and simulation workloads.</li> <li>Copper is a read-only cooperative caching layer designed to enable scalable data loading across massive numbers of compute nodes.</li> <li>It aims to avoid I/O bottlenecks, network contention, and interference with the storage network, file system, and compute network, thereby allowing more effective use of the compute network for data movement\u2014both for your job and for other jobs running on the system.</li> <li>The current intended use of Copper is to improve the performance of Python imports - dynamic shared library loading on Aurora.</li> <li>However, Copper can be used to improve the performance of any type of redundant data loading (Note: this is for the case where all the processes are loading the same files) on a supercomputer.</li> <li> <p>It is recommended to use Copper for any applications [preferably Python and I/O &lt;500 MB] in order to scale beyond 2k nodes.</p> <p></p> </li> </ul>"},{"location":"aurora/data-management/copper/copper/#how-to-use-copper-on-aurora","title":"How to use Copper on Aurora","text":"<p>In your job script or from an interactive session:</p> <pre><code>module load copper\nlaunch_copper.sh\nPYTHONPATH=/tmp/${USER}/copper/lus/flare/projects/datascience/kaushik/copper-test/lus_custom_pip_env/:$PYTHONPATH\n</code></pre> <p>Then run your <code>mpiexec</code> as you would normally run.</p> <ul> <li>If you want your I/O to go through Copper, add <code>/tmp/${USER}/copper/</code> to the beginning of your <code>PYTHONPATH</code>. Here, only the root compute node will do the I/O directly with the Lustre file system.</li> <li>If <code>/tmp/${USER}/copper/</code> is not added to the beginning of your paths, then all compute nodes would do I/O directly to the Lustre file system.</li> </ul>"},{"location":"aurora/data-management/copper/copper/#copper-options","title":"Copper Options","text":"<pre><code>-l log_level                [Allowed values: 6[no logging], 5[less logging], 4, 3, 2, 1[more logging]] [Default: 6]\n-t log_type                 [Allowed values: file or file_and_stdout] [Default: file]\n-T trees                    [Allowed values: any number] [Default: 1]\n-M max_cacheable_byte_size  [Allowed values: any number in bytes] [Default: 10MB]\n-s sleeptime                [Allowed values: Any number] [Default: 20 seconds] Recommended to use 60 seconds for 4k nodes\n-b physcpubind              [Allowed values: \"CORE NUMBER-CORE NUMBER\"] [Default: \"48-51\"]\n</code></pre> <p>For example, you can change the default values to:</p> <pre><code>launch_copper.sh -l 2 -t stdout_and_file -T 2 -s 40\n</code></pre>"},{"location":"aurora/data-management/copper/copper/#examples","title":"Examples:","text":""},{"location":"aurora/data-management/copper/copper/#example-1-standard-packages","title":"Example 1: Standard packages","text":"<p>If you are not using any custom packages in your application and you are using only default packages from <code>module load frameworks</code>, you do not need copper.</p>"},{"location":"aurora/data-management/copper/copper/#example-2-custom-packages","title":"Example 2: Custom packages","text":"<pre><code>module load frameworks\n# The below line is required only for the first time setup to install a package on a custom directory. This can be done in login node. \npython -m pip install  --target=/lus/flare/projects/datascience/kaushik/copper-test/lus_custom_pip_env/ dragonhpc\n\nmodule load copper \nlaunch_copper.sh\n\ntime mpirun --np ${NRANKS} --ppn ${RANKS_PER_NODE} --cpu-bind=list:4:56:9:61:14:66:19:71:20:74:25:79 --genvall \\\n            --genv=PYTHONPATH=/tmp/${USER}/copper/lus/flare/projects/datascience/kaushik/copper-test/lus_custom_pip_env/:$PYTHONPATH \\\n             python3 -c \"import dragon; print(dragon.__file__)\"\n\nstop_copper.sh # optional - enabled by default on the PBS epilog during cleanup.\n</code></pre>"},{"location":"aurora/data-management/copper/copper/#example-3-conda-environemnts","title":"Example 3: Conda environemnts","text":"<p>This example is divided into 2 sections: 1) How to install and create a clean conda environment without any dependency on the <code>~/home</code> directory and 2) A sample job script with Copper and conda. </p>"},{"location":"aurora/data-management/copper/copper/#creating-a-conda-environment","title":"Creating a conda environment","text":"<p>Step 0. Make sure your miniconda is not installed in <code>~/home</code></p> <pre><code>mkdir /lus/flare/projects/datascience/kaushik/copper-tests/dharma-test/miniconda-src\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /lus/flare/projects/datascience/kaushik/copper-tests/dharma-test/miniconda-src/miniconda.sh\nbash miniconda-src/miniconda.sh -b -u -p /lus/flare/projects/datascience/kaushik/copper-tests/dharma-test/miniconda-src\n</code></pre> <p>Step 1. Create conda environment with <code>--prefix</code> option instead of <code>conda create --name</code></p> <pre><code>conda create --prefix  /lus/flare/projects/datascience/kaushik/copper-tests/dharma-test/dharma-s-env python=3.9 \n</code></pre> <p>Step 2. Delete contents of .conda and .local directories under ~/home</p> <pre><code>rm -rf ~/.conda/* and ~/.local/*\n</code></pre> <p>Step 3. update .condarc file to have the right cache-package dirs and env dirs </p> <pre><code>vi ~/.condarc \nchannels:\n  - conda-forge\nenvs_dirs:\n  - /lus/flare/projects/datascience/kaushik/copper-tests/dharma-test/dharma-s-env\npkgs_dirs:\n  - /lus/flare/projects/datascience/kaushik/copper-tests/dharma-test/conda-cache1\n  - /lus/flare/projects/datascience/kaushik/copper-tests/dharma-test/conda-cache2\n</code></pre> <p>Step 4. verify your source <code>~/.bashrc</code> does not contain any <code>~/home</code> paths </p> <p>Step 5. remove anyother hidden or unknown site-packages under <code>~/home</code></p> <p>Step 6. verify all these below outputs are not pointing to <code>~/home</code> after <code>conda activate</code>, including the output of the <code>which python</code> command</p> <pre><code>ls -lah ~/.local\nls -lah ~/.conda\ndu -sh ~/.local\ndu -sh ~/.conda\necho $PYTHONUSERBASE $PYTHONPATH $VIRTUAL_ENV $CONDA_PREFIX $CONDA_ROOT $CONDARC\nwhich python\nwhich conda\n</code></pre> <p>Step 7. Set --target lustre directory on pip install</p> <pre><code>python -m pip install  --target=/lus/flare/projects/datascience/kaushik/copper-tests/dharma-test/main-packages torch\n</code></pre>"},{"location":"aurora/data-management/copper/copper/#example-job-script-with-copper-and-conda","title":"Example job script with copper and conda.","text":"<pre><code>module restore\nmodule load copper # Do not load python or frameworks module unless needed\nlaunch_copper.sh \n/lus/flare/projects/datascience/kaushik/copper-tests/dharma-test/miniconda-src/bin/conda init  \nconda activate /lus/flare/projects/datascience/kaushik/copper-tests/dharma-test/dharma-s-env  \nexport PYTHONPATH=/tmp/${USER}/copper//lus/flare/projects/datascience/kaushik/copper-tests/dharma-test/main-packages/:$PYTHONPATH\n\nls -lah ~/.local\nls -lah ~/.conda\ndu -sh ~/.local\ndu -sh ~/.conda\necho $PYTHONUSERBASE $PYTHONPATH $VIRTUAL_ENV $CONDA_PREFIX $CONDA_ROOT $CONDARC\nwhich python\nwhich conda\ncat ~/.condarc \ncat ~/.bashrc \n\n\ntime mpirun --np ${NRANKS} --ppn ${RANKS_PER_NODE} --cpu-bind=list:4:56:9:61:14:66:19:71:20:74:25:79 --genvall \\\n            --genv=PYTHONPATH=/tmp/${USER}/copper//lus/flare/projects/datascience/kaushik/copper-tests/dharma-test/main-packages/:$PYTHONPATH \\\n             python3 -c \"import torch; import intel_extension_for_pytorch; import oneccl_bindings_for_pytorch;\"\n</code></pre>"},{"location":"aurora/data-management/copper/copper/#example-4-python-virtual-environments","title":"Example 4: Python virtual environments","text":"<pre><code># The below lines are required only for the first time setup to install a package on a python virtual environments. This can be done in login node. \nmodule load frameworks\npython3 -m venv --system-site-packages copper-test-app-special-pyenv\nsource /lus/flare/projects/datascience/kaushik/copper-tests/copper-aurora/copper-normal-rpc/copper-test-app-special-pyenv/bin/activate\npip install dragonhpc\n\n\n# From compute node \nmodule load frameworks\nsource /lus/flare/projects/datascience/kaushik/copper-tests/copper-aurora/copper-normal-rpc/copper-test-app-special-pyenv/bin/activate\nmodule load copper \nlaunch_copper.sh\n\ntime mpirun --np ${NRANKS} --ppn ${RANKS_PER_NODE} --cpu-bind=list:4:56:9:61:14:66:19:71:20:74:25:79 --genvall \\\n            --genv=PYTHONPATH=/tmp/${USER}/copper/lus/flare/projects/datascience/kaushik/copper-tests/copper-aurora/copper-normal-rpc/copper-test-app-special-pyenv/lib64/python3.10/site-packages:$PYTHONPATH \\\n             python3 -c \"import dragon; print(dragon.__file__)\"\n\nstop_copper.sh # optional - enabled by default on the PBS epilog during cleanup.\n</code></pre>"},{"location":"aurora/data-management/copper/copper/#example-5-non-python-example-where-input-files-for-the-application-are-moved-through-copper","title":"Example 5: Non-Python Example where input files for the application are moved through copper","text":"<pre><code># Note thundersvm-train is the app and input_file_M100000_K25000_S0.836 is the input file passed as an argument to the app\n# Each individual input file (not the entire input directory) is recommended to be less than 10MB. \n# launch_copper -M max_cacheable_byte_size  [Allowed values: any number in bytes] [Default: 10MB] . Here I/O greater than 10 MB will not moved through copper and all compute nodes will directly access the files from lustre file system.\n\nmodule load copper \nlaunch_copper.sh\ntime mpiexec -np $ranks -ppn 12 --cpu-bind list:4:9:14:19:20:25:56:61:66:71:74:79 --no-vni -genvall \\\n        /lus/flare/projects/CSC250STDM10_CNDA/kaushik/thunder/svm_mpi/run/aurora/wrapper.sh \\\n        /lus/flare/projects/CSC250STDM10_CNDA/kaushik/thunder/svm_mpi/build_ws1024/bin/thundersvm-train \\\n            -s 0 -t 2 -g 1 -c 10 -o 1 /tmp/${USER}/copper/lus/flare/projects/CSC250STDM10_CNDA/kaushik/thunder/svm_mpi/data/sc-40-data/input_file_M100000_K25000_S0.836\n\nstop_copper.sh # optional - enabled by default on the PBS epilog during cleanup.\n</code></pre>"},{"location":"aurora/data-management/copper/copper/#example-6-pytorch-datasets-and-data-loaders","title":"Example 6: Pytorch datasets and data loaders","text":"<pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\ntrain_dataset = datasets.ImageFolder(root='/tmp/${USER}/copper/lus/flare/projects/agpt/resnet/dataset/train', transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n...\n</code></pre>"},{"location":"aurora/data-management/copper/copper/#verifying-with-strace","title":"Verifying with Strace","text":"<p>You can use the strace tool on Aurora to verify all the paths used in your Python program</p> <pre><code># strace -o trace_output.log python import-test.py \n# which strace\n# /usr/bin/strace\n# strace -- version 5.14 \n\n&gt; cat import-test.py\n\nimport torch\nimport intel_extension_for_pytorch\nimport oneccl_bindings_for_pytorch\n</code></pre>"},{"location":"aurora/data-management/copper/copper/#best-practices","title":"Best practices","text":"<ol> <li>The basic principle is to have a clean environment and the entire environment files and binaries under <code>/lus/project</code> directory and not under any hidden directories in home.</li> <li>Prepending <code>/tmp/${USER}/copper</code>/ to different environment variables should be done in a careful and need basis manner.</li> <li>You should not prepend copper path to all known variables like <code>PYTHON_PATH, VIRTUAL_ENV, CONDA_PREFIX, CONDA_ROOT, LD_LIBRARY_PATH and PATH</code>.</li> <li>When using python virutal environment, prepending <code>/tmp/${USER}/copper/</code> only to <code>PYTHONPATH</code> variable is sufficient.</li> <li>When using a personal conda environment, prepending <code>/tmp/${USER}/copper/</code> only to <code>PYTHONPATH</code> variable is sufficient.</li> <li>If you prefer the python and pip binary or any other binary under the virtual_env or conda_prefix to be in copper path, only then you should prepend <code>/tmp/${USER}/copper/..path_to_venv or path_to_conda ..bin/</code>  to $<code>PATH</code> variable.</li> <li>If your application is taking input files as argument, which you prefer to go through copper, you can prepend <code>/tmp/${USER}/copper/</code> to the input file path argument only.</li> <li>If there is a specific library say <code>/lus/flare/projects/agpt/custom_lib/libcustom.so</code> file that you want to move through copper, you can set <code>LD_LIBRARY_PATH=/tmp/${USER}/copper/lus/flare/projects/agpt/custom_lib/libcustom.so:$LD_LIBRARY_PATH</code>. Again prepending copper path to all paths in <code>LD_LIBRARY_PATH</code> is not recommended.</li> <li>Copper is read only and cannot be used to write any files. So, you should not use copper path for any output files or temporary files.</li> <li>Copper runs by default on cores <code>physcpubind=\"48-51\"</code> which should not be used in your application cpu bind list. You can also change the copper cores by <code>launch_copper.sh -b \"core_range\"</code> .</li> <li>You should be aware and cautious of any other hardcoded paths in your package or your application.</li> <li>The current copper supported filesystem operations are  init, open, read, readdir, readlink, getattr, ioctl, destroy.</li> <li>Note, write, unlink, rename, mkdir, rmdir, symlink, statfs, fsync, flush, mmap and other operations are not supported.</li> <li>System default modules like frameworks, python, intel, mpich whose metadata are baked into the os image do not require copper.</li> <li>Copper works only from the compute nodes, and you need a minimum of 2 nodes up to a max of any number of nodes (Aurora max 10624 nodes).</li> <li>Recommended size for max cacheable byte size is 10MB to 100MB.</li> <li>Recommended trees are 1 or 2.</li> <li>GitHub Copper Examples</li> </ol>"},{"location":"aurora/data-management/daos/daos-overview/","title":"DAOS Architecture","text":"<p>DAOS is a major file system in Aurora with 230 PB delivering up to &gt;30 TB/s with 1024 DAOS server storage Nodes. DAOS is an open-source software-defined object store designed for massively distributed Non-Volatile Memory (NVM) and NVMe SSD. DAOS presents a unified storage model with a native Key-array Value storage interface supporting POSIX, MPIO, DFS and HDF5. Users can use DAOS for their I/O and checkpointing on Aurora. DAOS is fully integrated with the wider Aurora compute fabric as can be seen in the overall storage architecture below.  </p>"},{"location":"aurora/data-management/daos/daos-overview/#daos-overview","title":"DAOS Overview","text":"<p>The first step in using DAOS is to get DAOS POOL space allocated for your project. Users should submit a request as noted below to have a DAOS pool created for your project.</p>"},{"location":"aurora/data-management/daos/daos-overview/#daos-pool-allocation","title":"DAOS Pool Allocation","text":"<p>DAOS pool is a physically allocated dedicated storage space for your project.</p> <p>Email support@alcf.anl.gov to request a DAOS pool with the following information:</p> <ul> <li>Project Name</li> <li>ALCF User Names</li> <li>Total Space requested (typically 100 TBs++)</li> <li>Justification</li> <li>Preferred pool name</li> </ul>"},{"location":"aurora/data-management/daos/daos-overview/#note","title":"Note","text":"<p>This is an initial test DAOS configuration and as such, any data on the DAOS system will eventually be deleted when the configuration is changed into a larger system. Warning will be given before the system is wiped to allow time for users to move any important data off.</p>"},{"location":"aurora/data-management/daos/daos-overview/#modules","title":"Modules","text":"<p>Please load the <code>daos</code> module when using DAOS. This should be done on the login node (UAN) or in the compute node (jobscript):</p> <pre><code>module use /soft/modulefiles\nmodule load daos\n</code></pre>"},{"location":"aurora/data-management/daos/daos-overview/#pool","title":"Pool","text":"<p>A pool is a dedicated space allocated to your project. Once your pool has been allocated for your project space, confirm that you are able to query the pool:</p> <pre><code>daos pool query &lt;pool_name&gt;\n</code></pre> Example output:<pre><code>daos pool query hacc\nPool 050b20a3-3fcc-499b-a6cf-07d4b80b04fd, ntarget=4096, disabled=0, leader=2, version=131\nPool space info:\n- Target(VOS) count:640\n- Storage tier 0 (SCM):\nTotal size: 6.0 TB\n  Free: 4.4 TB, min:6.5 GB, max:7.0 GB, mean:6.9 GB\n- Storage tier 1 (NVMe):\n  Total size: 200 TB\n  Free: 194 TB, min:244 GB, max:308 GB, mean:303 GB\nRebuild done, 4 objs, 0 recs\n</code></pre>"},{"location":"aurora/data-management/daos/daos-overview/#posix-containers","title":"POSIX Containers","text":"<p>In DAOS general terms, a container is a logical space within a pool where data and metadata are stored. It's essentially a self-contained object namespace and versioning space.  There are several types of containers, but all of the focus in this guide and all future references will be on utilizing containers of the POSIX type in the context of the DAOS File System (DFS). DFS is essentially a POSIX emulation layer on top of DAOS and is implemented in the libdfs library, allowing a DAOS container to be accessed as a hierarchical POSIX namespace. libdfs supports files, directories, and symbolic links, but not hard links.  The DAOS official documentation on DFS can be found here.</p> <p>With more than 1024 servers at full deployment, the user-accessible cluster named <code>daos_user</code> has 16,384 solid state drives (SSDs) and 16,384 persistent memory modules, and without some amount of data redundancy a hardware failure on any one could result in the loss of your data.  DAOS has several data redundancy options available, and a tradeoff must be made between data resiliency, performance, and volume.  The recommended tradeoff is to specify a redundancy factor of 3 on the container for both files and directories via the <code>rd_fac:3</code> container property.  By default, this means files will utilize an erasure coding algorithm with a ratio of 16 data blocks to 3 parity blocks (in DAOS file object class terms <code>EC_16P3GX</code>), which in simplest terms, means 19 blocks of erasure coding stores 16 blocks of data. For directories, the default is to create 3 full duplicates of the directory, which is basically an emulation of an inode in traditional file system terms, by setting the directory object class to <code>RP_4G1</code>. For this default setting, there is little performance tradeoff for directories at this redundancy level, since it just contains metadata.</p> <p>In the scenario with the above settings, when a server failure occurs, be it a software or hardware failure (e.g. an SSD, persistent memory module, or a networking switch failure) on up to 3 servers, a process called a rebuild occurs. During rebuild, the data on the failed servers is reconstructed to preserve data integrity, and the servers with the failures are excluded from the cluster. The servers or network can be repaired in the future so that the servers are eventually reintegrated to the cluster.  The rebuild process in this scenario does not disrupt service, and the cluster does not experience any outage.  If more than 3 servers are lost (say, due to a network issue) or more servers are lost during the rebuild, then the cluster will be taken offline to conduct repairs.</p> <p>These parameters are set at container creation as follows along with others which will be described below for best practices: <pre><code>daos container create --type=POSIX  --chunk-size=2097152  --properties=rd_fac:3,ec_cell_sz:131072,cksum:crc32,srv_cksum:on --file-oclass=EC_16P3GX --dir-oclass=RP_4G1 &lt;pool name&gt; &lt;container name&gt;\n</code></pre></p> <p>The chunk-size of 2 MB and the <code>ec_cell_sz</code> (erasure coding cell size) of 128 KB work together to optimally stripe the data across the 16 data servers plus 3 parity servers (19 erasure coding servers) and set the maximum amount of data written to one SSD on one server by one client per transaction to the <code>ec_cell_sz</code> of 128 KB. The general rule of thumb is the chunk-size should equal the number of data servers (excluding parity servers) multiplied by the <code>ec_cell_sz</code> or at least be an even multiple of it.  If your application does large amounts of IO per process, you could experiment with the settings by increasing them proportionately, e.g. setting the chunk-size to 16 MB and the <code>ec_cell_sz</code> to 1 MB.  DAOS containers have a property for both server and client checksum, whereby the client will retry the data transfer to or from the server in the case of corruption, however by default this is disabled, to enable it for best performance and acceptable accuracy usage of the CRC-32 algorithm is recommended with the above parameters <code>cksum:crc32,srv_cksum:on</code>.</p> <p>Now, the <code>GX</code> in <code>EC_16P3GX</code> tells the container to stripe the data across all servers in the pool, which is optimum if your application is writing a single shared file or at most one file per node, but instead if your application is writing more than one file per node, say file per process, for best performance you should change the <code>GX</code> to <code>G32</code>, the 32 being the hard-coded number of servers the data in the file will be striped across.  You can do this in one of two ways:</p> <ol> <li>Use the <code>--file-oclass</code> parameter explicitly in the container creation. The call would look like: <pre><code>daos container create --type=POSIX  --chunk-size=2097152 --file-oclass=EC_16P3G32 --dir-oclass=RP_4G1 --properties=rd_fac:3,ec_cell_sz:131072,cksum:crc32,srv_cksum:on &lt;pool name&gt; &lt;container name&gt;\n</code></pre></li> <li>Create a subdirectory in the container and set the attribute on it. For example, if your container was created with <code>EC_16P3GX</code> and you wanted a subdirectory <code>&lt;dir name&gt;</code> to have <code>EC_16P3G32</code>, mount the container (this is described in the POSIX Container Access via DFUSE section below) with directory <code>&lt;dir name&gt;</code> at <code>/tmp/&lt;pool name&gt;/&lt;container name&gt;</code> and then: <pre><code>daos fs set-attr --path=/tmp/&lt;pool name&gt;/&lt;container name&gt;/&lt;dir name&gt; --oclass=EC_16P3G32\n</code></pre> By default any top-level directory created in a container will inherit the directory and file object class from the container, and any subdirectory inherits from its parent, so in this fashion you can change the default and have a mix of file object classes in the same container.</li> </ol> <p>There is maintenance overhead with containers, therefore it is advisable to create just one or a few containers and create multiple directories in the few containers to partition your work.</p> <p></p>"},{"location":"aurora/data-management/daos/daos-overview/#daos-agent-check","title":"DAOS Agent Check","text":"<p>Whether you are accessing DAOS when running a job from a compute node or managing data from a login node, the DAOS agent daemon is needed to connect the DAOS client to the DAOS server cluster, in your case <code>daos_user</code>.  The DAOS agent facilitates all authentication and communication between the DAOS clients and servers.  The DAOS agent daemon should always be running for the <code>daos_user</code> cluster on the UANs, however on the compute nodes the <code>daos_user</code> agent is only started in the PBS prologue specified via the <code>-l filesystems=daos_user_fs</code> resource requirement, and is terminated in the PBS epilogue.  To verify that it is running, first load the <code>daos</code> module:</p> <pre><code>module use /soft/modulefiles\nmodule load daos\n</code></pre> <p>Then to verify the DAOS daemon process for <code>daos_user</code> is running, run this command:</p> <pre><code>ps -ef | grep daos\n</code></pre> <p>Additionally on the compute nodes, you can run this <code>clush</code> command to check if the agent is running on all nodes in the job:</p> <pre><code>clush --hostfile ${PBS_NODEFILE} ps \u2013ef | grep agent | grep -v grep'  | dshbak -c\n</code></pre> <p>On the UANs there may be several agents running for different clusters so you may get several lines of output (on the compute node you will get only one), but the one for daos_user is named <code>daos_agent_oneScratch</code> and looks like this:</p> <pre><code>daos_ag+   6431      1  0 Jul21 ?        00:00:12 /usr/bin/daos_agent --config-path=/etc/daos/daos_agent_oneScratch.yml --runtime_dir=/run/daos_agent_oneScratch --logfile=/var/log/daos_agent/daos_agent_oneScratch.log\n</code></pre> <p>Then verify the daos_user agent will be the one used by the DAOS client:</p> <pre><code>echo $DAOS_AGENT_DRPC_DIR\n</code></pre> <p>You should then see this:</p> <pre><code>/run/daos_agent_oneScratch\n</code></pre>"},{"location":"aurora/data-management/daos/daos-overview/#daos-pool-and-container-sanity-checks-is-the-daos_user-cluster-up-or-down","title":"DAOS pool and container sanity checks (is the daos_user cluster up or down?)","text":"<p>If any of the following command results in an error, then you can confirm the daos_user cluster is currently down</p> <pre><code>Note qsub ... -l filesystems=flare:daos_user_fs\n\nmodule use /soft/modulefiles\nmodule load daos\nexport DAOS_POOL=Your_allocated_pool_name\nexport DAOS_CONTAINER=any_label_name\ndaos container create --type=POSIX  --chunk-size=2097152  --properties=rd_fac:3,ec_cell_sz:131072,cksum:crc32,srv_cksum:on --file-oclass=EC_16P3GX --dir-oclass=RP_4G1  ${DAOS_POOL} ${DAOS_CONTAINER}\ndaos pool query ${DAOS_POOL}\ndaos cont list ${DAOS_POOL}\ndaos container get-prop  $DAOS_POOL  $DAOS_CONTAINER\n</code></pre> <ul> <li>Look for messages like <code>Rebuild busy and state degraded in the daos pool query.</code></li> <li>'Out of group or member list' error is an exception and can be safely ignored. This error message will be fixed in the next DAOS release.</li> </ul> <p>You can also use the following commands for further diagnosis.</p> <pre><code>daos pool      autotest  $DAOS_POOL\ndaos container check --pool=$DAOS_POOL --cont=$DAOS_CONTAINER\n</code></pre> <p>There are example programs and job scripts provided under <code>/soft/daos/examples/</code>.</p>"},{"location":"aurora/data-management/daos/daos-overview/#posix-container-access-via-dfuse","title":"POSIX Container Access via DFUSE","text":"<p>DAOS POSIX container access can be accomplished with no application code modifications needed through DAOS filesystem (DFS) dfuse mount points for both the compute and UANs.  Once mounted, you can access files in the container as you normally would via POSIX file system commands.  Currently, this must be done manually prior to use on any node on which you are working.  In the future, we hope to automate some of this via additional <code>qsub</code> options.</p>"},{"location":"aurora/data-management/daos/daos-overview/#1-to-mount-a-posix-container-on-a-uan","title":"1. To mount a POSIX container on a UAN","text":"<pre><code>mkdir -p /tmp/${USER}/${DAOS_POOL}/${DAOS_CONT}\nstart-dfuse.sh -m /tmp/${USER}/${DAOS_POOL}/${DAOS_CONT} --pool ${DAOS_POOL} --cont ${DAOS_CONT} # To mount\nmount | grep dfuse # To confirm if its mounted\n\n# Mode 1\nls /tmp/${USER}/${DAOS_POOL}/${DAOS_CONT}\ncd /tmp/${USER}/${DAOS_POOL}/${DAOS_CONT}\ncp ~/temp.txt ~ /tmp/${USER}/${DAOS_POOL}/${DAOS_CONT}/\ncat /tmp/${USER}/${DAOS_POOL}/${DAOS_CONT}/temp.txt\n\nfusermount3 -u /tmp/${USER}/${DAOS_POOL}/${DAOS_CONT} # To unmount - very important to clean up afterward on the UAN\n</code></pre>"},{"location":"aurora/data-management/daos/daos-overview/#2-to-mount-a-posix-container-on-compute-nodes","title":"2. To mount a POSIX container on Compute Nodes","text":"<p>You need to mount the container on all compute nodes. This is done via the <code>launch-dfuse.sh</code> script which does a <code>clush</code> command of <code>start-dfuse.sh</code>:</p> <pre><code>launch-dfuse.sh ${DAOS_POOL}:${DAOS_CONT} # launched using clush on all compute nodes mounted at: /tmp/&lt;pool&gt;/&lt;container&gt;\nmount | grep dfuse # To confirm if its mounted\n\nls /tmp/${DAOS_POOL}/${DAOS_CONT}/\n\nclean-dfuse.sh  ${DAOS_POOL}:${DAOS_CONT} # To unmount on all nodes - optional on compute nodes as PBS epilogue script does this for you\n</code></pre> <p>DAOS Data mover instruction is provided at here.</p>"},{"location":"aurora/data-management/daos/daos-overview/#unclean-container-status","title":"'UNCLEAN' Container Status","text":"<p>If you get an error trying to access your container (such as on the dfuse container mount) your container may have a status of 'UNCLEAN'.  You can check this with the following command:</p> <pre><code>daos cont get-prop &lt;pool name&gt; &lt;container name&gt;\n</code></pre> <p>You should see output with the 'Health' property set to 'UNCLEAN':</p> <pre><code>Properties for container posix-ec16p2gx-crc32\nName                                             Value\n----                                             -----\n...\nHealth (status)                                  UNCLEAN\n...\n</code></pre> <p>This 'UNCLEAN' status indicates that the DAOS system has had a temporary loss of redundancy which may or may not have resulted in corruption of the metadata (including directory structures) or the data itself.  In order to investigate to determine if there is actual metadata or data corruption, you will first need to be able to access the container by explicitly setting the status of the container to HEALTHY:</p> <pre><code>daos cont set-prop &lt;pool name&gt; &lt;container name&gt; status:HEALTHY\n</code></pre> <p>To check on metadata corruption run this DAOS filesystem command to have DAOS check for metadata corruption.:</p> <pre><code>daos fs check --flags=evict &lt;pool name&gt; &lt;container name&gt;\n</code></pre> <p>If the metadata is ok you should see something like this:</p> <pre><code>DFS checker: Start (2025-07-17-19:23:14)\nDFS checker: Create OIT table\nDFS checker: Iterating namespace and marking objects\nDFS checker: marked 836 files/directories (runtime: 3 sec))\nDFS checker: Checking unmarked OIDs (Pass 1)\nDFS checker: Done! (runtime: 4 sec)\nDFS checker: Number of leaked OIDs in namespace = 0\n</code></pre> <p>However if you see failure messages or the 'Number of leaked OIDs in namespace' is greater than 0 then you have metadata corruption.  Otherwise, the next step is to manually manually verify the data correctness yourself, by whatever means is appropriate (i.e. loading data into your simulator, loading the data into analysis programs, utilizing your own checksums, or just visually inspecting the files).  So if your metadata or data has been corrupted, you should report this data corruption to ALCF Support support@alcf.anl.gov and someone from the DAOS team will follow up wtih you to investigate.</p>"},{"location":"aurora/data-management/daos/daos-overview/#job-submission","title":"Job Submission","text":"<p>The <code>-l filesystems=daos_user_fs</code> PBS resource requirement will ensure that DAOS is accessible on the compute nodes.</p> <p>Job submission without requesting DAOS:</p> <pre><code># replace `./pbs_script1.sh` with `-I` for an interactive job\nqsub -l select=1 -l walltime=01:00:00 -A &lt;ProjectName&gt; -k doe -l filesystems=flare -q debug ./pbs_script1.sh\n</code></pre> <p>Job submission with DAOS:</p> <pre><code>qsub -l select=1 -l walltime=01:00:00 -A &lt;ProjectName&gt; -k doe -l filesystems=flare:daos_user_fs -q debug ./pbs_script1.sh\n</code></pre>"},{"location":"aurora/data-management/daos/daos-overview/#nic-and-core-binding","title":"NIC and Core Binding","text":"<p>Each Aurora compute node has 8 NICs and each DAOS server node has 2 NICs. Each NIC is capable of driving 20-25 GB/s unidirectional for data transfer. Every read and write goes over the NIC and hence NIC binding is the key to achieve good performance.</p> <p>For 12 PPN, the following binding is recommended:</p> <pre><code>CPU_BINDING1=list:4:9:14:19:20:25:56:61:66:71:74:79\n</code></pre> NIC 0 NIC 1 NIC 2 NIC 3 NIC 4 NIC 5 NIC 6 NIC 7 0 1 2 3 52 53 54 55 4 5 6 7 56 57 58 59 8 9 10 11 60 61 62 63 12 13 14 15 64 65 66 67 16 17 18 19 68 69 70 71 20 21 22 23 72 73 74 75 24 25 26 27 76 77 78 79 28 29 30 31 80 81 82 83 32 33 34 35 84 85 86 87 36 37 38 39 88 89 90 91 40 41 42 43 92 93 94 95 44 45 46 47 96 97 98 99 48 49 50 51 100 101 102 103 <p>: Sample NIC to Core binding</p>"},{"location":"aurora/data-management/daos/daos-overview/#interception-library-for-posix-containers","title":"Interception library for POSIX containers","text":"<p>The interception library (IL) is a next step in improving DAOS performance. This provides kernel-bypass for I/O data, leading to improved performance. The <code>libioil</code> IL will intercept basic read and write POSIX calls while all metadata calls still go through dFuse. The <code>libpil4dfs</code> IL should be used for both data and metadata calls to go through dFuse.</p> <p>The IL can provide a large performance improvement for bulk I/O as it bypasses the kernel and commuNICates with DAOS directly in userspace. It will also take advantage of the multiple NICs on the node based on how many MPI processes are running on the node and which CPU socket they are on.</p> <p></p> Interception library for POSIX mode<pre><code>mpiexec                                            # no interception\nmpiexec --env LD_PRELOAD=/usr/lib64/libioil.so     # only data is intercepted\nmpiexec --env LD_PRELOAD=/usr/lib64/libpil4dfs.so  # preferred - both metadata and data is intercepted. This provides close to DFS mode performance.\n</code></pre>"},{"location":"aurora/data-management/daos/daos-overview/#sample-job-script","title":"Sample job script","text":"<p>Currently, <code>--no-vni</code> is required in the <code>mpiexec</code> command to use DAOS.</p> <pre><code>#!/bin/bash -x\n#PBS -l select=512\n#PBS -l walltime=01:00:00\n#PBS -A &lt;ProjectName&gt;\n#PBS -q prod\n#PBS -k doe\n#PBS -l filesystems=flare:daos_user_fs\n\n# qsub -l select=512:ncpus=208 -l walltime=01:00:00 -A &lt;ProjectName&gt; -l filesystems=flare:daos_user_fs -q prod ./pbs_script.sh or - I\n\n# please do not miss -l filesystems=daos_user_fs and in your qsub :'(\n\nexport TZ='/usr/share/zoneinfo/US/Central'\ndate\nmodule use /soft/modulefiles\nmodule load daos\necho $DAOS_AGENT_DRPC_DIR                           #optional\nps -ef|grep daos                                    #optional\nclush --hostfile ${PBS_NODEFILE}  'ps -ef|grep agent|grep -v grep'  | dshbak -c  #optional\nDAOS_POOL=datascience\nDAOS_CONT=thundersvm_exp1\ndaos pool query ${DAOS_POOL}                        #optional\ndaos cont list ${DAOS_POOL}                         #optional\ndaos container destroy   ${DAOS_POOL}  ${DAOS_CONT} #optional\ndaos container create --type=POSIX  --chunk-size=2097152  --properties=rd_fac:3,ec_cell_sz:131072,cksum:crc32,srv_cksum:on --file-oclass=EC_16P3GX --dir-oclass=RP_4G1 ${DAOS_POOL}  ${DAOS_CONT}\ndaos container query     ${DAOS_POOL}  ${DAOS_CONT} #optional\ndaos container get-prop  ${DAOS_POOL}  ${DAOS_CONT} #optional\ndaos container list      ${DAOS_POOL}               #optional\nlaunch-dfuse.sh ${DAOS_POOL}:${DAOS_CONT}           # To mount on a compute node\n\n# mkdir -p /tmp/${USER}/${DAOS_POOL}/${DAOS_CONT}           # To mount on a login node\n# start-dfuse.sh -m /tmp/${USER}/${DAOS_POOL}/${DAOS_CONT}     --pool ${DAOS_POOL} --cont ${DAOS_CONT}  # To mount on a login node\n\nmount|grep dfuse                                    #optional\nls /tmp/${USER}/${DAOS_POOL}/${DAOS_CONT}         #optional for login node\nls /tmp/${DAOS_POOL}/${DAOS_CONT}                   #optional for compute node\n\n# cp /lus/flare/projects/CSC250STDM10_CNDA/kaushik/thundersvm/input_data/real-sim_M100000_K25000_S0.836 /tmp/${DAOS_POOL}/${DAOS_CONT} #one time\n# daos filesystem copy --src /lus/flare/projects/CSC250STDM10_CNDA/kaushik/thundersvm/input_data/real-sim_M100000_K25000_S0.836 --dst daos://tmp/${DAOS_POOL}/${DAOS_CONT}  # check https://docs.daos.io/v2.4/testing/datamover/\n\n\ncd $PBS_O_WORKDIR\necho Jobid: $PBS_JOBID\necho Running on nodes `cat $PBS_NODEFILE`\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nRANKS_PER_NODE=12          # Number of MPI ranks per node\nNRANKS=$(( NNODES * RANKS_PER_NODE ))\necho \"NUM_OF_NODES=${NNODES}  TOTAL_NUM_RANKS=${NRANKS}  RANKS_PER_NODE=${RANKS_PER_NODE}\"\nCPU_BINDING1=list:4:9:14:19:20:25:56:61:66:71:74:79\n\nexport THUN_WS_PROB_SIZE=1024\nexport ZE_FLAT_DEVICE_HIERARCHY=COMPOSITE\nexport AFFINITY_ORDERING=compact\nexport RANKS_PER_TILE=1\nexport PLATFORM_NUM_GPU=6\nexport PLATFORM_NUM_GPU_TILES=2\n\n\ndate\nLD_PRELOAD=/usr/lib64/libpil4dfs.so mpiexec -np ${NRANKS} -ppn ${RANKS_PER_NODE} --cpu-bind ${CPU_BINDING1}  \\\n                                            --no-vni -genvall  thunder/svm_mpi/run/aurora/wrapper.sh thunder/svm_mpi/build_ws1024/bin/thundersvm-train \\\n                                            -s 0 -t 2 -g 1 -c 10 -o 1  /tmp/datascience/thunder_1/real-sim_M100000_K25000_S0.836\ndate\n\nclean-dfuse.sh ${DAOS_POOL}:${DAOS_CONT} #to unmount on compute node\n# fusermount3 -u /tmp/${USER}/${DAOS_POOL}/${DAOS_CONT} #to unmount on login node\n</code></pre>"},{"location":"aurora/data-management/daos/daos-overview/#mpi-io-container-access","title":"MPI-IO Container Access","text":"<p>The MPICH MPI-IO layer on Aurora (ROMIO) provides multiple I/O backends including one for DAOS. ROMIO can be used with dFuse and the interception library utilizing the UFS backend, but the DAOS backend will provide optimal performance. By default ROMIO will auto-detect DFS and use the DAOS backend.   MPI-IO itself is a common backend for many I/O libraries, including HDF5 and PNetCDF.\u00a0 Whether using collective I/O MPI-IO calls directly or indirectly via an I/O library, a  process called collective buffering can be done where data from small non-contiguous chunks across many compute nodes in the collective is aggregated into larger contiguous buffers on a few compute nodes, referred to as aggregators, from which DFS API calls are made to write to or read from DAOS.\u00a0 Collective buffering can improve or degrade I/O performance depending on the I/O pattern, and in the case of DAOS, disabling it can lead to I/O failures in some cases, where the I/O traffic directly from all the compute nodes in the collective to DAOS is too stressful in the form of extreme numbers of small non-contiguous data reads and writes.\u00a0 In ROMIO there are hints that should be set to either optimally enable or disable collective buffering.\u00a0 At this time you should explicitly enable collective buffering in the most optimal fashion, as disabling it or allowing it to default to disabled could result in I/O failures.  To optimally enable collective buffering, create a file with the following contents: <pre><code>romio_cb_write enable\nromio_cb_read enable\ncb_buffer_size 16777216\ncb_config_list *:8\nstriping_unit 2097152\n</code></pre></p> <p>Then simply set the following environment variable at run time to point to it: <pre><code>export ROMIO_HINTS=&lt;path to hints file&gt;\n</code></pre></p> <p>If you want to verify the settings, additionally set: <pre><code>export ROMIO_PRINT_HINTS=1\n</code></pre></p> <p>Which will print out all the ROMIO hints at run time.</p>"},{"location":"aurora/data-management/daos/daos-overview/#dfs-container-access","title":"DFS Container Access","text":"<p>DFS is the user level API for DAOS. This API is very similar to POSIX but still has many differences that would require code changes to utilize DFS directly. The DFS API can provide the best overall performance for any scenario other than workloads which benefit from caching.</p> Reference code for using DAOS through DFS mode and DAOS APIs<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;mpi.h&gt;\n#include &lt;daos.h&gt;\n#include &lt;daos_fs.h&gt;\nint main(int argc, char **argv)\n{\n    dfs_t *dfs;\n    d_iov_t global;\n    ret = MPI_Init(&amp;argc, &amp;argv);\n    ret = MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    ret = dfs_init();\n    ret = dfs_connect(getenv(\"DAOS_POOL\"), NULL, getenv(\"DAOS_CONT\"), O_RDWR, NULL, &amp;dfs);\n    ret = dfs_open(dfs, NULL, filename, S_IFREG|S_IRUSR|S_IWUSR,  O_CREAT|O_WRONLY,  obj_class, chunk_size, NULL, &amp;obj);\n    ret = dfs_write(dfs, obj, &amp;sgl, off, NULL);\n    ret = dfs_read(dfs, obj, &amp;sgl, off, &amp;read, NULL);\n    ret = dfs_disconnect(dfs);\n    ret = daos_fini();\n    ret = MPI_Finalize();\n}\n</code></pre> <p>The full code is available on the Aurora filesystem within <code>/soft/daos/examples/src/</code></p>"},{"location":"aurora/data-management/daos/daos-overview/#example-of-pytorch-integration-pydaosdaos_torch-module","title":"Example of PyTorch integration: <code>pydaos.daos_torch</code> module","text":"<p>First, setup an interactive job on a compute node and initialize the environment as follows: <pre><code>qsub ... -l filesystem:flare,daos_perf_fs\n\nmodule use /soft/modulefiles\nmodule load daos_perf\nmodule load frameworks\nlaunch-dfuse_perf.sh ${DAOS_POOL}:${DAOS_CONT}\n\nexport LD_LIBRARY_PATH=/lus/flare/projects/datasets/softwares/py_daos/daos_client_master_build_may2/lib64:$LD_LIBRARY_PATH\nexport PYTHONPATH     =/lus/flare/projects/datasets/softwares/py_daos/just_pydaos_new/:$PYTHONPATH\nmpiexec -n ... python pydaos_torch_example.py\n</code></pre></p> <p>Where the example Python script is:&gt; pydaos_torch_example.py<pre><code>import torch as sys_torch\nfrom pydaos.daos_torch import Dataset as DaosDataset\nfrom pydaos.daos_torch import Checkpoint as DaosCheckpoint\nfrom io import BytesIO\nfrom mpi4py import MPI\n\ncomm = MPI.COMM_WORLD\npydaos_torch_ckpt = DaosCheckpoint(\"datascience\", \"my_container\", \"\") #To connect to DFS container\na    = sys_torch.ones(1048576)\ndata = dict()\ndata = { \"a\": a, }\nname = f\"/data-{comm.rank}-of-{comm.size}.pt\"\n\n# PyDAOS Torch dataloader example\ndef transform(data):\n     return np.load(BytesIO(data), allow_pickle=True)['x']\nds = DaosDataset(pool=\"datascience\", cont=\"my-dataset\", transform_fn=transform)\n\n# PyDAOS Torch checkpoint save example\nwith pydaos_torch_ckpt.writer(name) as f:\n    sys_torch.save(data, f)\nprint(f\"Torch save completed\")\n\n# PyDAOS Torch checkpoint load example\nstream = pydaos_torch_ckpt.reader(name)\nloaded_data = sys_torch.load(stream, weights_only=True)\nprint(f\"Torch load completed\")\n</code></pre></p> <ul> <li>PyDAOS uses <code>dfs_write()</code> and read functions, which are faster than POSIX <code>dfuse_write()</code> and read functions.</li> <li>PyDAOS uses DFS containers and Python DAOS containers.</li> <li>The path to the dataset folders inside these containers does not include <code>/tmp</code> and just starts from <code>/dataset_dir1</code> which assumes a folder inside the <code>DAOS_POOL</code> and <code>DAOS_CONT</code></li> <li>The above build path might be upgraded with newer builds without warning</li> <li>More examples can be found at DAOS GitHub repo &gt; <code>pydaos.torch</code></li> </ul>"},{"location":"aurora/data-management/daos/daos-overview/#daos-hardware","title":"DAOS Hardware","text":"<p>Each DAOS server node is based on the Intel Coyote Pass platform:</p> <ul> <li>(2) Xeon 5320 CPU (Ice Lake)</li> <li>(16) 32GB DDR4 DIMMs</li> <li>(16) 512GB Intel Optane Persistent Memory 200</li> <li>(16) 15.3TB Samsung PM1733 NVMe</li> <li>(2) HPE Slingshot NIC</li> </ul> <p></p>"},{"location":"aurora/data-management/daos/daos-overview/#darshan-profiler-for-daos","title":"Darshan profiler for DAOS","text":"<p>Darshan is a lightweight I/O profiling tool consisting of a shared library your application preloads at runtime which generates a binary log file at program termination, and a suite of utilities to analyze this file.  Full official documentation can be found here.</p>"},{"location":"aurora/data-management/daos/daos-overview/#1-darshan","title":"1. Darshan","text":"<p>On Aurora, Darshan has been built in the programming environment in <code>/soft</code>.</p> <p>To get the Darshan utilities loaded into your programming environment, execute the following:</p> <pre><code>module use /soft/perftools/darshan/darshan-3.4.7/share/craype-2.x/modulefiles\nmodule load darshan\n</code></pre> <p>However it has not yet been fully modularized so the shared library must be manually preloaded at run time via <code>LD_PRELOAD</code>, along with PNetCDF and HDF5 shared libraries since support for those I/O libraries is included, and all 3 must precede any DAOS interception library, so the specification would be:</p> <pre><code>LD_PRELOAD=/soft/perftools/darshan/darshan-3.4.7/lib/libdarshan.so:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/oneapi-2025.0.5/hdf5-1.14.5-zrlo32i/lib/libhdf5.so:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/oneapi-2025.0.5/parallel-netcdf-1.12.3-cszcp66/lib/libpnetcdf.so:/usr/lib64/libpil4dfs.so\n</code></pre> <p>If your application is using <code>gpu_tile_compact.sh</code> then this whole <code>LD_PRELOAD</code> will go in your personal copy of the Bash script via the <code>export</code> builtin command.</p> <p>Run your application normally as you would do with <code>mpiexec</code> or <code>mpirun</code>.</p> <p>This generates a binary log file which has two additional modules: DFS for the DAOS file system API layer, and DAOS for the underlying object store.</p> <p>By default, the binary log file is stored here:</p> <pre><code>/lus/flare/logs/darshan/aurora/YYYY/M/D\n</code></pre> <p>where the last 3 directories are the date the file is generated, with your user ID, job ID and timestamp in the file name.  Alternatively, at run time you can specify the file name to be saved with a specified name in a different location with the following environment variable:</p> <pre><code>export DARSHAN_LOGFILE=&lt;full path to binary file name&gt;\n</code></pre>"},{"location":"aurora/data-management/daos/daos-overview/#2-darshan-util-environment-module","title":"2. <code>darshan-util</code> environment module","text":"<p><code>module load darshan-util</code> is needed for <code>darshan-parser</code> and <code>pydarshan</code></p> <p><code>LD_PRELOAD=/soft/perftools/darshan/darshan-3.4.7/lib/libdarshan-util.so:$LD_PRELOAD</code></p>"},{"location":"aurora/data-management/daos/daos-overview/#3-darshan-parser-utility","title":"3. <code>darshan-parser</code> utility","text":"<p><code>darshan-parser</code> can be used on the binany log file to get a text output of all the metrics as follows: <pre><code>/soft/perftools/darshan/darshan-3.4.7/bin/darshan-parser /lus/flare/logs/darshan/aurora/2025/5/21/myfile.darshan &gt; out.txt.\n</code></pre></p>"},{"location":"aurora/data-management/daos/daos-overview/#4-pydarshan-library-and-python-module","title":"4. PyDarshan library and Python module","text":"<p>For generating a graphical summary report, it is recommended to use the PyDarshan module on Aurora. It is a simple process of creating and activating a Python environment, installing the Darshan package, and then running the summary report generation command:</p> <p>For custom build: <pre><code>module load python\nmkdir &lt;pyton env dir&gt;\npython -m venv &lt;pyton env dir&gt;\ncd &lt;pyton env dir&gt;\nsource bin/activate\npip install darshan\npython -m darshan summary &lt;binary log file&gt;\n</code></pre></p> <p>For system build: <pre><code>module load python\n. /soft/daos/pydarshan_plots_venv/bin/activate\npip show darshan\n</code></pre> The above 3 lines should be replaced by a simpler <code>module load pydarshan</code> in the future. </p> <pre><code>python -m darshan summary /lus/flare/logs/darshan/aurora/2025/5/21/my.darshan\n</code></pre> <p>should generate the <code>.html</code> Darshan report</p>"},{"location":"aurora/data-management/daos/daos-overview/#cluster-size","title":"Cluster Size","text":"<p>DAOS cluster size is the number of available DAOS servers. While we are working towards bringing up the entire 1024 DAOS server available users, currently different number of DAOS nodes could be up. Please check with support or run an IOR test to get an estimate on the current number of DAOS servers available. The bandwidth listed here in the last column is a theoretical peak bandwidth.</p> <p>Expected Bandwidth Expected number of DAOS servers and its approximate expected bandwidth</p> Nodes Percentage Throughput 20 2% 1 TB/s 128 12.50% 5 TB/s 600 60% 10 TB/s 800 78% 20 TB/s 1024 100% 30 TB/s <p>The size of your current DAOS cluster can be found using the following formula: <pre><code>daos_cluster_size = ntarget / targets_per_node\n</code></pre> The value of <code>ntarget</code> comes from the output of: <pre><code>daos pool query &lt;pool_name&gt;\n</code></pre> and the value of <code>targets_per_node=32</code> is fixed given the node hardware configuration of our filesystem.</p> <p>An example: <pre><code>&gt; daos pool query hacc\nPool 050b20a3-3fcc-499b-a6cf-07d4b80b04fd, ntarget=4096, disabled=0, leader=2, version=131\n</code></pre> So the DAOS cluster size is: <pre><code>4096 targets / 32 targets per node \n = 128 daos servers\n</code></pre></p>"},{"location":"aurora/data-management/daos/daos-overview/#sharing-containers-with-multiple-users","title":"Sharing containers with multiple users","text":"<p>If you'd like to create a container that includes a dataset and allows multiple users from your project team to reuse it concurrently (with simultaneous mounting and safe read/write operations, i.e., without race conditions), you can follow the below procedure below. Before proceeding, ensure that all intended users have the necessary access to your project, pool, and user group.</p> <pre><code>daos container get-prop DAOS_POOL DAOS_CONT                   # provides the details on the current ACLs\ndaos cont update-acl -e \"A::pkcoff@:rw\" DAOS_POOL DAOS_CONT   # add the username to whom you want to share the container with\ndaos cont update-acl -e \"A:G:users@:rwta\" DAOS_POOL DAOS_CONT # alternatively you can update the acl for the group instead of a user.\ndaos container get-prop DAOS_POOL DAOS_CONT                   # verify the updated ACLs\ngroups                                                        # to check if the users are in the same group name \nchmod -R 775 /tmp/$DAOS_POOL/$DAOS_CONT/shared-dir            # provide the right chmod settings on the directory where they can read or write\nkaushikvelusamy@x4405c0s0b0n0:&gt; daos container get-prop d9cbdfc4-628b-4ec1-ad01-0b506e4fb3c0 ba1d5b48-4a88-4052-b764-729328a0dac3 # POOLUUID CONTUUID\nProperties for container ba1d5b48-4a88-4052-b764-729328a0dac3\nName                                             Value                       \n----                                             -----                         \nGroup (group)                                    users@                    \nAccess Control List (acl)                        A::OWNER@:rwdtTaAo, A::pkcoff@:r, A:G:GROUP@:rwtT   \nkaushikvelusamy@x4405c0s0b0n0:&gt; groups\nusers \n</code></pre>"},{"location":"aurora/data-management/daos/daos-overview/#known-issues-and-workarounds","title":"Known issues and workarounds","text":""},{"location":"aurora/data-management/daos/daos-overview/#1-large-bulk-io-write-issue","title":"1. Large bulk I/O write issue","text":"<p>There is a known issue Python with <code>pil4dfs</code> - Fix provided in DAOS-17499  - Current workaround is to set <code>D_IL_COMPATIBLE=1</code> environment variable. Y - You can skip <code>pil4dfs</code> for now if that happens.</p> <pre><code>python: can't open file '/home/jlo/dfuse/./app.py': [Errno 95] Operation not supported\n</code></pre>"},{"location":"aurora/data-management/daos/daos-overview/#2-pydaosdaos_torch-disconnect-and-clean-up","title":"2. <code>pydaos.daos_torch</code> disconnect and clean up","text":"<p>There is a DFS disconnect clean up issue. This should be fixed in the next release.</p>"},{"location":"aurora/data-management/daos/daos-overview/#3-libfabric-endpoint-creation-error","title":"3. Libfabric endpoint creation error","text":"<p>Occasionally at a high number of nodes and/or high PPN the following error that looks like this may show up in your stderr log:</p> <pre><code>04/02-11:03:16.60 x4319c0s0b0n0 DAOS[53174/53174/0] external ERR  # [1092097.708457] mercury-&gt;ctx [error] /builddir/build/BUILD/mercury-2.4.0/src/na/na_ofi.c:5400 na_ofi_eq_open() fi_cq_open failed, rc: -17 (File exists)\n04/02-11:03:16.61 x4319c0s0b0n0 DAOS[53174/53174/0] external ERR  # [1092097.722714] mercury-&gt;cls [error] /builddir/build/BUILD/mercury-2.4.0/src/na/na_ofi.c:5191 na_ofi_basic_ep_open() Could not open event queues\n04/02-11:03:16.61 x4319c0s0b0n0 DAOS[53174/53174/0] external ERR  # [1092097.722737] mercury-&gt;cls [error] /builddir/build/BUILD/mercury-2.4.0/src/na/na_ofi.c:5158 na_ofi_endpoint_open() na_ofi_basic_ep_open() failed\n04/02-11:03:16.61 x4319c0s0b0n0 DAOS[53174/53174/0] external ERR  # [1092097.722743] mercury-&gt;cls [error] /builddir/build/BUILD/mercury-2.4.0/src/na/na_ofi.c:7712 na_ofi_initialize() Could not create endpoint\n04/02-11:03:16.61 x4319c0s0b0n0 DAOS[53174/53174/0] external ERR  # [1092097.722976] mercury-&gt;cls [error] /builddir/build/BUILD/mercury-2.4.0/src/na/na.c:879 NA_Initialize_opt2() Could not initialize plugin\n04/02-11:03:16.61 x4319c0s0b0n0 DAOS[53174/53174/0] external ERR  # [1092097.722988] mercury-&gt;cls [error] /scratchbox/daos/mschaara/io500/daos/build/external/debug/mercury/src/mercury_core.c:1347 hg_core_init() Could not initialize NA class (info_string=ofi+cxi://cxi4, listen=0)\n04/02-11:03:16.61 x4319c0s0b0n0 DAOS[53174/53174/0] external ERR  # [1092097.723007] mercury-&gt;cls [error] /scratchbox/daos/mschaara/io500/daos/build/external/debug/mercury/src/mercury_core.c:6074 HG_Core_init_opt2() Cannot initialize core class\n04/02-11:03:16.61 x4319c0s0b0n0 DAOS[53174/53174/0] external ERR  # [1092097.723014] mercury-&gt;cls [error] /scratchbox/daos/mschaara/io500/daos/build/external/debug/mercury/src/mercury.c:1128 HG_Init_opt2() Could not create HG core class\n</code></pre> <p>You can disregard this, as the DAOS client will simply retry the operation until it succeeds.</p>"},{"location":"aurora/data-management/daos/daos-overview/#4-issue-with-the-gpu_tile_compactsh-bash-script-and-the-daos-interception-libraries","title":"4. Issue with the <code>gpu_tile_compact.sh</code> bash script and the DAOS Interception Libraries","text":"<p>There is currently a bug between the oneAPI Level Zero, the DAOS Interception Libraries (/usr/lib64/libpil4dfs.so and /usr/lib64/libioil.so) and the /soft/tools/mpi_wrapper_utils/gpu_tile_compact.sh bash script where you may get an error like this sporadically at scale: <pre><code>terminate called after throwing an instance of 'std::invalid_argument'\n  what():  stoul\n/soft/tools/mpi_wrapper_utils/gpu_tile_compact.sh: line 47: 38240 Aborted                 \"$@\"\nx4616c3s4b0n0.hostmgmt2616.cm.aurora.alcf.anl.gov: rank 2355 exited with code 134\nx4616c3s4b0n0.hostmgmt2616.cm.aurora.alcf.anl.gov: rank 2358 died from signal 15\n</code></pre></p> <p>This issue is still under investigation. In the meantime, there is a workaround which is to take the <code>/soft/tools/mpi_wrapper_utils/gpu_tile_compact.sh</code> Bash script and create your own version of it to perform the <code>LD_PRELOAD</code> of the interception library within this script. In the case of the <code>libpil4dfs.so</code>, you would add the following line just before the execution of the binary: <pre><code>export LD_PRELOAD=/usr/lib64/libpil4dfs.so\n</code></pre> For an example, see: <pre><code>/lus/flare/projects/Aurora_deployment/pkcoff/scripts/gpu_tile_compact_LD_PRELOAD.sh\n</code></pre></p>"},{"location":"aurora/data-management/daos/daos-overview/#5-na_hostunreach-errors","title":"5. <code>NA_HOSTUNREACH</code> errors","text":"<pre><code>hg_core_send_input_cb() NA callback returned error (NA_HOSTUNREACH)\n</code></pre> <p>is almost always the no-vni issue or network issue and not a DAOS issue</p>"},{"location":"aurora/data-management/daos/daos-overview/#best-practices","title":"Best practices","text":"<ol> <li>Check that you requested DAOS:    <pre><code>qsub \u2013l filesystems=daos_user_fs\n</code></pre></li> <li>Check that you loaded the DAOS module:    <pre><code>module load daos\n</code></pre></li> <li>Check that you have your DAOS pool allocated:    <pre><code>daos pool query datascience\n</code></pre></li> <li>Check that the DAOS client is running on all your nodes:    <pre><code>ps -ef | grep daos\n</code></pre></li> <li>Check that your container is mounted on all nodes:    <pre><code>mount | grep dfuse\n</code></pre></li> <li>Check that you can <code>ls</code> in your container:    <pre><code>ls /tmp/${DAOS_POOL}/${DAOS_CONT}\n</code></pre></li> <li>Check that your I/O actually failed.</li> <li>Check the health property in your container:    <pre><code>daos container get-prop $DAOS_POOL $CONT\n</code></pre></li> <li>Check if your space is full (min and max):    <pre><code>daos pool query datascience\n</code></pre></li> <li>Check if your query shows failed targets or rebuild in process:     <pre><code>daos pool query datascience\n</code></pre></li> <li>Run the following commands to check the health of your DAOS pool and container:     <pre><code>daos pool autotest\ndaos container check\n</code></pre></li> <li>If you are still having issues, please submit a ticket at support@alcf.anl.gov</li> </ol>"},{"location":"aurora/data-management/lustre/flare/","title":"Flare Filesystem","text":"<p>Flare is a 91 PB Lustre Filesystem with 160 OSTs, 40 MDTs, and 48 Gateway nodes mounted at <code>/lus/flare/projects/</code> with a peak theoretical performance of 650 GB/s. You should launch jobs only from this Flare space.</p> <p>Home is a 12 PB Gecko Lustre Filesystem with 32 OSTs and 12 MDTs.</p> <p>Follow this link for more basic information on I/O optimization for the Lustre Filesystem I/O</p>"},{"location":"aurora/data-management/moving_data_to_aurora/daos_datamover/","title":"To move data to your DAOS POSIX container","text":""},{"location":"aurora/data-management/moving_data_to_aurora/daos_datamover/#using-cp","title":"Using <code>cp</code>","text":"<pre><code>cp /lus/flare/projects/CSC250STDM10_CNDA/kaushik/thundersvm/input_data/real-sim_M100000_K25000_S0.836 /tmp/${DAOS_POOL}/${DAOS_CONT}\n</code></pre>"},{"location":"aurora/data-management/moving_data_to_aurora/daos_datamover/#using-daos-filesystem-copy","title":"Using DAOS filesystem copy","text":"<pre><code>daos filesystem copy --src /lus/flare/projects/CSC250STDM10_CNDA/kaushik/thundersvm/input_data/real-sim_M100000_K25000_S0.836 --dst daos://${DAOS_POOL}/${DAOS_CONT}/path_starting_from_within_container/\n</code></pre> <p>Note <code>/**tmp**/pool_name/container_name</code> path is not used above. </p> <p>You may have to replace the <code>DAOS_POOL</code> and <code>DAOS_CONT</code> labels with their UUIDs. UUIDs can be copied from <code>daos pool query ${DAOS_POOL}</code> and <code>daos container query $DAOS_POOL_NAME $DAOS_CONT_NAME</code></p>"},{"location":"aurora/data-management/moving_data_to_aurora/daos_datamover/#using-mpifileutils-distributed-cp-dcp","title":"Using mpifileutils distributed <code>cp</code> (DCP)","text":"<p>You can also use other mpi fileutils binaries designed for scalability and performance even when not using DAOS.</p> <pre><code>kaushikvelusamy@x4210c6s0b0n0:/soft/daos/mpifileutils/bin/&gt; ls\ndbcast  dbz2  dchmod  dcmp  dcp  dcp1  ddup  dfilemaker1  dfind  dreln  drm  dstripe  dsync  dtar  dwalk\n\nkaushikvelusamy@x4210c6s0b0n0:/tmp&gt; mpiexec --env LD_PRELOAD=/usr/lib64/libpil4dfs.so  -np 8 -ppn 8 --cpu-bind list:4:56:9:61:14:66:19:71  /soft/daos/mpifileutils/bin/dcp source/ /tmp/datascience/1_fSX_dS1_rd_fac_0/\n[2025-05-17T04:08:18] Walking /tmp/source\n[2025-05-17T04:08:18] Walked 11 items in 0.001 secs (7992.078 items/sec) ...\n[2025-05-17T04:08:18] Walked 11 items in 0.002 seconds (6707.939 items/sec)\n[2025-05-17T04:08:18] Copying to /tmp/datascience/1_fSX_dS1_rd_fac_0\n[2025-05-17T04:08:18] Items: 11\n[2025-05-17T04:08:18]   Directories: 1\n[2025-05-17T04:08:18]   Files: 10\n[2025-05-17T04:08:18]   Links: 0\n[2025-05-17T04:08:18] Data: 200.000 GiB (20.000 GiB per file)\n[2025-05-17T04:08:18] Creating 1 directories\n[2025-05-17T04:08:18] Creating 10 files.\n[2025-05-17T04:08:18] Copying data.\n[2025-05-17T04:08:28] Copied 200.000 GiB (100%) in 10.206 secs (19.597 GiB/s) done\n[2025-05-17T04:08:28] Copy data: 200.000 GiB (214748364800 bytes)\n[2025-05-17T04:08:28] Copy rate: 19.597 GiB/s (214748364800 bytes in 10.206 seconds)\n[2025-05-17T04:08:28] Syncing data to disk.\n[2025-05-17T04:08:28] Sync completed in 0.001 seconds.\n[2025-05-17T04:08:28] Fixing permissions.\n[2025-05-17T04:08:28] Updated 11 items in 0.001 seconds (11288.859 items/sec)\n[2025-05-17T04:08:28] Syncing directory updates to disk.\n[2025-05-17T04:08:28] Sync completed in 0.001 seconds.\n[2025-05-17T04:08:28] Started: May-17-2025,04:08:18\n[2025-05-17T04:08:28] Completed: May-17-2025,04:08:28\n[2025-05-17T04:08:28] Seconds: 10.250\n[2025-05-17T04:08:28] Items: 11\n[2025-05-17T04:08:28]   Directories: 1\n[2025-05-17T04:08:28]   Files: 10\n[2025-05-17T04:08:28]   Links: 0\n[2025-05-17T04:08:28] Data: 200.000 GiB (214748364800 bytes)\n[2025-05-17T04:08:28] Rate: 19.513 GiB/s (214748364800 bytes in 10.250 seconds)\n\nkaushikvelusamy@x4210c6s0b0n0:/tmp&gt; mpiexec --env LD_PRELOAD=/usr/lib64/libpil4dfs.so  -np 16 -ppn 16 --cpu-bind list:4:5:6:7:8:9:10:11:56:57:58:59:60:61:62:63 /soft/daos/mpifileutils/bin/dcp source/ /tmp/datascience/1_fSX_dS1_rd_fac_0/\n[2025-05-17T04:08:39] Walking /tmp/source\n[2025-05-17T04:08:39] Walked 11 items in 0.002 secs (5838.681 items/sec) ...\n[2025-05-17T04:08:39] Walked 11 items in 0.002 seconds (4502.556 items/sec)\n[2025-05-17T04:08:39] Copying to /tmp/datascience/1_fSX_dS1_rd_fac_0\n[2025-05-17T04:08:39] Items: 11\n[2025-05-17T04:08:39]   Directories: 1\n[2025-05-17T04:08:39]   Files: 10\n[2025-05-17T04:08:39]   Links: 0\n[2025-05-17T04:08:39] Data: 200.000 GiB (20.000 GiB per file)\n[2025-05-17T04:08:39] Creating 1 directories\n[2025-05-17T04:08:39] Creating 10 files.\n[2025-05-17T04:08:39] Copying data.\n[2025-05-17T04:08:45] Copy data: 200.000 GiB (214748364800 bytes)\n[2025-05-17T04:08:45] Copy rate: 38.088 GiB/s (214748364800 bytes in 5.251 seconds)\n[2025-05-17T04:08:45] Syncing data to disk.\n[2025-05-17T04:08:45] Sync completed in 0.002 seconds.\n[2025-05-17T04:08:45] Fixing permissions.\n[2025-05-17T04:08:45] Updated 11 items in 0.001 seconds (7689.630 items/sec)\n[2025-05-17T04:08:45] Syncing directory updates to disk.\n[2025-05-17T04:08:45] Sync completed in 0.002 seconds.\n[2025-05-17T04:08:45] Started: May-17-2025,04:08:39\n[2025-05-17T04:08:45] Completed: May-17-2025,04:08:45\n[2025-05-17T04:08:45] Seconds: 5.299\n[2025-05-17T04:08:45] Items: 11\n[2025-05-17T04:08:45]   Directories: 1\n[2025-05-17T04:08:45]   Files: 10\n[2025-05-17T04:08:45]   Links: 0\n[2025-05-17T04:08:45] Data: 200.000 GiB (214748364800 bytes)\n[2025-05-17T04:08:45] Rate: 37.744 GiB/s (214748364800 bytes in 5.299 seconds)\n</code></pre> <p>Ref: DAOS Data Mover Documentation</p>"},{"location":"aurora/data-management/moving_data_to_aurora/globus/","title":"Transferring Files through Globus","text":""},{"location":"aurora/data-management/moving_data_to_aurora/globus/#flare-filesystem","title":"Flare filesystem","text":"<p>For transfers to/from Flare, you may use the Globus collection <code>alcf#dtn_flare</code>.</p>"},{"location":"aurora/data-management/moving_data_to_aurora/globus/#home-filesystem","title":"Home filesystem","text":"<p>Currently, for transfers to/from Aurora <code>/home</code>, only Globus Connect Personal is supported. Perform the following steps to transfer data to/from there:</p> <ol> <li> <p>On a fresh connection to the login nodes, ensure no proxies are being set (which may require commenting out the proxy settings in the <code>~/.bashrc</code> or <code>~/.bash_profile</code> files), and execute:</p> <pre><code>/soft/tools/proxychains/bin/proxychains4 -f /soft/tools/proxychains/etc/proxychains.conf /soft/tools/globusconnect/globusconnect -setup --no-gui\n</code></pre> </li> <li> <p>Paste the link provided by the above command into a browser and follow the instructions to set up a personal endpoint:</p> <ul> <li>When requested, input your ALCF username and one-time password from your CRYPTOCard/MobilePASS+ token.</li> <li>Select the Allow button.</li> <li>Enter the authentication code generated back into the terminal.</li> <li>Enter a name for the endpoint (e.g., <code>aurora_login_uan11</code>).</li> </ul> </li> <li> <p>On the same terminal, execute:</p> <pre><code>/soft/tools/proxychains/bin/proxychains4 -f /soft/tools/proxychains/etc/proxychains.conf /soft/tools/globusconnect/globusconnect -start &amp;\n</code></pre> <ul> <li>By default, the command only gives access to your home directory.</li> <li>You can add <code>-restrict-paths /lus/flare/projects/YOURPROJECT</code> to access your project directory.</li> </ul> </li> <li> <p>Open the Globus web app and search for the endpoint name defined above. You will now see your home directory (and project directory, if requested) on Aurora and can initiate transfers with other endpoints (e.g., the Eagle file system on Polaris at <code>alcf#dtn_eagle</code>).</p> </li> </ol>"},{"location":"aurora/data-science/jupyter/","title":"Running JupyterLab and Jupyter Notebook on Aurora","text":"<p>ALCF provides a JupyterHub for running JupyterLab and Jupyter Notebook on Polaris and Sophia with minimal setup required from the user. While this service is not yet available on Aurora, users can still run JupyterLab and Notebook using SSH tunneling and port forwarding.</p>"},{"location":"aurora/data-science/jupyter/#prerequisites","title":"Prerequisites","text":"<p>Please note that you only need a terminal (to SSH into Aurora) and a browser on your local machine (laptop or desktop). All the required packages need to be installed on Aurora only.</p>"},{"location":"aurora/data-science/jupyter/#1-initial-setup","title":"1. Initial Setup","text":"<ol> <li> <p>SSH into Aurora:    The first step is to connect to Aurora through SSH. Note that tunneling or port forwarding is not required for this step.    If you have a problem with this step, please check Getting Started on Aurora.    <pre><code>ssh &lt;your-username&gt;@aurora.alcf.anl.gov\n</code></pre>    Make a note of the specific login node ID that you landed on. Run <code>hostname -f</code>, which may return something like:    <pre><code>aurora-uan-0011.hostmgmt.cm.aurora.alcf.anl.gov\n</code></pre></p> </li> <li> <p>Create a Virtual Environment:    If you already have a Python environment, you can skip this step.    <pre><code>module load frameworks\npython3 -m venv myenv --system-site-packages\n</code></pre>    Note that this command will create a directory called <code>myenv</code> in the current working directory, and <code>myenv</code> will also be the name of the virtual environment. You can change the name as you see fit.    You can find more information about creating a virtual environment on Aurora here.</p> </li> <li> <p>Install Required Packages:    The third step is to install <code>jupyterlab</code> and/or <code>notebook</code> as well as <code>ipykernel</code>.    Note that you need to activate the virtual environment before installing the packages. Here we assume that the virtual environment is named <code>myenv</code> and is located in the current working directory.    <pre><code>source myenv/bin/activate\npip install jupyterlab notebook ipykernel\n</code></pre></p> </li> <li> <p>Install IPython Kernel:    The fourth step is to install the IPython kernel for the current virtual environment. IPython kernels enable easily switching between different Python environments on JupyterLab and Notebook.    <pre><code>python -m ipykernel install --user --name myenv\n</code></pre>    Steps 2, 3, and 4 are only required once for each virtual environment.</p> </li> </ol>"},{"location":"aurora/data-science/jupyter/#2-run-jupyterlab-on-a-login-node","title":"2. Run JupyterLab on a Login Node","text":"<p>Warning</p> <p>This is not recommended for compute-intensive or memory-intensive workloads. Run the JupyterLab server on a compute node (see below section) if the workload is heavy.</p> <ol> <li> <p>Start JupyterLab:    <pre><code>source myenv/bin/activate\njupyter lab --no-browser --port=9999\n</code></pre></p> </li> <li> <p>Copy the Address:    The address will be displayed as the output of the previous command.    <pre><code>http://127.0.0.1:9999/?token=&lt;provided-token&gt;\n</code></pre></p> </li> <li> <p>Set Up SSH Tunneling:    Open a new terminal tab or window on your local machine and run the following command:    <pre><code>ssh -L 9999:127.0.0.1:9999 &lt;your-username&gt;@&lt;login_node_hostname&gt;\n</code></pre>    where <code>&lt;login_node_hostname&gt;</code> is the specific login node address noted in step 1.1.</p> </li> <li> <p>Replace <code>9999</code> with another port if it is unavailable.</p> </li> <li> <p>Access JupyterLab:    Open your browser and navigate to the address copied above:    <pre><code>http://localhost:9999/?token=&lt;provided-token&gt;\n</code></pre></p> </li> </ol>"},{"location":"aurora/data-science/jupyter/#3-run-jupyterlab-on-a-compute-node","title":"3. Run JupyterLab on a Compute Node","text":""},{"location":"aurora/data-science/jupyter/#step-1-request-a-compute-node","title":"Step 1: Request a Compute Node","text":"<p>You need a job running on Aurora to launch JupyterLab on a compute node. Below is an example of how to submit an interactive job to request a compute node. Note that you can also connect to one of the compute nodes of any of your non-interactive jobs that is running on Aurora. See Running Jobs on Aurora for more information.</p> <ol> <li> <p>Submit a Job:    Submit an interactive job to request a compute node:    <pre><code>qsub -l select=1 -l walltime=60:00 -A &lt;project_name&gt; -q &lt;queue_name&gt; -I\n</code></pre>    You need to modify the <code>-A</code> and <code>-q</code> options to match your project name and queue name as well as the resources you need.</p> </li> <li> <p>Find Compute Node Hostname:    Once the interactive job starts, you will be connected to the compute node. You can check the hostname with:    <pre><code>hostname\n</code></pre>    If you are not running an interactive job, you can find the hostname of the compute node by checking the <code>qstat</code> output.    First, you need to find the job ID of the job you are interested in. The following command will list all the jobs you have submitted. You need the ID of any one of the running jobs you are interested in.    <pre><code>qstat -u &lt;your_username&gt;\n</code></pre>    Then, we can find the hostname of the compute node by running:    <pre><code>qstat -f &lt;job_id&gt;\n</code></pre>    The hostname of the compute node will be displayed in the <code>exec_host</code> field. You can extract the hostname from the output with the following command:    <pre><code>qstat -f &lt;job_id&gt; | awk -F '=' '/exec_host/ {print $2}' | tr '+' '\\n' | cut -d '/' -f 1\n</code></pre>    This should give you a hostname like <code>x4603c0s0b0n0</code>. Note that you can SSH into the compute nodes only when your job is running.</p> </li> </ol>"},{"location":"aurora/data-science/jupyter/#step-2-start-jupyterlab-on-the-compute-node","title":"Step 2: Start JupyterLab on the Compute Node","text":"<ol> <li> <p>SSH to the Compute Node:    From the login node:    <pre><code>ssh &lt;compute_node_hostname&gt;\n</code></pre></p> </li> <li> <p>Activate the Environment:    <pre><code>source &lt;path_to_your_virtual_environment&gt;/bin/activate\n</code></pre></p> </li> <li> <p>Start JupyterLab:    <pre><code>jupyter lab --no-browser --port=9999\n</code></pre></p> </li> </ol>"},{"location":"aurora/data-science/jupyter/#step-3-set-up-ssh-tunneling","title":"Step 3: Set Up SSH Tunneling","text":"<ol> <li> <p>Tunnel from Compute Node to Local Machine:    On your local machine, run:    <pre><code>ssh -L 9999:127.0.0.1:9999 -J &lt;your-username&gt;@aurora.alcf.anl.gov &lt;your-username&gt;@&lt;compute_node_hostname&gt;\n</code></pre>    Please note that the <code>-J</code> option is used to specify the jump host, which is the Aurora login node.    Replace <code>9999</code> with another port if it is unavailable.    Additionally, make sure to follow the recommended steps to enable ssh'ing from the login to the compute nodes and ensure that the public key from your local machine is added to <code>~/.ssh/authorized_keys</code> on Aurora.</p> </li> <li> <p>Access JupyterLab:    Open your browser and navigate to:    <pre><code>http://localhost:9999/?token=&lt;your-token&gt;\n</code></pre></p> </li> </ol> <p>Tip</p> <p>You can use <code>tmux</code> or <code>screen</code> to keep JupyterLab running if the SSH connection drops.</p>"},{"location":"aurora/data-science/profiling_dl/","title":"Profiling Deep Learning Applications","text":"<p>On Aurora, we can use the <code>unitrace</code> profiler from Intel to profile deep learning applications. Refer to the <code>unitrace</code> documentation page for details.</p>"},{"location":"aurora/data-science/profiling_dl/#example-usage","title":"Example Usage","text":"<p>We can use <code>unitrace</code> to trace an application running on multiple ranks and multiple nodes. A simple example, where we use a wrapper script to trace rank 0 on each node of a 4-node job running a PyTorch application, is below.</p> <p>There are several important shell variables in the wrapper, which may require modification:</p> <pre><code>#!/bin/bash\n## This wrapper should be used with unitrace to trace in any number of nodes.\n## The script for this example is set up to trace rank 0 of the first 4 nodes in the case of\n## profiling a job running on more than 4 nodes.\nFNAME_EXT=$(basename \"$2\")\nFNAME=\"${FNAME_EXT%%.*}\"\n\nNNODES=`wc -l &lt; $PBS_NODEFILE`\n\nWORK_DIR=/path/to/the/Python/program\nUNITRACE_DIR=/opt/aurora/24.180.1/support/tools/pti-gpu/063214e # (1)!\nUNITRACE_LIB=${UNITRACE_DIR}/lib64\nUNITRACE_BIN=${UNITRACE_DIR}/bin\nUNITRACE_EXE=${UNITRACE_BIN}/unitrace\nDTAG=$(date +%F_%H%M%S)\nUNITRACE_OUTDIR=${WORK_DIR}/logs/unitrace_profiles/name_of_choice_json_n${NNODES}_${DTAG}/${FNAME}_n${NNODES}_${DTAG}\nmkdir -p ${UNITRACE_OUTDIR}\nUNITRACE_OPTS=\" --ccl-summary-report --chrome-mpi-logging --chrome-sycl-logging \\\n--chrome-device-logging \\\n--chrome-ccl-logging --chrome-call-logging --chrome-dnn-logging --device-timing --host-timing \\\n--output-dir-path ${UNITRACE_OUTDIR} --output ${UNITRACE_OUTDIR}/UNITRACE_${FNAME}_n${NNODES}_${DTAG}.txt \"  # (2)!\n\nexport LD_LIBRARY_PATH=${UNITRACE_LIB}:${UNITRACE_BIN}:$LD_LIBRARY_PATH\n\n# Use $PMIX_RANK for MPICH and $SLURM_PROCID with srun.\nPROFRANK=0 # (3)!\nRANKCUTOFF=48 # (4)!\n\nif [[ $PALS_LOCAL_RANKID -eq $PROFRANK ]] &amp;&amp; [[ $PMIX_RANK -lt $RANKCUTOFF ]]; then\n  echo \"On rank $PMIX_RANK, collecting traces \"\n  $UNITRACE_EXE $UNITRACE_OPTS \"$@\"\nelse\n  \"$@\"\nfi\n</code></pre> <ol> <li><code>UNITRACE_DIR</code>: This is the main <code>unitrace</code> directory, which may change after an update to the programming environment.</li> <li><code>UNITRACE_OPTS</code>: These are the options that <code>unitrace</code> uses to trace data at different levels. Based on the number of options, the sizes of the output profiles will vary. Usually, enabling more options leads to a larger profile (in terms of storage in MB).</li> <li><code>PROFRANK</code>: As implemented, this variable is set by the user to trace the rank of choice. For example, this wrapper will trace rank 0 on each node.</li> <li><code>RANKCUTOFF</code>: This variable is Aurora-specific. As we can run as many as 12 ranks per node (without using CCS), the first 4 nodes of a job will have 48 ranks running. This provides the upper cutoff of the label (in number) of ranks, beyond which <code>unitrace</code> will not trace any rank. A user can change the number according to the number of maximum ranks running per node to set up how many ranks to be traced. <code>unitrace</code> will produce a profile (<code>json</code> file, by default) per traced rank. This profile can be viewed using the Perfetto trace viewer.</li> </ol>"},{"location":"aurora/data-science/profiling_dl/#deployment","title":"Deployment","text":"<p>The wrapper above can be deployed using the following PBS job script:</p> job_script.sh<pre><code>#!/bin/bash -x\n#PBS -l select=4\n#PBS -l place=scatter\n#PBS -l walltime=00:10:00\n#PBS -q debug-scaling\n#PBS -l filesystems=&lt;fs1:fs2&gt;\n#PBS -A &lt;ProjectName&gt;\n\nWORK_DIR=/path/to/the/Python/program\nUNITRACE_WRAPPER=${WORK_DIR}/unitrace_wrapper.sh\n\n# MPI and OpenMP settings\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=12\n\nlet NRANKS=${NNODES}*${NRANKS_PER_NODE}\n\nmodule load frameworks/2024.2.1_u1\n\nmpiexec --pmi=pmix -n ${NRANKS} -ppn ${NRANKS_PER_NODE} -l --line-buffer \\\n${UNITRACE_WRAPPER} python ${WORK_DIR}/application.py \n</code></pre>"},{"location":"aurora/data-science/python/","title":"Python on Aurora","text":"<p>Importing Python modules at scale</p> <p>We have system-installed frameworks modules described in this page, which contain common AI/ML packages such as PyTorch and TensorFlow. If a custom package or virtual environment is installed in your own home or project directory, it is highly recommended to use the Copper package to help reduce I/O overhead when importing Python modules at large node counts. We have seen that beyond 1000 nodes, importing Python modules from a home or Lustre project directory might be significantly slower, or it may even crash the Lustre file system. Please refer to Copper for detailed instructions on loading custom-installed Python packages using Copper.</p> <p>Info</p> <p>If you only use packages from the system installed framework module, Copper is not needed. </p>"},{"location":"aurora/data-science/python/#aiml-framework-module","title":"AI/ML Framework Module","text":"<p>For most Python users on Aurora, a good starting point is the AI/ML framework module.  The Anaconda environment loaded with this module makes available TensorFlow, Horovod, and PyTorch with Intel extensions and optimizations, among other popular Python and ML packages. </p> <p>The following command can be used both from an interactive session on a terminal and within a batch job script to load the latest module <pre><code>module load frameworks\n</code></pre></p> <p>Please note that:</p> <ul> <li>The <code>frameworks</code> module automatically activates a pre-built <code>conda</code> environment which comes with GPU-supported builds of PyTorch and TensorFlow. Both of these frameworks have <code>Horovod</code> support for multi-node calculations, as well as PyTorch DDP with oneCCL.</li> <li>The <code>frameworks</code> module may load a different oneAPI compiler SDK than the default module</li> <li>The <code>frameworks</code> module is updated approximately every quarter</li> </ul> <p>For more information on PyTorch and TensorFlow on Aurora, please see the respective pages: </p> <ul> <li>PyTorch</li> <li>TensorFlow</li> </ul>"},{"location":"aurora/data-science/python/#virtual-environments-via-venv","title":"Virtual environments via <code>venv</code>","text":"<p>While the Anaconda environment automatically loaded with the <code>frameworks</code> module contains many  of the most commonly used Python packages for our users, you may still  encounter a scenario in which you need to extend the functionality of the  environment (i.e. install additional packages). In this case, we suggest the use of Python virtual environments. </p> <p>Warning</p> <p>There are several alternative approaches for extending or modifying the base Anaconda environments that are generally not recommended on ALCF machines. On Aurora, there are additional performance and functionality pitfalls with those approaches. More detailed information on the alternatives can be seen on the Polaris Python documentation.</p> <p>Creating and activating a new virtual environment (<code>venv</code>) is straightforward. After loading the above module, execute:</p> <pre><code>python3 -m venv /path/to/new/venv --system-site-packages\nsource /path/to/new/venv/bin/activate\n</code></pre> <p>The <code>--system-site-packages</code> flag will make sure that all the packages included in the <code>frameworks</code> module are available after sourcing the <code>venv</code>. If, however, you would like to create an empty <code>venv</code>, simply remove this flag. You can always retroactively change the <code>--system-site-packages</code> flag state for  this virtual environment by editing <code>venv/pyvenv.cfg</code> and changing the value  of <code>include-system-site-packages</code> to <code>true</code>.</p> <p>To install a different version of a package that is already installed in the  base environment, you can use: <pre><code>pip install --ignore-installed ... # or -I\n</code></pre> The base environment is not writable, so it is not possible to remove or  uninstall packages from it. The packages installed with the above <code>pip</code> command  should shadow those installed in the base environment.</p> <p>Any time you wish to use this virtual environment in future shell sessions, be sure to first execute <code>module load frameworks</code> before <code>source /path/to/new/venv/bin/activate</code>.</p> <p>An alternative, although not recommended, approach to creating a <code>venv</code> is to install packages with <pre><code>pip install --user ...\n</code></pre> which will install packages in <code>$PYTHONUSERBASE/lib/pythonX.Y/site-packages</code>. Note that this approach may require the <code>PATH</code> environment variable to be modified with <code>export PATH=$PYTHONUSERBASE/bin:$PATH</code>. Cloning the Anaconda environment provided with the <code>frameworks</code> module, or using <code>venv</code> are both more flexible and transparent methods compared to <code>--user</code> installs.</p>"},{"location":"aurora/data-science/python/#intels-data-parallel-extensions-for-python-dpep","title":"Intel's Data Parallel Extensions for Python (DPEP)","text":"<p>On Aurora, users can access Intel's Python stack comprising of compilers and libraries for programming heterogenous devices, namely the Data Parallel Extensions for Python (DPEP). DPEP is composed of three main packages for programming on CPUs and GPUs:</p> <ul> <li>dpnp - Data Parallel Extensions for Numpy is a library that implements a subset of Numpy that can be executed on any data parallel device. The subset is a drop-in replacement of core Numpy functions and numerical data types, similar to CuPy for CUDA devices.</li> <li>dpctl - Data Parallel Control library provides utilities for device selection, allocation of data on devices, tensor data structure along with Python Array API Standard implementation, and support for creation of user-defined data-parallel extensions.</li> <li>numba_dpex - Data Parallel Extensions for Numba is an extension to Numba compiler for programming data-parallel devices similar to developing programs with Numba for CPU or CUDA devices.</li> </ul> <p>The DPEP packages follow the compute-follows-data programming model,  meaning that the offload target for a Python library call, or a hand-written kernel using numba-dpex,  does not need to be specified directly when making the call. Instead, the offload target is inferred from the input arguments to the library call. With this programming model, the user only needs to specify the offload target when creating the tensor/ndarray objects. For example,</p> <pre><code>import dpctl.tensor as dpt\n\nx_gpu = dpt.arange(100, device=\u201dgpu\u201d)\nsqx_gpu = dpt.square(x_gpu) # (1)!\nprint(sqx_gpu.device) # (2)!\n</code></pre> <ol> <li><code>dpct.square()</code> offloads to the \"gpu\" device</li> <li><code>sqx_gpu</code> is created on the \"gpu\" device</li> </ol> Output <pre><code>Device(level_zero:gpu:0)\n</code></pre> <p>However, note that operating on arrays created on different devices will raise an exception.</p>"},{"location":"aurora/data-science/python/#accessing-the-dpep-packages","title":"Accessing the DPEP Packages","text":"<p>Users can access the <code>dpnp</code> (v0.16.3) and <code>dpctl</code> (v0.18.3) packages by simply loading the latest AI/ML frameworks module with <code>module load frameworks</code>.</p> <p>Accessing numba-dpex on Aurora</p> <p>The current <code>frameworks</code> module does not come with the numba-dpex package installed, thus users need to install it separately.  This issue will be addressed in the next <code>frameworks</code> module, but in the mean time users can either create a new environment and install the dpnp and dpctl packages with <pre><code>module load frameworks\nmodule load cmake\nconda create -y --prefix /path/to/dpep_env python=3.10 pip\nconda install -y -c https://software.repos.intel.com/python/conda/linux-64 -c conda-forge --strict-channel-priority dpctl==0.18.3 dpnp==0.16.3\n</code></pre> or clone the base environment with <pre><code>module load frameworks\nconda create --prefix /path/to/dpep_env --clone /opt/aurora/24.347.0/frameworks/aurora_nre_models_frameworks-2025.0.0\n</code></pre> and then install numba-dpex from source with <pre><code>conda install -y scikit-build numba==0.59* -c conda-forge\npip install versioneer\ngit clone https://github.com/IntelPython/numba-dpex.git\ncd numba-dpex\nCXX=$(which dpcpp) python setup.py develop\n</code></pre></p>"},{"location":"aurora/data-science/python/#dpnp","title":"dpnp","text":"<p>The dpnp library implements the NumPy API using DPC++ and is meant to serve as a drop-in replacement for NumPy, similar to CuPy for CUDA devices. Therefore, dpnp should be used to port NumPy and CuPy code to Intel GPU, however, please refer to this comparison table to check the current coverage of dpnp API relative to NumPy and CuPy.</p> <p>Below is a minimal example using dpnp to create and operate on an array allocated on the PVC.</p> <pre><code>import dpnp as np\n\nx = np.asarray([1, 2, 3]) # (1)!\nprint(\"Array x allocated on the device:\", x.device)\ny = np.sum(x) # (2)!\nprint(\"Result y is located on the device:\", y.device)\n</code></pre> <ol> <li><code>np.asarray()</code> creates an array on the default SYCL device, which is the Intal Max 1550 GPU on Aurora. The queue associated with this array is now carried with <code>x</code>, and the pre-compiled kernel for <code>np.sum(x)</code> is submitted to that queue. </li> <li>The result <code>y</code> is allocated on the device and is associated with the queue of <code>x</code>.</li> </ol> Output <pre><code>Array x allocated on the device: Device(level_zero:gpu:0)\nResult y is located on the device: Device(level_zero:gpu:0)\n</code></pre> <p>All dpnp array creation routines and random number generators have additional optional keyword arguments (device, queue, and usm_type) which users can leverage to explicitly specify on which device or queue they want the data to be created along with the USM memory type to be used.</p> <p>Changes after version 0.15.0</p> <p>For dpnp version &lt;= 0.15.0, all dpnp kernels are hard-coded to sync with the CPU after completion (i.e., <code>event.wait()</code> is inserted before returning).  From dpnp version &gt; 0.15.0, all kernels are run asynchronously, with linear ordering of groups of tasks (similar to CuPy).  This results in faster runtime and better GPU utilization.  To time kernels with dpnp &gt; 0.15.0, insert <code>.sycl_queue.wait()</code> before measuring the end time, for example <pre><code>import dpnp as np\nfrom time import perf_counter\n\nx = np.random.randn(1000,1000)\ntic = perf_counter()\ny = np.matmul(x,x)\ny.sycl_queue.wait()\nprint(f\"Execution time: {perf_counter() - tic} sec\")\n</code></pre></p>"},{"location":"aurora/data-science/python/#dpctl","title":"dpctl","text":"<p>The dpctl package lets users access devices supported by the DPC++ SYCL runtime.  The package exposes features such as device instrospection, execution queue creation, memory allocation, and kernel submission.  Below are some of the basic device management functions, but more functionality is available on the dpctl documentation.</p> <pre><code>import dpctl\n\ndpctl.lsplatform()\nnum_devices = dpctl.get_num_devices(device_type=\"gpu\") # (1)!\ndevice_list =  dpctl.get_devices(device_type=\"gpu\") # (2)!\nprint(f\"Found {num_devices} GPU devices\")\nfor device in device_list:\n    print(f\"\\t{device}\")\nprint(\"\\nFound CPU devices: \", dpctl.has_cpu_devices()) # (3)!\n</code></pre> <ol> <li>Get the number of GPU devices on the node</li> <li>Get the list of GPU devices on the node</li> <li>Check if CPU devices are available on the node</li> </ol> Output <pre><code>Intel(R) Level-Zero 1.5\nFound 12 GPU devices\n    &lt;dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Data Center GPU Max 1550] at 0x154e8da03430&gt;\n    &lt;dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Data Center GPU Max 1550] at 0x154e8da034f0&gt;\n    &lt;dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Data Center GPU Max 1550] at 0x154e8da035b0&gt;\n    &lt;dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Data Center GPU Max 1550] at 0x154e8da03530&gt;\n    &lt;dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Data Center GPU Max 1550] at 0x154e8da03f70&gt;\n    &lt;dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Data Center GPU Max 1550] at 0x154e8d005770&gt;\n    &lt;dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Data Center GPU Max 1550] at 0x154e8b5a3ab0&gt;\n    &lt;dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Data Center GPU Max 1550] at 0x154e8d2467b0&gt;\n    &lt;dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Data Center GPU Max 1550] at 0x154e8da24ef0&gt;\n    &lt;dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Data Center GPU Max 1550] at 0x154e8da03fb0&gt;\n    &lt;dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Data Center GPU Max 1550] at 0x154e8da240b0&gt;\n    &lt;dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Data Center GPU Max 1550] at 0x154e8da24130&gt;\n\nFound CPU devices:  False\n</code></pre> <p>Managing GPU and CPU devices on Aurora</p> <p>On Aurora, <code>ONEAPI_DEVICE_SELECTOR=level_zero:gpu</code> is set by default, meaning that the GPU are the only devices visible to dpctl.  For this reason, <code>dpctl.has_cpu_devices()</code> returns <code>False</code>.  This setting allows dpnp and dpctl to use the GPU as the default SYCL device without needing to explicitly specify it. To access the CPU as a SYCL device, set <code>ONEAPI_DEVICE_SELECTOR=opencl:cpu</code>.</p> <p>In addition, the number of GPU devices visible on each node depends on the <code>ZE_FLAT_DEVICE_HIERARCHY</code> environment variable. With <code>ZE_FLAT_DEVICE_HIERARCHY=FLAT</code> 12 devices are visible (tile as device mode),  whereas with <code>ZE_FLAT_DEVICE_HIERARCHY=COMPOSITE</code> 6 devices are visible (GPU as device).</p> <p>The dpctl library contains <code>dpctl.tensor</code>, which is a tensor library implemented using DPC++ that follows the Python Array API standard. We refer the user to the dpctl.tensor documentation for details on all the array creation, manipulation, and linear algebra functions.  </p> <p>Changes after version 0.17.0</p> <p>Similarly to dpnp, dpctl version &gt; 0.17.0 runs all kernels asynchronously, therefore <code>.sycl_queue.wait()</code> must be used to measure execution time on GPU. </p>"},{"location":"aurora/data-science/python/#numba-dpex","title":"numba-dpex","text":"<p>Numba-dpex is Intel's Data Parallel Extension for Numba which allows users to apply Numba's JIT compiler and generate performant, parallel code on Intel's GPU. Its LLVM-based code generator implements a new kernel programming API (kapi) in pure Python that is modeled after the SYCL API. The example below implements and launches simple vector addition as a range kernel. Range kernels implement a basic parallel-for calculation that is ideally suited for embarrassingly parallel operations, such as element-wise computations over n-dimensional arrays.</p> <pre><code>import dpnp\nimport numba_dpex as dpex\nfrom numba_dpex import kernel_api as kapi\n\n# Data parallel kernel implementation of vector sum\n@dpex.kernel # (1)!\ndef vecadd(item: kapi.Item, a, b, c):\n    i = item.get_id(0) # (2)!\n    c[i] = a[i] + b[i]\n\nN = 1024 # (3)!\na = dpnp.ones(N)\nb = dpnp.ones_like(a)\nc = dpnp.zeros_like(a)\ndpex.call_kernel(vecadd, dpex.Range(N), a, b, c)\nassert dpnp.allclose(c,a+b)\nprint(\"Sum completed successfully\")\n</code></pre> <ol> <li>Decorate the <code>vecadd</code> function as a dpex kernel</li> <li>Get the work item</li> <li>Define the number of work items</li> </ol> <p>The <code>vecadd</code> function, when decorated as a dpex kernel, is compiled with numba-dpex into a data-parallel function to be executed individually by a set of work items (<code>item.get_id(0)</code>).  Numba-dpex follows the SPMD programming model, wherein each work item runs the function for a subset of the elements of the input arrays. The set of work items is defined by the <code>dpex.Range()</code> object and the <code>dpex.call_kernel()</code> call instructs every work item in the range to execute the <code>vecadd</code> kernel for a specific subset of the data. Numba-dpex also follows the compute-follows-data programming model, meaning that the kernel is run on the same device as the dpnp and dpctl arrays passed as inputs.</p> <p>Note that the numba-dpex kapi allows for more complex data parallel kernels (e.g., nd-range kernels) and the ability to create device callable functions.  For these and more features, we refer the users to the numba-dpex documentation.</p>"},{"location":"aurora/data-science/python/#dlpack","title":"DLPack","text":"<p>Thanks to dpctl supporting the Python Array API standard, both dpnp and dpctl provide interoperability with other Python libraries that follow the same standards, such as Numpy and PyTorch, through DLPack. This allows for zero-copy data access across the Python ecosystem.</p> <p>An example of using DLPack to pass arrays between dpnp and PyTorch is shown below  <pre><code>import dpnp as dp\nimport torch\nimport intel_extension_for_pytorch as ipex\n\nt_ary = torch.arange(4).to('xpu') # array [0, 1, 2, 3] on GPU\ndp_ary = dp.from_dlpack(t_ary)\nt_ary[0] = -2.0 # modify the PyTorch array\nprint(f'Original PyTorch array: {t_ary}')\nprint(f'dpnp view of PyTorch array: {dp_ary} on device {dp_ary.device}\\n')\ndel t_ary, dp_ary\n\ndp_ary = dp.arange(4) # array [0, 1, 2, 3] on GPU\nt_ary = torch.from_dlpack(dp_ary)\ndp_ary[0] = -3.0 # modify the dpnp array\nprint(f'Original dpnp array: {dp_ary} on device {dp_ary.device}')\nprint(f'PyTorch view of dpnp array: {t_ary}')\n</code></pre></p> Output <pre><code>Original PyTorch array: tensor([-2,  1,  2,  3], device='xpu:0')\ndpnp view of PyTorch array: [-2  1  2  3] on device Device(level_zero:gpu:0)\n\nOriginal dpnp array: [-3  1  2  3] on device Device(level_zero:gpu:0)\nPyTorch view of dpnp array: tensor([-3,  1,  2,  3], device='xpu:0')\n</code></pre> <p>DLPack notes on Aurora</p> <ul> <li><code>ZE_FLAT_DEVICE_HIERARCHY</code> must be set to <code>FLAT</code></li> <li>Zero-copy interoperability is supported between dpnp, dpctl, and PyTorch on CPU and GPU, and between Numpy as well on CPU only</li> <li>Interoperability between TensorFlow and the other packages is limited on the GPU due to TensorFlow not being compatible with the latest DLPack rules and still requiring the use of <code>dlcapsules</code></li> <li>Numba-dpex does not directly support DLPack, however numba-dpex kernels take as inputs dpnp and dpctl arrays, thus inperoperability between PyTorch and numba-dpex is available through those packages </li> </ul>"},{"location":"aurora/data-science/frameworks/dask/","title":"Dask","text":"<p>Dask is a Python library for parallel and distributed computing.  A Dask cluster is composed of one scheduler that coordinates the job of many workers, which can have access to CPU or GPU resources.  Here we show how to install Dask in a conda environment on Aurora and how to start a cluster with GPU workers and run a simple example script. </p>"},{"location":"aurora/data-science/frameworks/dask/#install-dask-on-aurora","title":"Install Dask on Aurora","text":"<p>From one of Aurora's login nodes, use the following commands to create a conda environment and install Dask.  This will also install other libraries needed to run an example script and create a Jupyter kernel that allows you to work interactively from a notebook. </p> <pre><code>module load frameworks\nconda create -y -n dask -c conda-forge python=3.11 pip dask ipykernel jupyterlab\nconda activate dask\n# install additional libraries\nconda install -y -c https://software.repos.intel.com/python/conda/ -c conda-forge dpnp\n# create the jupyter kernel\npython -m ipykernel install --prefix=${CONDA_PREFIX} --name dask\n</code></pre>"},{"location":"aurora/data-science/frameworks/dask/#start-a-dask-cluster","title":"Start a Dask cluster","text":"<p>Copy the following script into a file called <code>start_dask_aurora.sh</code> and make it executable with:</p> <pre><code>chmod a+x ./start_dask_aurora.sh\n</code></pre> start_dask_aurora.sh<pre><code>#!/bin/bash\n\n# start_dask_aurora.sh\n# Usage: \n# mpiexec -n NNODES * NUM_WORKERS_PER_NODE --ppn NUM_WORKERS_PER_NODE ./start_dask_aurora.sh WORKER_TYPE NUM_WORKERS_PER_NODE\n# Examples on two nodes:\n# mpiexec -n 12 --ppn 6 ./start_dask_aurora.sh gpu 6\n# mpiexec -n 208 --ppn 104 ./start_dask_aurora.sh cpu 104\n\nWORKER_TYPE=$1\nNUM_WORKERS_PER_NODE=$2\n# if using 12 GPU workers, assign one worker per tile, otherwise use one worker per GPU (2 tiles)\nif [ $NUM_WORKERS_PER_NODE = 12 ] &amp;&amp; [ $WORKER_TYPE = 'gpu' ]; then\n    export ZE_FLAT_DEVICE_HIERARCHY=FLAT\n    export ZE_ENABLE_PCI_ID_DEVICE_ORDER=1\nelse\n    export ZE_FLAT_DEVICE_HIERARCHY=COMPOSITE\nfi\n\n# Number of threads per worker (208 CPU threads per node divided by num workers)\nNTHREADS=$(( 208 / NUM_WORKERS_PER_NODE ))  # 208 / 12 \u2248 17\n# Memory limit per worker (1100GB RAM per node divided by num workers)\nMEMORY_PER_WORKER=$(( 1100 / NUM_WORKERS_PER_NODE ))GB  # 1100GB / 12 \u2248 91GB\nLOCAL_DIRECTORY=~/dask-local-directory\nDASK_DASHBOARD_PORT=${DASK_DASHBOARD_PORT:-8787}\nDASK_SCHEDULER_PORT=${DASK_SCHEDULER_PORT:-8786}\n\n# Start Dask scheduler on rank 0\nif [ $PALS_RANKID = 0 ]; then\n    # Purge Dask worker, log directories and config directories\n    rm -rf ${LOCAL_DIRECTORY}/* /tmp/dask-workers/*  ~/.config/dask\n    mkdir -p ${LOCAL_DIRECTORY}/logs /tmp/dask-workers\n    # Setup scheduler\n    nohup dask scheduler --port ${DASK_SCHEDULER_PORT} --dashboard-address $DASK_DASHBOARD_PORT \\\n        --scheduler-file ${LOCAL_DIRECTORY}/scheduler.json &gt; ${LOCAL_DIRECTORY}/logs/$HOSTNAME-scheduler.log 2&gt;&amp;1 &amp;\nfi\nsleep 10\n# Setup workers\nif [ $WORKER_TYPE = 'gpu' ]; then\n    ZE_AFFINITY_MASK=$PALS_LOCAL_RANKID dask worker \\\n        --resources \"GPU=1\" --memory-limit ${MEMORY_PER_WORKER} \\\n        --nthreads ${NTHREADS}  --local-directory /tmp/dask-workers \\\n        --scheduler-file ${LOCAL_DIRECTORY}/scheduler.json &gt;&gt; ${LOCAL_DIRECTORY}/logs/$HOSTNAME-worker.log 2&gt;&amp;1\nelse\n    dask worker \\\n        --nthreads ${NTHREADS} --local-directory /tmp/dask-workers \\\n        --scheduler-file ${LOCAL_DIRECTORY}/scheduler.json &gt;&gt; ${LOCAL_DIRECTORY}/logs/$HOSTNAME-worker.log 2&gt;&amp;1\nfi\n</code></pre>"},{"location":"aurora/data-science/frameworks/dask/#start-a-cluster-with-cpu-workers","title":"Start a cluster with CPU workers","text":"<p>Run the following commands from a compute node on Aurora to start a Dask cluster with 104 CPU workers per node: <pre><code>module load frameworks\nconda activate dask\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nmpiexec -n $(( $NNODES * 104 )) --ppn 104 ./start_dask_aurora.sh cpu 104\n</code></pre></p>"},{"location":"aurora/data-science/frameworks/dask/#start-a-cluster-with-gpu-workers","title":"Start a cluster with GPU workers","text":"<p>Run the following commands from a compute node on Aurora to start a Dask cluster with 6 GPU workers per node: <pre><code>module load frameworks\nconda activate dask\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nmpiexec -n $(( $NNODES * 6 )) --ppn 6 ./start_dask_aurora.sh gpu 6\n</code></pre></p>"},{"location":"aurora/data-science/frameworks/dask/#example","title":"Example","text":"<p>In this example, we will estimate Pi using a Monte Carlo method. </p> <p>Paste the following Python script into a file called <code>pi_dask_gpu.py</code>. Here is a breakdown of what the script does:</p> <ol> <li>It connects to the Dask cluster (that you should start beforehand) and prints some information including the number of workers and available memory.</li> <li>It divides the total number of points to sample between the workers, and each worker uses its GPU to</li> <li>generate random points uniformly inside the unit square</li> <li>return the number of points that are inside the unit circle</li> <li>When the results from the workers are ready, they are aggregated to compute Pi.</li> <li>A total of 5 Pi calculations are performed and timed (the very first iterations will incur initialization and warmup costs).</li> <li>At the end, the Dask cluster is shut down.</li> </ol> pi_dask_gpu.py<pre><code>import json\nimport pathlib\nfrom dask.distributed import Client\n\n\nfname = f'{pathlib.Path.home().as_posix()}/dask-local-directory/scheduler.json'\nwith open(fname, 'r') as f:\n    scheduler = json.load(f)\nclient = Client(scheduler['address'])\nprint(client)\n\n\nimport time\nimport dpnp as np\n\n\ndef count_points_inside_circle(N):\n    x = np.random.uniform(low=-1.0, high=1.0, size=(N, 2))\n    inside_circle = ((x * x).sum(axis=1) &lt; 1.).sum()\n    return int(inside_circle)\n\n\ndef compute_pi(inside_circle, N):\n    return 4 * inside_circle / N\n\n\ndef run():\n    start = time.time()\n    num_workers = len(client.scheduler_info()['workers'])\n    N = 10_400_000_004\n\n    # number of points per worker\n    Neach_section, extras = divmod(N, num_workers)\n    points_per_worker = [Neach_section for _ in range(num_workers)]\n    points_per_worker[-1] += extras\n\n    futures = client.map(count_points_inside_circle, points_per_worker)\n    inside_circle = client.submit(sum, futures).result()\n    pi = compute_pi(inside_circle, N)\n    end = time.time()\n    return f\"Num samples: {N:.2E}\\t\\tEstimate: {pi:.9f}\\t\\tTime taken: {end - start:.3f} s\"\n\n\ndef main(runs=5):\n    for i in range(runs):\n        print(f\"Run {i}\\t\\t{run()}\")\n\n\nmain()\nclient.shutdown()\n</code></pre>"},{"location":"aurora/data-science/frameworks/dask/#run-the-pi_dask_gpupy-example","title":"Run the <code>pi_dask_gpu.py</code> example","text":"<ul> <li>First, request an interactive job on 1 node.</li> <li>Then, start a Dask cluster with 6 GPU workers and wait about 10 seconds for the cluster to start.</li> <li>Press Ctrl+Z (SIGTSTP) and then execute <code>bg</code> to continue running the process in the background, or open a new shell and SSH onto the compute node. </li> <li>Run the example script:   <pre><code>module load frameworks\nconda activate dask\npython pi_dask_gpu.py\n</code></pre></li> </ul> Output <pre><code>&lt;Client: 'tcp://10.168.0.10:8786' processes=6 threads=204, memory=1.00 TiB&gt;\nRun 0           Num samples: 1.04E+10           Estimate: 3.141653798           Time taken: 1.596 s\nRun 1           Num samples: 1.04E+10           Estimate: 3.141570887           Time taken: 1.354 s\nRun 2           Num samples: 1.04E+10           Estimate: 3.141651954           Time taken: 1.451 s\nRun 3           Num samples: 1.04E+10           Estimate: 3.141636617           Time taken: 0.518 s\nRun 4           Num samples: 1.04E+10           Estimate: 3.141650108           Time taken: 0.511 s\n</code></pre>"},{"location":"aurora/data-science/frameworks/dask/#connect-to-a-dask-cluster-from-jupyterlab","title":"Connect to a Dask cluster from JupyterLab","text":"<p>Here are the steps to start a Dask cluster and connect to it interactively from a Jupyter notebook:</p> <ul> <li>First, request an interactive job on 1 node. Print the compute node's hostname (that you get with the command <code>hostname</code>), which will be used later.</li> <li>Then, start a Dask cluster and wait about 10 seconds for the cluster to start.</li> <li>On your local machine, open an SSH tunnel to the compute node (<code>COMPUTE_NODE</code> is the compute node's hostname and <code>YOUR_ALCF_USERNAME</code> is your ALCF username):   <pre><code>ssh -t -L 23456:localhost:23456 -L 8787:localhost:8787 YOUR_ALCF_USERNAME@bastion.alcf.anl.gov ssh -t -L 23456:localhost:23456 -L 8787:localhost:8787 login.aurora.alcf.anl.gov ssh -t -L 23456:localhost:23456 -L 8787:localhost:8787 COMPUTE_NODE\n</code></pre></li> </ul> <p>Failure</p> <p>If you have issues with the above sequence of <code>ssh</code> commands, check this page for troubleshooting.</p> <ul> <li>On the compute node where you land with the above ssh command, start JupyterLab:   <pre><code>module load frameworks\nconda activate dask\njupyter lab --no-browser --port=23456\n</code></pre></li> <li>Copy the line starting with <code>http://localhost:23456/lab?token=&lt;TOKEN&gt;</code> at the end of the Jupyter command's output.</li> <li>On your local machine, open a browser window and go to that URL.</li> <li>On the JupyterLab page, select the <code>dask</code> kernel and use this script to connect to the Dask cluster:   <pre><code>import json\nimport pathlib\nfrom dask.distributed import Client\n\nfname = f'{pathlib.Path.home().as_posix()}/dask-local-directory/scheduler.json'\nwith open(fname, 'r') as f:\n    scheduler = json.load(f)\nclient = Client(scheduler['address'])\nclient\n</code></pre></li> <li>The Dask dashboard will be available at http://localhost:8787</li> </ul>"},{"location":"aurora/data-science/frameworks/deepspeed/","title":"DeepSpeed","text":"<p>The base <code>frameworks</code> environment on Aurora now comes with Microsoft's DeepSpeed pre-installed. If a user needs an updated version, it should be installed outside the <code>frameworks</code> module, e.g. in a virtual environment. Further instructions for working with the base environment can be found here.</p> <p><pre><code>module load frameworks\n</code></pre> The following output is from the <code>frameworks/2025.2.0</code> module:</p> <pre><code>import deepspeed\n\ndeepspeed.__version__\n'0.17.5'\n</code></pre> <p>We describe below the steps needed to get started with DeepSpeed on Aurora.</p> <p>We focus on the <code>cifar</code> example provided in the DeepSpeedExamples repository, though this approach should be generally applicable for running any model with DeepSpeed support.</p>"},{"location":"aurora/data-science/frameworks/deepspeed/#running-deepspeed-on-aurora","title":"Running DeepSpeed on Aurora","text":"<p>Note</p> <p>The instructions below should be run directly from a compute node.</p> <p>Explicitly, to request an interactive job (from <code>uan-00xx</code>): <pre><code>qsub -A &lt;project&gt; -q debug -l filesystems=&lt;fs1:fs2&gt; -l select=1 -l walltime=01:00:00 -I\n</code></pre></p> <p>Refer to job scheduling and execution for additional information.</p> <ol> <li> <p>Load <code>frameworks</code> module:</p> <pre><code>module load frameworks\n</code></pre> </li> <li> <p>Create a (new) virtual environment:</p> <pre><code>python3 -m venv /path/to/new/venv --system-site-packages\nsource /path/to/new/venv/bin/activate\n</code></pre> </li> <li> <p>Install DeepSpeed:</p> <pre><code>pip install deepspeed\n</code></pre> </li> <li> <p>Clone microsoft/DeepSpeedExamples and navigate into the directory:</p> <pre><code>git clone https://github.com/microsoft/DeepSpeedExamples.git\ncd DeepSpeedExamples/training/cifar\n</code></pre> </li> </ol> <p>Launching DeepSpeed</p> <p>In both examples, the <code>train_batch_size</code> variable needs to be modified from 16 to 12 in the DeepSpeed config embedded in the function <code>get_ds_config()</code> from the Python file <code>cifar10_deepspeed.py</code>. This is because the default of 16 is not compatible with the 12 ranks per node we are launching with. DeepSpeed features can be further modified in the DeepSpeed config, and the full feature set is described in the DeepSpeed documentation.</p> Launching with MPICHLaunching with DeepSpeed <ol> <li> <p>Get the total number of available GPUs:</p> <ol> <li>Count the number of lines in <code>$PBS_NODEFILE</code> (1 host per line)</li> <li>Count the number of GPUs available on the current host</li> <li><code>NGPUS=\"$((${NHOSTS}*${NGPU_PER_HOST}))\"</code> <pre><code>NHOSTS=$(wc -l &lt; \"${PBS_NODEFILE}\")\nNGPU_PER_HOST=12\nNGPUS=\"$((${NHOSTS}*${NGPU_PER_HOST}))\"\n</code></pre></li> </ol> </li> <li> <p>Launch with <code>mpiexec</code>: <pre><code>mpiexec \\\n  --verbose \\\n  --envall \\\n  -n \"${NGPUS}\" \\\n  --ppn \"${NGPU_PER_HOST}\" \\\n  --hostfile=\"${PBS_NODEFILE}\" \\\n  python3 \\\n    cifar10_deepspeed.py\n</code></pre></p> </li> </ol> <ol> <li> <p>Create a DeepSpeed compliant <code>hostfile</code>, specifying the <code>hostname</code> and number of GPUs (<code>slots</code>) for each of our available workers (more info here): <pre><code>cat $PBS_NODEFILE &gt; hostfile\nsed -e 's/$/ slots=12/' -i hostfile\n</code></pre></p> </li> <li> <p>Create a <code>.deepspeed_env</code> (more info here) containing the environment variables our workers will need access to: <pre><code>echo \"PATH=${PATH}\" &gt;&gt; .deepspeed_env\necho \"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\" &gt;&gt; .deepspeed_env\necho \"http_proxy=${http_proxy}\" &gt;&gt; .deepspeed_env\necho \"https_proxy=${https_proxy}\" &gt;&gt; .deepspeed_env\n</code></pre></p> </li> </ol> <p>Warning</p> <p>The <code>.deepspeed_env</code> file expects each line to be of the form <code>KEY=VALUE</code>. Each of these will then be set as environment variables on each available worker specified in our <code>hostfile</code>.</p> <p>We can then run the <code>cifar10_deepspeed.py</code> module using DeepSpeed: <pre><code>deepspeed --hostfile=hostfile cifar10_deepspeed.py \\\n    --deepspeed \n</code></pre></p> <code>AssertionError: Micro batch size per gpu: 0 has to be greater than 0</code> <p>Depending on the details of your specific job, it may be necessary to modify the provided <code>ds_config.json</code>.</p> <p>If you encounter an error: <pre><code>x3202c0s31b0n0: AssertionError: Micro batch size per gpu: 0 has to be greater than 0\n</code></pre> you can modify the <code>\"train_batch_size\": 16</code> variable in the provided <code>ds_config.json</code> to the (total) number of available GPUs, and explicitly set <code>\"gradient_accumulation_steps\": 1</code>, as shown below. <pre><code>$ export NHOSTS=$(wc -l &lt; \"${PBS_NODEFILE}\")\n$ export NGPU_PER_HOST=$(nvidia-smi -L | wc -l)\n$ export NGPUS=\"$((${NHOSTS}*${NGPU_PER_HOST}))\"\n$ echo $NHOSTS $NGPU_PER_HOST $NGPUS\n24 4 96\n$ # replace \"train_batch_size\" with $NGPUS in ds_config.json\n$ # and write to `ds_config-polaris.json`\n$ sed \\\n    \"s/$(cat ds_config.json| grep batch | cut -d ':' -f 2)/ ${NGPUS},/\" \\\n    ds_config.json \\\n    &gt; ds_config-polaris.json\n$ cat ds_config-polaris.json\n{\n    \"train_batch_size\": 96,\n    \"gradient_accumulation_steps\": 1,\n    ...\n}\n</code></pre></p>"},{"location":"aurora/data-science/frameworks/gpytorch/","title":"GPyTorch on Aurora","text":""},{"location":"aurora/data-science/frameworks/gpytorch/#1-login-and-queue-a-job","title":"1. Login and Queue a Job","text":"<p>Login to Aurora:</p> <pre><code>ssh &lt;username&gt;@aurora.alcf.anl.gov\n</code></pre> <p>Refer to Getting Started on Aurora for additional information. In particular, you need to set the environment variables that provide access to the proxy host.</p> <p>Note</p> <p>The instructions below should be run directly from a compute node.</p> <p>Explicitly, to request an interactive job (from <code>aurora-uan</code>):</p> <pre><code>qsub -I -q &lt;your_Queue&gt; -l select=1,walltime=60:00 -A &lt;your_ProjectName&gt; -l filesystems=&lt;fs1:fs2&gt;\n</code></pre> <p>Refer to job scheduling and execution for additional information.</p>"},{"location":"aurora/data-science/frameworks/gpytorch/#2-once-on-a-compute-node-load-modules","title":"2. Once on a Compute Node, Load Modules","text":"<pre><code>module use /soft/modulefiles\nmodule load frameworks\npython3 -m venv --system-site-packages env_gpytorch\nsource env_gpytorch/bin/activate\npython3 -m pip install gpytorch\n</code></pre>"},{"location":"aurora/data-science/frameworks/gpytorch/#optional","title":"Optional","text":"<p>Create an <code>activation_env.sh</code> file that contains the following lines:</p> <pre><code>module use /soft/modulefiles\nmodule load frameworks\nsource env_gpytorch/bin/activate\n</code></pre> <p>and run <code>source activation_env.sh</code> to activate your environment for subsequent runs.</p>"},{"location":"aurora/data-science/frameworks/gpytorch/#3-running-on-gpus","title":"3. Running on GPUs","text":"<p>To run on GPUs, add the following to your code:</p> <pre><code>import intel_extension_for_pytorch as ipex\n</code></pre> <p>Set the device as follows in the code:</p> <pre><code>if torch.cuda.is_available():\n    device = torch.device('cuda')\nelif torch.xpu.is_available():\n    device = torch.device('xpu')\nelse: \n    device = torch.device('cpu')\n</code></pre> <p>(You might need to install an earlier version of GPyTorch for multiple GPU usage.)</p>"},{"location":"aurora/data-science/frameworks/megatron-deepspeed/","title":"Megatron-DeepSpeed","text":"<p>Megatron-DeepSpeed is a scalable, highly performant library for training large language models on any GPU<sup>1</sup>.</p> <p>In particular, it retains the core 4D parallelism<sup>2</sup> functionality of the NVIDIA / <code>Megatron-LM</code> library, while leveraging the microsoft / <code>DeepSpeed</code> library for efficient scaling and \ud83c\udf4b saforem2 / <code>ezpz</code> for automated device + backend selection.</p>"},{"location":"aurora/data-science/frameworks/megatron-deepspeed/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Clone the argonne-lcf / <code>Megatron-DeepSpeed</code> repository:</p> <pre><code>git clone https://github.com/argonne-lcf/Megatron-DeepSpeed\ncd Megatron-DeepSpeed\n</code></pre> </li> <li> <p>Set up your environment:</p> <pre><code>export PBS_O_WORKDIR=$(pwd)\nsource &lt;(curl -s https://raw.githubusercontent.com/saforem2/ezpz/refs/heads/main/src/ezpz/bin/utils.sh)\nezpz_setup_env\n</code></pre> [Optional] Setup WandB <p>To enable Weights &amp; Biases (WandB) logging, we need to install and login:</p> <pre><code>python3 -m pip install wandb --upgrade\nwandb login\n</code></pre> <p>NOTE: WandB can be disabled by setting <code>export WANDB_DISABLED=1</code></p> <p>See <code>wandb</code>: Quickstart for additional information</p> </li> <li> <p>Install dependencies:</p> <ol> <li>\ud83c\udf4b saforem2 / <code>ezpz</code>:</li> </ol> <pre><code>python3 -m pip install -e \"git+https://github.com/saforem2/ezpz#egg=ezpz\" --require-virtualenv\n</code></pre> <ol> <li>microsoft / <code>DeepSpeed</code>:</li> </ol> <pre><code>python3 -m pip install deepspeed\n</code></pre> </li> <li> <p>Launch training:</p> <pre><code># Before launching, `PBS_O_WORKDIR` should be set to Megatron-DeepSpeed's PATH\n# and venv inside Megatron-DeepSpeed/venv should be activated.\nTP=2 NLAYERS=10 DATA_FILE_LIST=ALCF/data-lists/aurora/books.txt bash train_aGPT_7B.sh\n</code></pre> <p>This will launch a distributed pre-training run with:</p> <ul> <li> <p><code>NLAYERS=10</code>: Llama style model consisting of 10 layers</p> </li> <li> <p><code>TP=2</code>: Split across 2 Tensor Parallel groups</p> </li> <li> <p><code>DATA_FILE_LIST</code>: Using the Books corpus of the Dolma dataset</p> </li> </ul> Overridable Options <p>This is a simple subset of the overridable options.</p> <p>The full list (as well as their default values) can be found in ALCF / <code>helpers.sh</code></p> <ul> <li><code>DTYPE</code>: Data type</li> <li><code>DATA_FILE_LIST</code>: Data file list</li> <li><code>FFN_HIDDEN_SIZE</code>: Feedforward Neural Network projection size</li> <li><code>GRAD_ACC_STEPS</code>: Gradient accumulation steps</li> <li><code>HEADS</code>: Number of attention heads</li> <li><code>HIDDEN</code>: Hidden size</li> <li><code>MICRO_BATCH</code>: Micro batch size</li> <li><code>NO_FLASH_ATTN</code>: No Flash Attention</li> <li><code>NLAYERS</code>: Number of layers</li> <li><code>NUM_KV_HEAD</code>: Number of key-value heads</li> <li><code>OPT</code>: Optimizer<ul> <li><code>adam</code></li> <li><code>adam8bit</code></li> <li><code>adamw</code></li> <li><code>adamwschedulefree</code></li> <li><code>apex.adam</code></li> <li><code>apex.sgd</code></li> <li><code>ds.fusedlamb</code></li> <li><code>ds.onebitlamb</code></li> <li><code>galoreadamw</code></li> <li><code>galoreadamw8bit</code></li> <li><code>galoreadamw8bitperlayer</code></li> <li><code>ipex.fusedlamb</code></li> <li><code>ipex.lamb</code></li> <li><code>shampoo</code></li> <li><code>sgd</code></li> <li><code>sgdschedulefree</code></li> <li><code>sophiag</code></li> </ul> </li> <li><code>PP</code>: Pipeline parallelism degree</li> <li><code>SEQ</code>: Sequence length</li> <li><code>SP</code>: Sequence parallelism (Ulysses) degree</li> <li><code>TP</code>: Tensor parallelism degree</li> <li><code>TRAIN_TOKENS</code>: Number of training tokens</li> <li><code>TRAIN_ITERS</code>: Number of training iterations</li> <li><code>USE_ACTIVATION_CHECKPOINTING</code>: Use activation checkpointing</li> <li><code>WEIGHT_DECAY</code>: Weight decay</li> <li><code>ZERO_STAGE</code>: Zero stage</li> </ul> </li> </ol> <ol> <li> <p>Megatron-DeepSpeed is designed to work on any GPU, including NVIDIA GPUs (NCCL), AMD GPUs (RCCL), and Intel XPUs (CCL).\u00a0\u21a9</p> </li> <li> <p>4D parallelism refers to data (DP), tensor (TP), pipeline (PP), and sequence (SP) parallelism degrees of freedom.\u00a0\u21a9</p> </li> </ol>"},{"location":"aurora/data-science/frameworks/oneCCL/","title":"oneCCL","text":"<p>oneAPI Collective Communications Library (oneCCL) provides an efficient implementation of communication patterns used in deep learning. oneCCL is governed by the UXL Foundation and is an implementation of the oneAPI specification.</p> <p>oneCCL can be used through:</p> <ol> <li>Native C++ SYCL mode</li> <li>Horovod</li> <li>PyTorch Distributed Data Parallel (DDP)</li> </ol>"},{"location":"aurora/data-science/frameworks/oneCCL/#aurora-oneccl-environment","title":"Aurora oneCCL environment","text":"<p><pre><code>hossainm@aurora-uan-0011:~&gt; module load frameworks\n(/opt/aurora/25.190.0/frameworks/aurora_frameworks-2025.2.0) hossainm@aurora-uan-0010:~&gt; echo $CCL_ROOT\n/opt/aurora/25.190.0/oneapi/ccl/latest\n(/opt/aurora/25.190.0/frameworks/aurora_frameworks-2025.2.0) hossainm@aurora-uan-0010:~&gt; cd /opt/aurora/25.190.0/oneapi/ccl/\n(/opt/aurora/25.190.0/frameworks/aurora_frameworks-2025.2.0) hossainm@aurora-uan-0010:/opt/aurora/25.190.0/oneapi/ccl&gt; ls -lah\ntotal 0\ndrwxr-xr-x  3 root root  44 Oct  3 17:35 .\ndrwxr-xr-x 30 root root 734 Oct  3 17:39 ..\ndrwxr-xr-x  8 root root 117 Oct  3 17:35 2021.16\nlrwxrwxrwx  1 root root   7 Oct  3 17:35 latest -&gt; 2021.16\n</code></pre> <code>2021.16</code> is the current version of oneCCL that is available to users  through the Aurora compute image.</p> <p>oneCCL environment variables</p> <p>We have identified a set of environment settings that typically provide better performance or address potential application hangs and crashes at large scale. This particular setup is still experimental, and it might change as the environment variable settings are refined. Users are encouraged to check this page regularly.</p> <pre><code>export CCL_PROCESS_LAUNCHER=pmix  \nexport CCL_ATL_TRANSPORT=mpi\nexport CCL_ALLREDUCE_SCALEOUT=\"direct:0-1048576;rabenseifner:1048577-max\"  # currently best allreduce algorithm at large scale\nexport CCL_BCAST=double_tree # currently best bcast algorithm at large scale\n\nexport CCL_KVS_MODE=mpi\nexport CCL_CONFIGURATION_PATH=\"\"\nexport CCL_CONFIGURATION=cpu_gpu_dpcpp\nexport CCL_KVS_CONNECTION_TIMEOUT=600 \n\nexport CCL_ZE_CACHE_OPEN_IPC_HANDLES_THRESHOLD=1024\nexport CCL_KVS_USE_MPI_RANKS=1\n\nexport MPI_PROVIDER=$FI_PROVIDER\nunset MPIR_CVAR_CH4_POSIX_COLL_SELECTION_TUNING_JSON_FILE\nunset MPIR_CVAR_CH4_COLL_SELECTION_TUNING_JSON_FILE\nunset MPIR_CVAR_COLL_SELECTION_TUNING_JSON_FILE\n</code></pre> <p>The following additional set of environment variable setups might be application-dependent. Users are encouraged to try to set them and see whether they help their applications.</p> <pre><code>ulimit -c unlimited\nexport FI_MR_ZE_CACHE_MONITOR_ENABLED=0\nexport FI_MR_CACHE_MONITOR=disabled\nexport FI_CXI_RX_MATCH_MODE=hybrid\nexport FI_CXI_OFLOW_BUF_SIZE=8388608\nexport FI_CXI_DEFAULT_CQ_SIZE=1048576\nexport FI_CXI_CQ_FILL_PERCENT=30\nexport INTELGT_AUTO_ATTACH_DISABLE=1\nexport PALS_PING_PERIOD=240\nexport PALS_RPC_TIMEOUT=240\nexport MPIR_CVAR_GATHERV_INTER_SSEND_MIN_PROCS=-1 # to solve the sync send issue in Horovod seg fault\nexport CCL_ATL_SYNC_COLL=1 # to avoid potential hang at large scale\nexport CCL_OP_SYNC=1 # to avoid potential hang at large scale\n</code></pre> <p>Algorithm selection</p> <p><pre><code>export CCL_COLLECTIVENAME=topo\nexport CCL_COLLECTIVENAME_SCALEOUT=ALGORITHM_NAME\n</code></pre> More info on Algorithm selection: oneCCL Environment Variables</p> <pre><code>export CCL_ALLREDUCE=topo\nexport CCL_ALLREDUCE_SCALEOUT=rabenseifner \n</code></pre>"},{"location":"aurora/data-science/frameworks/oneCCL/#native-c-sycl-mode","title":"Native C++ SYCL mode","text":"<p>You can compile examples from the oneCCL Git repository and use the library from the system default instead of local builds. More information at: oneCCL Benchmark User Guide</p> <p>To build the C++ benchmark examples:</p> <pre><code>cd oneccl\nmkdir build\ncd build\nmodule load cmake\ncmake .. -DCMAKE_C_COMPILER=icx-cc -DCMAKE_CXX_COMPILER=icpx -DCOMPUTE_BACKEND=dpcpp -DCMAKE_INSTALL_PREFIX=/lus/flare/projects/Aurora_deployment/kaushik/all_reduce_frameworks/gitrepos/oneCCL/build/\nmake -j install\n\nrm -rf _install/bin/* _install/lib/*mpi* _install/lib/*fabric* _install/opt/\n</code></pre> <p>To run from a job script:</p> <p><pre><code>#!/bin/bash -x\n# qsub -l nodes=2:ncpus=208 -q debug  -l walltime=02:00:00 -l filesystems=home:flare -A &lt;Project Name&gt; ./pbs_job_\n#PBS -A &lt;ProjectName&gt;\n#PBS -k doe\n\nmodule load frameworks \ncd $PBS_O_WORKDIR\necho Jobid: $PBS_JOBID\necho Running on nodes `cat $PBS_NODEFILE`\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nRANKS_PER_NODE=12          # Number of MPI ranks per node\nNRANKS=$(( NNODES * RANKS_PER_NODE ))\necho \"NUM_OF_NODES=${NNODES}  TOTAL_NUM_RANKS=${NRANKS}  RANKS_PER_NODE=${RANKS_PER_NODE}\"\n\n## Option 1\nexport CPU_BINDING1=\"list:4:9:14:19:20:25:56:61:66:71:74:79\" # 12 ppn to 12 cores\n## Option 2\nexport CPU_BINDING2=\"list:4-7:8-11:12-15:16-19:20-23:24-27:56-59:60-63:64-67:68-71:72-75:76-79\" # 12 ppn with each rank having 4 cores\n\n## Option 1 for oneCCL worker affinity \nexport CCL_WORKER_AFFINITY=42,43,44,45,46,47,94,95,96,97,98,99\n\n## Option 2\nunset CCL_WORKER_AFFINITY  # Default will pick up from the last 24 cores even if you didn't specify these in the binding.\nEXT_ENV=\"--env FI_CXI_DEFAULT_CQ_SIZE=1048576\"\nAPP1=/lus/flare/projects/Aurora_deployment/kaushik/all_reduce_frameworks/gitrepos/oneCCL/build/_install/examples/benchmark/benchmark\n\necho $CCL_ROOT\nexport LD_LIBRARY_PATH=$CCL_ROOT/lib:$LD_LIBRARY_PATH\nexport CPATH=$CCL_ROOT/include:$CPATH\nexport LIBRARY_PATH=$CCL_ROOT/lib:$LIBRARY_PATH\n\nexport CCL_PROCESS_LAUNCHER=pmix  \nexport CCL_ATL_TRANSPORT=mpi\nexport CCL_ALLREDUCE=topo\nexport CCL_ALLREDUCE_SCALEOUT=rabenseifner \n\nexport CCL_KVS_MODE=mpi\nexport CCL_CONFIGURATION_PATH=\"\"\nexport CCL_CONFIGURATION=cpu_gpu_dpcpp\nexport CCL_KVS_CONNECTION_TIMEOUT=600 \n\nwhich python\n\nmkdir -p ./out_${PBS_JOBID}/c_oneccl_gpu\nfor NNODES in 4 8 16 32 64 \ndo \nRANKS_PER_NODE=12          # Number of MPI ranks per node\nNRANKS=$(( NNODES * RANKS_PER_NODE ))\n\n    for BUF_SIZE in 1 2 4 8 16 32 64 128 256 512 1024 2048 4096 8192 16384 32768 65536 131072 262144 524288 1048576 2097152 4194304 8388608 16777216  33554432 67108864 134217728 268435456\n    do\n        date\n        mpiexec ${EXT_ENV}  --env CCL_LOG_LEVEL=info  --env CCL_PROCESS_LAUNCHER=pmix  --env CCL_ATL_TRANSPORT=mpi \\\n                            --np ${NRANKS} -ppn ${RANKS_PER_NODE} --cpu-bind  $CPU_BINDING1    $APP1   \\\n                            --elem_counts ${BUF_SIZE},${BUF_SIZE},${BUF_SIZE}  \\\n                            --coll allreduce -j off -i 1 -w 0  --backend sycl  --sycl_dev_type gpu &gt;  ./out_${PBS_JOBID}/c_oneccl_gpu/${PBS_JOBID}_${NNODES}_${NRANKS}_${RANKS_PER_NODE}_${BUF_SIZE}_sycl_ccl_gpu_out_w1.txt\n        date\n    echo ${BUF_SIZE}\n\n    done\ndone\n\n# For CPU only, change benchmark options to : --backend host --sycl_dev_type host\n</code></pre> For more information on oneCCL benchmark, please refer to: oneCCL Benchmark User Guide</p> <p>In the provided CPU binding list we have provided two options. First one is  based on one CPU core per rank. In the second option, we assign 4 CPU cores per rank. In the first oneCCL worker affinity option we pick 12 CPU cores, one per rank. Notice that, these cores are picked out from the last 12 cores of each  socket (CPU), aligned with oneCCL default core picking strategy. 42-47 belongs  to the first socket, and 94-99 belongs to the second socket. We leave a few  cores free, in case, the user may want to use other services like copper and DAOS along with their application. The second oneCCL option is to delegate  task of picking cores to the system. In this case, the user should not declare or export the <code>CCL_WORKER_AFFINITY</code> variable. </p>"},{"location":"aurora/data-science/frameworks/oneCCL/#horovod","title":"Horovod","text":"<p>TensorFlow Horovod example:</p> <pre><code>import datetime\nfrom time import perf_counter_ns\nimport sys\n\nimport tensorflow as tf\nimport horovod.tensorflow as hvd\nimport intel_extension_for_tensorflow as itex\nprint(itex.__version__)\nhvd.init()\n\nhvd_local_rank = hvd.local_rank()\nhvd_size = hvd.size()\nprint(\"hvd_local_rank = %d  hvd_size = %d\" % (hvd_local_rank, hvd_size))\n\nxpus = tf.config.experimental.list_physical_devices('XPU')\nlogical_gpus = tf.config.experimental.set_visible_devices(xpus[hvd.local_rank()], 'XPU')\nprint(xpus)\ntf.debugging.set_log_device_placement(True)\n\ndim_size = int(int(sys.argv[1]) / 4)\nelapsed1 = []\n\nfor _ in range(5):\n    with tf.device(f\"XPU:{hvd_local_rank % 12}\"):\n        x = tf.ones([1, dim_size], dtype=tf.float32)\n        # print(x)\n        t5 = perf_counter_ns() \n        y = hvd.allreduce(x, average=False)\n        t6 = perf_counter_ns()\n        elapsed1.append(t6 - t5)\n\nif hvd.rank() == 0:\n    for e in elapsed1:\n        print(e)\n</code></pre> <p>PyTorch Horovod example:</p> <pre><code>from time import perf_counter_ns\nimport sys\nimport intel_extension_for_pytorch  # Added Extra\nimport torch.nn.parallel\nimport horovod.torch as hvd\nhvd.init()\nhvd_local_rank = hvd.local_rank()\nhvd_size = hvd.size()\n# print(\"hvd_local_rank = %d  hvd_size = %d\" % (hvd_local_rank, hvd_size))\n\ndef get_default_device():\n    if torch.xpu.is_available():\n        return torch.device(f\"xpu:{hvd_local_rank % 12}\")\n    else:\n        return torch.device('cpu')\n\ndevice = get_default_device()\n\ndim_size = int(int(sys.argv[1]) / 4)\nelapsed1 = []\n\nfor _ in range(50):\n    x = torch.ones([1, dim_size], dtype=torch.float32).to(device, non_blocking=True)\n    # print(x)\n    t5 = perf_counter_ns() \n    y = hvd.allreduce(x, average=False)\n    t6 = perf_counter_ns()\n    elapsed1.append(t6 - t5)\n\nif hvd.rank() == 0:\n    for e in elapsed1:\n        print(e)\n</code></pre>"},{"location":"aurora/data-science/frameworks/oneCCL/#pytorch-ddp","title":"PyTorch DDP","text":"<pre><code>import datetime\nfrom time import perf_counter_ns\nimport sys\nimport os\nimport socket\nfrom mpi4py import MPI\nimport intel_extension_for_pytorch  # Added Extra\nimport torch.nn.parallel\nimport torch.distributed as dist\nimport oneccl_bindings_for_pytorch\n\nMPI.COMM_WORLD.Barrier()\n\nos.environ['RANK'] = str(os.environ.get('PMI_RANK', 0))\nos.environ['WORLD_SIZE'] = str(os.environ.get('PMI_SIZE', 1))\nmpi_world_size = MPI.COMM_WORLD.Get_size()\nmpi_my_rank = MPI.COMM_WORLD.Get_rank()\n\nif mpi_my_rank == 0:\n   master_addr = socket.gethostname()\n   sock = socket.socket()\n   sock.bind(('', 0))\n   # master_port = sock.getsockname()[1] \n   master_port = 2345\nelse:\n   master_addr = None\n   master_port = None\n\nmaster_addr = MPI.COMM_WORLD.bcast(master_addr, root=0)\nmaster_port = MPI.COMM_WORLD.bcast(master_port, root=0)\nos.environ[\"MASTER_ADDR\"] = master_addr\nos.environ[\"MASTER_PORT\"] = str(master_port)\n\nMPI.COMM_WORLD.Barrier()\ndist.init_process_group(backend=\"ccl\", init_method='env://', world_size=mpi_world_size, rank=mpi_my_rank, timeout=datetime.timedelta(seconds=3600))\nMPI.COMM_WORLD.Barrier()\n\ndist_my_rank = dist.get_rank()\ndist_world_size = dist.get_world_size()\n\ndef get_default_device():\n    if torch.xpu.is_available():\n        return torch.device(f\"xpu:{dist_my_rank % 12}\")\n    else:\n        return torch.device('cpu')\n\ndevice = get_default_device()\n\ndim_size = int(int(sys.argv[1]) / 4)\nMPI.COMM_WORLD.Barrier()\n\nelapsed1 = []\n\nfor _ in range(50):\n    x = torch.ones([1, dim_size], dtype=torch.float32).to(device, non_blocking=True)\n    # print(x)\n    t5 = perf_counter_ns() \n    dist.all_reduce(x, op=dist.ReduceOp.SUM)  # Added Extra op\n    MPI.COMM_WORLD.Barrier()\n    t6 = perf_counter_ns()\n    elapsed1.append(t6 - t5)\n\nif mpi_my_rank == 0:\n    for e in elapsed1:\n        print(e)\n</code></pre> <p>References</p> <ol> <li>oneCCL Environment Variables</li> <li>oneCCL GitHub Repository</li> <li>Intel Torch CCL</li> <li>Argonne LCF DL Scaling</li> <li>oneCCL Benchmark User Guide</li> </ol>"},{"location":"aurora/data-science/frameworks/pyg/","title":"PyTorch Geometric (PyG)","text":"<p>PyTorch Geometric (PyG) is a Python library built on top of PyTorch for deep learning on graphs. It provides tools for working with graph-structured data and implementations of many Graph Neural Networks (GNNs).</p>"},{"location":"aurora/data-science/frameworks/pyg/#pyg-on-aurora","title":"PyG on Aurora","text":"<p>PyTorch Geometric includes a base library, called <code>torch_geometric</code>, and a number of optional dependencies: - <code>torch_scatter</code> - <code>torch_sparse</code> - <code>torch_cluster</code> - <code>torch_spline_conv</code> - <code>pyg_lib</code></p> <p>The base library, <code>torch_geometric</code>, relies solely on PyTorch and can utilize Intel GPUs through the <code>xpu</code> device specification.</p> <p>The optional dependencies include optimized operations that are relevant to GNNs and are missing in PyTorch. They have only CPU and CUDA implementations and can therefore only run on Aurora CPUs.</p>"},{"location":"aurora/data-science/frameworks/pyg/#pyg-base-library","title":"PyG base library","text":"<p>Here we explain how to install the base library, <code>torch_geometric</code>, on Aurora and show a simple example of training a PyG model on Intel GPUs.</p>"},{"location":"aurora/data-science/frameworks/pyg/#installing-torch_geometric-on-aurora","title":"Installing <code>torch_geometric</code> on Aurora","text":"<p>We are going to install <code>torch_geometric</code> in a virtual environment that inherits PyTorch and the other libraries from the base frameworks module:</p> <pre><code>module load frameworks\npython3 -m venv --clear venv --system-site-packages\nsource venv/bin/activate\npip install torch_geometric\n</code></pre>"},{"location":"aurora/data-science/frameworks/pyg/#example","title":"Example","text":"<p>The following example is inspired by the <code>gcn.py</code> example on the PyG repository.</p> <ul> <li>Copy the following Python script into a file called <code>gcn.py</code>.   <pre><code># gcn.py\nimport argparse\nimport time\nimport torch\nimport intel_extension_for_pytorch as ipex\nimport torch_geometric\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--dataset', type=str, default='Cora')\nparser.add_argument('--hidden_channels', type=int, default=256)\nparser.add_argument('--lr', type=float, default=0.01)\nparser.add_argument('--epochs', type=int, default=20)\nparser.add_argument('--device', choices=['auto', 'cpu'], default='auto', help='device to use')\nparser.add_argument('--num_nodes', type=int, default=10000)\nparser.add_argument('--num_edges', type=int, default=5000000)\nparser.add_argument('--num_features', type=int, default=32)\nparser.add_argument('--num_classes', type=int, default=100)\nargs = parser.parse_args()\n\ndevice = torch.device(args.device)\nprint(f\"device: {device}\")\n\nedge_index = torch.randint(args.num_nodes, size=(args.num_edges, 2), dtype=torch.long)\nx = torch.randn(size=(args.num_nodes, args.num_features))\ny = torch.randint(args.num_classes, size=(args.num_nodes,), dtype=torch.long)\ndata = torch_geometric.data.Data(x=x, edge_index=edge_index.t().contiguous(), y=y, num_classes=(y.max()+1).item())\ndata = data.to(device)\n\nclass GCN(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels):\n        super().__init__()\n        self.conv1 = torch_geometric.nn.GCNConv(in_channels, hidden_channels)\n        self.conv2 = torch_geometric.nn.GCNConv(hidden_channels, out_channels)\n\n    def forward(self, x, edge_index, edge_weight=None):\n        x = torch.nn.functional.dropout(x, p=0.5, training=self.training)\n        x = self.conv1(x, edge_index, edge_weight).relu()\n        x = torch.nn.functional.dropout(x, p=0.5, training=self.training)\n        x = self.conv2(x, edge_index, edge_weight)\n        return x\n\nmodel = GCN(\n    in_channels=data.num_features,\n    hidden_channels=args.hidden_channels,\n    out_channels=data.num_classes,\n).to(device)\n\noptimizer = torch.optim.Adam([\n    dict(params=model.conv1.parameters(), weight_decay=5e-4),\n    dict(params=model.conv2.parameters(), weight_decay=0)\n], lr=args.lr)  # Only perform weight-decay on first convolution.\nmodel, optimizer = ipex.optimize(model, optimizer=optimizer)\n\ndef train():\n    model.train()\n    optimizer.zero_grad()\n    out = model(data.x, data.edge_index, data.edge_attr)\n    loss = torch.nn.functional.cross_entropy(out, data.y)\n    loss.backward()\n    optimizer.step()\n    return float(loss)\n\ntimes = []\nfor epoch in range(1, args.epochs + 1):\n    start = time.time()\n    loss = train()\n    times.append(time.time() - start)\nprint(f'Median time per epoch: {torch.tensor(times).median():.4f}s')\n</code></pre></li> <li>Start an interactive job on one node.</li> <li>Load the frameworks module, activate the virtual environment, and run the script:   <pre><code>module load frameworks\nsource venv/bin/activate\npython gcn.py\n</code></pre>   The output should look like:   <pre><code>device: xpu\nMedian time per epoch: 0.2721s\n</code></pre></li> <li>To run on the CPU, use <code>python gcn.py --device cpu</code>.</li> </ul>"},{"location":"aurora/data-science/frameworks/pyg/#optional-dependencies","title":"Optional dependencies","text":"<p>Use the following script to create a virtual environment and install the base library and the CPU versions of all the optional dependencies:</p> <pre><code>#!/bin/bash \n\nmodule load frameworks\n\nTORCH_LIB=$(python -c \"import torch; print(torch.__file__)\" | sed 's/__init__.py/lib/')\nTORCH_VERSION=`python -c \"import torch; print(torch.__version__)\" | sed 's/^\\([0-9.]*\\).*/\\1/'`\n\npython3 -m venv --clear venv --system-site-packages\nsource venv/bin/activate\n\nexport LD_LIBRARY_PATH=${TORCH_LIB}:$LD_LIBRARY_PATH\n\n# PyTorch Geometric and utils\npip install torch_geometric\n\nlibs=(\\\n\"https://github.com/rusty1s/pytorch_scatter.git\" \\\n\"https://github.com/rusty1s/pytorch_sparse.git\" \\\n\"https://github.com/rusty1s/pytorch_cluster.git\" \\\n\"https://github.com/rusty1s/pytorch_spline_conv.git\")\n\nfor lib in \"${libs[@]}\"; do\n    LIB_NAME=\"$(basename \"$lib\" .git)\"\n    git clone ${lib} &amp;&amp; cd \"$LIB_NAME\"\n    git submodule update --init --recursive\n    # get library version compatible with pytorch\n    LIB_VERSION=`wget -O - https://data.pyg.org/whl/torch-${TORCH_VERSION}%2Bcpu.html 2&gt;/dev/null | \\\n        grep -m1 $(echo ${LIB_NAME} | sed 's/pytorch_\\(.*\\)/\\1/') | \\\n        sed 's/.*torch_[a-z_]*-\\([^+-]*\\)[%+-].*/\\1/'`\n    git checkout ${LIB_VERSION} \n    # Force to install without OpenMP backend\n    sed \"s|if ('backend: OpenMP' in info and 'OpenMP not found' not in info|if (False|g\" setup.py &gt; tmp &amp;&amp; \\\n        mv tmp setup.py\n    pip install .\n    cd ..\n    rm -rf \"$LIB_NAME\"\ndone\n</code></pre>"},{"location":"aurora/data-science/frameworks/pytorch/","title":"PyTorch on Aurora","text":"<p>PyTorch is a popular, open-source deep learning framework developed and  released by Facebook. The PyTorch home page, has more information about PyTorch, which you can refer to. For troubleshooting on  Aurora, please contact support@alcf.anl.gov.</p>"},{"location":"aurora/data-science/frameworks/pytorch/#major-changes-in-the-frameworks-module","title":"Major Changes in the frameworks module","text":"<ul> <li>No more <code>torch_ccl</code>. <code>import oneccl_bindings_for_pytorch as torch_ccl</code> is not needed anymore.</li> <li>Must change <code>backend</code> to <code>xccl</code> from <code>ccl</code> when initializing <code>torch.distributed</code></li> <li><code>import intel_extension_for_pytorch as ipex</code> is optional. This is a work in  progress from the vendors side. If you experience performance variations,  switch back to importing it.</li> <li>No <code>horovod</code> support for PyTorch</li> </ul>"},{"location":"aurora/data-science/frameworks/pytorch/#provided-installation","title":"Provided Installation","text":"<p>PyTorch is already installed on Aurora with GPU support and available through the frameworks module.  To use it from a compute node, please load the following modules:</p> <p><pre><code>module load frameworks\n</code></pre> Then, you can <code>import</code> PyTorch in Python as usual (below showing results from the <code>frameworks/2025.2.0</code>  module): <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; torch.__version__\n'2.8.0a0+gitba56102'\n</code></pre> A simple but useful check could be to use PyTorch to get device information on a compute node. You can do this the following way:</p> get-device-info.py<pre><code>import torch\nimport intel_extension_for_pytorch as ipex\n\nprint(f\"GPU availability: {torch.xpu.is_available()}\")\nprint(f'Number of tiles = {torch.xpu.device_count()}')\ncurrent_tile = torch.xpu.current_device()\nprint(f'Current tile = {current_tile}')\nprint(f'Current device ID = {torch.xpu.device(current_tile)}')\nprint(f'Device properties = {torch.xpu.get_device_properties()}')\n</code></pre> Example output: <pre><code>GPU availability: True\nNumber of tiles = 12\nCurrent tile = 0\nCurrent device ID = &lt;intel_extension_for_pytorch.xpu.device object at 0x1540a9f25790&gt;\nDevice properties = _XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) Level-Zero', \\\ntype='gpu', driver_version='1.3.30872', total_memory=65536MB, max_compute_units=448, gpu_eu_count=448, \\\ngpu_subslice_count=56, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, \\\nhas_atomic64=1)\n</code></pre> <p>Each Aurora node has 6 GPUs (also called \"Devices\" or \"cards\") and each GPU is composed of two tiles (also called \"Sub-device\"). By default, each tile is mapped to one PyTorch device, giving a total of 12 devices per node in the above output. </p> Using GPU Devices as PyTorch devices <p>By default, each tile is mapped to one PyTorch device, giving a total of 12 devices per node, as seen above.  To map a PyTorch device to one particular GPU Device out of the 6 available on a compute node, these  environmental variables should be set</p> <p><pre><code>export ZE_FLAT_DEVICE_HIERARCHY=COMPOSITE\nexport ZE_AFFINITY_MASK=0\n\n# or, equivalently, following the syntax `Device.Sub-device`\nexport ZE_AFFINITY_MASK=0.0,0.1\n</code></pre> In the example given above, an application is targeting the <code>Device:0</code>  and <code>Sub-devices: 0, 1</code>, i.e. the two tiles of the GPU:0. This is  particularly important in setting a performance benchmarking baseline. Setting the above environmental variables after loading the frameworks modules, you can check that each PyTorch device is now mapped to one GPU: <pre><code>import torch\nimport intel_extension_for_pytorch as ipex\ntorch.xpu.device_count()\ntorch.xpu.get_device_properties()\n</code></pre></p> Example output <pre><code>1\n_XpuDeviceProperties(name='Intel(R) Data Center GPU Max 1550', platform_name='Intel(R) Level-Zero', type='gpu', driver_version='1.3.30872', total_memory=131072MB, max_compute_units=896, gpu_eu_count=896, gpu_subslice_count=112, max_work_group_size=1024, max_num_sub_groups=64, sub_group_sizes=[16 32], has_fp16=1, has_fp64=1, has_atomic64=1)\n</code></pre> <p>More information and details are available through the Level Zero Specification Documentation - Affinity Mask</p>"},{"location":"aurora/data-science/frameworks/pytorch/#code-changes-to-run-pytorch-on-aurora-gpus","title":"Code changes to run PyTorch on Aurora GPUs","text":"<p>Intel Extension for PyTorch (IPEX) is an open-source project that extends PyTorch with optimizations for extra performance boost on Intel CPUs and enables the use of Intel GPUs.</p> <p>Here we list some common changes that you may need to do to your PyTorch code in order to use Intel GPUs. Please consult Intel's IPEX Documentation for additional details and useful tutorials.</p> <p>Note: Steps related to <code>IPEX</code> are optional.</p> <ol> <li>Import the <code>intel_extension_for_pytorch</code> right after importing <code>torch</code>:    <pre><code>import torch\nimport intel_extension_for_pytorch as ipex\n</code></pre></li> <li>All the <code>API</code> calls involving <code>torch.cuda</code>, should be replaced with <code>torch.xpu</code>. For example:    <pre><code>- torch.cuda.device_count()\n+ torch.xpu.device_count()\n</code></pre></li> <li>When moving tensors and model to GPU, replace <code>\"cuda\"</code> with <code>\"xpu\"</code>. For example:    <pre><code>- model = model.to(\"cuda\")\n+ model = model.to(\"xpu\")\n</code></pre></li> <li>Convert model and loss criterion to <code>xpu</code>, and then call <code>ipex.optimize</code> for additional performance boost:    <pre><code>device = torch.device('xpu')\nmodel = model.to(device)\ncriterion = criterion.to(device)\nmodel, optimizer = ipex.optimize(model, optimizer=optimizer)\n</code></pre></li> </ol> <p>Tip</p> <p>A more portable solution to select the appropriate device is the following: <pre><code>if torch.cuda.is_available():\n    device = torch.device('cuda')\nelif torch.xpu.is_available():\n    device = torch.device('xpu')\nelse: \n    device = torch.device('cpu')\nmodel = model.to(device)\n</code></pre></p>"},{"location":"aurora/data-science/frameworks/pytorch/#example-training-a-pytorch-model-on-a-single-gpu-tile","title":"Example: training a PyTorch model on a single GPU tile","text":"<p>Here is a simple code to train a dummy PyTorch model on CPU:</p> pytorch_cpu.py<pre><code>import torch\n\ntorch.manual_seed(0)\n\nsrc = torch.rand((2048, 1, 512))\ntgt = torch.rand((2048, 20, 512))\ndataset = torch.utils.data.TensorDataset(src, tgt)\nloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n\nmodel = torch.nn.Transformer(batch_first=True)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = torch.nn.CrossEntropyLoss()\nmodel.train()\n\nfor epoch in range(10):\n    for source, targets in loader:\n        optimizer.zero_grad()\n\n        output = model(source, targets)\n        loss = criterion(output, targets)\n\n        loss.backward()\n        optimizer.step()\n</code></pre> <p>And here is the code to train the same model on a single GPU tile on Aurora, with new or modified lines highlighted:</p> <p>Note: Steps related to <code>IPEX</code> are optional.</p> pytorch_xpu.py<pre><code>import torch\nimport intel_extension_for_pytorch as ipex\ndevice = torch.device('xpu')\n\ntorch.manual_seed(0)\n\nsrc = torch.rand((2048, 1, 512))\ntgt = torch.rand((2048, 20, 512))\ndataset = torch.utils.data.TensorDataset(src, tgt)\nloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n\nmodel = torch.nn.Transformer(batch_first=True)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = torch.nn.CrossEntropyLoss()\nmodel.train()\nmodel = model.to(device)\ncriterion = criterion.to(device)\nmodel, optimizer = ipex.optimize(model, optimizer=optimizer)\n\nfor epoch in range(10):\n    for source, targets in loader:\n        source = source.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n\n        output = model(source, targets)\n        loss = criterion(output, targets)\n\n        loss.backward()\n        optimizer.step()\n</code></pre> <p>Here are the steps to run the above code on Aurora:</p> <ol> <li>Login to Aurora:     <pre><code>ssh &lt;username&gt;@aurora.alcf.anl.gov\n</code></pre></li> <li>Request a one-node interactive job for 30 minutes:    <pre><code>qsub -q debug -A &lt;your_project_name&gt; -l select=1,walltime=30:00 -l filesystems=home:flare -k doe -j oe -I\n</code></pre></li> <li>Copy the above Python script into a file called <code>pytorch_xpu.py</code> and make it executable with <code>chmod a+x pytorch_xpu.py</code>.</li> <li>Load the frameworks module:    <pre><code>module load frameworks\n</code></pre></li> <li>Run the script:    <pre><code>python pytorch_xpu.py\n</code></pre></li> </ol>"},{"location":"aurora/data-science/frameworks/pytorch/#pytorch-best-practices-on-aurora","title":"PyTorch Best Practices on Aurora","text":"<p>When running PyTorch applications, we have found the following practices to be  generally, if not universally, useful and encourage you to try some of these  techniques to boost performance of your own applications.</p> <ol> <li> <p>Use Reduced Precision. Reduced Precision is available on Intel Max 1550 and  is supported with PyTorch operations. In general, the way to do this is via the  PyTorch Automatic Mixed Precision package (AMP), as described in the  mixed precision documentation. In  PyTorch, users generally need to manage casting and loss scaling manually,  though context managers and function decorators can provide easy tools to do  this.</p> </li> <li> <p>PyTorch has a <code>JIT</code> module as well as backends to support op fusion, similar to TensorFlow's <code>tf.function</code> tools. See TorchScript for more information.</p> </li> <li> <p><code>torch.compile</code> will be available through the next framework release.</p> </li> <li> <p>In order to run an application with <code>TF32</code> precision type, one must set the following environmental parameter: <code>export IPEX_FP32_MATH_MODE=TF32</code>. This allows calculations using <code>TF32</code> as opposed to the default <code>FP32</code>, and done through <code>intel_extension_for_pytorch</code> module.</p> </li> <li> <p>For convolutional neural networks, using <code>channels_last</code> (NHWC) memory format gives better performance. More info here and here</p> </li> </ol>"},{"location":"aurora/data-science/frameworks/pytorch/#distributed-training-on-multiple-gpus","title":"Distributed Training on multiple GPUs","text":"<p>Distributed training with PyTorch on Aurora is facilitated through both Distributed Data Parallel (DDP) and Horovod, with comparable performance.  We recommend using native PyTorch DDP to perform Data Parallel training on Aurora. </p>"},{"location":"aurora/data-science/frameworks/pytorch/#distributed-data-parallel-ddp","title":"Distributed Data Parallel (DDP)","text":""},{"location":"aurora/data-science/frameworks/pytorch/#code-changes-to-train-on-multiple-gpus-using-ddp","title":"Code changes to train on multiple GPUs using DDP","text":"<p>The key steps in performing distributed training are:</p> <ol> <li>Initialize PyTorch's <code>DistributedDataParallel</code> with <code>backend='xccl'</code></li> <li>Use <code>DistributedSampler</code> to partition the training data among the ranks</li> <li>Pin each rank to a GPU</li> <li>Wrap the model in DDP to keep it in sync across the ranks </li> <li>Rescale the learning rate</li> <li>Use <code>set_epoch</code> for shuffling data across epochs</li> </ol> <p>Here is the code to train the same dummy PyTorch model on multiple GPUs, where new or modified lines have been highlighted:</p> <p>Note: Steps related to <code>IPEX</code> are optional.</p> pytorch_ddp.py<pre><code>from mpi4py import MPI\nimport os, socket\nimport torch\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nimport intel_extension_for_pytorch as ipex\n\n# DDP: Set environmental variables used by PyTorch\nSIZE = MPI.COMM_WORLD.Get_size()\nRANK = MPI.COMM_WORLD.Get_rank()\nLOCAL_RANK = os.environ.get('PALS_LOCAL_RANKID')\nos.environ['RANK'] = str(RANK)\nos.environ['WORLD_SIZE'] = str(SIZE)\nMASTER_ADDR = socket.gethostname() if RANK == 0 else None\nMASTER_ADDR = MPI.COMM_WORLD.bcast(MASTER_ADDR, root=0)\nos.environ['MASTER_ADDR'] = f\"{MASTER_ADDR}.hsn.cm.aurora.alcf.anl.gov\"\nos.environ['MASTER_PORT'] = str(2345)\nprint(f\"DDP: Hi from rank {RANK} of {SIZE} with local rank {LOCAL_RANK}. {MASTER_ADDR}\")\n\n# DDP: initialize distributed communication with xccl backend\ntorch.distributed.init_process_group(backend='xccl', init_method='env://', rank=int(RANK), world_size=int(SIZE))\n\n# DDP: pin GPU to local rank.\ntorch.xpu.set_device(int(LOCAL_RANK))\ndevice = torch.device('xpu')\ntorch.manual_seed(0)\n\nsrc = torch.rand((2048, 1, 512))\ntgt = torch.rand((2048, 20, 512))\ndataset = torch.utils.data.TensorDataset(src, tgt)\n# DDP: use DistributedSampler to partition the training data\nsampler = torch.utils.data.distributed.DistributedSampler(dataset, shuffle=True, num_replicas=SIZE, rank=RANK, seed=0)\nloader = torch.utils.data.DataLoader(dataset, sampler=sampler, batch_size=32)\n\nmodel = torch.nn.Transformer(batch_first=True)\n# DDP: scale learning rate by the number of GPUs.\noptimizer = torch.optim.Adam(model.parameters(), lr=(0.001*SIZE))\ncriterion = torch.nn.CrossEntropyLoss()\nmodel.train()\nmodel = model.to(device)\ncriterion = criterion.to(device)\nmodel, optimizer = ipex.optimize(model, optimizer=optimizer)\n# DDP: wrap the model in DDP\nmodel = DDP(model)\n\nfor epoch in range(10):\n    # DDP: set epoch to sampler for shuffling\n    sampler.set_epoch(epoch)\n\n    for source, targets in loader:\n        source = source.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n\n        output = model(source, targets)\n        loss = criterion(output, targets)\n\n        loss.backward()\n        optimizer.step()\n\n# DDP: cleanup\ntorch.distributed.destroy_process_group()\n</code></pre> <p>Here are the steps to run the above code on Aurora:</p> <ol> <li>Login to Aurora:     <pre><code>ssh &lt;username&gt;@aurora.alcf.anl.gov\n</code></pre></li> <li>Request an interactive job on two nodes for 30 minutes:    <pre><code>qsub -q debug -A &lt;your_project_name&gt; -l select=2,walltime=30:00 -l filesystems=home:flare -k doe -j oe -I\n</code></pre></li> <li>Copy the above Python script into a file called <code>pytorch_ddp.py</code> and make it executable with <code>chmod a+x pytorch_ddp.py</code>.</li> <li>Load the frameworks module:    <pre><code>module load frameworks\n</code></pre></li> <li>Run the script on 24 tiles, 12 per node:    <pre><code>mpiexec -n 24 -ppn 12 python pytorch_ddp.py\n</code></pre></li> </ol> <p>Settings for training beyond 16 nodes</p> Setting the CPU Affinity <p>The CPU affinity can be set manually through mpiexec.  You can do this the following way (after having loaded all needed modules):</p> <pre><code>## Option 1\nexport CPU_BIND=\"list:4:9:14:19:20:25:56:61:66:71:74:79\" # 12 ppn to 12 cores\n\n## Option 2\nexport CPU_BIND=\"verbose,list:4-7:8-11:12-15:16-19:20-23:24-27:56-59:60-63:64-67:68-71:72-75:76-79\" # 12 ppn with each rank having 4 cores\nmpiexec ... --cpu-bind=${CPU_BIND}\n</code></pre> <p>These bindings should be used along with the following oneCCL and Horovod  environment variable settings:</p> <pre><code>HOROVOD_THREAD_AFFINITY=\"4,8,12,16,20,24,56,60,64,68,72,76\"\n\n## Option 1\nCCL_WORKER_AFFINITY=\"42,43,44,45,46,47,94,95,96,97,98,99\"\n\n## Option 2\nunset CCL_WORKER_AFFINITY  # Default will pick up from the last 24 cores even if you didn't specify these in the binding.\n</code></pre> <p>When running 12 ranks per node with these settings the <code>framework</code>s use 4 cores,  with Horovod tightly coupled with the <code>framework</code>s using one of the 4 cores, and  oneCCL using a separate core for better performance, e.g. with rank 0 the  <code>framework</code>s would use cores 4-7, Horovod would use core 4, and oneCCL would  use core 42.</p> <p>In the provided CPU binding list we have provided two options. First one is based on one CPU core per rank. In the second option, we assign 4 CPU cores per rank. In the first oneCCL worker affinity option we pick 12 CPU cores, one per rank. Notice that, these cores are picked out from the last 12 cores of each socket (CPU), aligned with oneCCL default core picking strategy. 42-47 belongs to the first socket, and 94-99 belongs to the second socket. We leave a few cores free, in case, the user may want to use other services like copper and DAOS along with their application. The second oneCCL option is to delegate task of picking cores to the system. In this case, the user should not declare or export the <code>CCL_WORKER_AFFINITY</code> variable.</p> <p>Each workload may perform better with different settings.  The criteria for choosing the cpu bindings are:</p> <ul> <li>Binding for GPU and NIC affinity \u2013 To bind the ranks to cores on the proper      socket or NUMA nodes.</li> <li>Binding for cache access \u2013 This is the part that will change per application      and some experimentation is needed.</li> </ul> <p>Important: This setup is a work in progress, and based on observed  performance. The recommended settings are likely to changed with new <code>framework</code> releases.</p>"},{"location":"aurora/data-science/frameworks/pytorch/#distributed-training-with-multiple-ccss","title":"Distributed Training with Multiple CCSs","text":"<p>The Intel PVC GPUs contain 4 Compute Command Streamers (CCSs) on each tile, which can be used to group Execution Units (EUs) into common pools.  These pools can then be accessed by separate processes thereby enabling distributed training with multiple MPI processes per tile.  This feature on PVC is similar to MPS on NVIDIA GPUs  and can be beneficial for increasing computational throughput when training or performing inference with smaller models which do not require the entire memory of a PVC tile. For more information, see the section on using multiple CCSs under the Running Jobs on Aurora page.</p> <p>For DDP distributed training with multiple CCSs can be enabled programmatically within the user code by explicitly setting the <code>xpu</code> device in PyTorch, for example</p> <pre><code>import os\nfrom argparse import ArgumentParser\nimport torch\nimport intel_extension_for_pytorch\n\nparser = ArgumentParser(description='CCS Test')\nparser.add_argument('--ppd', default=1, type=int, choices=[1,2,4], \n                    help='Number of MPI processes per GPU device') # (1)!\nargs = parser.parse_args()\n\nlocal_rank = int(os.environ.get('PALS_LOCAL_RANKID'))\nif torch.xpu.is_available():\n    xpu_id = local_rank//args.ppd if torch.xpu.device_count()&gt;1 else 0\n    assert xpu_id&gt;=0 and xpu_id&lt;torch.xpu.device_count(), \\\n           f\"Assert failed: xpu_id={xpu_id} and {torch.xpu.device_count()} available devices\"\n    torch.xpu.set_device(xpu_id)\n</code></pre> <ol> <li>PVC GPU allow the use of 1, 2 or 4 CCSs on each tile</li> </ol> <p>and then adding the proper environment variables and <code>mpiexec</code> settings in the run script.  For example, to run distributed training with 48 MPI processes per node exposing 4 CCSs per tile, set</p> <pre><code>export ZEX_NUMBER_OF_CCS=0:4,1:4,2:4,3:4,4:4,5:4,6:4,7:4,8:4,9:4,10:4,11:4\nBIND_LIST=\"1:2:4:6:8:10:12:14:16:18:20:22:24:26:28:30:32:34:36:38:40:42:44:46:53:54:56:58:60:62:64:66:68:70:72:74:76:78:80:82:84:86:88:90:92:94:96:98\"\nmpiexec --pmi=pmix --envall -n 48 --ppn 48 \\\n    --cpu-bind=verbose,list:${BIND_LIST} \\\n    python training_script.py --ppd=4\n</code></pre> <p>Alternatively, users can use the following modified GPU affinity script in their <code>mpiexec</code> command in order to bind multiple MPI processes to each tile by setting <code>ZE_AFFINITY_MASK</code></p> gpu_affinity_ccs.sh<pre><code>#!/bin/bash\n\nnum_ccs=$1 # (1)!\nshift\ngpu_id=$(( PALS_LOCAL_RANKID / num_ccs ))\nexport ZE_AFFINITY_MASK=$gpu_id\nexec \"$@\"\n</code></pre> <ol> <li>Note that the script takes the number of CCSs exposed as a command line argument</li> </ol> <p>Checking PVC usage with <code>xpu-smi</code></p> <p>Users are invited to check correct placement of the MPI ranks on the different tiles by connecting to the compute node being used and executing  <pre><code>module load xpu-smi\nwatch -n 0.1 xpu-smi stats -d &lt;GPU_ID&gt; # (1)!\n</code></pre></p> <ol> <li>In this case, GPU_ID refers to the 6 GPU on each node, not an individual tile</li> </ol> <p>and checking the GPU and memory utilization of both tiles.</p> <p>Multiple CCSs and oneCCL</p> <ul> <li>When performing distributed training exposing multiple CCSs, the collective communications with the oneCCL backend are delegated to the CPU. This is done in the background by oneCCL, so no change to the users' code is required to move data between host and device, however it may impact the performance of the collectives at scale.</li> <li>When using PyTorch DDP, the model must be offloaded to the XPU device after calling the <code>DDP()</code> wrapper on the model to avoid hangs.</li> </ul>"},{"location":"aurora/data-science/frameworks/scikit-learn/","title":"scikit-learn on Aurora","text":"<p>scikit-learn is a popular open-source Python library for machine learning. It has wide coverage of machine learning algorithms (other than neural networks), such as k-means clustering and random forests.</p> <p>scikit-learn (abbreviated \"sklearn\") is built for CPUs. However, the \"Extension to Scikit-learn\" (formerly the \"Intel(R) Extension for Scikit-learn\"), abbreviated \"sklearnex\", is a free Python package that speeds up scikit-learn on Intel CPUs &amp; GPUs and adds support for additional functionality, such as incremental and distributed algorithms. For more information, see the scikit-learn-intelex GitHub page, the documentation, or Intel's website.</p>"},{"location":"aurora/data-science/frameworks/scikit-learn/#environment-setup","title":"Environment Setup","text":"<p>Extension for Scikit-learn is not currently in the <code>frameworks</code> module. Below is an example of building Extension for Scikit-learn in a <code>venv</code> on top of the <code>conda</code> environment in the <code>frameworks</code> module. For more information about virtual environments, see the Python page. Please note the warning about importing Python packages at large scale. When you build Extension for Scikit-learn, it should find the oneDAL library that is part of the oneAPI installation on Aurora.  <pre><code>git clone https://github.com/intel/scikit-learn-intelex.git\nmodule load frameworks\npython -m venv sklearnex_build --system-site-packages\nsource sklearnex_build/bin/activate\npip install pybind11==3.0.0 cmake==4.0.3 clang-format\n\ncd scikit-learn-intelex\nbash conda-recipe/build.sh\n</code></pre></p>"},{"location":"aurora/data-science/frameworks/scikit-learn/#usage","title":"Usage","text":""},{"location":"aurora/data-science/frameworks/scikit-learn/#patching","title":"Patching","text":"<p>To accelerate existing scikit-learn code with minimal code changes, Extension for Scikit-learn uses patching: replacing stock scikit-learn algorithms with versions that utilize Intel(R) oneAPI Data Analytics Library (oneDAL).</p> <p>Note that patching only affects supported algorithms and parameters. To see the current support, check Intel's page here. Otherwise, the Extension will fall back on stock scikit-learn, which has to run on the CPU. To know which version is being used, enable Verbose Mode, for example, with the environment variable <code>SKLEARNEX_VERBOSE=INFO</code>. However, verbose mode is only available for supported algorithms.</p> <p>There are multiple ways to patch scikit-learn with the Extension, as Intel documents here. For example, you can patch within the script, like this:</p> <pre><code>from sklearnex import patch_sklearn\npatch_sklearn()\n</code></pre> <p>It is important to note that this needs to happen before importing scikit-learn. To explicitly only patch certain estimators, you can import particular functions from <code>sklearnex</code> instead of <code>sklearn</code>, like this:</p> <pre><code>from sklearnex.neighbors import NearestNeighbors\n</code></pre>"},{"location":"aurora/data-science/frameworks/scikit-learn/#gpu-acceleration","title":"GPU Acceleration","text":"<p>Extension for Scikit-learn can execute algorithms on the GPU via the dpctl package, which should be included in the frameworks module. If not, refer to Aurora's Python page &gt; dpctl section. dpctl implements oneAPI concepts like queues and devices.</p> <p>As described in more detail in Intel's documentation here, there are two ways to run on the GPU.</p> <ol> <li>Pass the input data to the algorithm as <code>dpctl.tensor.usm_ndarray</code>. Then the algorithm will run on the same device as the data and return the result as a usm_array on the same device.</li> <li>Configure Extension for Scikit-learn, for example, by setting a context: <code>sklearnex.config_context</code>.</li> </ol> <p>Patching (described above) can be helpful in the case of functionality that already exists in scikit-learn because you can import the functions from <code>sklearn</code> instead of <code>sklearnex</code>.</p>"},{"location":"aurora/data-science/frameworks/scikit-learn/#distributed-mode","title":"Distributed Mode","text":"<p>To distribute an <code>sklearnex</code> algorithm across multiple GPUs, we need several ingredients demonstrated in an example below. We recommend using the MPI backend rather than the CCL backend since it is tested more thoroughly on Aurora.</p> <p>Multi-GPU scaling performance</p> <p>The current version of Extension to scikit-learn does not scale well to multiple GPUs. The cause is that scikit-learn includes some array checks before starting an algorithm, and Intel has not implemented performing those checks on the GPU. For now, the data gets copied to the host to perform these checks, which can be a significant bottleneck. However, you can use a parameter to bypass those checks. Either run a function within a <code>with sklearnex.config_context(use_raw_input=True)</code> block or run <code>sklearnex.set_config(use_raw_input=True).</code> Alternatively, you could use the oneDAL C++ API directly.</p> <ol> <li>Use dpctl to create a SYCL queue (connection to the GPU devices you choose).</li> <li>Using dpctl and your queue, move your data to the GPU devices.</li> <li>Run the algorithm on that data. The compute will happen where the data is. The algorithm should be from <code>sklearnex.spmd</code>.</li> </ol> <p>Since you are importing the algorithm from <code>sklearnex</code> instead of <code>sklearn</code>, patching is not necessary here.</p>"},{"location":"aurora/data-science/frameworks/scikit-learn/#an-example-python-script","title":"An Example Python Script","text":"<p>This example is adapted from an example in Intel's scikit-learn-intelex GitHub repo.</p> knn_mpi4py_spmd.py<pre><code>import dpctl\nimport dpctl.tensor as dpt\nfrom mpi4py import MPI\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport sklearnex\nfrom sklearnex.spmd.neighbors import KNeighborsClassifier\n\n# Temporary solution until Intel implements array checks on GPU\nsklearnex.set_config(use_raw_input=True)\n\n# Create a GPU SYCL queue to store data on device.\nq = dpctl.SyclQueue(\"gpu\")\n\n# mpi4py is one way to handle arranging data across ranks.\n# For the sake of a concise demo, each rank is generating different random training data.\ncomm = MPI.COMM_WORLD\nrank = comm.Get_rank()\nX, y = make_classification(n_samples=100000, n_features=8, random_state=rank)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n\n# Move the data to the GPU devices.\ndpt_X_train = dpt.asarray(X_train, usm_type=\"device\", sycl_queue=q)\ndpt_X_val = dpt.asarray(X_val, usm_type=\"device\", sycl_queue=q)\ndpt_y_train = dpt.asarray(y_train, usm_type=\"device\", sycl_queue=q)\n\n# Run the algorithm.\nmodel_spmd = KNeighborsClassifier(\n    algorithm=\"brute\", n_neighbors=20, weights=\"uniform\", p=2, metric=\"minkowski\"\n)\nmodel_spmd.fit(dpt_X_train, dpt_y_train)\n\n# for this algorithm, predict is more expensive than fit\ny_val_predict = model_spmd.predict(dpt_X_val)\n</code></pre>"},{"location":"aurora/data-science/frameworks/scikit-learn/#an-example-job-script","title":"An Example Job Script","text":"<p>Below we give an example job script. Note that we are using Aurora MPICH (the default MPI library on Aurora) and not using oneCCL, so we don't need special oneCCL settings. For more about pinning ranks to CPU cores and GPUs, see the Running Jobs page.</p> <p>example_scikit-learn_distributed.sh<pre><code>module load frameworks\n# Activate venv where you installed Extension to scikit-learn\nsource sklearnex_build/bin/activate\n\n# This is to resolve an issue due to a package called \"numexpr\".\n# It sets the variable\n# 'numexpr.nthreads' to available number of threads by default, in this case\n# to 208. However, the 'NUMEXPR_MAX_THREADS' is also set to 64 as a package\n# default. The solution is to either set the 'NUMEXPR_NUM_THREADS' to less than\n# or equal to '64' or to increase the 'NUMEXPR_MAX_THREADS' to the available\n# number of threads. Both of these variables can be set manually.\nexport NUMEXPR_NUM_THREADS=64\n\nexport CPU_BIND=\"verbose,list:2-4:10-12:18-20:26-28:34-36:42-44:54-56:62-64:70-72:78-80:86-88:94-96\"\n\n# Launch the script\nmpiexec -np 12 -ppn 12 --cpu-bind ${CPU_BIND} gpu_tile_compact.sh python knn_mpi4py_spmd.py\n</code></pre> The highlighted line, which pins each of the 12 MPI ranks to specific CPU physical cores, is essential to achieving good performance across all 12 GPU Tiles on an Aurora node.</p>"},{"location":"aurora/data-science/frameworks/scikit-learn/#an-incremental-statistics-calculation-example","title":"An incremental statistics calculation example","text":"<p>Below, we give an example of a basic incremental calculation. This example is adapted from an example in Intel's scikit-learn-intelex GitHub repo. The incremental interface is accessible via the methods of the <code>sklearnex.basic_statistics.IncrementalBasicStatistics</code> class. There are two options: use the <code>partial_fit</code>method for each chunk of available data, or, if you have access to the whole data, call the <code>fit</code> method.</p> <p>incremental_basic_statistics.py<pre><code>import numpy as np\n\nfrom sklearnex.basic_statistics import IncrementalBasicStatistics\n\nincbs = IncrementalBasicStatistics(result_options=[\"mean\", \"max\", \"sum\"])\n\n# We do partial_fit for each batch and then print final result.\nX_1 = np.array([[0, 1], [0, 1]])\nresult = incbs.partial_fit(X_1)\n\nX_2 = np.array([[1, 2]])\nresult = incbs.partial_fit(X_2)\n\nX_3 = np.array([[1, 1], [1, 2], [2, 3]])\nresult = incbs.partial_fit(X_3)\n\nprint(f\"Mean:\\n{result.mean_}\")\nprint(f\"Max:\\n{result.max_}\")\nprint(f\"Sum:\\n{result.sum_}\")\nprint(f\"Sum Squares:\\n{result.sum_squares_}\")\n\n# We put the whole data to fit method, it is split automatically and then\n# partial_fit is called for each batch.\nincbs = IncrementalBasicStatistics(result_options=[\"mean\", \"max\", \"sum\"], batch_size=3)\nX = np.array([[0, 1], [0, 1], [1, 2], [1, 1], [1, 2], [2, 3]])\nresult = incbs.fit(X)\n\nprint(f\"Mean:\\n{result.mean_}\")\nprint(f\"Max:\\n{result.max_}\")\nprint(f\"Sum:\\n{result.sum_}\")\nprint(f\"Sum Squares:\\n{result.sum_squares_}\")\n</code></pre> To execute on the GPU via the dpctl package, one should add the following highlighted modifications: incremental_basic_statistics_dpctl.py<pre><code>import dpctl\nimport dpctl.tensor as dpt\n\nimport numpy as np\n\nfrom sklearnex.basic_statistics import IncrementalBasicStatistics\n\n# We create GPU SyclQueue and then put data to dpctl tensor using\n# the queue. It allows us to do computation on GPU.\n\nqueue = dpctl.SyclQueue(\"gpu\")\n\nincbs = IncrementalBasicStatistics(result_options=[\"mean\", \"max\", \"sum\"])\n\n# We do partial_fit for each batch and then print final result.\nX_1 = np.array([[0, 1], [0, 1]], sycl_queue=queue)) # &lt;-- Highlighted: sycl_queue=queue\nresult = incbs.partial_fit(X_1)\n\nX_2 = np.array([[1, 2]], sycl_queue=queue)) # &lt;-- Highlighted: sycl_queue=queue\nresult = incbs.partial_fit(X_2)\n\nX_3 = np.array([[1, 1], [1, 2], [2, 3]], sycl_queue=queue)) # &lt;-- Highlighted: sycl_queue=queue\nresult = incbs.partial_fit(X_3)\n\nprint(f\"Mean:\\n{result.mean_}\")\nprint(f\"Max:\\n{result.max_}\")\nprint(f\"Sum:\\n{result.sum_}\")\nprint(f\"Sum Squares:\\n{result.sum_squares_}\")\n\n# We put the whole data to fit method, it is split automatically and then\n# partial_fit is called for each batch.\nincbs = IncrementalBasicStatistics(result_options=[\"mean\", \"max\", \"sum\"], batch_size=3)\nX = np.array([[0, 1], [0, 1], [1, 2], [1, 1], [1, 2], [2, 3]], sycl_queue=queue)) # &lt;-- Highlighted: sycl_queue=queue\nresult = incbs.fit(X)\n\nprint(f\"Mean:\\n{result.mean_}\")\nprint(f\"Max:\\n{result.max_}\")\nprint(f\"Sum:\\n{result.sum_}\")\nprint(f\"Sum Squares:\\n{result.sum_squares_}\")\n</code></pre> More examples about how to compute covariance and perform linear regression incrementally can be found in Intel's scikit-learn-intelex GitHub repo.</p>"},{"location":"aurora/data-science/frameworks/tensorflow/","title":"TensorFlow on Aurora","text":"<p>TensorFlow is a popular, open-source deep learning framework developed and  released by Google. The  TensorFlow home page has more information about  TensorFlow, which you can refer to. For troubleshooting on Aurora, please  contact support@alcf.anl.gov.</p>"},{"location":"aurora/data-science/frameworks/tensorflow/#major-changes","title":"Major Changes:","text":"<p><code>TensorFlow</code> has a separate module now, as opposed to being part of the  <code>frameworks</code> module. </p>"},{"location":"aurora/data-science/frameworks/tensorflow/#provided-installation","title":"Provided Installation","text":"<p>TensorFlow is already preinstalled on Aurora, available in the <code>tensorflow</code>  module. To use it from a compute node, load the module: <pre><code>module load tensorflow\n</code></pre></p> <p>Then you can <code>import</code> TensorFlow as usual, the following is an output from the  <code>tensorflow/2025.2.0</code> module:</p> <p><pre><code>import tensorflow as tf\ntf.__version__\n</code></pre> <pre><code>'2.15.1'\n</code></pre> This import will fail on login nodes because there is no XPU on login nodes. </p> <p>A simple but useful check could be to use TensorFlow to get device information  on a compute node. You can do this the following way:</p> <p><pre><code>tf.config.list_physical_devices()\n</code></pre> <pre><code>[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), \nPhysicalDevice(name='/physical_device:XPU:0', device_type='XPU'), \nPhysicalDevice(name='/physical_device:XPU:1', device_type='XPU'), \nPhysicalDevice(name='/physical_device:XPU:2', device_type='XPU'), \nPhysicalDevice(name='/physical_device:XPU:3', device_type='XPU'), \nPhysicalDevice(name='/physical_device:XPU:4', device_type='XPU'), \nPhysicalDevice(name='/physical_device:XPU:5', device_type='XPU'), \nPhysicalDevice(name='/physical_device:XPU:6', device_type='XPU'), \nPhysicalDevice(name='/physical_device:XPU:7', device_type='XPU'), \nPhysicalDevice(name='/physical_device:XPU:8', device_type='XPU'), \nPhysicalDevice(name='/physical_device:XPU:9', device_type='XPU'), \nPhysicalDevice(name='/physical_device:XPU:10', device_type='XPU'), \nPhysicalDevice(name='/physical_device:XPU:11', device_type='XPU')]\n</code></pre></p> <p>Note that, here <code>tf.config</code> return 12 tiles of 6 cards (the number of GPU  resources on an Aurora compute node), and treat each tile as a device. The user can choose to set the environmental variable <code>ZE_FLAT_DEVICE_HIERARCHY</code> with  appropriate values to achieve desired behavior, as described in the  Level Zero Specification documentation. This environment variable is equivalent to the <code>ITEX_TILE_AS_DEVICE</code>, which is to be deprecated soon.</p> <p>Intel Extension for TensorFlow has been made publicly available as an  open-source project at  GitHub.</p> <p>Please consult the following resources for additional details and useful tutorials:</p> <ul> <li>Intel's Documentation</li> <li>Intel's Examples</li> <li>Intel's ITEX Features Guide</li> <li>Intel's Practice Guide</li> </ul>"},{"location":"aurora/data-science/frameworks/tensorflow/#tensorflow-best-practices-on-aurora","title":"TensorFlow Best Practices on Aurora","text":""},{"location":"aurora/data-science/frameworks/tensorflow/#single-device-performance","title":"Single Device Performance","text":"<p>To expose one particular tile out of the 12 available (6 GPUs, each with 2  tiles, treating each tile as a device) on a compute node,  this environmental variable should be set</p> <p><pre><code>export ZE_AFFINITY_MASK=0 ## Exposing tile 0 on GPU 0\n</code></pre> More information and details are available through Level Zero Specification Documentation - Affinity Mask</p>"},{"location":"aurora/data-science/frameworks/tensorflow/#single-node-performance","title":"Single Node Performance","text":"<p>When running TensorFlow applications, we have found the following practices to  be generally, if not universally, useful and encourage you to try some of these  techniques to boost performance of your own applications.</p>"},{"location":"aurora/data-science/frameworks/tensorflow/#reduced-precision","title":"Reduced Precision","text":"<p>Use Reduced Precision, whenever the application allows. Reduced Precision is  available on Intel Max 1550 and is supported with TensorFlow operations. In  general, the way to do this is via the <code>tf.keras.mixed_precision</code> Policy, as  described in the  mixed precision documentation Intel's extension for TensorFlow is fully compatible with the Keras mixed  precision API in TensorFlow. It also provides an advanced auto mixed precision  feature. For example, you can just set two environment variables to get the  performance benefit from low-precision data type <code>FP16</code>/<code>BF16</code> without changing the  application code.</p> <p><pre><code>export ITEX_AUTO_MIXED_PRECISION=1\nexport ITEX_AUTO_MIXED_PRECISION_DATA_TYPE=\"BFLOAT16\" # or \"FLOAT16\"\n</code></pre> If you use a custom training loop (and not <code>keras.Model.fit</code>), you will also  need to apply loss scaling.</p>"},{"location":"aurora/data-science/frameworks/tensorflow/#tensorflows-graph-api","title":"TensorFlow's graph API","text":"<p>Use TensorFlow's graph API to improve efficiency of operations. TensorFlow is,  in general, an imperative language but with function decorators like  <code>@tf.function</code> you can trace functions in your code. Tracing replaces your  python function with a lower-level, semi-compiled TensorFlow Graph. More  information about the <code>tf.function</code> interface is available  here.  When possible, use <code>jit_compile</code>, but be aware of sharp bits when using  <code>tf.function</code>: python expressions that aren't tensors are often replaced as  constants in the graph, which may or may not be your intention.</p> <p>There is an experimental feature, which allows for aggressive fusion of kernels through  oneDNN Graph API. Intel's extension for TensorFlow can offload performance critical graph  partitions to oneDNN library to get more aggressive graph optimizations. It can be done by setting this environmental variable:</p> <p><pre><code>export ITEX_ONEDNN_GRAPH=1\n</code></pre> This feature is experimental, and actively under development.</p>"},{"location":"aurora/data-science/frameworks/tensorflow/#tf32-math-mode","title":"<code>TF32</code> Math Mode","text":"<p>The Intel Xe Matrix Extensions (Intel XMX) engines in Intel Max 1550 Xe-HPC  GPUs natively support <code>TF32</code> math mode. Through the Intel Extension for TensorFlow, you can enable it by setting the following environmental variable:</p> <pre><code>export ITEX_FP32_MATH_MODE=\"TF32\"\n</code></pre>"},{"location":"aurora/data-science/frameworks/tensorflow/#xla-compilation-plannedupcoming","title":"XLA Compilation (Planned/Upcoming)","text":"<p>XLA is the Accelerated Linear Algebra library that is available in TensorFlow  and critical in software like JAX. XLA will compile a <code>tf.Graph</code> object,  generated with <code>tf.function</code> or similar, and perform optimizations like  operation-fusion. XLA can give impressive performance boosts with almost no  user changes except to set an environment variable <code>TF_XLA_FLAGS=--tf_xla_auto_jit=2</code>.  If your code is complex, or has dynamically sized tensors (tensors where the  shape changes every iteration), XLA can be detrimental: the overhead for  compiling functions can be large enough to mitigate performance improvements.  XLA is particularly powerful when combined with reduced precision,  yielding speedups &gt; 100% in some models. </p> <p>Intel provides initial Intel GPU support for TensorFlow models with XLA  acceleration through  Intel Extension for OpenXLA. Full TensorFlow and PyTorch support is planned for development.</p>"},{"location":"aurora/data-science/frameworks/tensorflow/#a-simple-example","title":"A simple example","text":"<p>A simple example on how to use Intel GPU with TensorFlow is the following:</p> intel-xpu-tf-example.py<pre><code>import tensorflow as tf   # TensorFlow registers PluggableDevices here.\nimport intel_extension_for_tensorflow as itex # Intel extensions for GPU usage\ntf.config.list_physical_devices()  # XPU device is visible to TensorFlow.\n\n#Section 1 Run implicitly\na = tf.random.normal(shape=[5], dtype=tf.float32)  # Runs on XPU.\nb = tf.nn.relu(a)         # Runs on XPU .\n\n#Section 2 Run with explicit device setting\nwith tf.device(\"/XPU:0\"):  # Users can also use 'with tf.device' syntax.\n  c = tf.nn.relu(a)        # Runs on XPU.\nwith tf.device(\"/CPU:0\"):\n  c = tf.nn.relu(a)        # Runs on CPU.\n\n#Section 3 Run with graph mode\n@tf.function  # Defining a tf.function\ndef run():\n  d = tf.random.uniform(shape=[100], dtype=tf.float32)\n  e = tf.nn.relu(d)\nrun()  # PluggableDevices also work with tf.function and graph mode. Runs on XPU\n</code></pre>"},{"location":"aurora/data-science/frameworks/tensorflow/#multi-gpu-multi-node-scale-up","title":"Multi-GPU / Multi-Node Scale Up","text":"<p>TensorFlow is compatible with scaling up to multiple GPUs per node, and across  multiple nodes. Good performance with tensorFlow has been seen with horovod in  particular. For details, please see the  Horovod documentation. Some Aurora specific details might be helpful to you.</p>"},{"location":"aurora/data-science/frameworks/tensorflow/#environment-variables","title":"Environment Variables","text":"<p>The following environmental variables should be set on the batch submission  script (PBSPro script) in the case of attempting to run beyond 16 nodes.</p> <p>oneCCL environment variables</p> <p>We have identified a set of environment settings that typically provide better performance or address potential application hangs and crashes at large scale. This particular setup is still experimental, and it might change as the environment variable settings are refined. Users are encouraged to check this page regularly.</p> <pre><code>export CCL_PROCESS_LAUNCHER=pmix  \nexport CCL_ATL_TRANSPORT=mpi\nexport CCL_ALLREDUCE_SCALEOUT=\"direct:0-1048576;rabenseifner:1048577-max\"  # currently best allreduce algorithm at large scale\nexport CCL_BCAST=double_tree # currently best bcast algorithm at large scale\n\nexport CCL_KVS_MODE=mpi\nexport CCL_CONFIGURATION_PATH=\"\"\nexport CCL_CONFIGURATION=cpu_gpu_dpcpp\nexport CCL_KVS_CONNECTION_TIMEOUT=600 \n\nexport CCL_ZE_CACHE_OPEN_IPC_HANDLES_THRESHOLD=1024\nexport CCL_KVS_USE_MPI_RANKS=1\n\nexport MPI_PROVIDER=$FI_PROVIDER\nunset MPIR_CVAR_CH4_POSIX_COLL_SELECTION_TUNING_JSON_FILE\nunset MPIR_CVAR_CH4_COLL_SELECTION_TUNING_JSON_FILE\nunset MPIR_CVAR_COLL_SELECTION_TUNING_JSON_FILE\n</code></pre> <p>The following additional set of environment variable setups might be application-dependent. Users are encouraged to try to set them and see whether they help their applications.</p> <pre><code>ulimit -c unlimited\nexport FI_MR_ZE_CACHE_MONITOR_ENABLED=0\nexport FI_MR_CACHE_MONITOR=disabled\nexport FI_CXI_RX_MATCH_MODE=hybrid\nexport FI_CXI_OFLOW_BUF_SIZE=8388608\nexport FI_CXI_DEFAULT_CQ_SIZE=1048576\nexport FI_CXI_CQ_FILL_PERCENT=30\nexport INTELGT_AUTO_ATTACH_DISABLE=1\nexport PALS_PING_PERIOD=240\nexport PALS_RPC_TIMEOUT=240\nexport MPIR_CVAR_GATHERV_INTER_SSEND_MIN_PROCS=-1 # to solve the sync send issue in Horovod seg fault\nexport CCL_ATL_SYNC_COLL=1 # to avoid potential hang at large scale\nexport CCL_OP_SYNC=1 # to avoid potential hang at large scale\n</code></pre>"},{"location":"aurora/data-science/frameworks/tensorflow/#cpu-affinity","title":"CPU Affinity","text":"<p>The CPU affinity should be set manually through mpiexec.  You can do this the following way:</p> <pre><code>## Option 1\nexport CPU_BIND=\"list:4:9:14:19:20:25:56:61:66:71:74:79\" # 12 ppn to 12 cores\n\n## Option 2\nexport CPU_BIND=\"verbose,list:4-7:8-11:12-15:16-19:20-23:24-27:56-59:60-63:64-67:68-71:72-75:76-79\" # 12 ppn with each rank having 4 cores\nmpiexec ... --cpu-bind=${CPU_BIND}\n</code></pre> <p>These bindings should be used along with the following oneCCL and Horovod  environment variable settings:</p> <pre><code>HOROVOD_THREAD_AFFINITY=\"4,8,12,16,20,24,56,60,64,68,72,76\"\n\n## Option 1\nCCL_WORKER_AFFINITY=\"42,43,44,45,46,47,94,95,96,97,98,99\"\n\n## Option 2\nunset CCL_WORKER_AFFINITY  # Default will pick up from the last 24 cores even if you didn't specify these in the binding.\n</code></pre> <p>When running 12 ranks per node with these settings the <code>framework</code>s use 4 cores,  with Horovod tightly coupled with the <code>framework</code>s using one of the 4 cores, and  oneCCL using a separate core for better performance, e.g. with rank 0 the  <code>framework</code>s would use cores 4-7, Horovod would use core 4, and oneCCL would  use core 42.</p> <p>In the provided CPU binding list we have provided two options. First one is based on one CPU core per rank. In the second option, we assign 4 CPU cores per rank. In the first oneCCL worker affinity option we pick 12 CPU cores, one per rank. Notice that, these cores are picked out from the last 12 cores of each socket (CPU), aligned with oneCCL default core picking strategy. 42-47 belongs to the first socket, and 94-99 belongs to the second socket. We leave a few cores free, in case, the user may want to use other services like copper and DAOS along with their application. The second oneCCL option is to delegate task of picking cores to the system. In this case, the user should not declare or export the <code>CCL_WORKER_AFFINITY</code> variable.</p> <p>Each workload may perform better with different settings.  The criteria for choosing the cpu bindings are:</p> <ul> <li>Binding for GPU and NIC affinity \u2013 To bind the ranks to cores on the proper      socket or NUMA nodes.</li> <li>Binding for cache access \u2013 This is the part that will change per application      and some experimentation is needed.</li> </ul> <p>Note</p> <p>This setup is a work in progress, and based on observed performance. The recommended settings are likely to change with new <code>framework</code> releases. To learn more about the CPU binding, please visit the  Running Jobs page.</p>"},{"location":"aurora/data-science/frameworks/tensorflow/#distributed-training","title":"Distributed Training","text":"<p>Distributed training with TensorFlow  on Aurora is facilitated through Horovod, using Intel Optimization for Horovod.</p> <p>The key steps in performing distributed training are laid out in the following example:</p> <ul> <li>TensorFlow examples with Intel Optimization for Horovod</li> </ul> <p>Detailed implementation of the same example is here:</p> <ul> <li>TensorFlow with Keras and Horovod</li> </ul> <p>A suite of detailed and well documented examples is part of Intel's optimization for Horovod repository:</p> <ul> <li>Distributed Training Example Suite</li> </ul>"},{"location":"aurora/data-science/frameworks/tensorflow/#a-simple-job-script","title":"A simple Job Script","text":"<p>Below we give a simple job script:</p> <pre><code>#!/bin/bash -l\n#PBS -l select=512                              # selecting 512 Nodes\n#PBS -l place=scatter\n#PBS -l walltime=1:59:00\n#PBS -q prod                                   # a specific queue\n#PBS -A &lt;ProjectName&gt;                          # project allocation\n#PBS -l filesystems=&lt;fs1:fs2&gt;                   # specific filesystem, can be a list separated by :\n#PBS -k doe\n#PBS -e /home/$USER/path/to/errordir\n#PBS -o /home/$USER/path/to/outdir              # path to `stdout` or `.OU` files\n#PBS -j oe                                      # output and error placed in the `stdout` file\n#PBS -N a.name.for.the.job\n\n#####################################################################\n# This block configures the total number of ranks, discovering\n# it from PBS variables.\n# 12 Ranks per node, if doing rank/tile\n#####################################################################\n\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=12\nlet NRANKS=${NNODES}*${NRANKS_PER_NODE}\n\n# This is a fix for running over 16 nodes:\nexport FI_CXI_DEFAULT_CQ_SIZE=131072\nexport FI_CXI_OFLOW_BUF_SIZE=8388608\nexport FI_CXI_CQ_FILL_PERCENT=20\n# These are workaround for a known Cassini overflow issue\n\nexport FI_LOG_LEVEL=warn\n#export FI_LOG_PROV=tcp\nexport FI_LOG_PROV=cxi\n# These allow for logging from a specific provider (libfabric)\n\nexport MPIR_CVAR_ENABLE_GPU=0\n\n#####################################################################\n# FRAMEWORK Variables that make a performance difference\n#####################################################################\n\n# Toggle tf32 on (or don't):\nexport ITEX_FP32_MATH_MODE=TF32\n\n#####################################################################\n# End of perf-adjustment section\n#####################################################################\n\n#####################################################################\n# Environment set up, using the latest frameworks drop\n#####################################################################\n\nmodule load frameworks\n\n## CCL setup\nexport FI_CXI_DEFAULT_CQ_SIZE=131072\nexport FI_CXI_OVFLOW_BUF_SIZE=8388608\nexport FI_CXI_CQ_FILL_PERCENT=20\n\nexport FI_LOG_LEVEL=warn\n#export FI_LOG_PROV=tcp\nexport FI_LOG_PROV=cxi\n\nexport CCL_KVS_GET_TIMEOUT=600\n\nexport LD_LIBRARY_PATH=$CCL_ROOT/lib:$LD_LIBRARY_PATH\nexport CPATH=$CCL_ROOT/include:$CPATH\nexport LIBRARY_PATH=$CCL_ROOT/lib:$LIBRARY_PATH\n\nexport CCL_PROCESS_LAUNCHER=pmix  \nexport CCL_ATL_TRANSPORT=mpi\nexport CCL_ALLREDUCE=topo\nexport CCL_ALLREDUCE_SCALEOUT=rabenseifner  # currently best allreduce algorithm at large scale\nexport CCL_BCAST=double_tree # currently best bcast algorithm at large scale\n\nexport CCL_KVS_MODE=mpi\nexport CCL_CONFIGURATION_PATH=\"\"\nexport CCL_CONFIGURATION=cpu_gpu_dpcpp\nexport CCL_KVS_CONNECTION_TIMEOUT=600 \n\nexport CCL_ZE_CACHE_OPEN_IPC_HANDLES_THRESHOLD=1024\nexport CCL_KVS_USE_MPI_RANKS=1\n\n#####################################################################\n# End of environment setup section\n#####################################################################\n\n#####################################################################\n# JOB LAUNCH\n######################################################################\n\n\nexport CCL_LOG_LEVEL=\"WARN\"\nexport CPU_BIND=\"verbose,list:2-8:10-16:18-24:26-32:34-40:42-48:54-60:62-68:70-76:78-84:86-92:94-100\"\nHOROVOD_THREAD_AFFINITY=\"4,12,20,28,36,44,56,64,72,80,88,96\"\nCCL_WORKER_AFFINITY=\"1,9,17,25,33,41,53,61,69,77,85,93\"\n\nulimit -c 0\n\n# Launch the script\nmpiexec -np ${NRANKS} -ppn ${NRANKS_PER_NODE} \\\n--cpu-bind ${CPU_BIND} \\\npython path/to/application.py\n</code></pre>"},{"location":"aurora/data-science/inference/libtorch/","title":"LibTorch C++ Library","text":"<p>LibTorch is a C++ library for Torch, with many of the APIs that are available in PyTorch. Users can find more information in the PyTorch documentation. This is useful for integrating the Torch ML framework into traditional HPC simulation codes and therefore enables training and inference of ML models. On Aurora, the Intel Extension for PyTorch (IPEX) library is needed to access the Max 1550 GPU, which has the device name <code>kXPU</code> in LibTorch. During compilation, Intel optimizations will be activated automatically once the IPEX dynamic library is linked.</p>"},{"location":"aurora/data-science/inference/libtorch/#environment-setup","title":"Environment Setup","text":"<p>To use LibTorch on Aurora, load the ML frameworks module:</p> <pre><code>module load frameworks\n</code></pre> <p>This will also load the consistent oneAPI SDK (version 2024.2) and <code>cmake</code>.</p>"},{"location":"aurora/data-science/inference/libtorch/#torch-and-ipex-libraries","title":"Torch and IPEX libraries","text":"<p>With the ML frameworks module loaded as shown above, run:</p> <pre><code>python -c 'import torch; print(torch.__path__[0])'\npython -c 'import torch; print(torch.utils.cmake_prefix_path)'\n</code></pre> <p>to find the path to the Torch libraries, include files, and CMake files.</p> <p>For the path to the IPEX dynamic library, run:</p> <pre><code>python -c 'import torch; print(torch.__path__[0].replace(\"torch\",\"intel_extension_for_pytorch\"))'\n</code></pre>"},{"location":"aurora/data-science/inference/libtorch/#linking-libtorch-and-ipex-libraries","title":"Linking LibTorch and IPEX Libraries","text":"<p>When using the CMake build system, LibTorch and IPEX libraries can be linked to an example C++ application using the following <code>CMakeLists.txt</code> file:</p> <pre><code>cmake_minimum_required(VERSION 3.5 FATAL_ERROR)\ncmake_policy(SET CMP0074 NEW)\nproject(project-name)\n\nfind_package(Torch REQUIRED)\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${TORCH_CXX_FLAGS} -Wl,--no-as-needed\")\nset(TORCH_LIBS ${TORCH_LIBRARIES})\n\nfind_library(IPEX_LIB intel-ext-pt-gpu PATHS ${INTEL_EXTENSION_FOR_PYTORCH_PATH}/lib NO_DEFAULT_PATH REQUIRED)\nset(TORCH_LIBS ${TORCH_LIBS} ${IPEX_LIB})\ninclude_directories(SYSTEM ${INTEL_EXTENSION_FOR_PYTORCH_PATH}/include)\n\nadd_executable(exe main.cpp)\ntarget_link_libraries(exe ${TORCH_LIBS})\n\nset_property(TARGET exe PROPERTY CXX_STANDARD 17)\n</code></pre> <p>and configuring the build with:</p> <pre><code>cmake \\\n    -DCMAKE_PREFIX_PATH=`python -c 'import torch; print(torch.utils.cmake_prefix_path)'` \\\n    -DINTEL_EXTENSION_FOR_PYTORCH_PATH=`python -c 'import torch; print(torch.__path__[0].replace(\"torch\",\"intel_extension_for_pytorch\"))'` \\\n    ./\nmake\n</code></pre>"},{"location":"aurora/data-science/inference/libtorch/#device-introspection","title":"Device Introspection","text":"<p>Similarly to PyTorch, LibTorch provides APIs to perform introspection on the devices available on the system. The simple code below shows how to check if XPU devices are available, how many are present, and how to loop through them to discover some properties.</p> <pre><code>#include &lt;torch/torch.h&gt;\n#include &lt;c10/xpu/XPUFunctions.h&gt;\n\nint main(int argc, const char* argv[])\n{\n  torch::DeviceType device;\n  int num_devices = 0;\n  if (torch::xpu::is_available()) {\n    std::cout &lt;&lt; \"XPU devices detected\" &lt;&lt; std::endl;\n    device = torch::kXPU;\n\n    num_devices = torch::xpu::device_count();\n    std::cout &lt;&lt; \"Number of XPU devices: \" &lt;&lt; num_devices &lt;&lt; std::endl;\n\n    for (int i = 0; i &lt; num_devices; ++i) {\n      c10::xpu::set_device(i);\n      std::cout &lt;&lt; \"Device \" &lt;&lt; i &lt;&lt; \":\" &lt;&lt; std::endl;\n\n      c10::xpu::DeviceProp device_prop{};\n      c10::xpu::get_device_properties(&amp;device_prop, i);\n      std::cout &lt;&lt; \"  Name: \" &lt;&lt; device_prop.name &lt;&lt; std::endl;\n      std::cout &lt;&lt; \"  Total memory: \" &lt;&lt; device_prop.global_mem_size / (1024 * 1024) &lt;&lt; \" MB\" &lt;&lt; std::endl;\n    }\n  } else {\n    device = torch::kCPU;\n    std::cout &lt;&lt; \"No XPU devices detected, setting device to CPU\" &lt;&lt; std::endl;\n  }\n\n  return 0;\n}\n</code></pre>"},{"location":"aurora/data-science/inference/libtorch/#model-inferencing-using-the-torch-api","title":"Model Inferencing Using the Torch API","text":"<p>This example shows how to perform inference with the ResNet50 model using LibTorch. First, get a JIT-traced version of the model by executing <code>python resnet50_trace.py</code> (shown below) on a compute node.</p> <pre><code>import torch\nimport torchvision\nimport intel_extension_for_pytorch as ipex\nfrom time import perf_counter\n\ndevice = 'xpu'\n\nmodel = torchvision.models.resnet50()\nmodel.to(device)\nmodel.eval()\n\ndummy_input = torch.rand(1, 3, 224, 224).to(device)\n\nmodel_jit = torch.jit.trace(model, dummy_input)\ntic = perf_counter()\npredictions = model_jit(dummy_input)\ntoc = perf_counter()\nprint(f\"Inference time: {toc-tic}\")\n\ntorch.jit.save(model_jit, f\"resnet50_jit.pt\")\n</code></pre> <p>Then, build <code>inference-example.cpp</code> (shown below):</p> <pre><code>#include &lt;torch/torch.h&gt;\n#include &lt;torch/script.h&gt;\n\nint main(int argc, const char* argv[]) {\n  torch::jit::script::Module model;\n  try {\n    model = torch::jit::load(argv[1]);\n    std::cout &lt;&lt; \"Loaded the model\\n\";\n  }\n  catch (const c10::Error&amp; e) {\n    std::cerr &lt;&lt; \"error loading the model\\n\";\n    return -1;\n  }\n\n  model.to(torch::Device(torch::kXPU));\n  std::cout &lt;&lt; \"Model offloaded to GPU\\n\\n\";\n\n  auto options = torch::TensorOptions()\n                      .dtype(torch::kFloat32)\n                      .device(torch::kXPU);\n  torch::Tensor input_tensor = torch::rand({1,3,224,224}, options);\n  assert(input_tensor.dtype() == torch::kFloat32);\n  assert(input_tensor.device().type() == torch::kXPU);\n  std::cout &lt;&lt; \"Created the input tensor on GPU\\n\";\n\n  torch::Tensor output = model.forward({input_tensor}).toTensor();\n  std::cout &lt;&lt; \"Performed inference\\n\\n\";\n\n  std::cout &lt;&lt; \"Slice of predicted tensor is : \\n\";\n  std::cout &lt;&lt; output.slice(/*dim=*/1, /*start=*/0, /*end=*/10) &lt;&lt; '\\n';\n\n  return 0;\n}\n</code></pre> <p>and execute it with <code>./inference-example ./resnet50_jit.pt</code>.</p>"},{"location":"aurora/data-science/inference/libtorch/#libtorch-interoperability-with-sycl-pipelines","title":"LibTorch Interoperability with SYCL Pipelines","text":"<p>The LibTorch API can be integrated with data pipelines using SYCL to operate on input and output data already offloaded to the Intel Max 1550 GPU. The code below extends the above example of performing inference with the ResNet50 model by first generating the input data on the CPU, then offloading it to the GPU with SYCL, and finally passing the device pointer to LibTorch for inference using <code>torch::from_blob()</code>, which creates a Torch tensor from a data pointer with zero-copy.</p> <p>The source code for <code>inference-example.cpp</code> is modified as follows:</p> <pre><code>#include &lt;torch/torch.h&gt;\n#include &lt;torch/script.h&gt;\n#include &lt;iostream&gt;\n#include \"sycl/sycl.hpp\"\n#include &lt;vector&gt;\n\nconst int N_BATCH = 1;\nconst int N_CHANNELS = 3;\nconst int N_PIXELS = 224;\nconst int INPUTS_SIZE = N_BATCH*N_CHANNELS*N_PIXELS*N_PIXELS;\nconst int OUTPUTS_SIZE = N_BATCH*N_CHANNELS;\n\nint main(int argc, const char* argv[]) {\n  torch::jit::script::Module model;\n  try {\n    model = torch::jit::load(argv[1]);\n    std::cout &lt;&lt; \"Loaded the model\\n\";\n  }\n  catch (const c10::Error&amp; e) {\n    std::cerr &lt;&lt; \"error loading the model\\n\";\n    return -1;\n  }\n\n  model.to(torch::Device(torch::kXPU));\n  std::cout &lt;&lt; \"Model offloaded to GPU\\n\\n\";\n\n  // Create the input data on the host\n  std::vector&lt;float&gt; inputs(INPUTS_SIZE);\n  srand(12345);\n  for (int i=0; i&lt;INPUTS_SIZE; i++) {\n    inputs[i] = static_cast &lt;float&gt; (rand()) / static_cast &lt;float&gt; (RAND_MAX);\n  }\n  std::cout &lt;&lt; \"Generated input data on the host \\n\\n\";\n\n  // Move input data to the device with SYCL\n  sycl::queue Q(sycl::gpu_selector_v);\n  std::cout &lt;&lt; \"SYCL running on \"\n            &lt;&lt; Q.get_device().get_info&lt;sycl::info::device::name&gt;()\n            &lt;&lt; \"\\n\\n\";\n  float *d_inputs = sycl::malloc_device&lt;float&gt;(INPUTS_SIZE, Q);\n  Q.memcpy((void *) d_inputs, (void *) inputs.data(), INPUTS_SIZE*sizeof(float));\n  Q.wait();\n\n  // Pre-allocate the output array on device and fill with a number\n  double *d_outputs = sycl::malloc_device&lt;double&gt;(OUTPUTS_SIZE, Q);\n  Q.submit([&amp;](sycl::handler &amp;cgh) {\n    cgh.parallel_for(OUTPUTS_SIZE, [=](sycl::id&lt;1&gt; idx) {\n      d_outputs[idx] = 1.2345;\n    });\n  });\n  Q.wait();\n  std::cout &lt;&lt; \"Offloaded input data to the GPU \\n\\n\";\n\n  // Convert input array to Torch tensor\n  auto options = torch::TensorOptions()\n                      .dtype(torch::kFloat32)\n                      .device(torch::kXPU);\n  torch::Tensor input_tensor = torch::from_blob(\n                                 d_inputs,\n                                 {N_BATCH,N_CHANNELS,N_PIXELS,N_PIXELS},\n                                 options);\n  assert(input_tensor.dtype() == torch::kFloat32);\n  assert(input_tensor.device().type() == torch::kXPU);\n  std::cout &lt;&lt; \"Created the input Torch tensor on GPU\\n\\n\";\n\n  // Perform inference\n  torch::NoGradGuard no_grad; // equivalent to \"with torch.no_grad():\" in PyTorch\n  torch::Tensor output = model.forward({input_tensor}).toTensor();\n  std::cout &lt;&lt; \"Performed inference\\n\\n\";\n\n  // Copy the output Torch tensor to the SYCL pointer\n  auto output_tensor_ptr = output.contiguous().data_ptr();\n  Q.memcpy((void *) d_outputs, (void *) output_tensor_ptr, OUTPUTS_SIZE*sizeof(double));\n  Q.wait();\n  std::cout &lt;&lt; \"Copied output Torch tensor to SYCL pointer\\n\";\n\n  return 0;\n}\n</code></pre> <p>Note that an additional C++ flag is needed in this case, as shown below in the <code>cmake</code> command:</p> <pre><code>cmake \\\n    -DCMAKE_CXX_FLAGS=\"-std=c++17 -fsycl\" \\\n    -DCMAKE_PREFIX_PATH=`python -c 'import torch; print(torch.utils.cmake_prefix_path)'` \\\n    -DINTEL_EXTENSION_FOR_PYTORCH_PATH=`python -c 'import torch; print(torch.__path__[0].replace(\"torch\",\"intel_extension_for_pytorch\"))'` \\\n    ./\n</code></pre>"},{"location":"aurora/data-science/inference/openvino/","title":"Model Inference with OpenVINO","text":"<p>OpenVINO is a library developed by Intel specifically designed for accelerating inference of ML models on their CPU and GPU hardware.  This page contains build and run instructions for Python, but please refer to the OpenVINO GitHub page for more information.</p>"},{"location":"aurora/data-science/inference/openvino/#installing-the-openvino-python-runtime-and-cli-tools","title":"Installing the OpenVINO Python Runtime and CLI Tools","text":"<p>OpenVINO does not come with the default frameworks module on Aurora, but it can be installed manually within a Python virtual environment as shown below: <pre><code>module load frameworks\npython -m venv --clear /path/to/_ov_env --system-site-packages\nsource /path/to/_ov_env/bin/activate\npip install openvino==2024.4.0\npip install openvino-dev==2024.4.0\n</code></pre></p> <p>It is recommended that the path to the virtual environment be in the user's project space on Flare.</p>"},{"location":"aurora/data-science/inference/openvino/#model-converter","title":"Model Converter","text":"<p>The first suggested step is to convert the model from one of the ML frameworks into OpenVINO's Intermediate Representation (IR).  This consists of an <code>.xml</code> file which describes the network topology and a <code>.bin</code> file which contains the weights and biases in binary format.  The conversion can be done from the command line with <code>ovc</code> or using the Python API <code>openvino.convert_model()</code>. Note that PyTorch models cannot be converted directly with <code>ovc</code> and need to be converted to ONNX format first. You can find more information on the conversion process on OpenVINO's documentation page.</p> <p>The following code snippet demonstrates how to use the Python API to convert the ResNet50 model from TorchVision and save the OpenVINO IR. <pre><code>import openvino as ov\nimport torch\nfrom torchvision.models import resnet50\n\nmodel = resnet50(weights='DEFAULT')\ninput_data = torch.rand(1, 3, 224, 224)\n\nov_model = ov.convert_model(model, example_input=input_data)\nov.save_model(ov_model, 'resnet50.xml')\n</code></pre></p> <p>Information on using the CLI conversion tool can be found by running <code>ovc -h</code>, which will save the model in IR format by default.</p> <p>Note that by default, both <code>ovc</code> and <code>openvino.save_model()</code> perform compression of the model weights to FP16. This reduces the memory needed to store the model and can provide an increase in performance.  To disable this feature, use: <pre><code>ov.save_model(ov_model, 'resnet50.xml', compress_to_fp16=False)\n</code></pre></p> <p>or</p> <pre><code>ovc model.onnx --compress_to_fp16=False\n</code></pre>"},{"location":"aurora/data-science/inference/openvino/#benchmark-app","title":"Benchmark App","text":"<p>Before writing a script or program to perform inference with the OpenVINO runtime, the performance of the model can be tested with the CLI tool <code>benchmark_app</code>. </p> <p>A minimal example to run on a single Intel Max 1550 tile is shown below: <pre><code>benchmark_app -m resnet50.xml -hint latency -d GPU.0 -data_shape [1,3,224,224]\n</code></pre></p> <p>which returns a series of information on the parameters set for the benchmark tests and the performance of the tests. The last few lines of the output are shown below.</p> <pre><code>[ INFO ] Execution Devices:['GPU.0']\n[ INFO ] Count:            42847 iterations\n[ INFO ] Duration:         60001.96 ms\n[ INFO ] Latency:\n[ INFO ]    Median:        1.38 ms\n[ INFO ]    Average:       1.38 ms\n[ INFO ]    Min:           1.35 ms\n[ INFO ]    Max:           21.31 ms\n[ INFO ] Throughput:   714.09 FPS\n</code></pre> <p>Note that <code>benchmark_app</code> takes a number of additional configuration options which are listed by running <code>benchmark_app -h</code>. </p>"},{"location":"aurora/data-science/inference/openvino/#inference-with-python-openvino-api","title":"Inference with Python OpenVINO API","text":"<p>Inference can be performed by invoking the compiled model directly or using the OpenVINO Runtime API explicitly to create inference requests.</p> <p>An example of performing direct inference with the compiled model is shown below.  This leads to compact code, but it performs a single synchronous inference request.  Future calls to the model will reuse the same inference request created, thus experiencing less overhead. <pre><code>import openvino as ov\nimport torch\n\ncore = ov.Core()\ncompiled_model = core.compile_model(\"resnet50.xml\")\n\ninput_data = torch.rand((1, 3, 224, 224))\nresults = compiled_model(input_data)[0]\n</code></pre></p> <p>By default, OpenVINO performs inference with FP16 precision on GPU, but the precision and device can be selected with hints, such as: <pre><code>import openvino.properties.hint as hints\ncore.set_property(\n    \"GPU.0\",\n    {hints.execution_mode: hints.ExecutionMode.ACCURACY},\n)\n</code></pre></p> <p>More information on the available hints can be found on the OpenVINO documentation page.</p> <p>Other than the direct call to the model, the Runtime API can be used to create inference requests and control their execution. For this approach, we refer the user to the OpenVINO documentation page.</p>"},{"location":"aurora/data-science/inference/vllm/","title":"Inference with vLLM","text":"<p>vLLM is an open-source library designed to optimize the inference and serving. Originally developed at UC Berkeley's Sky Computing Lab, it has evolved into a community-driven project. The library is built around the innovative PagedAttention algorithm, which significantly improves memory management by reducing waste in Key-Value (KV) cache memory.</p>"},{"location":"aurora/data-science/inference/vllm/#install-vllm","title":"Install vLLM","text":"<p>First, SSH to an Aurora login node: <pre><code>ssh &lt;username&gt;@aurora.alcf.anl.gov\n</code></pre></p> <p>Refer to Getting Started on Aurora for additional information. In particular, you need to set the environment variables that provide access to the proxy host.</p> <p>Note</p> <p>The instructions below should be run directly from a compute node. Explicitly, to request an interactive job (from <code>aurora-uan</code>): <pre><code>qsub -I -q &lt;your_Queue&gt; -l select=1,walltime=60:00 -A &lt;your_ProjectName&gt; -l filesystems=&lt;fs1:fs2&gt;\n</code></pre></p> <p>Refer to job scheduling and execution for additional information.</p> Install vLLM using pre-built wheels<pre><code>export http_proxy=\"proxy.alcf.anl.gov:3128\"\nexport https_proxy=\"proxy.alcf.anl.gov:3128\"\nmodule load frameworks\nconda create --name vllm python=3.10 -y\nconda activate vllm\n\nmodule unload oneapi/eng-compiler/2024.07.30.002\nmodule use /opt/aurora/24.180.3/spack/unified/0.8.0/install/modulefiles/oneapi/2024.07.30.002\nmodule use /soft/preview/pe/24.347.0-RC2/modulefiles\nmodule add oneapi/release\n\npip install /flare/datasets/softwares/vllm-install/wheels/*\npip install /flare/datasets/softwares/vllm-install/vllm-0.6.6.post2.dev28+g5dbf8545.d20250129.xpu-py3-none-any.whl\n</code></pre>"},{"location":"aurora/data-science/inference/vllm/#access-model-weights","title":"Access Model Weights","text":"<p>Model weights for commonly used open-weight models are downloaded and available in the following directory on Aurora: <pre><code>/flare/datasets/model-weights/hub\n</code></pre> To ensure your workflows utilize the preloaded model weights and datasets, update the following environment variables in your session. Some models hosted on Hugging Face may be gated, requiring additional authentication. To access these gated models, you will need a Hugging Face authentication token. <pre><code>export HF_HOME=\"/flare/datasets/model-weights\"\nexport HF_DATASETS_CACHE=\"/flare/datasets/model-weights\"\nexport HF_MODULES_CACHE=\"/flare/datasets/model-weights\"\nexport HF_TOKEN=\"YOUR_HF_TOKEN\"\nexport RAY_TMPDIR=\"/tmp\"\nexport TMPDIR=\"/tmp\"\n</code></pre></p>"},{"location":"aurora/data-science/inference/vllm/#common-configuration-recommendations","title":"Common Configuration Recommendations","text":"<p>For small models that fit within a single tile's memory (64 GB), no additional configuration is required to serve the model. Simply set <code>TP=1</code> (Tensor Parallelism). This configuration ensures the model is run on a single tile without the need for distributed setup. Models with fewer than 7 billion parameters typically fit within a single tile. To utilize multiple tiles for larger models (<code>TP&gt;1</code>), a more advanced setup is necessary. This involves configuring a Ray cluster and setting the <code>ZE_FLAT_DEVICE_HIERARCHY</code> environment variable: <pre><code>export ZE_FLAT_DEVICE_HIERARCHY=FLAT\n\nexport VLLM_HOST_IP=$(getent hosts $(hostname).hsn.cm.aurora.alcf.anl.gov | awk '{ print $1 }' | tr ' ' '\\n' | sort | head -n 1)\nexport tiles=12\nray --logging-level debug start --head --verbose --node-ip-address=$VLLM_HOST_IP --port=6379 --num-cpus=64 --num-gpus=$tiles&amp;\n\nexport no_proxy=\"localhost,127.0.0.1\" #Set no_proxy for the client to interact with the locally hosted model\n</code></pre></p>"},{"location":"aurora/data-science/inference/vllm/#serve-small-models","title":"Serve Small Models","text":""},{"location":"aurora/data-science/inference/vllm/#using-single-tile","title":"Using Single Tile","text":"<p>The following command serves <code>meta-llama/Llama-2-7b-chat-hf</code> on a single tile of a single node: <pre><code>vllm serve meta-llama/Llama-2-7b-chat-hf --port 8000 --device xpu --dtype float16\n</code></pre></p>"},{"location":"aurora/data-science/inference/vllm/#using-multiple-tiles","title":"Using Multiple Tiles","text":"<p>Refer to Common Configuration Recommendations for guidance on setting up the Ray cluster. The following script demonstrates how to serve the <code>meta-llama/Llama-2-7b-chat-hf</code> model across 8 tiles on a single node:</p> <pre><code>export VLLM_HOST_IP=$(getent hosts $(hostname).hsn.cm.aurora.alcf.anl.gov | awk '{ print $1 }' | tr ' ' '\\n' | sort | head -n 1)\nvllm serve meta-llama/Llama-2-7b-chat-hf --port 8000 --tensor-parallel-size 8 --device xpu --dtype float16 --trust-remote-code\n</code></pre>"},{"location":"aurora/data-science/inference/vllm/#serve-medium-models","title":"Serve Medium Models","text":""},{"location":"aurora/data-science/inference/vllm/#using-single-node","title":"Using Single Node","text":"<p>Refer to Common Configuration Recommendations for guidance on setting up the Ray cluster. The following script demonstrates how to serve <code>meta-llama/Llama-3.3-70B-Instruct</code> on 8 tiles on a single node. Models with up to 70 billion parameters can usually fit within a single node, utilizing multiple tiles.</p> <pre><code>export VLLM_HOST_IP=$(getent hosts $(hostname).hsn.cm.aurora.alcf.anl.gov | awk '{ print $1 }' | tr ' ' '\\n' | sort | head -n 1)\nvllm serve meta-llama/Llama-3.3-70B-Instruct --port 8000 --tensor-parallel-size 8 --device xpu --dtype float16 --trust-remote-code --max-model-len 32768\n</code></pre>"},{"location":"aurora/data-science/inference/vllm/#serve-large-models","title":"Serve Large Models","text":""},{"location":"aurora/data-science/inference/vllm/#using-multiple-nodes","title":"Using Multiple Nodes","text":"<p>The following example serves <code>meta-llama/Llama-3.1-405B-Instruct</code> model using 2 nodes with <code>TP=8</code> and <code>PP=2</code>. Models exceeding 70 billion parameters generally require more than one Aurora node. First, use <code>setup_ray_cluster.sh</code> script to setup a Ray cluster across nodes:</p> Setup script setup_ray_cluster.sh<pre><code>########################################################################\n# FUNCTIONS\n########################################################################\n\n# Setup environment and variables needed to setup ray and vllm\nsetup_environment() {\n    echo \"[$(hostname)] Setting up the environment...\"\n    # Set proxy configurations\n    export HTTP_PROXY=\"http://proxy.alcf.anl.gov:3128\"\n    export HTTPS_PROXY=\"http://proxy.alcf.anl.gov:3128\"\n    export http_proxy=\"http://proxy.alcf.anl.gov:3128\"\n    export https_proxy=\"http://proxy.alcf.anl.gov:3128\"\n    export ftp_proxy=\"http://proxy.alcf.anl.gov:3128\"\n\n    # Define the common setup script path (make sure this file is accessible on all nodes)\n    export COMMON_SETUP_SCRIPT=\"/path/to/setup_ray_cluster.sh\"\n\n    # Load modules and activate your conda environment\n    module load frameworks\n    conda activate vllm_0125\n\n    module unload oneapi/eng-compiler/2024.07.30.002\n    module use /opt/aurora/24.180.3/spack/unified/0.8.0/install/modulefiles/oneapi/2024.07.30.002\n    module use /soft/preview/pe/24.347.0-RC2/modulefiles\n    module add oneapi/release\n\n    export TORCH_LLM_ALLREDUCE=1\n    export CCL_ZE_IPC_EXCHANGE=drmfd\n\n    export ZE_FLAT_DEVICE_HIERARCHY=FLAT\n\n    export HF_TOKEN=\"YOUR_HF_TOKEN\"\n    export HF_HOME=\"/flare/datasets/model-weights/hub\"\n    export HF_DATASETS_CACHE=\"/flare/datasets/model-weights/hub\"\n    export TMPDIR=\"/tmp\"\n\n    export RAY_TMPDIR=\"/tmp\"\n    export VLLM_IMAGE_FETCH_TIMEOUT=60\n\n    ulimit -c unlimited\n\n    # Derive the node's HSN IP address (modify the getent command as needed)\n    export HSN_IP_ADDRESS=$(getent hosts \"$(hostname).hsn.cm.aurora.alcf.anl.gov\" | awk '{ print $1 }' | sort | head -n 1)\n    export VLLM_HOST_IP=\"$HSN_IP_ADDRESS\"\n\n    echo \"[$(hostname)] Environment setup complete. HSN_IP_ADDRESS is $HSN_IP_ADDRESS\"\n}\n\n# Stop any running Ray processes\nstop_ray() {\n    echo \"[$(hostname)] Stopping Ray (if running)...\"\n    ray stop -f\n}\n\n# Start Ray head node\nstart_ray_head() {\n    echo \"[$(hostname)] Starting Ray head...\"\n    ray start --num-gpus=8 --num-cpus=64 --head --node-ip-address=\"$HSN_IP_ADDRESS\" --temp-dir=/tmp\n\n    # Wait until Ray reports that the head node is up\n    echo \"[$(hostname)] Waiting for Ray head to be up...\"\n    until ray status &amp;&gt;/dev/null; do\n        sleep 5\n        echo \"[$(hostname)] Waiting for Ray head...\"\n    done\n    echo \"[$(hostname)] ray status: $(ray status)\"\n    echo \"[$(hostname)] Ray head node is up.\"\n}\n\n# Start Ray worker node\nstart_ray_worker() {\n    echo \"[$(hostname)] Starting Ray worker, connecting to head at $RAY_HEAD_IP...\"\n    echo \"HSN IP Address : $HSN_IP_ADDRESS\"\n    ray start --num-gpus=8 --num-cpus=64 --address=\"$RAY_HEAD_IP:6379\" --node-ip-address=\"$HSN_IP_ADDRESS\" --temp-dir=/tmp\n\n    echo \"[$(hostname)] Waiting for Ray worker to be up...\"\n    until ray status &amp;&gt;/dev/null; do\n        sleep 5\n        echo \"[$(hostname)] Waiting for Ray worker...\"\n    done\n    echo \"[$(hostname)] ray status: $(ray status)\"\n    echo \"[$(hostname)] Ray worker node is up.\"\n}\n\n########################################################################\n# MAIN SCRIPT LOGIC\n########################################################################\n\n\nmain() {\n\n    # Ensure that the script is being run within a PBS job\n    if [ -z \"$PBS_NODEFILE\" ]; then\n        echo \"Error: PBS_NODEFILE not set. This script must be run within a PBS job allocation.\"\n        exit 1\n    fi\n\n    # Read all nodes from the PBS_NODEFILE into an array.\n    mapfile -t nodes_full &lt; \"$PBS_NODEFILE\"\n    num_nodes=${#nodes_full[@]}\n\n    echo \"Allocated nodes ($num_nodes):\"\n    printf \" - %s\\n\" \"${nodes_full[@]}\"\n\n    # Require at least 2 nodes (one head + one worker)\n    if [ \"$num_nodes\" -lt 2 ]; then\n        echo \"Error: Need at least 2 nodes to launch the Ray cluster.\"\n        exit 1\n    fi\n\n    # The first node will be our Ray head.\n    head_node_full=\"${nodes_full[0]}\"\n\n    # All remaining nodes will be the workers.\n    worker_nodes_full=(\"${nodes_full[@]:1}\")\n\n    # It is a good idea to run this master script on the designated head node.\n    current_node=$(hostname -f)\n\n\n    echo \"[$(hostname)] Running on head node.\"\n\n    # --- Setup and start the head node ---\n    setup_environment\n    stop_ray\n    start_ray_head\n\n    # Export the head node's IP so that workers can join.\n    export RAY_HEAD_IP=\"$HSN_IP_ADDRESS\"\n    echo \"[$(hostname)] RAY_HEAD_IP exported as $RAY_HEAD_IP\"\n\n    # --- Launch Ray workers on each of the other nodes via SSH ---\n    for worker in \"${worker_nodes_full[@]}\"; do\n        echo \"[$(hostname)] Launching Ray worker on $worker...\"\n        ssh \"$worker\" \"bash -l -c 'set -x; export RAY_HEAD_IP=${RAY_HEAD_IP}; export COMMON_SETUP_SCRIPT=\"/path/to/setup_ray_cluster.sh\" ;source \\$COMMON_SETUP_SCRIPT; setup_environment; stop_ray; start_ray_worker'\" &amp;\n    done\n\n    # Wait for all background SSH jobs to finish.\n    wait\n\n    echo \"[$(hostname)] Ray cluster is up and running with $num_nodes nodes.\"\n}\n\nmain \n</code></pre> <p>From a login node, initiate the Ray cluster and execute vLLM serve: <pre><code>source /path/to/setup_ray_cluster.sh\nmain \nvllm serve meta-llama/Llama-3.1-405B-Instruct --port 8000 --tensor-parallel-size 8 --pipeline-parallel-size 2 --device xpu --dtype float16 --trust-remote-code --max-model-len 1024\n</code></pre> Setting <code>--max-model-len</code> is important in order to fit this model on 2 nodes. In order to use higher <code>--max-model-len</code> values, you will need to use additonal nodes.  In <code>setup_ray_cluster.sh</code>, change <code>/path/to/setup_ray_cluster.sh</code> to a path in your environment. </p>"},{"location":"aurora/debugging/","title":"Debugging on Aurora - Overview","text":"<p>There are 3 debuggers available on Aurora:</p> <ol> <li>gdb-oneapi - This is Intel's version of gdb augmented to allow debugging kernels executing on the PVC GPUs.</li> <li>DDT - The Linaro parallel debugger. This is the same parallel debugger that we have on Polaris. It supports a client-server mode and (via using <code>gdb-oneapi</code> internally) debugging kernels executing on the PVC GPUs.</li> <li>gdb4hpc - An alternative for CPU debugging only that will apply commands to all threads in the MPI process group.</li> </ol> <p>There is also a correctness tool for Fortran:</p> <ol> <li>Codee - This is a tool from Codee which can automatically analyze your code line-by-line to identify and fix opportunities for correctness, modernization, security and optimization. It is especially useful for legacy Fortran codes.</li> </ol>"},{"location":"aurora/debugging/#preliminary-steps","title":"Preliminary steps","text":"<ul> <li>You can use the module <code>mpich/dbg</code>. The module enables runtime checks during MPICH execution.</li> <li>The <code>mpich/dbg</code> module also allows you to run valgrind (from <code>module load valgrind</code>) as: <code>mpirun $OPT valgrind $BIN</code> </li> <li>You can also recompile your code with <code>-fsanitize=address</code> to help detect memory access errors (will work for both CPU and GPU, see Intel documentation for more details)</li> </ul>"},{"location":"aurora/debugging/codee/","title":"Using Codee to analyze Fortran code for correctness and modernization","text":"<p>The Codee tool automatically analyzes your code line-by-line to identify and fix opportunities for correctness, modernization, security and optimization. </p>"},{"location":"aurora/debugging/codee/#load-the-tool","title":"Load the tool","text":"<pre><code>module use /soft/modulefiles\nmodule load codee\n</code></pre> <p>There is documentation, including quickstarts here: https://docs.codee.com/</p>"},{"location":"aurora/debugging/codee/#known-issue","title":"Known Issue","text":"<p>Note that if you use <code>bear</code> as discussed in the https://docs.codee.com/, you may run into the error: <pre><code>&gt; bear -- make\nwrapper: failed with: gRPC call failed: failed to connect to all addresses; last error: UNKNOWN: HTTP proxy returned response code 403\n</code></pre> This occurs due to the http proxy settings  <pre><code>export HTTP_PROXY=http://proxy.alcf.anl.gov:3128 \nexport HTTPS_PROXY=http://proxy.alcf.anl.gov:3128 \nexport http_proxy=http://proxy.alcf.anl.gov:3128 \nexport https_proxy=http://proxy.alcf.anl.gov:3128\n</code></pre> You can work around this by temporarily resetting these proxy settings: <pre><code>unset HTTP_PROXY\nunset HTTPS_PROXY\nunset http_proxy\nunset https_proxy\n</code></pre> although note that you may need to reset them if you are pulling code from GitHub for example after.</p>"},{"location":"aurora/debugging/ddt-aurora/","title":"Debugging on Aurora with DDT","text":"<p>We have licenses for Linaro DDT on Aurora, a parallel debugger that is able to use gdb-oneapi as its underlying engine on Aurora. This is not a tutorial on DDT; for that, you should use Linaro's documentation, such as the documentation bundled with their client programs. Here we provide specific information on using DDT interactively in the GUI client-server mode on Aurora.</p>"},{"location":"aurora/debugging/ddt-aurora/#client","title":"Client","text":"<p>Download and install the latest Linaro Forge client for your desktop/laptop system from the Linaro website. This is available for Linux, macOS, and Windows systems.</p>"},{"location":"aurora/debugging/ddt-aurora/#configuring-the-remote-client","title":"Configuring the Remote Client","text":"<p>Before you can start a DDT debugging session on Aurora compute nodes, you must set your client for remote connection from Aurora compute nodes. Your client window should look something like this:</p> <p></p> <p>Click the Remote Launch pull-down and click Configure to create a connector for Aurora:</p> <p></p> <p>Click the Add button on the Configure Remote Connections screen:</p> <p></p> <p>Create a configuration named \"aurora,\" and set it up like this example, replacing \"username\" with your actual ALCF login name:</p> <p></p> <p>The path in the Remote Installation Directory field changes when new versions of DDT are installed on Aurora. To find the correct path, use the <code>which</code> command. After you've loaded the <code>forge</code> module, this will show you the path to use (remove the <code>/bin/ddt</code> portion when entering it into the DDT client Remote Installation Directory field):</p> <pre><code>aurora-uan-0011&gt; which ddt\n/opt/aurora/24.180.3/support/tools/forge/24.1.1/bin/ddt\naurora-uan-0011&gt;\n</code></pre> <p>You may want to test the configuration. To do that, click the Test Remote Launch button. If you see a login prompt like the following example, use your usual ALCF one-time password:</p> <p></p> <p>If the test is successful, you are ready to proceed from an Aurora compute node.</p>"},{"location":"aurora/debugging/ddt-aurora/#invoking-the-ddt-server-from-aurora","title":"Invoking the DDT Server from Aurora","text":"<p>To run DDT interactively from Aurora, start up an interactive PBS job. You'll need to load a module to access DDT:</p> <pre><code>module load forge\n</code></pre> <p>If you are using a wrapper script to map MPI ranks to PVC GPU tiles, you must set this environment variable to the full path to that wrapper script:</p> <pre><code>export FORGE_DEBUGGER_WRAPPER=/opt/aurora/default/support/tools/mpi_wrapper_utils/gpu_tile_compact.sh\n</code></pre> <p>(The path to the default <code>gpu_tile_compact.sh</code> script changes when there's a new default software module update. You may find the up-to-date path using the command <code>which gpu_tile_compact.sh</code>.)</p> <p>As discussed with respect to gdb-oneapi, you must explicitly enable GPU debugging on all the PVC GPUs you are using, on all the nodes you are using. One way to do this is to create a script and execute it across all your compute nodes using <code>mpiexec</code>. Here is an example script, which takes an argument <code>1</code> to enable debugging or <code>0</code> to disable it:</p> helper_toggle_eu_debug.sh<pre><code>#!/usr/bin/env bash\n# helper_toggle_eu_debug.sh\n\nexport MY_RANK=${PMIX_RANK}\nexport MY_NODE=${PALS_NODEID}\nexport MY_LOCAL_RANK=${PALS_LOCAL_RANKID}\n\neu_debug_toggle() {\n  for f in /sys/class/drm/card*/prelim_enable_eu_debug\n  do\n    echo $1 &gt; $f\n  done\n  echo \"INFO: EU debug state on rank-${MY_RANK}: $(cat /sys/class/drm/card*/prelim_enable_eu_debug | tr '\\n' ' ')\"\n  # sleep 10\n}\n\n# One rank per node toggles eu debug:\nif [ ${MY_LOCAL_RANK} -eq 0 ]; then\n    eu_debug_toggle $1\nfi\n</code></pre> <p>From the interactive prompt on your lead Aurora compute node, issue the following commands:</p> <pre><code>export NNODES=`wc -l &lt; $PBS_NODEFILE`\nmpiexec -n $NNODES ./helper_toggle_eu_debug.sh 1\nexport ZET_ENABLE_PROGRAM_DEBUGGING=1\n</code></pre> <p>To start the DDT server and connect to your client, make sure your client is running and you have selected the remote connection to Aurora you created as shown above. On the Aurora compute node shell prompt, issue the command to debug your binary like this example, which starts up DDT on 16 nodes, with 12 MPI ranks per node:</p> <pre><code>ddt --np=192 --connect --mpi=generic --mpiargs=\"-l --ppn 12 --cpu-bind verbose,list:0-7,104-111:8-15,112-119:16-23,120-127:24-31,128-135:32-39,136-143:40-47,144-151:52-59,156-163:60-67,164-171:68-75,172-179:76-83,180-187:84-91,188-195:92-99,196-203 -envall\" ./a.out\n</code></pre> <p>On the client, you should see a connection pop-up like this:</p> <p></p> <p>Click the Connect button. This should bring up a DETAILS pane that looks like the following example. Make sure the Implementation is set to \"Generic\" (change it to Generic if it isn't). Likewise, confirm and adjust the number of OpenMP threads and other parameters to be correct for your run. For PVC debugging, the Intel Xe box should be checked:</p> <p></p> <p>When you are satisfied with the details, click the Run button. This should pop up a window that shows the multiple processes starting up. If that startup completes normally, the pop-up will disappear and your client window should reveal the full DDT debugging GUI interface, something like this example:</p> <p></p> <p>From here, you should be able to control starting and stopping processes, ranks, and threads (CPU and GPU threads). If you set a breakpoint or otherwise stop in the source code for a GPU-offloaded kernel, you should be able to click the Thread radio button and see threads with a \"GPU\" badge on them. As mentioned above, this is not meant to be full documentation on how to use DDT. A good place to start with that is to open the User Guide from the Help menu in the client application.</p>"},{"location":"aurora/debugging/ddt-aurora/#running-a-local-version-on-aurora","title":"Running a local version on Aurora","text":"<p>You may want to install and run a local version of Forge from the Linaro website on Aurora. Once you install it, you can use the following license file to run the local version with the Forge license on Aurora:</p> <pre><code>FORGE_LICENSE_FILE=/pe/licenses/arm_forge/Licence &lt;path_to_the_local_version&gt;/ddt --connect &lt;other DDT parameters&gt; \n</code></pre>"},{"location":"aurora/debugging/gdb-oneapi/","title":"Debugging on Aurora with <code>gdb-oneapi</code>","text":"<p>The <code>gdb-oneapi</code> tool is part of Intel's oneAPI software and is available via the default modules loaded on Aurora. It provides the ability to debug kernels offloaded to the PVC GPUs, as well as CPU code debugging. It does not provide multiprocess or multinode debugging; it is not integrated with MPI. For parallel debugging, we recommend using DDT. You may also use noninteractive debugging for all or selected MPI ranks.</p> <p>You may find it useful to peruse the Intel\u00ae Distribution for GDB* Documentation. For generic documentation on <code>gdb</code>, refer to the FSF guide Debugging with GDB.</p>"},{"location":"aurora/debugging/gdb-oneapi/#preliminaries","title":"Preliminaries","text":"<p>To use <code>gdb-oneapi</code> effectively, you need to compile and link your application with <code>-g</code>. To get anywhere with GPU debugging, the current best practice is to compile and link with <code>-g -O0</code>.</p> <p>Before you debug with <code>gdb-oneapi</code>, you must explicitly enable GPU debugging on all the PVC GPUs you are using, on all the nodes you are using. One way to do this is to create a script and execute it across all your compute nodes using <code>mpiexec</code>. Here is an example script, which takes an argument <code>1</code> to enable debugging or <code>0</code> to disable it:</p> helper_toggle_eu_debug.sh<pre><code>#!/usr/bin/env bash\n\nexport MY_RANK=${PMIX_RANK}\nexport MY_NODE=${PALS_NODEID}\nexport MY_LOCAL_RANK=${PALS_LOCAL_RANKID}\n\neu_debug_toggle() {\n  for f in /sys/class/drm/card*/prelim_enable_eu_debug\n  do\n    echo $1 &gt; $f\n  done\n  echo \"INFO: EU debug state on rank-${MY_RANK}: $(cat /sys/class/drm/card*/prelim_enable_eu_debug | tr '\\n' ' ')\"\n  # sleep 10\n}\n\n# One rank per node toggles eu debug:\nif [ ${MY_LOCAL_RANK} -eq 0 ]; then\n    eu_debug_toggle $1\nfi\n</code></pre> <p>From the interactive prompt on your lead Aurora compute node, issue</p> <pre><code>export NNODES=`wc -l &lt; $PBS_NODEFILE`\nmpiexec -n $NNODES ./helper_toggle_eu_debug.sh 1\nZET_ENABLE_PROGRAM_DEBUGGING=1\n</code></pre>"},{"location":"aurora/debugging/gdb-oneapi/#notes-on-gpu-debugging","title":"Notes on GPU Debugging","text":"<p>The man page and <code>gdb-oneapi --help</code> do not include any information about GPU debugging\u2014only the generic <code>gdb</code> information. The current build of <code>gdb-oneapi</code> does support the TUI (Text User Interface) mode via the <code>--tui</code> command-line switch. The <code>help</code> command from the <code>(gdb)</code> command prompt command-line interface does not offer any insights into GPU debugging, since the commands to use are really just the normal gdb commands. The key is that it provides access to GPU threads, not just CPU threads. If you query the threads, you will see CPU threads (such as OpenMP threads) and example GPU threads if there are any scheduled. The GPU threads look like the last line in this example output, in which 2.481 is a single GPU thread id running on that GPU. All the other threads in this example are CPU threads, which are mostly waiting for GPU kernels to complete:</p> <pre><code>(gdb) info threads -s\nId      Target Id                                          Frame\n1.1     Thread 0x155523298880 (LWP 25335) \"xgc-es-cpp-gpu\" 0x000015552d310407 in sched_yield () from /lib64/libc.so.6\n1.3     Thread 0x15551b307700 (LWP 27775) \"xgc-es-cpp-gpu\" 0x000015552d2efba1 in clock_nanosleep@GLIBC_2.2.5 () from /lib64/libc.so.6\n1.4     Thread 0x155515e9b700 (LWP 27809) \"xgc-es-cpp-gpu\" 0x000015552d32bcdf in epoll_wait () from /lib64/libc.so.6\n1.5     Thread 0x155505c17780 (LWP 28039) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.6     Thread 0x155505815800 (LWP 28046) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.7     Thread 0x155505413880 (LWP 28056) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.8     Thread 0x155505011900 (LWP 28062) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.9     Thread 0x155504c0f980 (LWP 28065) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.10    Thread 0x15550480da00 (LWP 28070) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.11    Thread 0x15550440ba80 (LWP 28075) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.12    Thread 0x155504009b00 (LWP 28080) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.13    Thread 0x155503c07b80 (LWP 28096) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.14    Thread 0x155503805c00 (LWP 28110) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.15    Thread 0x155503403c80 (LWP 28121) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.16    Thread 0x155503001d00 (LWP 28137) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.17    Thread 0x155502bffd80 (LWP 28151) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.18    Thread 0x1555027fde00 (LWP 28153) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.19    Thread 0x1555023fbe80 (LWP 28155) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1.20    Thread 0x155501ffa700 (LWP 28160) \"xgc-es-cpp-gpu\" 0x000015552d41a70c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n* 2.481:0 ZE 0.7.4.0                                       get_f0_grid&lt;Kokkos::Device&lt;Kokkos::Experimental::SYCL, Kokkos::Experimental::SYCLDeviceUSMSpace&gt; &gt;\n (grid=..., magnetic_field=..., species=..., vgrid=..., pol_decomp=...,\n part=..., grid_wts0=..., f0_ptl=...) at getf0.tpp:22\n</code></pre> <p>You may use the <code>thread apply</code> command followed by a specific thread number, followed by a <code>gdb</code> command, to execute that command on the specific thread. For example:</p> <pre><code>thread apply 2.481 where\n</code></pre> <p>This will show the call stack for that GPU thread, which should show the GPU kernel function calls.</p> <p>To set a mode where the stepping commands such as <code>next</code> and <code>stepi</code> only apply to a single thread, use:</p> <pre><code>set scheduler-locking step\n</code></pre> <p>You may find it useful to look at PVC assembly code. In stepping through GPU code, you may use:</p> <pre><code>disassemble $pc - 0x20, $pc + 0x20\n</code></pre> <p>This shows the assembly code for a range of instructions before and after the current step (program counter). Adjust the hex value larger or smaller than <code>0x20</code> to increase/decrease the range of assembly instructions displayed.</p> <p>When debugging in GPU code, you should be able to use the usual <code>gdb</code> inspection commands such as <code>print</code> to look at GPU data structures, variables, and registers.</p>"},{"location":"aurora/debugging/gdb-oneapi/#stopping-at-gpu-segmentation-faults-aka-page-faults","title":"Stopping at GPU Segmentation Faults (a.k.a. \"Page Faults\")","text":"<p>GPU segmentation faults are a common reason for debugging. To make <code>gdb-oneapi</code> stop where they occur, use</p> <pre><code>handle all stop print\n</code></pre> <p>before the first <code>run</code> command (or sometime before you expect the fault to happen).</p>"},{"location":"aurora/debugging/gdb-oneapi/#noninteractive-debugging","title":"Noninteractive Debugging","text":"<p>For MPI programs run using a wrapper script to map ranks to GPUs, you may use a modified wrapper script to invoke a set of predetermined <code>gdb-oneapi</code> commands on some or all of the ranks. For example: mpi-wrapper-gdb-oneapi.sh<pre><code>#!/bin/bash\ndisplay_help() {\n  echo \" Will map MPI ranks to gpu tiles in compact and then round-robin fashion\"\n  echo \" Usage:\"\n  echo \"   mpiexec --np N $gpu_tile_compact_gdb-oneapi ./a.out\"\n  exit 1\n}\n\nnum_gpu=6\nnum_tile=2\n\nif [ \"$#\" -eq 0 ] || [ \"$1\" == \"--help\" ] || [ \"$1\" == \"-h\" ] || [ \"$num_gpu\" = 0 ]; then\n  display_help\nfi\n\ngpu_id=$(( (PALS_LOCAL_RANKID / num_tile ) % num_gpu ))\ntile_id=$((PALS_LOCAL_RANKID % num_tile))\n\nunset EnableWalkerPartition\nexport EnableImplicitScaling=0\nexport ZE_ENABLE_PCI_ID_DEVICE_ORDER=1\nexport ZE_AFFINITY_MASK=$gpu_id.$tile_id\n\nexport ZET_ENABLE_PROGRAM_DEBUGGING=1 # needed for gdb-oneapi:\n\ngdb-oneapi -batch -ex \"handle all stop print\" -ex run -ex \"thread apply all bt\" --args $* &gt;out.${PBS_JOBID%.*}.$PALS_RANKID 2&gt;err.${PBS_JOBID%.*}.$PALS_RANKID\n</code></pre></p> <p>This example prints a backtrace where GPU segmentation violations or other types of errors occur, and pipes the output into file names including the MPI rank number.</p>"},{"location":"aurora/debugging/gdb4hpc/","title":"HPE gdb4hpc on Aurora","text":"<p>The gdb4hpc is not a GPU-aware debugger but can be used to debug general code problems at scale. This debugger will apply commands to all threads in the MPI process group.</p>"},{"location":"aurora/debugging/gdb4hpc/#attaching-to-a-running-job","title":"Attaching to a running job","text":"<p>Determine the <code>jobid</code> of interest:</p> <pre><code>qstat -u $USER\n</code></pre> <pre><code>harms@aurora-uan-0009:~/working/all2all&gt; qstat -u $USER\n\naurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov: \n                                                            Req'd  Req'd   Elap\nJob ID          Username Queue    Jobname    SessID NDS TSK Memory Time  S Time\n--------------- -------- -------- ---------- ------ --- --- ------ ----- - -----\n127750.aurora-* harms    workq    all2all       --    4   4    --  00:30 R   -- \n</code></pre> <p>Next find a node the job is running on. Choose the first node in the list of <code>vnodes</code>: <pre><code>qstat -f 127750 | grep exec_vnode\n</code></pre></p> <pre><code>harms@aurora-uan-0009:~/working/all2all&gt; qstat -f 127750 | grep exec_vnode\nexec_vnode = (x4305c2s6b0n0:ncpus=1)+(x4305c2s7b0n0:ncpus=1)+(x4305c4s0b0n0\n</code></pre> <p>Log in to this node, find your <code>mpiexec</code> process id, and run <code>gdb4hpc</code>:</p> <pre><code>ssh x4305c2s6b0n0\nps -eaf | grep mpiexec\nmodule load gdb4hpc\nCTI_WLM_IMPL=ssh gdb4hpc\n</code></pre> Example output <pre><code>harms@aurora-uan-0009:~/working/all2all&gt; ssh x4305c2s6b0n0\nharms@x4305c2s6b0n0:~&gt; ps -eaf | grep mpiexec\nharms    108581 108569  0 16:05 ?        00:00:00 mpiexec -l --no-transfer --line-buffer --np 16 -ppn 4 --cpu-bind core ./a2a-p2p\nharms    109440 109354  0 16:11 pts/4    00:00:00 grep --color=auto mpiexec\nharms@x4305c2s6b0n0:~&gt; module load gdb4hpc\nharms@x4305c2s6b0n0:~&gt; CTI_WLM_IMPL=ssh gdb4hpc\n\ngdb4hpc 4.14.7 - Cray Line Mode Parallel Debugger\nWith Cray Comparative Debugging Technology.\nCopyright 2007-2022 Hewlett Packard Enterprise Development LP.\nCopyright 1996-2016 University of Queensland. All Rights Reserved.\n\nType \"help\" for a list of commands.\nType \"help &lt;cmd&gt;\" for detailed help about a command.\ndbg all&gt;\n</code></pre> <p>Now attach to the <code>mpiexec</code> process:</p> <pre><code>  dbg all&gt; attach $a &lt;pid&gt;\n</code></pre> Example output <pre><code>dbg all&gt; attach $a 108581\n0/16 ranks connected... (timeout in 299 seconds)\n0/16 ranks connected... (timeout in 298 seconds)\n...\n12/16 ranks connected... (timeout in 300 seconds)\n16/16 ranks connected.\nCreated network...\nConnected to application...\nCurrent rank location:\na{0}: #0  0x00001472aba12699 in MPIDI_progress_test\n... backtrace ...\n</code></pre>"},{"location":"aurora/node-performance-overview/node-performance-overview/","title":"Single node \"GPU-Peak\" benchmarks","text":"<p>This work was done on a pre-production supercomputer with early versions of the Aurora software development kit.</p> <p>This page aims to give you a high-level overview of key performance numbers for a single Aurora node.</p> <ul> <li>We are providing both 1 Tile and Full Node numbers.</li> <li>The Full Node numbers are the weak scaling version of the single node one.</li> <li>The Full Node numbers have been achieved by one rank per tile, 12 ranks.</li> <li>All benchmarks' source code and launch options are included so you can tweak them as needed.</li> <li>The results we provide are not exhaustive and do not paint a complete picture of a node's performance. Please assume we cherry-picked the correct size to get the best numbers.</li> <li>We will not compare the results to some \u201ctheoretical\u201d value. Theoretical values are full of assumptions, and we want to keep this page short.</li> <li>We will not compare the results to other hardware. Feel free to do it yourself \ud83d\ude42</li> <li>To improve reproducibility, only the \u201cbest\u201d numbers are reported (e.g., we take the minimum time of repetition step). When doing \"real\" science, please perform better statistical analysis.</li> <li>The code will use a mixture of OpenMP and SYCL in C++ (sorry, Fortran, Python, and Level Zero lovers).</li> </ul> <p>Don't hesitate to contact ALCF staff (via email or Slack) for complaints, bug reports, or praise for these benchmarks.</p>"},{"location":"aurora/node-performance-overview/node-performance-overview/#micro-benchmarks","title":"Micro-benchmarks","text":"One Tile Full Node Scaling Single Precision Peak Flops 23 TFlop/s 267 TFlop/s 11.8 Double Precision Peak Flops 17 TFlop/s 187 TFlop/s 10.9 Memory Bandwidth (triad) 1 TB/s 12 TB/s 11.9 PCIe Unidirectional Bandwidth (H2D) 54 GB/s 329 GB/s 6.1 PCIe Unidirectional Bandwidth (D2H) 55 GB/s 263 GB/s 4.8 PCIe Bidirectional Bandwidth 76 GB/s 357 GB/s 4.7 Tile2Tile Bidirectional Bandwidth 287 GB/s 2 TB/s 5.9 GPU2GPU Unidirectional Bandwidth 15 GB/s 95 GB/s 6.3 GPU2GPU Bidirectional Bandwidth 23 GB/s 142 GB/s 6.2"},{"location":"aurora/node-performance-overview/node-performance-overview/#benchmark-description","title":"Benchmark description","text":"<ul> <li>Double Precision Peak Flops: Chain of FMA.  (<code>flops.cpp</code>)</li> <li>Memory Bandwidth (triad): Triad, 2 loads, 1 store (<code>triad.cpp</code>)</li> <li>PCIe Unidirectional Bandwidth (H2D): Host to Device data transfer. (<code>pci.cpp</code>)</li> <li>PCIe Unidirectional Bandwidth (D2H): Device to Host data transfer.</li> <li>PCIe Bidirectional Bandwidth: Concurrent Host to Device and Device to Host data transfer.</li> <li>Tile2Tile Bidirectional Bandwidth: MPI Rank 0 (GPU N, Tile 0) will send a GPU buffer to Rank 1 (GPU N, Tile 1). Concurrently, Rank 1 will also send a buffer to Rank 0. (<code>peer2peer.cpp</code>)</li> <li>GPU2GPU Unidirectional Bandwidth: MPI Rank 0 (GPU 0, Tile 0) will send a GPU buffer to Rank 1 (GPU 1, Tile 0). (<code>peer2peer.cpp</code>)</li> <li>GPU2GPU Bidirectional Bandwidth: MPI Rank 0 (GPU 0, Tile 0) will send a GPU buffer to Rank 1 (GPU 1, Tile 0). Concurrently, Rank 1 will also send a buffer to Rank 0. (<code>peer2peer.cpp</code>)</li> </ul>"},{"location":"aurora/node-performance-overview/node-performance-overview/#tile2tile-unidirectional-bandwidth","title":"Tile2Tile unidirectional bandwidth","text":"<p>For this Tile2Tile Unidirectional Bandwidth test, MPI Rank 0 (GPU N, Tile 0) will send a GPU buffer to Rank 1 (GPU N, Tile 1). The bandwidth is higher for writes vs. reads, but the performance is roughly uniform among all possible combinations of tiles (excluding the case of two tiles on the same physical GPU, which has much higher overall bandwidth, with Read bandwidth &gt; Write bandwidth):</p> <pre><code>Detected 12 GPUs\n.......{WRITE} GPU 0 to GPU &lt;*&gt;.......\nGPU 0 -&gt; GPU 1: Bandwidth = 158.52 GB/s\nGPU 0 -&gt; GPU 2: Bandwidth = 18.8828 GB/s\nGPU 0 -&gt; GPU 3: Bandwidth = 18.9062 GB/s\nGPU 0 -&gt; GPU 4: Bandwidth = 18.9062 GB/s\nGPU 0 -&gt; GPU 5: Bandwidth = 18.8858 GB/s\nGPU 0 -&gt; GPU 6: Bandwidth = 18.9068 GB/s\nGPU 0 -&gt; GPU 7: Bandwidth = 18.887 GB/s\nGPU 0 -&gt; GPU 8: Bandwidth = 18.9071 GB/s\nGPU 0 -&gt; GPU 9: Bandwidth = 18.8874 GB/s\nGPU 0 -&gt; GPU 10: Bandwidth = 18.8833 GB/s\nGPU 0 -&gt; GPU 11: Bandwidth = 18.9067 GB/s\n.......{READ} GPU&lt;*&gt; to GPU 0.......\nGPU 1 -&gt; GPU 0: Bandwidth = 173.569 GB/s\nGPU 2 -&gt; GPU 0: Bandwidth = 15.779 GB/s\nGPU 3 -&gt; GPU 0: Bandwidth = 15.7959 GB/s\nGPU 4 -&gt; GPU 0: Bandwidth = 15.7963 GB/s\nGPU 5 -&gt; GPU 0: Bandwidth = 15.7815 GB/s\nGPU 6 -&gt; GPU 0: Bandwidth = 15.7963 GB/s\nGPU 7 -&gt; GPU 0: Bandwidth = 15.7821 GB/s\nGPU 8 -&gt; GPU 0: Bandwidth = 15.7971 GB/s\nGPU 9 -&gt; GPU 0: Bandwidth = 15.7821 GB/s\nGPU 10 -&gt; GPU 0: Bandwidth = 15.7795 GB/s\nGPU 11 -&gt; GPU 0: Bandwidth = 15.7961 GB/s\n</code></pre> <p>See the source code for this test: [<code>mpi_sycl_intranode_bw.cpp</code>](./src/mpi_sycl_intranode_bw.cpp]</p>"},{"location":"aurora/node-performance-overview/node-performance-overview/#gemm","title":"GEMM","text":"One Tile Full Node Scaling DGEMM 15 TFlop/s 179 TFlop/s 11.9 SGEMM 22 TFlop/s 258 TFlop/s 11.7 HGEMM 263 TFlop/s 2606 TFlop/s 9.9 BF16GEMM 273 TFlop/s 2645 TFlop/s 9.7 TF32GEMM 110 TFlop/s 1311 TFlop/s 11.9 I8GEMM 577 TFlop/s 5394 TFlop/s 9.4 <p>See the source code for this test: [<code>gemm.cpp</code>](./src/gemm.cpp]</p>"},{"location":"aurora/node-performance-overview/node-performance-overview/#fft","title":"FFT","text":"One Tile Full Node Scaling Single-precision FFT C2C 1D 3 TFlop/s 34 TFlop/s 10.8 Single-precision FFT C2C 2D 3 TFlop/s 35 TFlop/s 10.4 <p>See the source code for this test: [<code>fft2c.cpp</code>](./src/fft2c.cpp]</p>"},{"location":"aurora/performance-tools/","title":"Performance Tools Overview","text":""},{"location":"aurora/performance-tools/#light-weight-profiling-tools","title":"Light-weight profiling tools","text":"<ul> <li>THAPI/iprof</li> <li>Intel unitrace</li> <li>Intel xpu-smi</li> </ul>"},{"location":"aurora/performance-tools/#intel-analyzers","title":"Intel Analyzers","text":"<ul> <li>Intel VTune Profiler</li> <li>Intel Advisor</li> <li>Intel APS (Application Performance Snapshot)</li> </ul>"},{"location":"aurora/performance-tools/#community-tools","title":"Community tools","text":"<ul> <li>HPCToolkit at 2025 ALCF Hands-on HPC workshop</li> <li>TAU at 2025 ALCF Hands-on HPC workshop</li> </ul>"},{"location":"aurora/performance-tools/advisor/","title":"Advisor","text":""},{"location":"aurora/performance-tools/advisor/#introduction","title":"Introduction","text":"<p>Intel\u00ae Advisor is a design and analysis tool for developing performant code. The tool supports C, C++, Fortran, SYCL, OpenMP, OpenCL\u2122 code, and Python. It helps with the following:</p> <ul> <li>Performant CPU Code: Design your application for efficient threading, vectorization, and memory use.</li> <li>Efficient GPU Offload: Identify parts of the code that can be profitably offloaded. Optimize the code for compute and memory.</li> <li>Flow Graph Design and Analysis: Create, visualize, and analyze task and dependency computation for heterogeneous algorithms. </li> </ul>"},{"location":"aurora/performance-tools/advisor/#roofline-and-performance-insights-for-gpus","title":"Roofline and Performance Insights for GPUs","text":"<p>Get actionable advice for performant GPU code. In addition to the Roofline Analysis for kernels, you can:</p> <ul> <li>Get specific, actionable recommendations to design code that runs optimally on GPUs.</li> <li>See the CPU and GPU code performance side-by-side with a unified dashboard.</li> <li>Discover GPU application performance characterization, such as bandwidth sensitivity, instruction mix, and cache-line use.</li> </ul>"},{"location":"aurora/performance-tools/advisor/#offload-modeling","title":"Offload Modeling","text":"<p>Understand if your code benefits from GPU porting or how much performance acceleration your GPU code can get from moving to a next-generation GPU. You can:</p> <ul> <li>Pinpoint offload opportunities where it pays off the most.</li> <li>Project the performance on a GPU.</li> <li>Identify bottlenecks and potential performance gains.</li> <li>Get guidance for optimizing data transfer between host and target devices.</li> </ul>"},{"location":"aurora/performance-tools/advisor/#a-quick-instruction-for-advisor-roofline-analysis-on-intel-gpus","title":"A quick instruction for Advisor roofline analysis on Intel GPUs","text":"<p>Step 1: Setting the environments</p> <pre><code>$ module load oneapi\n$ export PRJ=&lt;your_project_dir&gt;\n</code></pre> <p>Step 2-a: Collecting the GPU Roofline data on a single GPU (Survey analysis and Trip Count with FLOP analysis)</p> <pre><code>$ advisor --collect=roofline --profile-gpu --project-dir=$PRJ -- &lt;your_executable&gt; &lt;your_arguments&gt;\n</code></pre> <p>Step 2-b: Collecting the GPU Roofline data on one of MPI ranks (Survey analysis and Trip Count with FLOP analysis)</p> <pre><code>$ mpirun -n 1 gpu_tile_compact.sh advisor --collect=survey --profile-gpu --project-dir=$PRJ -- &lt;your_executable&gt; &lt;your_arguments&gt; : -n 1 gpu_tile_compact.sh &lt;your_executable&gt; &lt;your_arguments&gt;\n$ mpirun -n 1 gpu_tile_compact.sh advisor --collect=tripcounts --profile-gpu --flop --no-trip-counts --project-dir=$PRJ -- &lt;your_executable&gt; &lt;your_arguments&gt; : -n 1 gpu_tile_compact.sh &lt;your_executable&gt; &lt;your_arguments&gt;\n</code></pre> <p>Step 3-a: Generate a GPU Roofline report, and then review the HTML report</p> <pre><code>$ advisor --report=all --project-dir=$PRJ --report-output=${PRJ}/roofline_all.html\n</code></pre> <p>Step 3-b: Download the project folder to your local system and open it with the stand-alone Advisor Client</p>"},{"location":"aurora/performance-tools/advisor/#simple-examples","title":"Simple examples","text":""},{"location":"aurora/performance-tools/advisor/#advisor-roofline-analysis-for-one-mpi-rank-out-of-12-mpi-ranks","title":"Advisor roofline analysis for one MPI rank out of 12 MPI ranks","text":"<pre><code>$ mpiexec -n 1 gpu_tile_compact.sh advisor --collect=survey --profile-gpu --project-dir=Advisor_results -- ./Comp_GeoSeries_omp_mpicxx_DP 2048 1000 : -n 11 gpu_tile_compact.sh ./Comp_GeoSeries_omp_mpicxx_DP 2048 1000\n$ mpiexec -n 1 gpu_tile_compact.sh advisor --collect=tripcounts --profile-gpu --flop --no-trip-counts --project-dir=Advisor_results -- ./Comp_GeoSeries_omp_mpicxx_DP 2048 1000 : -n 11 gpu_tile_compact.sh ./Comp_GeoSeries_omp_mpicxx_DP 2048 1000\n$ advisor --report=all --project-dir=Advisor_results --report-output=Advisor_results/roofline_all.html\n</code></pre> <p>Advisor HTML report with AMR-Wind application</p>"},{"location":"aurora/performance-tools/advisor/#references","title":"References","text":"<p>Intel Advisor User Guide</p> <p>Intel Advisor Performance Optimization Cookbook</p> <p>2025 ALCF INCITE Hackathon virtual week</p>"},{"location":"aurora/performance-tools/aps/","title":"Application Performance Snapshot","text":""},{"location":"aurora/performance-tools/aps/#introduction","title":"Introduction","text":"<p>Use Application Performance Snapshot for a quick scan of performance aspects that relate to compute-intensive applications:</p> <ul> <li>MPI usage</li> <li>OpenMP usage</li> <li>Intel\u00ae oneAPI Collective Communications Library (oneCCL) usage</li> <li>CPU/GPU usage</li> <li>Efficiency of memory access</li> <li>Vectorization</li> <li>I/O and memory footprint</li> </ul> <p>Application Performance Snapshot displays key optimization areas and suggests specialized tools for tuning particular performance aspects, such as Intel VTune Profiler and Intel\u00ae Advisor. You can run Application Performance Snapshot on large MPI workloads to analyze scalability issues. </p>"},{"location":"aurora/performance-tools/aps/#instruction","title":"Instruction","text":""},{"location":"aurora/performance-tools/aps/#loading-the-module","title":"Loading the module","text":"<pre><code>$ module load oneapi\n$ aps --version\nIntel(R) VTune(TM) Profiler 2025.0.1 (build 629235) Command Line Tool\nCopyright (C) 2009 Intel Corporation. All rights reserved.\n</code></pre>"},{"location":"aurora/performance-tools/aps/#usage-of-aps-and-aps-report","title":"Usage of <code>aps</code> and <code>aps-report</code>","text":"<pre><code>$ aps -h\nIntel(R) VTune(TM) Profiler 2025.0.1 (build 629235) Command Line Tool\nCopyright (C) 2009 Intel Corporation. All rights reserved.\nUsage: 1. aps [--result-dir=&lt;dir&gt; | -r=&lt;dir&gt;] [--start-paused] [--collection-mode=&lt;mode&gt; | -c=&lt;mode&gt;] &lt;app&gt;\n       2. &lt;mpi_launcher&gt; &lt;mpi_parameters&gt; aps [--result-dir=&lt;dir&gt; | -r=&lt;dir&gt;] [--collection-mode=&lt;mode&gt; | -c=&lt;mode&gt;] [--stat-level=&lt;0-5&gt; | -L &lt;0-5&gt;] [--mpi-imbalance=&lt;0-2&gt; | -I &lt;0-2&gt;] [--storage-format=&lt;format&gt; | -F &lt;format&gt;] &lt;app&gt;\n       3. aps --report | -O &lt;option&gt; &lt;dir&gt;\n       4. aps &lt;option&gt;\n1. Run analysis for an application or script &lt;app&gt; and store results in &lt;dir&gt;\n2. Run analysis for an MPI application &lt;app&gt; and store results in &lt;dir&gt;\n     --collection-mode=&lt;mode&gt;       Specify a comma separated list of data to collect. Possible values: hwc - hardware counters, omp - OpenMP statistics, mpi - MPI statistics, all - all possible data (default).\n     --start-paused                 \"Start data collection in the paused mode. Data collection resumes when the application calls __itt_resume or MPI_Pcontrol(1).\n     --stat-level                   Set MPI statistic collection level.\n     --mpi-imbalance                Set MPI imbalance collection mode.\n     --tmp-dir=&lt;path&gt;               Specify the directory path where temporary data (generated during the collection run) is saved.\n     --storage-format=&lt;format&gt;      Specify the trace format: simple (a small number of MPI ranks per node) or compact (numerous MPI ranks per node).\n3. Show analysis report based on data from &lt;dir&gt;\n     Tip: use\n       aps-report --help\n     to review report options. Additional details include statistics view by ranks, message sizes, collective operations, and communicators, as well as the ability to explore rank-to-rank and node-to-node communication statistics.\n4. Show additional product info. Where &lt;option&gt; can be:\n     --help, -h show this help and exit\n     --version show version information and exit\n\n\n\n\n$ aps-report -h\nUsage: aps-report [keys] [options] &lt;file-name(s)&gt;\n\nGeneral KEYS:\n  -h [ --help ]                         Show this help and exit.\n  -a [ --all ]                          Show all available diagrams.\n\nSpecific KEYS:\n  -s [ --summary ]                      Show Summary information. Default \n                                        option.\n  -g [ --html-summary ]                 Generate Summary HTML report file. \n                                        Default option. (See option '-H' to set\n                                        the file name.)\n  -o [ --counters ]                     Show Counters &amp; Memory usage \n                                        statistics.\n  -f [ --functions ]                    Show MPI Function Summary for all ranks\n                                        diagram. (Use Time filter. See '-T' \n                                        option.)\n  -t [ --mpi-time-per-rank ]            Show MPI Function Time per Rank \n                                        diagram. (Use Time filter. See '-T' \n                                        option.)\n  -m [ --message-sizes ]                Show Message Size diagram. (Use Time \n                                        filter. See '-T' option.)\n  -x [ --transfers-per-communication ]  Show Data Transfers per Communication \n                                        diagram. (Use Time filter. See '-T' \n                                        option.) Use -v option to generate Data\n                                        Transfers by volume, not by time (which\n                                        is the default value)\n  -e [ --transfers-per-rank ]           Show Data Transfers per Rank diagram. \n                                        (Use Volume filter. See '-V' option.)\n  -n [ --node-to-node ]                 Show Node-to-Node Transfers(MB)\n  -u [ --transfers-per-function ]       Show Data Transfers per Function \n                                        diagram. (Use Volume filter. See '-V' \n                                        option.)\n  -l [ --communicators-list ]           Show list of communicators used.\n  --node-topology                       Show the association between ranks, \n                                        nodes, and PCI devices in the collected\n                                        data.\n  --metrics arg                         Show the selected performance metrics \n                                        per node/rank. The metric names should \n                                        be separated using the comma. Use \n                                        --metrics=? to see the list of metrics \n                                        available for the selected result. The \n                                        special value \"all\" enables the display\n                                        of all available metrics. Example: \n                                        --metrics=\"Elapsed Time, Vectorization,\n                                        PCI\"\n  -j [ --itac-config ] arg              Generate specified Intel(R) Trace \n                                        Analyzer and Collector config. \n                                        Available config types are \"time\", \n                                        \"imbalance\", \"volume\". Use -N to \n                                        specify number of MPI functions in \n                                        config file.\n\nOPTIONS:\n  -R [ --rank ] arg                     Specify ranks to show in the report \n                                        (the list of ranks should be defined \n                                        using comma and dash separators, \n                                        example: -R 0,1,4,4-10).\n  --node arg                            Specify nodes to show in the report \n                                        (the list of nodes should be defined \n                                        using commas as separators, example: \n                                        --node=localhost,test1).\n  -X [ --comm-matrix-size ] arg         Show Communication matrix as a square \n                                        with specific dimensions. Applied to \n                                        '-x'.\n  -M [ --comm-id ] arg                  Show detailed info about collective \n                                        operations for specified communicator \n                                        ID. Applied to '-f'.\n  -D [ --details ]                      Show details for the ranks with \n                                        minimum, average, and maximum time \n                                        values from the selected diagram. For \n                                        Message Size diagram shows detailed \n                                        info about functions for each size. \n                                        Applied to the options '-t', '-c', '-f'\n                                        and '-m'.\n  -C [ --communicators ]                Shows additional information about \n                                        communicators for collective \n                                        operations. Applied to the options '-f'\n                                        and '-m -D'.\n  -E [ --internal-communicators ]       Shows information about internal IDs of\n                                        communicators provided by Intel(R) MPI.\n                                        Applied to '-l', '-f -C', '-m -D -C'.\n  -P [ --func-group ]                   Group data by function name. Applied to\n                                        the options '-m -D'.\n  -V [ --volume-threshold ] arg         Threshold for data volume in % from \n                                        total transferred volume. Lines with \n                                        volume less than the threshold will be \n                                        skipped. Set to 0 to disable the \n                                        filter. By default - 1%.\n  -T [ --time-threshold ] arg           Threshold for time in % from total \n                                        process lifetime. Lines with time less \n                                        than the threshold will be skipped. Set\n                                        to 0 to disable the filter. By default \n                                        - 1%.\n  --functions-filter arg                Gather statistics only for specified \n                                        MPI functions\n  -v [ --by-volume ]                    Show Data Transfers per Communication \n                                        diagram by volume\n  --format arg                          Generate file of specified format for \n                                        the diagram. Supported values: txt, \n                                        csv, html\n  -H [ --html-summary-file ] arg        Name of Summary HTML report file. By \n                                        default - 'aps_report_&lt;date&gt;_&lt;time&gt;.htm\n                                        l' in current folder.\n\n\nThe following environment variables are used:\n    APS_STAT_DIR_PREFIX    a string to define the base name for the results directory.\n                           By default, the results directory is \"stat\"\n\n    APS_STAT_DIR_POSTFIX   a string to define a postfix for the results directory name and _mpi postfix.\n                           The default value for the bundled version is _%D-%T, where:\n                           %D - current date in the format YYYYMMDD\n                           %T - current time in the format hhmmss\n                           These placeholders are supported by the Intel MPI Library only.\n    APS_STAT_FILE_PREFIX   a string to define the base name for statistics files.\n                           The default value is \"stat-\". Rank number and \".bin\" are added automatically.\n\nFILE-NAMES:\n  Path to the results directory or any statistics file inside the results directory.\n  Examples: `aps-report -t -D stat_20160923-141516`  -  APS parses this directory.\n            `aps-report -t -D stat-0.bin`  -  APS tries to recognize all stat* files in the current directory.\n</code></pre>"},{"location":"aurora/performance-tools/aps/#running-with-an-mpi-application","title":"Running with an MPI application","text":""},{"location":"aurora/performance-tools/aps/#collection-on-compute-nodes","title":"Collection on compute nodes","text":"<pre><code>$ mpirun &lt;mpi arguments&gt; aps -r &lt;aps_result_dir&gt; &lt;application&gt; &lt;args&gt;\n</code></pre>"},{"location":"aurora/performance-tools/aps/#html-report-generation","title":"HTML report generation","text":"<pre><code>$ aps --report &lt;aps_result_dir&gt;\n</code></pre>"},{"location":"aurora/performance-tools/aps/#simple-examples","title":"Simple examples","text":""},{"location":"aurora/performance-tools/aps/#aps-collection-for-amr-wind-application-with-48-mpi-ranks-on-four-aurora-nodes","title":"<code>aps</code> collection for <code>amr-wind</code> application with 48 MPI ranks on four Aurora nodes","text":""},{"location":"aurora/performance-tools/aps/#collection","title":"Collection","text":"<pre><code>$ mpirun -n 48 --ppn 12 gpu_tile_compact.sh aps -r aps_report_amr-wind_4N ../amr_wind abl_godunov_4N_ST100.inp \n==============================================================================\n                AMR-Wind (https://github.com/exawind/amr-wind)\n\n  AMR-Wind version :: v3.4.2\n  AMR-Wind Git SHA :: ed475a0533dfacf1fdff0b707518ccf99040d9f9\n  AMReX version    :: 25.04-9-g30a9768150c4\n\n...&lt;skipping application standard output&gt;...\n\nAMReX (25.04-9-g30a9768150c4) finalized\n\nIntel(R) VTune(TM) Profiler 2025.0.1 collection completed successfully. Use the \"aps --report /lus/flare/projects/Aurora_deployment/jkwack/JK_AT_Tools/Apps/amr-wind_v3.4.2/build_20250513/jk_test/aps_report_amr-wind_4N\" command to generate textual and HTML reports for the profiling session.\n</code></pre> <p>During the collection, the following warning can be ignored: <pre><code>vtune: Warning: EMON Collector Message: Warning: PMU counter(s) [FP0 FP1 FP2 ] is (are) already in use by other software and the data collected on these counter(s) may be incorrect\n</code></pre></p>"},{"location":"aurora/performance-tools/aps/#report","title":"Report","text":"<pre><code>$ aps --report /lus/flare/projects/Aurora_deployment/jkwack/JK_AT_Tools/Apps/amr-wind_v3.4.2/build_20250513/jk_test/aps_report_amr-wind_4N\n| Summary information\n|--------------------------------------------------------------------\n  Application                   : amr_wind\n  Report creation date          : 2025-05-19 00:39:10\n  Number of ranks               : 48\n  Ranks per node                : 12\n  HW Platform                   : Intel(R) Xeon(R) Processor code named Sapphirerapids\n  Frequency                     : 2.00 GHz\n  Logical core count per node   : 208\n  Collector type                : Event-based sampling driver,Event-based counting driver,User-mode sampling and tracing\n  Used statistics               : /lus/flare/projects/Aurora_deployment/jkwack/JK_AT_Tools/Apps/amr-wind_v3.4.2/build_20250513/jk_test/aps_report_amr-wind_4N\n|\n| Your application might underutilize the available logical CPU cores\n| because of insufficient parallel work, blocking on synchronization, or too much I/O. Perform function or source line-level profiling with tools like Intel(R) VTune(TM) Profiler to discover why the CPU is underutilized.\n|\n  Elapsed Time:                             867.22 s\n  SP GFLOPS:                                  0.00\n  DP GFLOPS:                                  0.01\n  Average CPU Frequency:                      4.80 GHz\n  IPC Rate:                                   1.65\n  GPU Accumulated Time:                    4732.36 s\n  MPI Time:                                 153.27 s            17.68% of Elapsed Time\n| Your application is MPI bound. This may be caused by high busy wait time\n| inside the library (imbalance), non-optimal communication schema or MPI\n| library settings. Explore the MPI Imbalance metric if it is available or use\n| MPI profiling tools like Intel(R) Trace Analyzer and Collector to explore\n| possible performance bottlenecks.\n| Some of the individual values contributing to this average metric are\n| statistical outliers that can significantly distort the average metric value.\n| They can also be a cause of performance degradation.\n| Please use --counters or --metrics=\"MPI Time\" reports for details.\n    MPI Imbalance:                            N/A*\n| * No information about MPI Imbalance time is available. Set APS_IMBALANCE_TYPE\n| to 1 or 2 to collect it.\n    Top 5 MPI functions (avg time):\n        MPI_Waitall:                        103.02 s            11.89% of Elapsed Time\n        MPI_Allreduce:                       22.22 s             2.56% of Elapsed Time\n        MPI_Isend:                           19.92 s             2.30% of Elapsed Time\n        MPI_Barrier:                          3.14 s             0.36% of Elapsed Time\n        MPI_Testall:                          1.46 s             0.17% of Elapsed Time\n  Physical Core Utilization:                106.67%\n  Average Physical Core Utilization:        110.96 out of 208 Physical Cores\n  GPU Stack Utilization:                     93.75%\n    XVE State:\n       Active:                               66.68%\n       Stalled:                              18.25%\n| Some of the individual values contributing to this average metric are\n| statistical outliers that can significantly distort the average metric value.\n| They can also be a cause of performance degradation.\n| Please use --counters or --metrics=\"XVE State: Stalled\" reports for details.\n       Idle:                                115.02%\n| A significant portion of GPU time is spent idle. This is usually caused by\n| imbalance or thread scheduling problems.\n| Some of the individual values contributing to this average metric are\n| statistical outliers that can significantly distort the average metric value.\n| They can also be a cause of performance degradation.\n| Please use --counters or --metrics=\"XVE State: Idle\" reports for details.\n  GPU Occupancy:                             72.47% of Peak Value\n| Some of the individual values contributing to this average metric are\n| statistical outliers that can significantly distort the average metric value.\n| They can also be a cause of performance degradation.\n| Please use --counters or --metrics=\"GPU Occupancy\" reports for details.\n  Memory Stalls:                             62.90% of Pipeline Slots\n| The metric value can indicate that a significant fraction of execution\n| pipeline slots could be stalled due to demand memory load and stores. See the\n| second level metrics to define if the application is cache- or DRAM-bound and\n| the NUMA efficiency. Use Intel(R) VTune(TM) Profiler Memory Access analysis to\n| review a detailed metric breakdown by memory hierarchy, memory bandwidth\n| information, and correlation by memory objects.\n    Cache Stalls:                            66.60% of Cycles\n| A significant proportion of cycles are spent on data fetches from cache. Use\n| Intel(R) VTune(TM) Profiler Memory Access analysis to see if accesses to L2 or\n| L3 cache are problematic and consider applying the same performance tuning as\n| you would for a cache-missing workload. This may include reducing the data\n| working set size, improving data access locality, blocking or partitioning the\n| working set to fit in the lower cache levels, or exploiting hardware\n| prefetchers.\n    DRAM Stalls:                              3.95% of Cycles\n    DRAM Bandwidth\n       Peak:                                426.75 GB/s\n       Average:                              16.41 GB/s\n       Bound:                                14.05%\n  Vectorization:                             30.22%\n     Instruction Mix:\n       SP FLOPs:                              0.00% of uOps\n       DP FLOPs:                              0.00% of uOps\n       Non-FP:                              200.00% of uOps\n     FP Arith/Mem Rd Instr. Ratio:            0.00\n     FP Arith/Mem Wr Instr. Ratio:            0.00\n Average PCI Bandwidth:\n   Average PCIe Bandwidth Usage by GPU:\n     Inbound PCIe Read:                     607.84 MB/s\n     Inbound PCIe Write:                   6826.98 MB/s\n   Average PCIe Bandwidth Usage by Network Controller Devices:\n     Inbound PCIe Read:                    6120.50 MB/s\n     Inbound PCIe Write:                   4131.81 MB/s\n Disk I/O Bound:                              0.94 s             0.11% of Elapsed Time\n      Disk read:                             153.1 KB\n      Disk write:                             50.1 GB\n Memory Footprint:\n Resident:\n       Per node:\n           Peak resident set size    :         8944.00 MB (node x4013c2s1b0n0)\n           Average resident set size :         8919.50 MB\n       Per rank:\n           Peak resident set size    :          906.00 MB (rank 24)\n           Average resident set size :          743.29 MB\n Virtual:\n       Per node:\n           Peak memory consumption    :     64187493.00 MB (node x4013c2s0b0n0)\n           Average memory consumption :     64186991.25 MB\n       Per rank:\n           Peak memory consumption    :      5349075.00 MB (rank 36)\n           Average memory consumption :      5348915.94 MB\n\nGraphical representation of this data is available in the HTML report: /lus/flare/projects/Aurora_deployment/jkwack/JK_AT_Tools/Apps/amr-wind_v3.4.2/build_20250513/jk_test/aps_report_20250519_004709.html\n</code></pre> <p>Download the HTML file and open it on a web browser.</p> <p> </p>"},{"location":"aurora/performance-tools/aps/#aps-report-cli-interface-for-the-details","title":"<code>aps-report</code> CLI interface for the details","text":"<pre><code>$ aps-report --metrics=? aps_report_amr-wind_4N/\n| Available Metrics:\n|--------------------\nElapsed Time\nMPI Time\nMPI Time\nMPI Imbalance\nMPI Hotspot 1 - MPI_Waitall\nMPI Hotspot 1 - MPI_Waitall\nMPI Hotspot 2 - MPI_Allreduce\nMPI Hotspot 2 - MPI_Allreduce\nMPI Hotspot 3 - MPI_Isend\nMPI Hotspot 3 - MPI_Isend\nMPI Hotspot 4 - MPI_Barrier\nMPI Hotspot 4 - MPI_Barrier\nMPI Hotspot 5 - MPI_Testall\nMPI Hotspot 5 - MPI_Testall\nDisk I/O Bound\nDisk I/O Bound\nDisk read\nDisk write\nResident Memory Usage per Rank\nResident Memory Usage per Node\nVirtual Memory Usage per Rank\nVirtual Memory Usage per Node\nInstructions Per Cycle Rate\nAverage CPU Frequency\nPhysical Core Utilization\nAverage Physical Core Utilization\nMemory Stalls\nCache Stalls\nDRAM Stalls\nAverage DRAM Bandwidth\nDRAM Bandwidth Peak\nDRAM Bandwidth Average\nDRAM Bandwidth Bound\nSP GFLOPS\nDP GFLOPS\nVectorization\nSP FLOPs\nDP FLOPs\nNon-FP\nFP Arith/Mem Rd Instr. Ratio\nFP Arith/Mem Wr Instr. Ratio\nGPU Accumulated Time\nGPU Stack Utilization\nXVE State: Active\nXVE State: Stalled\nXVE State: Idle\nGPU Occupancy\nGPU Inbound PCIe Read\nGPU Inbound PCIe Write\nGPU Outbound PCIe Read\nGPU Outbound PCIe Write\nNetwork Controller Inbound PCIe Read\nNetwork Controller Inbound PCIe Write\nNetwork Controller Outbound PCIe Read\nNetwork Controller Outbound PCIe Write\nInbound PCIe Read Per Device\nInbound PCIe Write Per Device\nOutbound PCIe Read Per Device\nOutbound PCIe Write Per Device\nGPU Accumulated Time Per Device\nGPU Stack Utilization Per Device\nXVE State: Active Per Device\nXVE State: Stalled Per Device\nXVE State: Idle Per Device\nGPU Occupancy Per Device\n\n\n$ aps-report --metrics=\"GPU Stack Utilization Per Device, OpenMP Offload Time, GPU Accumulated Time Per Device, MPI Time\" aps_report_amr-wind_4N\n| Metric Table%\n|--------------------------------------------------------------------------------------------------------------------------------\nMetric Name                                Node Name           Rank    Device Type      Device Name   Metric Value   Outlier Type\nMPI Time, s                            x4013c2s1b0n0             14            N/A              N/A        166.471           None\nMPI Time, s                            x4013c2s1b0n0             15            N/A              N/A        165.058           None\nMPI Time, s                            x4013c2s3b0n0             36            N/A              N/A        164.408           None\nMPI Time, s                            x4013c2s2b0n0             29            N/A              N/A        163.307           None\nMPI Time, s                            x4013c2s3b0n0             39            N/A              N/A        162.385           None\nMPI Time, s                            x4013c2s3b0n0             38            N/A              N/A        162.119           None\nMPI Time, s                            x4013c2s3b0n0             41            N/A              N/A        162.084           None\nMPI Time, s                            x4013c2s2b0n0             28            N/A              N/A        161.303           None\nMPI Time, s                            x4013c2s1b0n0             16            N/A              N/A        159.364           None\nMPI Time, s                            x4013c2s2b0n0             25            N/A              N/A          159.1           None\nMPI Time, s                            x4013c2s3b0n0             37            N/A              N/A        158.898           None\nMPI Time, s                            x4013c2s0b0n0              4            N/A              N/A        157.763           None\nMPI Time, s                            x4013c2s1b0n0             13            N/A              N/A        157.692           None\nMPI Time, s                            x4013c2s1b0n0             20            N/A              N/A        157.515           None\nMPI Time, s                            x4013c2s0b0n0              5            N/A              N/A        156.837           None\nMPI Time, s                            x4013c2s2b0n0             30            N/A              N/A        156.188           None\nMPI Time, s                            x4013c2s2b0n0             34            N/A              N/A        155.781           None\nMPI Time, s                            x4013c2s1b0n0             21            N/A              N/A        155.483           None\nMPI Time, s                            x4013c2s1b0n0             12            N/A              N/A        155.452           None\nMPI Time, s                            x4013c2s3b0n0             44            N/A              N/A        155.092           None\nMPI Time, s                            x4013c2s1b0n0             22            N/A              N/A        154.587           None\nMPI Time, s                            x4013c2s2b0n0             26            N/A              N/A        154.353           None\nMPI Time, s                            x4013c2s2b0n0             27            N/A              N/A        154.302           None\nMPI Time, s                            x4013c2s1b0n0             18            N/A              N/A        154.197           None\nMPI Time, s                            x4013c2s2b0n0             32            N/A              N/A        154.155           None\nMPI Time, s                            x4013c2s0b0n0              8            N/A              N/A        153.864           None\nMPI Time, s                            x4013c2s3b0n0             42            N/A              N/A        153.821           None\nMPI Time, s                            x4013c2s1b0n0             19            N/A              N/A        153.713           None\nMPI Time, s                            x4013c2s3b0n0             43            N/A              N/A        153.701           None\nMPI Time, s                            x4013c2s2b0n0             33            N/A              N/A        153.685           None\nMPI Time, s                            x4013c2s3b0n0             47            N/A              N/A        153.273           None\nMPI Time, s                            x4013c2s3b0n0             45            N/A              N/A         153.21           None\nMPI Time, s                            x4013c2s2b0n0             31            N/A              N/A        152.941           None\nMPI Time, s                            x4013c2s3b0n0             46            N/A              N/A         152.49           None\nMPI Time, s                            x4013c2s0b0n0              9            N/A              N/A        151.611           None\nMPI Time, s                            x4013c2s2b0n0             35            N/A              N/A         151.37           None\nMPI Time, s                            x4013c2s0b0n0              6            N/A              N/A         150.94           None\nMPI Time, s                            x4013c2s0b0n0              1            N/A              N/A        150.864           None\nMPI Time, s                            x4013c2s0b0n0              3            N/A              N/A        150.579           None\nMPI Time, s                            x4013c2s0b0n0              7            N/A              N/A        150.239           None\nMPI Time, s                            x4013c2s1b0n0             23            N/A              N/A        149.236           None\nMPI Time, s                            x4013c2s0b0n0             10            N/A              N/A        148.357           None\nMPI Time, s                            x4013c2s0b0n0             11            N/A              N/A        144.026           None\nMPI Time, s                            x4013c2s0b0n0              0            N/A              N/A        140.557           None\nMPI Time, s                            x4013c2s3b0n0             40            N/A              N/A        136.304           None\nMPI Time, s                            x4013c2s1b0n0             17            N/A              N/A        134.898           None\nMPI Time, s                            x4013c2s2b0n0             24            N/A              N/A        131.685           None\nMPI Time, s                            x4013c2s0b0n0              2            N/A              N/A        121.563      Statistic\nMPI Time, % of Elapsed Time            x4013c2s1b0n0             14            N/A              N/A        19.2067           None\nMPI Time, % of Elapsed Time            x4013c2s1b0n0             15            N/A              N/A        19.0436           None\nMPI Time, % of Elapsed Time            x4013c2s3b0n0             36            N/A              N/A        18.9743           None\nMPI Time, % of Elapsed Time            x4013c2s2b0n0             29            N/A              N/A        18.8438           None\nMPI Time, % of Elapsed Time            x4013c2s3b0n0             39            N/A              N/A        18.7408           None\nMPI Time, % of Elapsed Time            x4013c2s3b0n0             38            N/A              N/A        18.7101           None\nMPI Time, % of Elapsed Time            x4013c2s3b0n0             41            N/A              N/A        18.7061           None\nMPI Time, % of Elapsed Time            x4013c2s2b0n0             28            N/A              N/A        18.6125           None\nMPI Time, % of Elapsed Time            x4013c2s1b0n0             16            N/A              N/A        18.3867           None\nMPI Time, % of Elapsed Time            x4013c2s2b0n0             25            N/A              N/A        18.3583           None\nMPI Time, % of Elapsed Time            x4013c2s3b0n0             37            N/A              N/A        18.3384           None\nMPI Time, % of Elapsed Time            x4013c2s1b0n0             13            N/A              N/A        18.1938           None\nMPI Time, % of Elapsed Time            x4013c2s0b0n0              4            N/A              N/A        18.1918           None\nMPI Time, % of Elapsed Time            x4013c2s1b0n0             20            N/A              N/A        18.1733           None\nMPI Time, % of Elapsed Time            x4013c2s0b0n0              5            N/A              N/A        18.0851           None\nMPI Time, % of Elapsed Time            x4013c2s2b0n0             30            N/A              N/A        18.0223           None\nMPI Time, % of Elapsed Time            x4013c2s2b0n0             34            N/A              N/A        17.9754           None\nMPI Time, % of Elapsed Time            x4013c2s1b0n0             21            N/A              N/A        17.9389           None\nMPI Time, % of Elapsed Time            x4013c2s1b0n0             12            N/A              N/A        17.9353           None\nMPI Time, % of Elapsed Time            x4013c2s3b0n0             44            N/A              N/A        17.8991           None\nMPI Time, % of Elapsed Time            x4013c2s1b0n0             22            N/A              N/A        17.8356           None\nMPI Time, % of Elapsed Time            x4013c2s2b0n0             26            N/A              N/A        17.8105           None\nMPI Time, % of Elapsed Time            x4013c2s2b0n0             27            N/A              N/A        17.8047           None\nMPI Time, % of Elapsed Time            x4013c2s1b0n0             18            N/A              N/A        17.7905           None\nMPI Time, % of Elapsed Time            x4013c2s2b0n0             32            N/A              N/A        17.7878           None\nMPI Time, % of Elapsed Time            x4013c2s3b0n0             42            N/A              N/A        17.7524           None\nMPI Time, % of Elapsed Time            x4013c2s0b0n0              8            N/A              N/A        17.7422           None\nMPI Time, % of Elapsed Time            x4013c2s3b0n0             43            N/A              N/A        17.7386           None\nMPI Time, % of Elapsed Time            x4013c2s1b0n0             19            N/A              N/A        17.7347           None\nMPI Time, % of Elapsed Time            x4013c2s2b0n0             33            N/A              N/A        17.7335           None\nMPI Time, % of Elapsed Time            x4013c2s3b0n0             47            N/A              N/A        17.6892           None\nMPI Time, % of Elapsed Time            x4013c2s3b0n0             45            N/A              N/A        17.6819           None\nMPI Time, % of Elapsed Time            x4013c2s2b0n0             31            N/A              N/A        17.6477           None\nMPI Time, % of Elapsed Time            x4013c2s3b0n0             46            N/A              N/A        17.5988           None\nMPI Time, % of Elapsed Time            x4013c2s0b0n0              9            N/A              N/A        17.4825           None\nMPI Time, % of Elapsed Time            x4013c2s2b0n0             35            N/A              N/A        17.4664           None\nMPI Time, % of Elapsed Time            x4013c2s0b0n0              6            N/A              N/A        17.4051           None\nMPI Time, % of Elapsed Time            x4013c2s0b0n0              1            N/A              N/A        17.3963           None\nMPI Time, % of Elapsed Time            x4013c2s0b0n0              3            N/A              N/A        17.3635           None\nMPI Time, % of Elapsed Time            x4013c2s0b0n0              7            N/A              N/A        17.3243           None\nMPI Time, % of Elapsed Time            x4013c2s1b0n0             23            N/A              N/A        17.2182           None\nMPI Time, % of Elapsed Time            x4013c2s0b0n0             10            N/A              N/A        17.1073           None\nMPI Time, % of Elapsed Time            x4013c2s0b0n0             11            N/A              N/A        16.6078           None\nMPI Time, % of Elapsed Time            x4013c2s0b0n0              0            N/A              N/A        16.2078           None\nMPI Time, % of Elapsed Time            x4013c2s3b0n0             40            N/A              N/A        15.7308           None\nMPI Time, % of Elapsed Time            x4013c2s1b0n0             17            N/A              N/A        15.5639           None\nMPI Time, % of Elapsed Time            x4013c2s2b0n0             24            N/A              N/A        15.1949           None\nMPI Time, % of Elapsed Time            x4013c2s0b0n0              2            N/A              N/A        14.0176      Statistic\nGPU Accumulated Time Per Device, s     x4013c2s0b0n0            N/A            GPU    GPU 0 Stack 0        574.952           None\nGPU Accumulated Time Per Device, s     x4013c2s0b0n0            N/A            GPU    GPU 0 Stack 1        561.112           None\nGPU Accumulated Time Per Device, s     x4013c2s1b0n0            N/A            GPU    GPU 0 Stack 0        555.666           None\nGPU Accumulated Time Per Device, s     x4013c2s2b0n0            N/A            GPU    GPU 0 Stack 0        552.534           None\nGPU Accumulated Time Per Device, s     x4013c2s3b0n0            N/A            GPU    GPU 0 Stack 0        546.085           None\nGPU Accumulated Time Per Device, s     x4013c2s3b0n0            N/A            GPU    GPU 0 Stack 1        543.687           None\nGPU Accumulated Time Per Device, s     x4013c2s0b0n0            N/A            GPU    GPU 1 Stack 1        543.447           None\nGPU Accumulated Time Per Device, s     x4013c2s2b0n0            N/A            GPU    GPU 0 Stack 1        543.261           None\nGPU Accumulated Time Per Device, s     x4013c2s1b0n0            N/A            GPU    GPU 0 Stack 1        543.069           None\nGPU Accumulated Time Per Device, s     x4013c2s0b0n0            N/A            GPU    GPU 1 Stack 0        541.997           None\nGPU Accumulated Time Per Device, s     x4013c2s0b0n0            N/A            GPU    GPU 2 Stack 0        533.238           None\nGPU Accumulated Time Per Device, s     x4013c2s0b0n0            N/A            GPU    GPU 2 Stack 1        529.018           None\nGPU Accumulated Time Per Device, s     x4013c2s2b0n0            N/A            GPU    GPU 1 Stack 1        526.305           None\nGPU Accumulated Time Per Device, s     x4013c2s2b0n0            N/A            GPU    GPU 1 Stack 0        525.409           None\nGPU Accumulated Time Per Device, s     x4013c2s1b0n0            N/A            GPU    GPU 2 Stack 0        523.241           None\nGPU Accumulated Time Per Device, s     x4013c2s3b0n0            N/A            GPU    GPU 1 Stack 0        521.108           None\nGPU Accumulated Time Per Device, s     x4013c2s3b0n0            N/A            GPU    GPU 1 Stack 1         520.34           None\nGPU Accumulated Time Per Device, s     x4013c2s2b0n0            N/A            GPU    GPU 2 Stack 1        518.369           None\nGPU Accumulated Time Per Device, s     x4013c2s2b0n0            N/A            GPU    GPU 2 Stack 0         516.94           None\nGPU Accumulated Time Per Device, s     x4013c2s1b0n0            N/A            GPU    GPU 2 Stack 1        516.645           None\nGPU Accumulated Time Per Device, s     x4013c2s1b0n0            N/A            GPU    GPU 1 Stack 0        516.139           None\nGPU Accumulated Time Per Device, s     x4013c2s3b0n0            N/A            GPU    GPU 2 Stack 0        514.991           None\nGPU Accumulated Time Per Device, s     x4013c2s3b0n0            N/A            GPU    GPU 2 Stack 1        513.923           None\nGPU Accumulated Time Per Device, s     x4013c2s1b0n0            N/A            GPU    GPU 1 Stack 1         513.66           None\nGPU Accumulated Time Per Device, s     x4013c2s0b0n0            N/A            GPU    GPU 5 Stack 0        268.919           None\nGPU Accumulated Time Per Device, s     x4013c2s0b0n0            N/A            GPU    GPU 5 Stack 1        268.893           None\nGPU Accumulated Time Per Device, s     x4013c2s0b0n0            N/A            GPU    GPU 4 Stack 1        268.416           None\nGPU Accumulated Time Per Device, s     x4013c2s0b0n0            N/A            GPU    GPU 4 Stack 0        266.623           None\nGPU Accumulated Time Per Device, s     x4013c2s0b0n0            N/A            GPU    GPU 3 Stack 0        266.087           None\nGPU Accumulated Time Per Device, s     x4013c2s0b0n0            N/A            GPU    GPU 3 Stack 1        262.871           None\nGPU Accumulated Time Per Device, s     x4013c2s2b0n0            N/A            GPU    GPU 4 Stack 1        258.085           None\nGPU Accumulated Time Per Device, s     x4013c2s2b0n0            N/A            GPU    GPU 4 Stack 0        256.988           None\nGPU Accumulated Time Per Device, s     x4013c2s2b0n0            N/A            GPU    GPU 5 Stack 1         255.12           None\nGPU Accumulated Time Per Device, s     x4013c2s2b0n0            N/A            GPU    GPU 5 Stack 0        254.068           None\nGPU Accumulated Time Per Device, s     x4013c2s2b0n0            N/A            GPU    GPU 3 Stack 1        253.944           None\nGPU Accumulated Time Per Device, s     x4013c2s3b0n0            N/A            GPU    GPU 4 Stack 1        252.502           None\nGPU Accumulated Time Per Device, s     x4013c2s1b0n0            N/A            GPU    GPU 3 Stack 0        252.348           None\nGPU Accumulated Time Per Device, s     x4013c2s1b0n0            N/A            GPU    GPU 5 Stack 1        252.127           None\nGPU Accumulated Time Per Device, s     x4013c2s1b0n0            N/A            GPU    GPU 5 Stack 0        251.616           None\nGPU Accumulated Time Per Device, s     x4013c2s1b0n0            N/A            GPU    GPU 4 Stack 1        250.515           None\nGPU Accumulated Time Per Device, s     x4013c2s3b0n0            N/A            GPU    GPU 3 Stack 0        250.468           None\nGPU Accumulated Time Per Device, s     x4013c2s1b0n0            N/A            GPU    GPU 3 Stack 1        250.404           None\nGPU Accumulated Time Per Device, s     x4013c2s1b0n0            N/A            GPU    GPU 4 Stack 0         250.19           None\nGPU Accumulated Time Per Device, s     x4013c2s3b0n0            N/A            GPU    GPU 5 Stack 1        250.123           None\nGPU Accumulated Time Per Device, s     x4013c2s2b0n0            N/A            GPU    GPU 3 Stack 0        249.972           None\nGPU Accumulated Time Per Device, s     x4013c2s3b0n0            N/A            GPU    GPU 3 Stack 1        248.308           None\nGPU Accumulated Time Per Device, s     x4013c2s3b0n0            N/A            GPU    GPU 4 Stack 0        248.101           None\nGPU Accumulated Time Per Device, s     x4013c2s3b0n0            N/A            GPU    GPU 5 Stack 0        247.606           None\nGPU Stack Utilization Per Device, %    x4013c2s0b0n0            N/A            GPU    GPU 0 Stack 0          132.9           None\nGPU Stack Utilization Per Device, %    x4013c2s0b0n0            N/A            GPU    GPU 0 Stack 1          129.9           None\nGPU Stack Utilization Per Device, %    x4013c2s1b0n0            N/A            GPU    GPU 0 Stack 0          128.3           None\nGPU Stack Utilization Per Device, %    x4013c2s2b0n0            N/A            GPU    GPU 0 Stack 0          127.4           None\nGPU Stack Utilization Per Device, %    x4013c2s0b0n0            N/A            GPU    GPU 1 Stack 1          126.2           None\nGPU Stack Utilization Per Device, %    x4013c2s3b0n0            N/A            GPU    GPU 0 Stack 0          126.1           None\nGPU Stack Utilization Per Device, %    x4013c2s0b0n0            N/A            GPU    GPU 1 Stack 0          125.8           None\nGPU Stack Utilization Per Device, %    x4013c2s3b0n0            N/A            GPU    GPU 0 Stack 1          125.5           None\nGPU Stack Utilization Per Device, %    x4013c2s2b0n0            N/A            GPU    GPU 0 Stack 1          125.4           None\nGPU Stack Utilization Per Device, %    x4013c2s1b0n0            N/A            GPU    GPU 0 Stack 1          125.4           None\nGPU Stack Utilization Per Device, %    x4013c2s0b0n0            N/A            GPU    GPU 2 Stack 0          123.7           None\nGPU Stack Utilization Per Device, %    x4013c2s0b0n0            N/A            GPU    GPU 2 Stack 1          122.7           None\nGPU Stack Utilization Per Device, %    x4013c2s2b0n0            N/A            GPU    GPU 1 Stack 1          121.8           None\nGPU Stack Utilization Per Device, %    x4013c2s2b0n0            N/A            GPU    GPU 1 Stack 0          121.7           None\nGPU Stack Utilization Per Device, %    x4013c2s1b0n0            N/A            GPU    GPU 2 Stack 0          121.2           None\nGPU Stack Utilization Per Device, %    x4013c2s3b0n0            N/A            GPU    GPU 1 Stack 0          120.8           None\nGPU Stack Utilization Per Device, %    x4013c2s3b0n0            N/A            GPU    GPU 1 Stack 1          120.4           None\nGPU Stack Utilization Per Device, %    x4013c2s2b0n0            N/A            GPU    GPU 2 Stack 1            120           None\nGPU Stack Utilization Per Device, %    x4013c2s1b0n0            N/A            GPU    GPU 2 Stack 1          119.7           None\nGPU Stack Utilization Per Device, %    x4013c2s2b0n0            N/A            GPU    GPU 2 Stack 0          119.7           None\nGPU Stack Utilization Per Device, %    x4013c2s1b0n0            N/A            GPU    GPU 1 Stack 0          119.6           None\nGPU Stack Utilization Per Device, %    x4013c2s3b0n0            N/A            GPU    GPU 2 Stack 0          119.3           None\nGPU Stack Utilization Per Device, %    x4013c2s3b0n0            N/A            GPU    GPU 2 Stack 1            119           None\nGPU Stack Utilization Per Device, %    x4013c2s1b0n0            N/A            GPU    GPU 1 Stack 1          118.9           None\nGPU Stack Utilization Per Device, %    x4013c2s0b0n0            N/A            GPU    GPU 5 Stack 1           67.5      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s0b0n0            N/A            GPU    GPU 5 Stack 0           67.5      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s0b0n0            N/A            GPU    GPU 4 Stack 1           67.4      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s0b0n0            N/A            GPU    GPU 4 Stack 0           66.9      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s0b0n0            N/A            GPU    GPU 3 Stack 0           66.8      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s0b0n0            N/A            GPU    GPU 3 Stack 1             66      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s2b0n0            N/A            GPU    GPU 4 Stack 1           64.9      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s2b0n0            N/A            GPU    GPU 4 Stack 0           64.6      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s2b0n0            N/A            GPU    GPU 5 Stack 1           64.1      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s2b0n0            N/A            GPU    GPU 5 Stack 0           63.9      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s2b0n0            N/A            GPU    GPU 3 Stack 1           63.8      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s3b0n0            N/A            GPU    GPU 4 Stack 1           63.5      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s1b0n0            N/A            GPU    GPU 5 Stack 1           63.4      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s1b0n0            N/A            GPU    GPU 3 Stack 0           63.4      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s1b0n0            N/A            GPU    GPU 5 Stack 0           63.2      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s1b0n0            N/A            GPU    GPU 4 Stack 1             63      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s3b0n0            N/A            GPU    GPU 3 Stack 0             63      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s3b0n0            N/A            GPU    GPU 5 Stack 1           62.9      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s1b0n0            N/A            GPU    GPU 4 Stack 0           62.9      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s1b0n0            N/A            GPU    GPU 3 Stack 1           62.9      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s2b0n0            N/A            GPU    GPU 3 Stack 0           62.8      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s3b0n0            N/A            GPU    GPU 4 Stack 0           62.4      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s3b0n0            N/A            GPU    GPU 3 Stack 1           62.4      Threshold\nGPU Stack Utilization Per Device, %    x4013c2s3b0n0            N/A            GPU    GPU 5 Stack 0           62.2      Threshold\n</code></pre>"},{"location":"aurora/performance-tools/aps/#references","title":"References","text":"<p>Intel Application Performance Snapshot User's Guide</p> <p>2025 ALCF INCITE Hackathon virtual week</p>"},{"location":"aurora/performance-tools/iprof/","title":"THAPI/iprof","text":""},{"location":"aurora/performance-tools/iprof/#introduction","title":"Introduction","text":"<p>THAPI is a portable tracing infrastructure for heterogeneous computing applications with backends for OpenCL, L0, CUDA HIP, OPMT and MPI.  <code>iprof</code> is a wrapper around the OpenCL, Level Zero, and CUDA tracers. It gives aggregated profiling information.</p>"},{"location":"aurora/performance-tools/iprof/#instruction","title":"Instruction","text":""},{"location":"aurora/performance-tools/iprof/#loading-the-thapi-module","title":"Loading the THAPI module","text":"<pre><code>$ module load thapi\n$ iprof --version\nv0.0.12-23-g9f2ed86\n</code></pre>"},{"location":"aurora/performance-tools/iprof/#usage-of-iprof","title":"Usage of <code>iprof</code>","text":"<pre><code>$ iprof -h\nUsage: iprof [options] [--] [command]\n        --trace-output PATH          Define where the CTF trace will be saved.\n                                     Default: `$THAPI_HOME/thapi-traces/thapi--[trace-type][date]`\n                                     (`$THAPI_HOME` defaults to `$HOME`,\n                                      and `date` is formatted using ISO 8601 convention).\n        --analysis-output PATH       Define where the analysis output (summary, pretty printing, etc.) will be saved.\n                                     Default: printed to `stdout`.\n    -m, --tracing-mode MODE          Define the category of events to trace.\n                                     Values allowed: [\"minimal\", \"default\", \"full\"]\n                                     Default: default\n        --traced-ranks RANK          Select which MPI ranks will be traced.\n                                     Use -1 to trace all ranks.\n                                     Default: -1\n        --[no-]profile               Enable or disable device profiling.\n                                     Default: true\n        --[no-]analysis              Enable or disable analysis of the LTTng trace.\n                                     Default: true\n    -b, --backends BACKENDS          Select which backends to use and their grouping level.\n                                     Format: backend_name[:backend_level],...\n                                     Default: mpi:3,omp:2,cl:1,ze:1,cuda:1,hip:1\n        --[no-]archive               Enable or disable archive support.\n                                     Default: false\n    -r, --replay [PATH]              Replay traces for post-mortem analysis.\n                                     If `PATH` is omitted, it defaults to the newest trace in `$HOME/thapi-traces/`.\n    -t, --trace                      Pretty-print the LTTng trace.\n    -l, --timeline [PATH]            Dump the trace timeline to a binary file.\n                                     If `PATH` is omitted, defaults to `out.pftrace`.\n                                     Open with Perfetto: `https://ui.perfetto.dev/#!/viewer`.\n    -j, --json                       Output the tally in JSON format.\n    -e, --extended                   Print the tally for for each Hostname / Process / Thread / Device.\n    -k, --kernel-verbose             The tally will report kernels execution time with SIMD width and global/local sizes.\n        --max-name-size SIZE         Set the maximum allowed kernels name size.\n                                     Use -1 for no limit.\n                                     Default: 80\n    -s, --sample                     Enable counters sampling.\n        --metadata                   Display trace metadata.\n    -v, --version                    Print the Version String.\n    -h, --help                       Display this message.\n        --debug [LEVEL]              Set the debug level.\n                                     If `LEVEL` is omitted, it defaults to 1.\n                                     Default: 3\n                                                      __\nFor complaints, praises, or bug reports please use: &lt;(o )___\n   https://github.com/argonne-lcf/THAPI              ( ._&gt; /\n   or send email to {apl,bvideau}@anl.gov             `---'\n</code></pre>"},{"location":"aurora/performance-tools/iprof/#running-with-an-mpi-application","title":"Running with an MPI application","text":"<pre><code>$ mpirun &lt;mpi arguments&gt; iprof &lt;iprof arguments&gt; -- &lt;application excutable binary&gt; &lt;application arguments&gt;\n</code></pre>"},{"location":"aurora/performance-tools/iprof/#simple-examples","title":"Simple examples","text":""},{"location":"aurora/performance-tools/iprof/#iprof-for-amr-wind-application-with-24-mpi-ranks-on-two-aurora-nodes","title":"<code>iprof</code> for <code>amr-wind</code> application with 24 MPI ranks on two Aurora nodes","text":"<pre><code>$ mpirun -n 24 --ppn 12 gpu_tile_compact.sh iprof -- ../amr_wind abl_godunov.inp \n==============================================================================\n                AMR-Wind (https://github.com/exawind/amr-wind)\n\n  AMR-Wind version :: v3.4.2\n  AMR-Wind Git SHA :: ed475a0533dfacf1fdff0b707518ccf99040d9f9\n  AMReX version    :: 25.04-9-g30a9768150c4\n\n...&lt;skipping application standard output&gt;...\n\nAMReX (25.04-9-g30a9768150c4) finalized\nTHAPI: Trace location: /home/jkwack/thapi-traces/thapi_aggreg--2025-05-18T22:32:29-05:00\nBACKEND_MPI | 2 Hostnames | 24 Processes | 24 Threads | \n\n                  Name |     Time | Time(%) |  Calls |  Average |      Min |      Max |         \n         MPI_Allreduce |  2.15min |  35.78% |  21703 |   5.95ms |    145ns |    2.21s |         \n       MPI_Comm_create |  1.90min |  31.63% |    408 | 279.75ms |  35.80us |    6.51s |         \n              MPI_Init |  1.59min |  26.38% |     24 |    3.97s | 343.86ms |    7.21s |         \n           MPI_Waitall |   15.80s |   4.38% |  58360 | 270.78us |    193ns | 226.00ms |         \n         MPI_Allgather |    2.26s |   0.63% |     72 |  31.45ms |  29.37us | 182.51ms |         \n           MPI_Barrier |    2.14s |   0.59% |    120 |  17.82ms |  16.84us |  81.07ms |         \n             MPI_Bcast | 558.40ms |   0.15% |     48 |  11.63ms |  29.18us |  22.95ms |         \n           MPI_Testall | 430.25ms |   0.12% |  42384 |  10.15us |    125ns |   2.01ms |         \n            MPI_Reduce | 425.03ms |   0.12% |    336 |   1.26ms |   2.82us |  70.40ms |         \n          MPI_Finalize | 246.94ms |   0.07% |     24 |  10.29ms |   7.28ms |  17.41ms |         \n             MPI_Isend | 209.20ms |   0.06% | 173930 |   1.20us |    819ns | 535.44us |         \n          MPI_Comm_dup | 111.12ms |   0.03% |     24 |   4.63ms |  96.50us |   9.21ms |         \n             MPI_Irecv | 110.05ms |   0.03% | 173930 | 632.71ns |    137ns | 309.75us |         \nMPI_Type_create_struct |  26.75ms |   0.01% |     72 | 371.50us |   1.13us |   1.18ms |         \n   MPI_Type_contiguous |  25.81ms |   0.01% |     24 |   1.08ms |   1.01ms |   1.13ms |         \n   MPI_Comm_split_type |  24.47ms |   0.01% |     24 |   1.02ms | 970.41us |   1.07ms |         \n           MPI_Gatherv |  15.68ms |   0.00% |    552 |  28.40us |    387ns |   7.18ms |         \n        MPI_Allgatherv |   1.26ms |   0.00% |     24 |  52.31us |  47.35us |  62.52us |         \n         MPI_Comm_rank | 833.41us |   0.00% |   3342 | 249.38ns |    104ns |   7.03us |         \n         MPI_Comm_size | 761.44us |   0.00% |   2118 | 359.51ns |    112ns |   5.63us |         \n         MPI_Comm_free | 687.23us |   0.00% |     65 |  10.57us |    984ns |  83.16us |         \n        MPI_Comm_group | 505.78us |   0.00% |    745 | 678.90ns |    199ns |   1.99us |         \n        MPI_Group_free | 465.72us |   0.00% |   1153 | 403.92ns |    120ns |   4.80us |         \n        MPI_Group_incl | 384.95us |   0.00% |    408 | 943.50ns |    339ns |   8.11us |         \n             MPI_Wtime | 313.32us |   0.00% |   1056 | 296.70ns |    118ns |   3.01us |         \n         MPI_Type_free | 305.71us |   0.00% |     96 |   3.18us |    113ns |  15.24us |         \nMPI_Get_processor_name |  61.66us |   0.00% |     24 |   2.57us |   1.63us |   4.55us |         \n       MPI_Type_commit |  50.33us |   0.00% |     96 | 524.22ns |    119ns |   3.46us |         \n       MPI_Get_address |  30.23us |   0.00% |     72 | 419.89ns |    118ns |    843ns |         \n     MPI_Comm_get_attr |  25.78us |   0.00% |     24 |   1.07us |    722ns |   2.29us |         \n   MPI_Type_get_extent |  25.09us |   0.00% |     72 | 348.47ns |    127ns |    958ns |         \n      MPI_Query_thread |  23.46us |   0.00% |     24 | 977.71ns |    813ns |   1.50us |         \n       MPI_Initialized |  17.52us |   0.00% |     24 | 730.12ns |    325ns |   1.15us |         \n                 Total |  6.01min | 100.00% | 481378 |                                          \n\nBACKEND_ZE | 2 Hostnames | 24 Processes | 32 Threads | \n\n                               Name |     Time | Time(%) |   Calls |  Average |     Min |      Max |         \n                     zeModuleCreate |  1.65min |  93.53% |    1260 |  78.52ms | 88.01us |    2.94s |         \n      zeCommandListAppendMemoryCopy |    2.21s |   2.09% |  198146 |  11.16us |  4.65us |   1.99ms |         \n    zeCommandListAppendLaunchKernel |    1.83s |   1.73% |  229951 |   7.96us |  5.83us |   2.24ms |         \n             zeEventHostSynchronize |    1.63s |   1.54% |  213448 |   7.61us |   144ns |   1.83ms |         \n                   zeEventHostReset | 618.33ms |   0.58% |  427929 |   1.44us |   181ns |   1.29ms |         \n  zeCommandQueueExecuteCommandLists | 123.55ms |   0.12% |   80518 |   1.53us |  1.08us | 620.24us |         \n               zeMemGetAddressRange |  70.47ms |   0.07% |  441272 | 159.71ns |   122ns | 533.06us |         \n                     zeEventDestroy |  56.18ms |   0.05% |   98472 | 570.52ns |   137ns |   1.05ms |         \n     zexDriverImportExternalPointer |  52.44ms |   0.05% |      96 | 546.30us | 19.31us | 717.93us |         \n               zeKernelSetGroupSize |  38.86ms |   0.04% |  229951 | 169.00ns |   129ns | 313.42us |         \n                      zeEventCreate |  37.08ms |   0.04% |   98472 | 376.56ns |   224ns |  95.31us |         \n       zeCommandListCreateImmediate |  27.44ms |   0.03% |      72 | 381.06us | 64.80us |   1.00ms |         \n        zeContextMakeMemoryResident |  22.52ms |   0.02% |      96 | 234.57us |  5.69us | 749.01us |         \n                    zeModuleDestroy |  19.59ms |   0.02% |    1260 |  15.55us |  1.74us | 475.10us |         \n                 zeCommandListReset |  19.53ms |   0.02% |   80474 | 242.74ns |   182ns | 299.30us |         \n                   zeMemAllocDevice |  16.35ms |   0.02% |      96 | 170.36us | 14.93us | 331.10us |         \n                          zeMemFree |  16.34ms |   0.02% |     216 |  75.64us |  3.02us | 875.15us |         \n                 zeCommandListClose |  13.37ms |   0.01% |   80518 | 166.07ns |   130ns | 307.78us |         \n                     zeKernelCreate |  11.66ms |   0.01% |    4980 |   2.34us |   663ns |  22.81us |         \n                   zeMemAllocShared |   9.10ms |   0.01% |      72 | 126.33us | 23.36us | 280.39us |         \nzeDriverGetExtensionFunctionAddress |   4.02ms |   0.00% |     336 |  11.97us |   303ns | 257.23us |         \n               zeCommandQueueCreate |   4.02ms |   0.00% |      64 |  62.75us |  9.60us | 218.51us |         \n                    zeKernelDestroy |   3.22ms |   0.00% |    4980 | 646.74ns |   211ns |  23.05us |         \n                   zeContextDestroy |   1.74ms |   0.00% |      48 |  36.27us |   855ns | 241.75us |         \n                  zeEventPoolCreate |   1.30ms |   0.00% |      72 |  18.00us |  7.56us |  45.93us |         \n                     zeMemAllocHost |   1.12ms |   0.00% |      48 |  23.26us | 13.35us |  32.95us |         \n              zeDeviceGetSubDevices |   1.06ms |   0.00% |    2136 | 495.30ns |   149ns |   1.45us |         \n    zexDriverReleaseImportedPointer |   1.01ms |   0.00% |      96 |  10.53us |  5.00us |  24.42us |         \n                 zeEventPoolDestroy | 991.51us |   0.00% |      72 |  13.77us |  5.33us |  29.80us |         \n                zeCommandListCreate | 900.73us |   0.00% |      44 |  20.47us |  5.90us |  53.93us |         \n                zeMemCloseIpcHandle | 588.25us |   0.00% |      50 |  11.76us |  7.35us |  31.52us |         \n               zexMemOpenIpcHandles | 557.27us |   0.00% |      50 |  11.15us |  4.43us |  38.08us |         \n          zeKernelSetIndirectAccess | 459.64us |   0.00% |     996 | 461.48ns |   180ns |    931ns |         \n               zeCommandListDestroy | 417.36us |   0.00% |     116 |   3.60us |   785ns |  22.47us |         \n                        zeDeviceGet | 343.86us |   0.00% |     240 |   1.43us |   155ns |  35.11us |         \n            zeModuleBuildLogDestroy | 200.46us |   0.00% |     996 | 201.27ns |   133ns |    946ns |         \n                    zeContextCreate | 134.03us |   0.00% |      96 |   1.40us |   980ns |   1.97us |         \n                             zeInit | 109.94us |   0.00% |      96 |   1.15us |   487ns |   3.00us |         \n                zexMemGetIpcHandles | 104.26us |   0.00% |      16 |   6.52us |   829ns |  15.77us |         \n                        zeDriverGet |  85.08us |   0.00% |     168 | 506.40ns |   186ns |    949ns |         \n              zeDeviceGetRootDevice |  74.26us |   0.00% |     312 | 238.02ns |   111ns |    723ns |         \n              zeCommandQueueDestroy |  49.05us |   0.00% |      64 | 766.41ns |   384ns |   2.08us |         \n              zeDriverGetApiVersion |  12.64us |   0.00% |      24 | 526.54ns |   416ns |    674ns |         \n                  zeMemPutIpcHandle |   8.43us |   0.00% |       8 |   1.05us |   959ns |   1.23us |         \n                              Total |  1.76min | 100.00% | 2198427 |                                         \n\nDevice profiling | 2 Hostnames | 24 Processes | 24 Threads | 24 Devices | 24 Subdevices | \n\n                                                                            Name |     Time | Time(%) |  Calls |  Average |      Min |      Max |         \namrex::launch&lt;amrex::detail::Parallel[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 373.05ms |  20.68% |  69551 |   5.36us |   3.20us |  27.04us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 248.76ms |  13.79% |  35200 |   7.07us |   5.60us |  39.20us |         \n                                              zeCommandListAppendMemoryCopy(D2D) | 164.99ms |   9.15% |  80830 |   2.04us |    720ns |  11.04us |         \namrex::launch&lt;amrex::detail::Parallel[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 158.63ms |   8.79% |  23756 |   6.68us |   5.28us |  16.48us |         \namrex::ParallelFor&lt;256, amrex::mlndla[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 106.01ms |   5.88% |   6634 |  15.98us |  14.72us |  33.28us |         \namrex::ParallelFor&lt;256, amrex::MLPois[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  89.72ms |   4.97% |  14168 |   6.33us |   5.28us |  13.76us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  85.32ms |   4.73% |   4576 |  18.65us |   9.28us |  24.48us |         \n                                              zeCommandListAppendMemoryCopy(D2H) |  35.39ms |   1.96% |   8491 |   4.17us |   1.04us |  33.52us |         \namrex::ParallelFor&lt;256, int, amrex::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  31.76ms |   1.76% |   9521 |   3.34us |   1.60us |  19.84us |         \namrex::ParallelFor&lt;256, int, amrex::C[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  28.53ms |   1.58% |   7564 |   3.77us |   2.72us |  24.16us |         \n                                              zeCommandListAppendMemoryCopy(D2M) |  28.49ms |   1.58% |   2376 |  11.99us |   2.32us |  21.60us |         \namrex::launch&lt;256, amrex::ReduceOps&lt;a[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  27.39ms |   1.52% |   4150 |   6.60us |   3.20us |  15.52us |         \namrex::ParallelFor&lt;256, int, amrex::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  27.21ms |   1.51% |   6707 |   4.06us |   2.40us |  10.88us |         \namrex::ParallelFor&lt;256, amr_wind::FPl[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  20.01ms |   1.11% |    176 | 113.71us |  59.20us | 178.88us |         \namrex::ParallelFor&lt;256, int, amrex::a[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  19.48ms |   1.08% |   2629 |   7.41us |   4.32us |  15.52us |         \namrex::MLTensorOp::apply(int, int, am[...]nst::{lambda(sycl::_V1::nd_item&lt;2&gt;)#1} |  18.22ms |   1.01% |    936 |  19.47us |  18.24us |  26.24us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  16.09ms |   0.89% |   2234 |   7.20us |   4.32us |  14.40us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  15.37ms |   0.85% |   1521 |  10.11us |   4.64us |  18.40us |         \namrex::ParallelFor&lt;256, int, amrex::M[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  14.67ms |   0.81% |   2343 |   6.26us |   4.80us |  10.72us |         \namrex::ParallelFor&lt;256, amr_wind::FPl[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  14.25ms |   0.79% |    264 |  53.96us |  32.00us |  95.20us |         \namrex::ParallelFor&lt;256, amr_wind::Vel[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  12.80ms |   0.71% |     88 | 145.48us | 136.32us | 158.72us |         \namrex::ParallelFor&lt;256, int, amrex::A[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  12.54ms |   0.70% |   2848 |   4.40us |   3.52us |  11.20us |         \namrex::ParallelFor&lt;256, amrex::MLPois[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  12.42ms |   0.69% |   3387 |   3.67us |   2.40us |  15.52us |         \namrex::MLTensorOp::apply(int, int, am[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  12.17ms |   0.67% |    936 |  13.00us |  12.48us |  17.44us |         \n                                              zeCommandListAppendMemoryCopy(H2D) |  11.55ms |   0.64% | 105873 | 109.05ns |     80ns | 214.32us |         \namrex::ParallelFor&lt;256, int, amrex::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  10.76ms |   0.60% |   2565 |   4.20us |   2.88us |  11.36us |         \namrex::launch&lt;amrex::MLTensorOp::appl[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   9.51ms |   0.53% |    936 |  10.16us |   8.96us |  16.96us |         \n_ZTSZZN5amrex6launchILi256EZNS_9Reduc[...]lerEE_clES19_EUlNS17_7nd_itemILi1EEEE_ |   9.44ms |   0.52% |   1579 |   5.98us |   3.36us |  12.80us |         \namrex::ParallelFor&lt;256, amrex::GpuBnd[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   8.19ms |   0.45% |    768 |  10.67us |   7.20us |  17.76us |         \n_ZTSZZN5amrex6launchILi256EZNS_9Reduc[...]lerEE_clES1B_EUlNS19_7nd_itemILi1EEEE_ |   7.63ms |   0.42% |   1012 |   7.54us |   4.80us |  14.08us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   7.45ms |   0.41% |   1100 |   6.77us |   6.08us |  13.92us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   6.58ms |   0.36% |   1100 |   5.98us |   4.80us |  13.12us |         \namrex::launch&lt;amrex::detail::Parallel[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   6.48ms |   0.36% |    636 |  10.19us |   6.08us |  17.76us |         \namrex::ParallelFor&lt;256, int, PPM::Pre[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   6.24ms |   0.35% |    208 |  30.01us |  19.04us |  40.80us |         \namrex::launch&lt;256, amrex::ReduceOps&lt;a[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   6.20ms |   0.34% |    456 |  13.59us |   6.24us |  29.12us |         \namrex::ParallelFor&lt;256, int, amrex::a[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   5.62ms |   0.31% |    858 |   6.55us |   3.52us |  13.44us |         \namrex::ParallelFor&lt;256, amrex::GpuBnd[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   5.30ms |   0.29% |    576 |   9.20us |   8.00us |  14.40us |         \namrex::ParallelFor&lt;256, int, amrex::M[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   4.20ms |   0.23% |    912 |   4.60us |   4.16us |  10.72us |         \namrex::ParallelFor&lt;256, int, amrex::M[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   4.05ms |   0.22% |    936 |   4.33us |   3.04us |  20.80us |         \namrex::ParallelFor&lt;256, int, amrex::a[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   3.78ms |   0.21% |    520 |   7.26us |   6.08us |  32.64us |         \namrex::ParallelFor&lt;256, int, int, God[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   3.77ms |   0.21% |    208 |  18.12us |  14.08us |  21.60us |         \namrex::ParallelFor&lt;256, int, int, int[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   3.76ms |   0.21% |    208 |  18.09us |  13.92us |  22.40us |         \namrex::ParallelFor&lt;256, int, PPM::Pre[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   3.73ms |   0.21% |    104 |  35.87us |  32.80us |  40.80us |         \namrex::ParallelFor&lt;256, int, int, God[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   3.72ms |   0.21% |    208 |  17.87us |  13.92us |  21.76us |         \namrex::ParallelFor&lt;256, int, int, God[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   3.69ms |   0.20% |    208 |  17.75us |  13.92us |  21.28us |         \namrex::ParallelFor&lt;256, amr_wind::Vel[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   3.54ms |   0.20% |     88 |  40.24us |  39.20us |  43.04us |         \n_ZTSZZN5amrex6launchILi256EZNS_9Reduc[...]lerEE_clES1F_EUlNS1D_7nd_itemILi1EEEE_ |   3.10ms |   0.17% |    444 |   6.98us |   4.00us |  15.36us |         \namrex::ParallelFor&lt;256, int, amrex::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   2.90ms |   0.16% |    728 |   3.98us |   2.72us |  10.88us |         \namrex::ParallelFor&lt;256, int, Godunov:[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   2.90ms |   0.16% |    208 |  13.93us |  10.56us |  17.76us |         \namrex::ParallelFor&lt;256, int, Godunov:[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   2.88ms |   0.16% |    208 |  13.86us |  10.40us |  16.96us |         \namrex::ParallelFor&lt;256, int, Godunov:[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   2.63ms |   0.15% |    208 |  12.62us |   9.60us |  15.84us |         \namrex::ParallelFor&lt;256, amrex::GpuBnd[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   2.59ms |   0.14% |    312 |   8.30us |   7.04us |  13.60us |         \namrex::ParallelFor&lt;256, int, int, int[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   2.57ms |   0.14% |    104 |  24.75us |  23.68us |  28.32us |         \namrex::ParallelFor&lt;256, int, amrex::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   2.42ms |   0.13% |    448 |   5.40us |   1.44us |  20.48us |         \namrex::ParallelFor&lt;256, int, amrex::I[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   2.33ms |   0.13% |    528 |   4.42us |   3.36us |  11.20us |         \namrex::ParallelFor&lt;256, amrex::MultiM[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   2.27ms |   0.13% |    552 |   4.12us |   1.60us |  20.16us |         \namrex::ParallelFor&lt;256, amrex::MLCell[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   2.22ms |   0.12% |    416 |   5.33us |   4.16us |  11.68us |         \namrex::ParallelFor&lt;256, int, amrex::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   2.18ms |   0.12% |    520 |   4.20us |   2.88us |  11.52us |         \n_ZTSZZN5amrex6launchILi256EZNS_9Reduc[...]lerEE_clES1C_EUlNS1A_7nd_itemILi1EEEE_ |   2.07ms |   0.11% |    474 |   4.36us |   3.36us |  14.88us |         \namrex::MLNodeLinOp::buildMasks()::{la[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.91ms |   0.11% |    168 |  11.36us |   4.16us |  33.60us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.90ms |   0.11% |    320 |   5.95us |   3.84us |  21.76us |         \namrex::ParallelFor&lt;256, int, amrex::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.82ms |   0.10% |    552 |   3.29us |   1.60us |  15.68us |         \namrex::launch&lt;amrex::detail::Parallel[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.74ms |   0.10% |    400 |   4.35us |   3.04us |  14.56us |         \namrex::ParallelFor&lt;256, int, amrex::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.48ms |   0.08% |    267 |   5.54us |   4.00us |  11.68us |         \namrex::ParallelFor&lt;256, Godunov::Comp[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.40ms |   0.08% |    104 |  13.44us |  12.48us |  19.04us |         \noneapi::mkl::rng::device::detail::ini[...]::mkl::rng::device::philox4x32x10&lt;1&gt; &gt; |   1.39ms |   0.08% |     24 |  58.11us |  56.48us |  59.84us |         \namrex::ParallelFor&lt;256, int, HydroUti[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.39ms |   0.08% |    208 |   6.67us |   5.76us |  10.40us |         \namrex::ParallelFor&lt;256, Godunov::Extr[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.34ms |   0.07% |    104 |  12.85us |  12.00us |  16.80us |         \namrex::ParallelFor&lt;256, int, HydroUti[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.30ms |   0.07% |    208 |   6.27us |   4.80us |  11.52us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.30ms |   0.07% |    104 |  12.50us |  11.68us |  18.24us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.23ms |   0.07% |    208 |   5.93us |   5.28us |  13.12us |         \namrex::ParallelFor&lt;256, amr_wind::pde[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.22ms |   0.07% |    208 |   5.86us |   5.28us |  11.68us |         \namrex::ParallelFor&lt;256, Godunov::Extr[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.19ms |   0.07% |    104 |  11.45us |  10.56us |  17.44us |         \namrex::ParallelFor&lt;256, int, amrex::D[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.19ms |   0.07% |    312 |   3.82us |   3.04us |  10.24us |         \namrex::ParallelFor&lt;256, Godunov::Extr[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.18ms |   0.07% |    104 |  11.38us |  10.24us |  17.44us |         \namrex::ParallelFor&lt;256, int, amrex::M[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.16ms |   0.06% |    312 |   3.71us |   2.88us |   9.92us |         \namrex::ParallelFor&lt;256, Godunov::Extr[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.16ms |   0.06% |    104 |  11.11us |  10.40us |  15.52us |         \namrex::ParallelFor&lt;256, amr_wind::pde[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.14ms |   0.06% |    208 |   5.50us |   4.96us |  11.20us |         \namrex::ParallelFor&lt;256, amrex::MLNode[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.14ms |   0.06% |    112 |  10.15us |   9.12us |  15.68us |         \namrex::ParallelFor&lt;256, int, amrex::B[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.10ms |   0.06% |    208 |   5.30us |   3.36us |  11.36us |         \namrex::ParallelFor&lt;256, int, HydroUti[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.07ms |   0.06% |    208 |   5.14us |   4.16us |  10.88us |         \namrex::ParallelFor&lt;256, int, HydroUti[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.07ms |   0.06% |    208 |   5.13us |   4.16us |  10.72us |         \namrex::ParallelFor&lt;256, amr_wind::pde[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.05ms |   0.06% |    208 |   5.05us |   4.48us |  11.04us |         \namrex::ParallelFor&lt;256, amr_wind::pde[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |   1.04ms |   0.06% |    208 |   4.98us |   4.48us |  10.72us |         \namrex::ParallelFor&lt;256, Godunov::Extr[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 992.64us |   0.06% |    104 |   9.54us |   7.84us |  17.44us |         \namrex::ParallelFor&lt;256, Godunov::Extr[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 945.60us |   0.05% |    104 |   9.09us |   8.00us |  15.36us |         \namrex::ParallelFor&lt;256, diffusion::fi[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 926.24us |   0.05% |    260 |   3.56us |   3.04us |   9.28us |         \namrex::(anonymous namespace)::MLNodeL[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 912.64us |   0.05% |    126 |   7.24us |   3.52us |  13.60us |         \namrex::ParallelFor&lt;256, diffusion::fi[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 882.72us |   0.05% |    260 |   3.40us |   2.88us |   9.92us |         \n_ZTSZZN5amrex6launchILi256EZNS_9Reduc[...]lerEE_clES18_EUlNS16_7nd_itemILi1EEEE_ | 882.08us |   0.05% |     88 |  10.02us |   8.80us |  15.52us |         \n_ZTSZZN5amrex6launchILi256EZNS_9Reduc[...]lerEE_clES18_EUlNS16_7nd_itemILi1EEEE_ | 856.16us |   0.05% |     88 |   9.73us |   8.96us |  16.48us |         \namrex::computeDivergence(amrex::Multi[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 851.04us |   0.05% |    104 |   8.18us |   7.36us |  14.08us |         \namrex::ParallelFor&lt;256, amr_wind::fvm[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 816.32us |   0.05% |    104 |   7.85us |   5.92us |  11.84us |         \namrex::ParallelFor&lt;256, amr_wind::ABL[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 804.16us |   0.04% |    156 |   5.15us |   4.16us |  11.04us |         \namrex::ParallelFor&lt;256, Godunov::Extr[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 758.08us |   0.04% |    104 |   7.29us |   6.08us |  10.24us |         \namrex::ParallelFor&lt;256, amr_wind::ABL[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 754.40us |   0.04% |    104 |   7.25us |   5.12us |  12.64us |         \namrex::ParallelFor&lt;256, amr_wind::tra[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 734.88us |   0.04% |    208 |   3.53us |   3.04us |   9.60us |         \namrex::ParallelFor&lt;256, int, amrex::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 721.12us |   0.04% |    168 |   4.29us |   1.92us |  20.00us |         \namrex::ParallelFor&lt;256, amr_wind::tra[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 717.28us |   0.04% |    208 |   3.45us |   3.04us |   9.28us |         \namrex::ParallelFor&lt;256, amrex::OwnerM[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 717.12us |   0.04% |    126 |   5.69us |   1.44us |  11.52us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 714.72us |   0.04% |     88 |   8.12us |   7.52us |  12.16us |         \namrex::MLPoissonT&lt;amrex::MultiFab&gt;::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 685.60us |   0.04% |    104 |   6.59us |   5.76us |  12.64us |         \namrex::ParallelFor&lt;256, int, amrex::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 684.96us |   0.04% |    104 |   6.59us |   5.92us |  10.24us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 673.44us |   0.04% |    104 |   6.48us |   5.76us |  12.80us |         \namrex::MLPoissonT&lt;amrex::MultiFab&gt;::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 669.76us |   0.04% |    104 |   6.44us |   5.60us |  12.48us |         \namrex::MLPoissonT&lt;amrex::MultiFab&gt;::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 665.92us |   0.04% |    104 |   6.40us |   5.44us |  12.32us |         \namrex::ParallelFor&lt;256, amrex::MLNode[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 644.64us |   0.04% |    112 |   5.76us |   5.12us |  11.36us |         \namrex::ParallelFor&lt;256, amrex::MLNode[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 641.28us |   0.04% |    112 |   5.73us |   4.96us |  11.52us |         \namrex::ParallelFor&lt;256, int, amrex::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 633.76us |   0.04% |    192 |   3.30us |   3.04us |   9.60us |         \namrex::launch&lt;amrex::detail::Parallel[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 631.68us |   0.04% |    112 |   5.64us |   4.48us |  12.16us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 614.72us |   0.03% |    104 |   5.91us |   5.12us |  11.68us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 612.80us |   0.03% |     65 |   9.43us |   5.76us |  12.80us |         \namrex::ParallelFor&lt;256, amrex::MLCell[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 593.44us |   0.03% |    104 |   5.71us |   4.64us |  11.68us |         \namrex::launch&lt;amrex::detail::Parallel[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 589.44us |   0.03% |    112 |   5.26us |   4.16us |  11.84us |         \namrex::ParallelFor&lt;256, amr_wind::Fix[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 526.56us |   0.03% |    104 |   5.06us |   3.52us |  11.36us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 515.04us |   0.03% |    104 |   4.95us |   4.16us |  10.88us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 501.92us |   0.03% |    104 |   4.83us |   4.00us |  10.88us |         \namrex::ParallelFor&lt;256, int, amrex::e[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 489.92us |   0.03% |    104 |   4.71us |   3.84us |  10.88us |         \namrex::ParallelFor&lt;256, int, incflo::[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 466.56us |   0.03% |     88 |   5.30us |   4.64us |  10.88us |         \namrex::ParallelFor&lt;256, int, amrex::M[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 457.76us |   0.03% |    112 |   4.09us |   3.36us |   9.92us |         \namrex::ParallelFor&lt;256, int, amrex::M[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 441.44us |   0.02% |    112 |   3.94us |   3.20us |   9.76us |         \namrex::ParallelFor&lt;256, int, amrex::F[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 427.04us |   0.02% |    134 |   3.19us |   2.88us |   9.44us |         \namrex::ParallelFor&lt;256, incflo::Apply[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 403.36us |   0.02% |     88 |   4.58us |   3.84us |  10.08us |         \namrex::ParallelFor&lt;256, amr_wind::fvm[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 365.28us |   0.02% |     52 |   7.02us |   5.76us |  13.12us |         \namrex::ParallelFor&lt;256, amr_wind::fvm[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 364.00us |   0.02% |     52 |   7.00us |   5.76us |  12.32us |         \namrex::ParallelFor&lt;256, amrex::mlndla[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 316.64us |   0.02% |     56 |   5.65us |   4.16us |  12.64us |         \namrex::ParallelFor&lt;256, unsigned long[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 313.92us |   0.02% |     48 |   6.54us |   1.28us |   8.32us |         \namrex::ParallelFor&lt;256, amrex::mlndla[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 311.20us |   0.02% |     56 |   5.56us |   4.64us |  11.36us |         \namrex::launch&lt;amrex::detail::Parallel[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 249.12us |   0.01% |     56 |   4.45us |   3.52us |  11.68us |         \namrex::ParallelFor&lt;256, int, amrex::S[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 187.52us |   0.01% |     24 |   7.81us |   6.40us |  10.56us |         \namrex::launch&lt;amrex::detail::Parallel[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 177.60us |   0.01% |     48 |   3.70us |   2.72us |  11.36us |         \namrex::ParallelFor&lt;256, int, incflo::[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 165.44us |   0.01% |     24 |   6.89us |   4.64us |  11.20us |         \n                                              zeCommandListAppendMemoryCopy(M2D) | 162.64us |   0.01% |    576 | 282.36ns |     80ns |   6.48us |         \namrex::ParallelFor&lt;256, incflo::Apply[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 146.08us |   0.01% |     24 |   6.09us |   3.84us |  10.08us |         \n_ZTSZZN5amrex6launchILi256EZNS_9Reduc[...]lerEE_clES18_EUlNS16_7nd_itemILi1EEEE_ | 105.76us |   0.01% |      8 |  13.22us |  12.96us |  13.44us |         \namrex::ParallelFor&lt;256, amr_wind::ABL[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} | 105.76us |   0.01% |      8 |  13.22us |  12.96us |  13.60us |         \n_ZTSZZN5amrex6launchILi256EZNS_9Reduc[...]lerEE_clES18_EUlNS16_7nd_itemILi1EEEE_ | 102.56us |   0.01% |      8 |  12.82us |  12.16us |  13.44us |         \namrex::ParallelFor&lt;256, amr_wind::ABL[...]nst::{lambda(sycl::_V1::nd_item&lt;1&gt;)#1} |  88.00us |   0.00% |      8 |  11.00us |  10.40us |  11.68us |         \n                                                                           Total |    1.80s | 100.00% | 428097 |                                          \n\nExplicit memory traffic (BACKEND_MPI) | 2 Hostnames | 24 Processes | 24 Threads | \n\n         Name |     Byte | Byte(%) |  Calls | Average | Min |     Max |         \n    MPI_Irecv | 983.52MB |  49.96% | 173930 |  5.65kB | 32B | 82.94kB |         \n    MPI_Isend | 983.52MB |  49.96% | 173930 |  5.65kB | 32B | 82.94kB |         \nMPI_Allreduce |   1.51MB |   0.08% |  21703 |  69.43B |  8B |  1.15kB |         \n    MPI_Bcast |  70.90kB |   0.00% |     48 |  1.48kB |  8B |  2.95kB |         \n   MPI_Reduce |   4.22kB |   0.00% |    336 |  12.57B |  8B |     16B |         \n        Total |   1.97GB | 100.00% | 369947 |                                   \n\nExplicit memory traffic (BACKEND_ZE) | 2 Hostnames | 24 Processes | 24 Threads | \n\n                              Name |     Byte | Byte(%) |  Calls | Average |  Min |     Max |         \n       zeContextMakeMemoryResident |   1.24TB |  99.90% |     96 | 12.89GB |   1B | 51.54GB |         \nzeCommandListAppendMemoryCopy(D2D) | 916.67MB |   0.07% |  80830 | 11.34kB |  72B | 82.94kB |         \nzeCommandListAppendMemoryCopy(H2D) | 224.00MB |   0.02% | 105873 |  2.12kB |  24B |  5.69kB |         \nzeCommandListAppendMemoryCopy(D2H) |  68.51MB |   0.01% |   8491 |  8.07kB |   8B |  1.33MB |         \nzeCommandListAppendMemoryCopy(D2M) |   1.32MB |   0.00% |   2376 | 554.67B | 384B |  1.15kB |         \nzeCommandListAppendMemoryCopy(M2D) |  29.95kB |   0.00% |    576 |  52.00B |  24B |    144B |         \n                             Total |   1.24TB | 100.00% | 198242 |                                    \n</code></pre>"},{"location":"aurora/performance-tools/iprof/#iprof-trace-timeline-view","title":"<code>iprof</code> trace timeline view","text":"<pre><code>$ mpirun -n 24 --ppn 12 gpu_tile_compact.sh iprof -l -- ../amr_wind abl_godunov.inp \n==============================================================================\n                AMR-Wind (https://github.com/exawind/amr-wind)\n\n  AMR-Wind version :: v3.4.2\n  AMR-Wind Git SHA :: ed475a0533dfacf1fdff0b707518ccf99040d9f9\n  AMReX version    :: 25.04-9-g30a9768150c4\n\n...&lt;skipping application standard output&gt;...\n\n\nAMReX (25.04-9-g30a9768150c4) finalized\nTHAPI: Trace location: /home/jkwack/thapi-traces/thapi_interval--2025-05-18T22:37:27-05:00\nTHAPI: Perfetto trace location: out.pftrace\n</code></pre> <p>Download <code>out.pftrace</code> and open it with Perfetto </p> <p> </p> <p></p>"},{"location":"aurora/performance-tools/iprof/#references","title":"References","text":"<p>THAPI github repository 2025 ALCF INCITE Hackathon virtual week</p>"},{"location":"aurora/performance-tools/unitrace/","title":"Unified Tracing and Profiling Tool","text":""},{"location":"aurora/performance-tools/unitrace/#introduction","title":"Introduction","text":"<p>This a performance tool for Intel(R) oneAPI applications. It traces and profiles host/device activities, interactions and hardware utilizations for Intel(R) GPU applications.</p>"},{"location":"aurora/performance-tools/unitrace/#features","title":"Features","text":"<ul> <li>Level Zero (L0) or Level Zero + OpenCL tracking/profiling</li> <li>Host activities</li> <li>Device and kernel activities</li> <li>Trace and profile layers (e.g., MPI, SYCL, CCL, oneDNN) above L0/OpenCL</li> <li>Categorizing GPU kernels</li> <li>Profile hardware performance metrics</li> </ul>"},{"location":"aurora/performance-tools/unitrace/#instruction","title":"Instruction","text":""},{"location":"aurora/performance-tools/unitrace/#loading-the-module","title":"Loading the module","text":"<pre><code>$ module load pti-gpu\n$ unitrace --version\n2.1.2 (31dd08753125943b26475cec6a489b7c52c064dd)\n</code></pre>"},{"location":"aurora/performance-tools/unitrace/#usage-of-unitrace","title":"Usage of <code>unitrace</code>","text":"<pre><code>$ unitrace --help\nUsage: unitrace [options] &lt;application&gt; &lt;args&gt;\nOptions:\n--call-logging [-c]            Trace host API calls\n--host-timing  [-h]            Report host API execution time\n--device-timing [-d]           Report kernels execution time\n--ccl-summary-report [-r]      Report CCL execution time summary\n--kernel-submission [-s]       Report append (queued), submit and execute intervals for kernels\n--device-timeline [-t]         Report device timeline\n--opencl                       Trace OpenCL\n--chrome-mpi-logging           Trace MPI\n--chrome-sycl-logging          Trace SYCL runtime and plugin\n--chrome-ccl-logging           Trace oneCCL\n--chrome-dnn-logging           Trace oneDNN\n--chrome-call-logging          Trace Level Zero and/or OpenCL host calls\n--chrome-kernel-logging        Trace device and host kernel activities\n--chrome-device-logging        Trace device activities\n--chrome-itt-logging           Trace activities in applications instrumented using Intel(R) Instrumentation and Tracing Technology APIs\n--chrome-no-thread-on-device   Trace device activities without per-thread info.\n                               Device activities are traced per thread if this option is not present\n--chrome-no-engine-on-device   Trace device activities without per-Level-Zero-engine-or-OpenCL-queue info.\n                               Device activities are traced per Level-Zero engine or OpenCL queue if this option is not present\n--chrome-event-buffer-size &lt;number-of-events&gt;    Size of event buffer on host per host thread(default is -1 or unlimited)\n--chrome-device-timeline       DEPRECATED - use --chrome-kernel-logging instead\n--chrome-kernel-timeline       DEPRECATED - use --chrome-kernel-logging instead\n--chrome-device-stages         DEPRECATED - use --chrome-kernel-logging instead\n--verbose [-v]                 Enable verbose mode to show kernel shapes\n                               Kernel shapes are always enabled in timelines for Level Zero backend\n--demangle                     Demangle kernel names. For OpenCL backend only. Kernel names are always demangled for Level Zero backend\n--kernels-per-tile             DEPRECATED - use --separate-tiles instead\n--separate-tiles               Trace each tile separately in case of implicit scaling\n--tid                          Output TID in host API trace\n--pid                          Output PID in host API and device activity trace\n--output [-o] &lt;filename&gt;       Output profiling result to file\n--conditional-collection       Enable conditional collection\n--output-dir-path &lt;path&gt;       Output directory path for result files\n--metric-query [-q]            Query hardware metrics for each kernel instance is enabled for level-zero.\n--metric-sampling [-k]         Sample hardware performance metrics for each kernel instance in time-based mode\n--group [-g] &lt;metric-group&gt;    Hardware metric group (ComputeBasic by default)\n--sampling-interval [-i] &lt;interval&gt; Hardware performance metric sampling interval in us (default is 50 us) in time-based mode\n--device-list                  Print available devices\n--metric-list                  Print available metric groups and metrics\n--stall-sampling               Sample hardware execution unit stalls. Valid for Intel(R) Data Center GPU Max Series and later GPUs\n--ranks-to-sample &lt;ranks&gt;      MPI ranks to sample. The argument &lt;ranks&gt; is a list of comma separated MPI ranks\n--version                      Print version\n--help                         Show this help message and exit. Please refer to the README.md file for further details.\n</code></pre>"},{"location":"aurora/performance-tools/unitrace/#running-with-an-mpi-application","title":"Running with an MPI application","text":"<pre><code>$ mpirun &lt;mpi arguments&gt; unitrace [options] &lt;application&gt; &lt;args&gt;\n</code></pre>"},{"location":"aurora/performance-tools/unitrace/#simple-examples","title":"Simple examples","text":""},{"location":"aurora/performance-tools/unitrace/#unitrace-mpi-and-sycl-tracing-for-amr-wind-application-with-24-mpi-ranks-on-two-aurora-nodes","title":"<code>unitrace</code> MPI and SYCL tracing for <code>amr-wind</code> application with 24 MPI ranks on two Aurora nodes","text":"<pre><code>$ mpirun -n 24 --ppn 12 gpu_tile_compact.sh unitrace --chrome-mpi-logging --chrome-sycl-logging  ../amr_wind abl_godunov.inp  \n==============================================================================\n                AMR-Wind (https://github.com/exawind/amr-wind)\n\n  AMR-Wind version :: v3.4.2\n  AMR-Wind Git SHA :: ed475a0533dfacf1fdff0b707518ccf99040d9f9\n  AMReX version    :: 25.04-9-g30a9768150c4\n\n...&lt;skipping application standard output&gt;...\n\nAMReX (25.04-9-g30a9768150c4) finalized\n\n[INFO] Timeline is stored in amr_wind.31084.13.json\n[INFO] Timeline is stored in amr_wind.31085.14.json\n[INFO] Timeline is stored in amr_wind.31086.15.json\n[INFO] Timeline is stored in amr_wind.31088.17.json\n[INFO] Timeline is stored in amr_wind.31090.19.json\n[INFO] Timeline is stored in amr_wind.31096.21.json\n[INFO] Timeline is stored in amr_wind.31089.18.json\n[INFO] Timeline is stored in amr_wind.31091.20.json\n[INFO] Timeline is stored in amr_wind.31087.16.json\n[INFO] Timeline is stored in amr_wind.31099.22.json\n[INFO] Timeline is stored in amr_wind.31102.23.json\n[INFO] Timeline is stored in amr_wind.31083.12.json\n[INFO] Timeline is stored in amr_wind.66221.8.json\n[INFO] Timeline is stored in amr_wind.66271.10.json\n[INFO] Timeline is stored in amr_wind.66272.11.json\n[INFO] Timeline is stored in amr_wind.66270.9.json\n[INFO] Timeline is stored in amr_wind.66214.7.json\n[INFO] Timeline is stored in amr_wind.66209.2.json\n[INFO] Timeline is stored in amr_wind.66211.4.json\n[INFO] Timeline is stored in amr_wind.66208.1.json\n[INFO] Timeline is stored in amr_wind.66212.5.json\n[INFO] Timeline is stored in amr_wind.66213.6.json\n[INFO] Timeline is stored in amr_wind.66210.3.json\n[INFO] Timeline is stored in amr_wind.66207.0.json\n</code></pre> <p>Download json files and open them with Perfetto </p> <p> </p> <p></p>"},{"location":"aurora/performance-tools/unitrace/#references","title":"References","text":"<p>unitrace github repository 2025 ALCF INCITE Hackathon virtual week</p>"},{"location":"aurora/performance-tools/vtune/","title":"VTune","text":""},{"location":"aurora/performance-tools/vtune/#introduction","title":"Introduction","text":"<p>Intel VTune Profiler can be used to find and fix performance bottlenecks quickly. There are several options (i.e., GPU Hotspots analysis, GPU Offload analysis, and HPC Performance Characterization analysis) available for Intel CPUs and GPUs on Aurora.</p> <p>Intel\u00ae VTune\u2122 Profiler is a performance analysis tool for serial, multithreaded, GPU-accelerated applications. Use VTune Profiler to analyze your choice of algorithm. Identify potential benefits for your application on Intel CPUs and GPUs on Aurora.</p> <p>Use VTune Profiler to locate or determine:</p> <ul> <li>The most time-consuming (hot) functions in your application and/or on the whole system</li> <li>Sections of code that do not effectively utilize available processor time</li> <li>The best sections of code to optimize for sequential performance and for threaded performance</li> <li>Synchronization objects that affect the application performance</li> <li>Whether, where, and why your application spends time on input/output operations</li> <li>Whether your application is CPU or GPU bound and how effectively it offloads code to the GPU</li> <li>The performance impact of different synchronization methods, different numbers of threads, or different algorithms</li> <li>Thread activity and transitions</li> <li>Hardware-related issues in your code such as data sharing, cache misses, branch misprediction, and others</li> </ul>"},{"location":"aurora/performance-tools/vtune/#vtune-analysis-types-for-intel-gpus","title":"VTune analysis types for Intel GPUs","text":""},{"location":"aurora/performance-tools/vtune/#gpu-offload","title":"GPU offload","text":"<pre><code>vtune \u2013collect gpu-offload &lt;target&gt;\n</code></pre> <p>This analysis enables you to: * Identify how effectively your application uses SYCL, OpenMP, or OpenCL kernels and explore them further with GPU Compute/Media Hotspots analysis * Analyze execution of Intel Media SDK tasks over time * Explore GPU usage and analyze a software queue for GPU engines at each moment of time</p>"},{"location":"aurora/performance-tools/vtune/#gpu-computemedia-hotspots","title":"GPU Compute/Media Hotspots","text":"<pre><code>vtune \u2013collect gpu-hotspots &lt;target&gt;\n</code></pre> <p>Use the GPU Compute/Media Hotspots analysis to: * Explore GPU kernels with high GPU utilization, estimate the effectiveness of this utilization, identify possible reasons for stalls or low occupancy, and options. * Explore the performance of your application per selected GPU metrics over time. * Analyze the hottest SYCL* standards or OpenCL\u2122 kernels for inefficient kernel code algorithms or incorrect work item configuration.</p> <p>The GPU Compute/Media Hotspots analysis is a good next step if you have already run the GPU Offload analysis and identified: * a performance-critical kernel for further analysis and optimization; * a performance-critical kernel that is tightly connected with other kernels in the program and may slow down their performance.</p> <p>For source-level in-kernel profiling, applications should be built with -fdebug-info-for-profiling -gline-tables-only.</p>"},{"location":"aurora/performance-tools/vtune/#a-quick-instruction-for-vtune-analysis-on-intel-gpus","title":"A quick instruction for VTune analysis on Intel GPUs","text":"<p>GPU hotspots analysis can be used as the first step. Without special knobs, its overhead is minimal, and it provides useful performance data such as kernel time, instance count, SIMD width, EU Array active/stalled/idle ratio, EU occupancy, GPU barriers/atomic, and so on. The following are simple instructions on Intel GPUs:</p>"},{"location":"aurora/performance-tools/vtune/#running-an-application-with-vtune-on-intel-gpus","title":"Running an application with VTune on Intel GPUs","text":"<pre><code>module load oneapi\n\n### To run an application on a single stack of a GPU\nZE_AFFINITY_MASK=0.0 vtune -collect gpu-hotspots -r VTune_results_1S -- ./a.out\n\n### To run an application on two stacks of a single GPU\nZE_AFFINITY_MASK=0 vtune -collect gpu-hotspots -r VTune_results_2S -- ./a.out\n\n### To run an MPI application (e.g., 24 MPI ranks on two Aurora nodes)\nmpirun -n 24 gpu_tile_compact.sh vtune -collect gpu-hotspots -r VTune_results_MPI -- ./a.out\n\n### To run an MPI application with VTune on a select MPI (e.g., MPI rank 5 out of 24 ranks)\nmpirun -n 5 gpu_tile_compact.sh ./a.out : -n 1 gpu_tile_compact.sh vtune -collect gpu-hotspots -r VTune_results_MPI_5 -- ./a.out : -n 18 ./a.out \n</code></pre>"},{"location":"aurora/performance-tools/vtune/#checking-if-vtune-collection-is-successful-or-not","title":"Checking if VTune collection is successful or not","text":"<p>After successful VTune analysis, VTune provides Hottest GPU Computing Tasks with High Sampler Usage with non-zero data. The following is an example from a GeoSeries benchmark:</p> <pre><code>Hottest GPU Computing Tasks with High Sampler Usage\nComputing Task                                                                                                                         Total Time\n-------------------------------------------------------------------------------------------------------------------------------------  ----------\nComp_Geo(cl::sycl::queue, double*, double*, int, int)::{lambda(cl::sycl::handler&amp;)#1}::operator()(cl::sycl::handler&amp;) const::Comp_Geo      0.627s\nzeCommandListAppendMemoryCopy         \n</code></pre>"},{"location":"aurora/performance-tools/vtune/#after-collecting-the-performance-data-vtune-profiler-web-server-can-be-used-for-the-post-processing","title":"After collecting the performance data, VTune profiler web server can be used for the post-processing.","text":"<p>Step 1: Open a new terminal and log into an Aurora login node (no X11 forwarding required) <pre><code>ssh &lt;username&gt;@aurora.alcf.anl.gov\n</code></pre> Step 2: Start VTune server on an Aurora login node after loading the oneAPI module and setting the corresponding environmental variables for VTune <pre><code>module load oneapi\nvtune-backend --data-directory=&lt;location of precollected VTune results&gt;\n</code></pre> Step 3: Open a new terminal and login to the same login node on Step 2 (e.g., if Step 2 uses <code>aurora-uan-0009</code>, directly login to <code>aurora-uan-0009.aurora.alcf.anl.gov</code>) with SSH port forwarding enabled as follows: <pre><code>ssh -L 127.0.0.1:&lt;port printed by vtune-backend&gt;:127.0.0.1:&lt;port printed by vtune-backend&gt; &lt;username&gt;@aurora-uan-00xx.aurora.alcf.anl.gov\n</code></pre></p> <p>Step 4: Open the URL printed by VTune server in Firefox web browser on your local computer. For a security warning, click \"Advanced...\" and then \"Accept the Risk and Continue\".</p> <ul> <li> <p>Accept VTune server certificate: When you open VTune GUI, your web browser will complain about VTune self-signed certificate. You either need to tell the web browser to proceed or install the VTune server certificate on your client machine so that the browser trusts it. To install the certificate, note the path to the public part of the certificate printed by VTune server in the output, copy it to your client machine, and add it to the trusted certificates.</p> </li> <li> <p>Set the passphrase: When you run the server for the first time, the URL that it outputs contains a one-time token. When you open such a URL in the browser, VTune server prompts you to set a passphrase. Other users can't access your VTune server without knowing this passphrase. The hash of the passphrase will be persisted on the server. Also, a secure HTTP cookie will be stored in your browser so that you do not need to enter the passphrase each time you open VTune GUI.</p> </li> </ul> <p></p> <p></p>"},{"location":"aurora/performance-tools/vtune/#simple-examples","title":"Simple examples","text":""},{"location":"aurora/performance-tools/vtune/#vtune-gpu-offload-analysis","title":"VTune gpu-offload analysis","text":"<pre><code>mpiexec -n 12 gpu_tile_compact.sh vtune -collect gpu-offload -r VTune_gpu-offload ./Comp_GeoSeries_omp_mpicxx_DP 2048 1000\n</code></pre>"},{"location":"aurora/performance-tools/vtune/#vtune-gpu-hotspots-analysis","title":"VTune gpu-hotspots analysis","text":"<pre><code>mpiexec -n 12 gpu_tile_compact.sh vtune -collect gpu-hotspots -r VTune_gpu-hotspots ./Comp_GeoSeries_omp_mpicxx_DP 2048 1000\n</code></pre>"},{"location":"aurora/performance-tools/vtune/#vtune-instruction-count-analysis","title":"VTune instruction count analysis","text":"<pre><code>mpiexec -n 12 gpu_tile_compact.sh vtune -collect gpu-hotspots -knob characterization-mode=instruction-count -r VTune_inst-count ./Comp_GeoSeries_omp_mpicxx_DP 2048 1000\n</code></pre>"},{"location":"aurora/performance-tools/vtune/#vtune-source-analysis","title":"VTune source analysis","text":"<pre><code>mpiexec -n 12 gpu_tile_compact.sh vtune -collect gpu-hotspots -knob profiling-mode=source-analysis -r VTune_source ./Comp_GeoSeries_omp_mpicxx_DP 2048 1000\n</code></pre>"},{"location":"aurora/performance-tools/vtune/#vtune-memory-latency-analysis","title":"VTune memory latency analysis","text":"<pre><code>mpiexec -n 12 gpu_tile_compact.sh vtune -collect gpu-hotspots -knob profiling-mode=source-analysis -knob source-analysis=mem-latency -r VTune_mem-latency ./Comp_GeoSeries_omp_mpicxx_DP 2048 1000\n</code></pre>"},{"location":"aurora/performance-tools/vtune/#known-issues-and-workarounds","title":"Known issues and workarounds","text":"<ul> <li> <p><code>gpu-offload</code> analysis may hang with some applications. Workaround: add <code>-run-pass-thru=--perf-threads=none</code> to the VTune command line</p> </li> <li> <p>source analysis or memory latency analysis may return <code>Assertion failed: tool_gtpin_support:126: (buffer)</code>. If so, try a newer version of VTune with the following module: <pre><code>module use /soft/preview/components/vtune/2025.6.0.31/modulefiles\nmodule add vtune/2025.6\n</code></pre></p> </li> </ul>"},{"location":"aurora/performance-tools/vtune/#references","title":"References","text":"<p>Intel VTune Profiler User Guide</p> <p>Downloadable documents for VTune Profiler</p> <p>2025 ALCF INCITE Hackathon virtual week</p>"},{"location":"aurora/performance-tools/xpu-smi/","title":"XPU System Management Interface","text":""},{"location":"aurora/performance-tools/xpu-smi/#introduction","title":"Introduction","text":"<p>This a tool for monitoring and managing Intel data center GPUs and it is designed to simplify administration, maximize reliability and uptime, and improve utilization. Intel(R) XPU System Management Interface (XPU-SMI) is the daemon-less version of XPU Manager and it only provides the local interface.</p>"},{"location":"aurora/performance-tools/xpu-smi/#instruction","title":"Instruction","text":""},{"location":"aurora/performance-tools/xpu-smi/#loading-the-module","title":"Loading the module","text":"<pre><code>$ module load xpu-smi\n$ xpu-smi --version\nxpu-smiCLI:\n    Version: 1.2.39.20240906\n    Build ID: 11f3c29a\n\nService:\n    Version: 1.2.39.20240906\n    Build ID: 11f3c29a\n    Level Zero Version: 1.20.2\n</code></pre>"},{"location":"aurora/performance-tools/xpu-smi/#usage-of-xpu-smi","title":"Usage of <code>xpu-smi</code>","text":"<pre><code>$ xpu-smi -h\nIntel XPU System Management Interface -- v1.2\nIntel XPU System Management Interface provides the Intel datacenter GPU model. It can also be used to update the firmware.\nIntel XPU System Management Interface is based on Intel oneAPI Level Zero. Before using Intel XPU System Management Interface, the GPU driver and Intel oneAPI Level Zero should be installed rightly.\n\nSupported devcies:\n - Intel Data Center GPU\n\nUsage: xpu-smi [Options]\n  xpu-smi -v\n  xpu-smi -h\n  xpu-smi discovery\n\nOptions:\n  -h,--help                   Print this help message and exit\n  -v,--version                Display version information and exit.\n\nSubcommands:\n  discovery                   Discover the GPU devices installed on this machine and provide the device info.\n  topology                    Get the system topology.\n  diag                        Run some test suites to diagnose GPU.\n  health                      Get the GPU device component health status.\n  updatefw                    Update GPU firmware\n  config                      Get and change the GPU settings.\n  ps                          List status of processes.\n  vgpu                        Create and remove virtual GPUs in SRIOV configuration.\n  stats                       List the GPU statistics.\n  dump                        Dump device statistics data.\n  log                         Collect GPU debug logs.\n\n\n$ xpu-smi -h dump\nDump device statistics data.\n\nUsage: xpu-smi dump [Options]\n  xpu-smi dump -d [deviceIds] -t [deviceTileIds] -m [metricsIds] -i [timeInterval] -n [dumpTimes]\n  xpu-smi dump -d [pciBdfAddress] -t [deviceTileIds] -m [metricsIds] -i [timeInterval] -n [dumpTimes]\n\nOptions:\n  -h,--help                   Print this help message and exit\n  -j,--json                   Print result in JSON format\n\n  -d,--device                 The device IDs or PCI BDF addresses to query. The value of \"-1\" means all devices.\n  -t,--tile                   The device tile IDs to query. If the device has only one tile, this parameter should not be specified.\n  -m,--metrics                Metrics type to collect raw data, options. Separated by the comma.\n                              0. GPU Utilization (%), GPU active time of the elapsed time, per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              1. GPU Power (W), per tile or device.\n                              2. GPU Frequency (MHz), per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              3. GPU Core Temperature (Celsius Degree), per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              4. GPU Memory Temperature (Celsius Degree), per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              5. GPU Memory Utilization (%), per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              6. GPU Memory Read (kB/s), per tile or device. Device-level is the sum value of tiles for multi-tiles.\n                              7. GPU Memory Write (kB/s), per tile or device. Device-level is the sum value of tiles for multi-tiles.\n                              8. GPU Energy Consumed (J), per tile or device.\n                              9. GPU EU Array Active (%), the normalized sum of all cycles on all EUs that were spent actively executing instructions. Per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              10. GPU EU Array Stall (%), the normalized sum of all cycles on all EUs during which the EUs were stalled.\n                                  At least one thread is loaded, but the EU is stalled. Per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              11. GPU EU Array Idle (%), the normalized sum of all cycles on all cores when no threads were scheduled on a core. Per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              12. Reset Counter, per tile or device. Device-level is the sum value of tiles for multi-tiles.\n                              13. Programming Errors, per tile or device. Device-level is the sum value of tiles for multi-tiles.\n                              14. Driver Errors, per tile or device. Device-level is the sum value of tiles for multi-tiles.\n                              15. Cache Errors Correctable, per tile or device. Device-level is the sum value of tiles for multi-tiles.\n                              16. Cache Errors Uncorrectable, per tile or device. Device-level is the sum value of tiles for multi-tiles.\n                              17. GPU Memory Bandwidth Utilization (%), per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              18. GPU Memory Used (MiB), per tile or device. Device-level is the sum value of tiles for multi-tiles.\n                              19. PCIe Read (kB/s), per device.\n                              20. PCIe Write (kB/s), per device.\n                              21. Xe Link Throughput (kB/s), a list of tile-to-tile Xe Link throughput.\n                              22. Compute engine utilizations (%), per tile.\n                              23. Render engine utilizations (%), per tile.\n                              24. Media decoder engine utilizations (%), per tile.\n                              25. Media encoder engine utilizations (%), per tile.\n                              26. Copy engine utilizations (%), per tile.\n                              27. Media enhancement engine utilizations (%), per tile.\n                              28. 3D engine utilizations (%), per tile.\n                              29. GPU Memory Errors Correctable, per tile or device. Other non-compute correctable errors are also included. Device-level is the sum value of tiles for multi-tiles.\n                              30. GPU Memory Errors Uncorrectable, per tile or device. Other non-compute uncorrectable errors are also included. Device-level is the sum value of tiles for multi-tiles.\n                              31. Compute engine group utilization (%), per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              32. Render engine group utilization (%), per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              33. Media engine group utilization (%), per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              34. Copy engine group utilization (%), per tile or device. Device-level is the average value of tiles for multi-tiles.\n                              35. Throttle reason, per tile.\n                              36. Media Engine Frequency (MHz), per tile or device. Device-level is the average value of tiles for multi-tiles.\n\n  -i                          The interval (in seconds) to dump the device statistics to screen. Default value: 1 second.\n  -n                          Number of the device statistics dump to screen. The dump will never be ended if this parameter is not specified.\n\n  --file                      Dump the raw statistics to the file.\n  --ims                       The interval (in milliseconds) to dump the device statistics to file for high-frequency monitoring.\n                              The recommended metrics types for high-frequency sampling: GPU power, GPU frequency, GPU utilization,\n                              GPU temperature, GPU memory read/write/bandwidth, GPU PCIe read/write, GPU engine utilizations, Xe Link throughput.\n  --time                      Dump total time in seconds.\n  --date                      Show date in timestamp.\n</code></pre>"},{"location":"aurora/performance-tools/xpu-smi/#simple-examples","title":"Simple examples","text":""},{"location":"aurora/performance-tools/xpu-smi/#discover-the-gpu-devices-on-an-aurora-compute-node","title":"Discover the GPU devices on an Aurora compute node","text":"<pre><code>$ xpu-smi discovery\n+-----------+--------------------------------------------------------------------------------------+\n| Device ID | Device Information                                                                   |\n+-----------+--------------------------------------------------------------------------------------+\n| 0         | Device Name: Intel(R) Data Center GPU Max 1550                                       |\n|           | Vendor Name: Intel(R) Corporation                                                    |\n|           | SOC UUID: 00000000-0000-0000-926a-83c28645e226                                       |\n|           | PCI BDF Address: 0000:18:00.0                                                        |\n|           | DRM Device: /dev/dri/card0                                                           |\n|           | Function Type: physical                                                              |\n+-----------+--------------------------------------------------------------------------------------+\n| 1         | Device Name: Intel(R) Data Center GPU Max 1550                                       |\n|           | Vendor Name: Intel(R) Corporation                                                    |\n|           | SOC UUID: 00000000-0000-0000-41ba-014c9029529c                                       |\n|           | PCI BDF Address: 0000:42:00.0                                                        |\n|           | DRM Device: /dev/dri/card1                                                           |\n|           | Function Type: physical                                                              |\n+-----------+--------------------------------------------------------------------------------------+\n| 2         | Device Name: Intel(R) Data Center GPU Max 1550                                       |\n|           | Vendor Name: Intel(R) Corporation                                                    |\n|           | SOC UUID: 00000000-0000-0000-ef03-1b4749c20cb0                                       |\n|           | PCI BDF Address: 0000:6c:00.0                                                        |\n|           | DRM Device: /dev/dri/card2                                                           |\n|           | Function Type: physical                                                              |\n+-----------+--------------------------------------------------------------------------------------+\n| 3         | Device Name: Intel(R) Data Center GPU Max 1550                                       |\n|           | Vendor Name: Intel(R) Corporation                                                    |\n|           | SOC UUID: 00000000-0000-0000-a9e9-a41ad019b491                                       |\n|           | PCI BDF Address: 0001:18:00.0                                                        |\n|           | DRM Device: /dev/dri/card3                                                           |\n|           | Function Type: physical                                                              |\n+-----------+--------------------------------------------------------------------------------------+\n| 4         | Device Name: Intel(R) Data Center GPU Max 1550                                       |\n|           | Vendor Name: Intel(R) Corporation                                                    |\n|           | SOC UUID: 00000000-0000-0000-1198-22ef5c1e3288                                       |\n|           | PCI BDF Address: 0001:42:00.0                                                        |\n|           | DRM Device: /dev/dri/card4                                                           |\n|           | Function Type: physical                                                              |\n+-----------+--------------------------------------------------------------------------------------+\n| 5         | Device Name: Intel(R) Data Center GPU Max 1550                                       |\n|           | Vendor Name: Intel(R) Corporation                                                    |\n|           | SOC UUID: 00000000-0000-0000-cec2-eaa8508708c5                                       |\n|           | PCI BDF Address: 0001:6c:00.0                                                        |\n|           | DRM Device: /dev/dri/card5                                                           |\n|           | Function Type: physical                                                              |\n+-----------+--------------------------------------------------------------------------------------+\n</code></pre>"},{"location":"aurora/performance-tools/xpu-smi/#monitoring-gpu-utilization-gpu-power-gpu-frequency-and-gpu-memory-utilization-of-six-gpus-on-an-aurora-compute-node","title":"Monitoring GPU utilization, GPU power, GPU frequency and GPU memory utilization of six GPUs on an Aurora compute node","text":"<pre><code>$ xpu-smi dump -d 0 1 2 3 4 5 -m 0 1 2 5\nTimestamp, DeviceId, GPU Utilization (%), GPU Power (W), GPU Frequency (MHz), GPU Memory Utilization (%)\n23:48:25.043,    0,  N/A, 280.50, 1600.00,  N/A\n23:48:25.043,    1,  N/A, 286.91, 1600.00,  N/A\n23:48:25.043,    2,  N/A, 277.71, 1600.00,  N/A\n23:48:25.043,    3,  N/A, 281.91, 1600.00,  N/A\n23:48:25.043,    4,  N/A, 279.70, 1600.00,  N/A\n23:48:25.043,    5,  N/A, 285.25, 1600.00,  N/A\n23:48:26.043,    0,  N/A, 279.97, 1600.00, 11.15\n23:48:26.043,    1,  N/A, 287.57, 1600.00, 11.53\n23:48:26.043,    2,  N/A, 278.04, 1600.00, 12.56\n23:48:26.043,    3,  N/A, 282.30, 1600.00, 12.00\n23:48:26.043,    4,  N/A, 279.89, 1600.00, 11.78\n23:48:26.043,    5,  N/A, 285.01, 1600.00, 11.78\n23:48:27.043,    0,  N/A, 280.53, 1600.00, 11.15\n23:48:27.043,    1,  N/A, 286.90, 1600.00, 11.53\n23:48:27.043,    2,  N/A, 277.65, 1600.00, 12.56\n23:48:27.043,    3,  N/A, 282.60, 1600.00, 12.00\n23:48:27.043,    4,  N/A, 279.76, 1600.00, 11.78\n23:48:27.043,    5,  N/A, 284.93, 1600.00, 11.78\n23:48:28.043,    0,  N/A, 280.52, 1600.00, 11.15\n23:48:28.043,    1,  N/A, 286.88, 1600.00, 11.53\n23:48:28.043,    2,  N/A, 277.71, 1600.00, 12.56\n23:48:28.043,    3,  N/A, 282.09, 1600.00, 12.00\n23:48:28.043,    4,  N/A, 280.09, 1600.00, 11.78\n23:48:28.043,    5,  N/A, 285.01, 1600.00, 11.78\n23:48:29.043,    0,  N/A, 279.89, 1600.00, 11.15\n23:48:29.043,    1,  N/A, 287.58, 1600.00, 11.53\n23:48:29.043,    2,  N/A, 277.54, 1600.00, 12.56\n23:48:29.043,    3,  N/A, 282.07, 1600.00, 12.00\n23:48:29.043,    4,  N/A, 279.88, 1600.00, 11.78\n23:48:29.043,    5,  N/A, 285.72, 1600.00, 11.78\n23:48:30.043,    0,  N/A, 280.54, 1600.00, 11.15\n23:48:30.043,    1,  N/A, 286.89, 1600.00, 11.53\n23:48:30.043,    2,  N/A, 277.63, 1600.00, 12.56\n23:48:30.043,    3,  N/A, 282.55, 1600.00, 12.00\n23:48:30.043,    4,  N/A, 279.78, 1600.00, 11.78\n23:48:30.043,    5,  N/A, 285.25, 1600.00, 11.78\n23:48:31.043,    0,  N/A, 280.05, 1600.00, 11.15\n23:48:31.043,    1,  N/A, 286.92, 1600.00, 11.53\n23:48:31.043,    2,  N/A, 278.32, 1600.00, 12.56\n23:48:31.043,    3,  N/A, 282.17, 1600.00, 12.00\n23:48:31.043,    4,  N/A, 280.62, 1600.00, 11.78\n23:48:31.043,    5,  N/A, 285.00, 1600.00, 11.78\n23:48:32.043,    0,  N/A, 279.88, 1600.00, 11.15\n23:48:32.043,    1,  N/A, 287.18, 1600.00, 11.53\n23:48:32.043,    2,  N/A, 277.83, 1600.00, 12.56\n23:48:32.043,    3,  N/A, 281.86, 1600.00, 12.00\n23:48:32.043,    4,  N/A, 280.41, 1600.00, 11.78\n23:48:32.043,    5,  N/A, 285.70, 1600.00, 11.78\n23:48:33.043,    0,  N/A, 280.38, 1600.00, 11.15\n23:48:33.043,    1,  N/A, 286.77, 1600.00, 11.53\n23:48:33.043,    2,  N/A, 277.72, 1600.00, 12.56\n23:48:33.043,    3,  N/A, 282.43, 1600.00, 12.00\n23:48:33.043,    4,  N/A, 279.98, 1600.00, 11.78\n23:48:33.043,    5,  N/A, 285.77, 1600.00, 11.78\n23:48:34.043,    0,  N/A, 280.11, 1600.00, 11.15\n23:48:34.043,    1,  N/A, 287.02, 1600.00, 11.53\n23:48:34.043,    2,  N/A, 278.22, 1600.00, 12.56\n23:48:34.043,    3,  N/A, 282.26, 1600.00, 12.00\n23:48:34.043,    4,  N/A, 280.68, 1600.00, 11.78\n23:48:34.043,    5,  N/A, 285.06, 1600.00, 11.78\n23:48:35.043,    0,  N/A, 280.21, 1600.00, 11.15\n23:48:35.043,    1,  N/A, 287.58, 1600.00, 11.53\n23:48:35.043,    2,  N/A, 277.82, 1600.00, 12.56\n23:48:35.043,    3,  N/A, 281.84, 1600.00, 12.00\n23:48:35.043,    4,  N/A, 280.40, 1600.00, 11.78\n23:48:35.043,    5,  N/A, 285.54, 1600.00, 11.78\n^C\n</code></pre>"},{"location":"aurora/performance-tools/xpu-smi/#references","title":"References","text":"<p>XPU manager github repository 2025 ALCF INCITE Hackathon virtual week</p>"},{"location":"aurora/programming-models/hip-aurora/","title":"HIP on Aurora","text":"<p>ALCF experimentally supports applications which use the HIP programming model via chipStar. </p>"},{"location":"aurora/programming-models/hip-aurora/#example","title":"Example","text":"<p>Below is a simple example of setting the HIP environment, building, and running a HIP code on Aurora. </p>"},{"location":"aurora/programming-models/hip-aurora/#setting-the-environment-to-use-hip-on-aurora","title":"Setting the environment to use HIP on Aurora","text":"<pre><code>module use /soft/modulefiles\nmodule load chipStar/1.2.1\n</code></pre> <p>With this, the <code>hipcc</code> executable should be in your path. For projects using CMake, there is support via <code>find_package(hip CONFIG REQUIRED)</code> which can be used with chipStar.</p> saxpy.cpp<pre><code>#include &lt;stdio.h&gt;\n#include &lt;math.h&gt;\n#include \"hip/hip_runtime.h\"\n\n#define HIP_ASSERT(x) (assert((x)==hipSuccess))\n\n__global__\nvoid saxpy(int n, float a, float *x, float *y)\n{\n  int i = hipBlockDim_x * hipBlockIdx_x + hipThreadIdx_x;\n  if (i &lt; n) y[i] = a*x[i] + y[i];\n}\n\nint main(void)\n{\n  int N = 1&lt;&lt;20;\n  float *x, *y, *d_x, *d_y;\n  x = (float*)malloc(N*sizeof(float));\n  y = (float*)malloc(N*sizeof(float));\n\n  HIP_ASSERT(hipMalloc(&amp;d_x, N*sizeof(float)));\n  HIP_ASSERT(hipMalloc(&amp;d_y, N*sizeof(float)));\n\n  for (int i = 0; i &lt; N; i++) {\n    x[i] = 1.0f;\n    y[i] = 2.0f;\n  }\n\n  HIP_ASSERT(hipMemcpy(d_x, x, N*sizeof(float), hipMemcpyHostToDevice));\n  HIP_ASSERT(hipMemcpy(d_y, y, N*sizeof(float), hipMemcpyHostToDevice));\n\n  // Perform SAXPY on 1M elements\n  hipLaunchKernelGGL(saxpy,(N+255)/256, 256,0,0,N, 2.0f, d_x, d_y );\n\n  HIP_ASSERT(hipMemcpy(y, d_y, N*sizeof(float), hipMemcpyDeviceToHost));\n\n  float maxError = 0.0f;\n  for (int i = 0; i &lt; N; i++)\n    maxError = ( maxError &gt; abs(y[i]-4.0f) ) ? maxError : abs(y[i]-4.0f) ;\n  printf(\"Max error: %f\\n\", maxError);\n\n  HIP_ASSERT(hipFree(d_x));\n  HIP_ASSERT(hipFree(d_y));\n  free(x);\n  free(y);\n}\n</code></pre>"},{"location":"aurora/programming-models/hip-aurora/#building-hip-code-on-aurora","title":"Building HIP code on Aurora","text":"<pre><code>&gt; hipcc saxpy.cpp\n</code></pre>"},{"location":"aurora/programming-models/hip-aurora/#running-hip-code-on-aurora","title":"Running HIP code on Aurora","text":"<pre><code>&gt; ./a.out\nMax error: 0.000000\n</code></pre> <p>There are additional details in the chipStar user documentation.</p>"},{"location":"aurora/programming-models/kokkos-aurora/","title":"Kokkos","text":""},{"location":"aurora/programming-models/kokkos-aurora/#kokkos","title":"Kokkos","text":"<p>Kokkos Core implements a programming model in C++ for writing performance-portable applications targeting all major HPC platforms. For that purpose, it provides abstractions for both parallel execution of code and data management. Kokkos is designed to target complex node architectures with N-level memory hierarchies and multiple types of execution resources. It currently can use Serial and OpenMP (threads) for CPU execution spaces (\"backends\") and CUDA, HIP, SYCL, and OpenMPTarget for GPU execution spaces. By convention, Kokkos only allows one GPU backend at a time.</p>"},{"location":"aurora/programming-models/kokkos-aurora/#kokkos-documentation","title":"Kokkos Documentation","text":"<ul> <li>Kokkos-core Wiki</li> <li>Kokkos GitHub</li> </ul>"},{"location":"aurora/programming-models/kokkos-aurora/#kokkos-on-aurora","title":"Kokkos on Aurora","text":"<p>The prebuilt Kokkos on Aurora includes 3 backends: Serial and OpenMP for CPU execution and SYCL for GPU execution (with ahead-of-time (AOT) compilation, not just-in-time (JIT) compilation). To use it, run:</p> <pre><code>module load kokkos\n</code></pre> <p>This sets the following environment variables, some of which are used by <code>cmake</code>:</p> <ul> <li><code>KOKKOS_ROOT</code> - path to the <code>lib64/</code>, <code>include/</code> files installed</li> <li><code>LIBRARY_PATH</code> - prepends <code>$KOKKOS_ROOT/lib64</code> to this variable used by <code>cmake</code></li> <li><code>CPATH</code> - prepends <code>$KOKKOS_ROOT/include</code> to this variable used by <code>cmake</code></li> <li><code>LD_LIBRARY_PATH</code> - prepends <code>$KOKKOS_ROOT/lib64</code> to this variable</li> </ul>"},{"location":"aurora/programming-models/kokkos-aurora/#building-a-kokkos-application-using-cmake","title":"Building a Kokkos Application Using <code>cmake</code>","text":"<p>Add these lines to <code>CMakeLists.txt</code>:</p> <pre><code>find_package(Kokkos REQUIRED)\ntarget_link_libraries(myTarget Kokkos::kokkos)\n</code></pre> <p>Here is a simple example <code>CMakeLists.txt</code> to compile an example program:</p> <pre><code>cmake_minimum_required(VERSION 3.22)\nproject(buildExample)\nfind_package(Kokkos REQUIRED)\n\nset(buildExample_SOURCE_DIR \".\")\n\nset(top_SRCS\n  ${buildExample_SOURCE_DIR}/example1.cpp)\n\nset(SOURCE_FILES ${top_SRCS})\n\nadd_executable(example1_sycl_aot ${SOURCE_FILES})\ntarget_link_libraries(example1_sycl_aot Kokkos::kokkos)\ntarget_include_directories(example1_sycl_aot PUBLIC ${buildExample_SOURCE_DIR})\n</code></pre> <p>Configure and build it like this:</p> <pre><code>mkdir build\ncd build\ncmake -DCMAKE_CXX_COMPILER=icpx ..\nmake\n</code></pre>"},{"location":"aurora/programming-models/kokkos-aurora/#building-a-kokkos-application-using-make","title":"Building a Kokkos Application Using <code>make</code>","text":"<p>Here's an example <code>Makefile</code>:</p> <pre><code># KOKKOS_ROOT set via:\n#   module load kokkos\n# \n# You can look at the first lines of\n# $KOKKOS_ROOT/lib64/cmake/Kokkos/KokkosConfigCommon.cmake to see the flags\n# used in cmake configuration of the kokkos library build. The default Kokkos\n# module on Aurora was built with the default oneAPI module and includes\n# Serial, OpenMP (threads) and SYCL backends. So you should have that\n# environment module loaded and include compiler flags for sycl and openmp:\n\n# Aurora MPICH wrapper for C++ and C compilers:\nCXX=\"mpic++ -cxx=icpx\"\nCC=\"mpicc -cc=icx\"\n\nSYCL_AOT_CPPFLAGS=-fsycl -fsycl-targets=spir64_gen -fno-sycl-id-queries-fit-in-int -fsycl-dead-args-optimization -fsycl-unnamed-lambda -std=c++17\nSYCL_AOT_LDFLAGS=-Xsycl-target-backend \"-device pvc\"\n\nCPPFLAGS=-g -O2 -fiopenmp -I $(KOKKOS_ROOT)/include $(SYCL_AOT_CPPFLAGS) -Wno-deprecated-declarations -Wno-tautological-constant-compare -Wno-unknown-attributes -ffp-model=precise\n\nLDFLAGS=$(CPPFLAGS) $(SYCL_AOT_LDFLAGS)\nLDLIBS=-L$(KOKKOS_ROOT)/lib64 -lkokkoscore -lkokkossimd -lkokkoscontainers -lpthread\n\nSRCS=example1.cpp\nOBJS=$(subst .cpp,.o,$(SRCS))\n\nall: example1_aurora\n\nexample1_aurora: $(OBJS)\n    $(CXX) $(LDFLAGS) -o example1_aurora $(OBJS) $(LDLIBS)\n\nexample1.o: example1.cpp\n\nclean:\n    rm -f $(OBJS)\n\ndistclean: clean\n    rm -f example1_aurora\n</code></pre>"},{"location":"aurora/programming-models/kokkos-aurora/#configuring-your-own-kokkos-build-on-aurora","title":"Configuring Your Own Kokkos Build on Aurora","text":"<p>Here are recommended environment settings and configuration to build your own Kokkos libraries on Aurora:</p>"},{"location":"aurora/programming-models/kokkos-aurora/#environment","title":"Environment","text":"<p>To match what was done in the centrally-built Kokkos associated with the modules discussed above, use the same oneAPI version as indicated in <code>module help kokkos</code> and use the Aurora MPICH wrapper <code>mpic++ -cxx=icpx</code> as the C++ compiler (or just use <code>icpx</code> if you're not using MPI). To build Kokkos, you'll need CMake.</p>"},{"location":"aurora/programming-models/kokkos-aurora/#cmake-configuration","title":"CMake Configuration","text":"<p>This example builds three backends: OpenMP, Serial, and SYCL.</p> <pre><code>git clone git@github.com:kokkos/kokkos.git\ncd kokkos\nmkdir build\ncd build\n\ncmake\\\n    -DCMAKE_CXX_COMPILER=icpx\\\n    -DKokkos_ENABLE_SERIAL=ON\\\n    -DKokkos_ENABLE_OPENMP=ON\\\n    -DKokkos_ENABLE_SYCL=ON\\\n    -DKokkos_ARCH_INTEL_PVC=ON\\\n    -DCMAKE_CXX_FLAGS=\"-fp-model=precise\"\\\n    -DCMAKE_INSTALL_PREFIX=/path/to/your/install/directory\\\n    ..\n\nmake -j16 -l16 install\n</code></pre>"},{"location":"aurora/programming-models/level-0/","title":"Level-Zero on Aurora","text":""},{"location":"aurora/programming-models/level-0/#overview","title":"Overview","text":"<p>The objective of the \u2018oneAPI\u2019 Level-Zero Application Programming Interface (API) is to provide direct-to-metal interfaces to offload accelerator devices. Its programming interface can be tailored to any device's needs and can be adapted to support a broader set of language features such as function pointers, virtual functions, unified memory, and I/O capabilities.</p>"},{"location":"aurora/programming-models/level-0/#setting-the-environment-to-use-level-zero-on-aurora","title":"Setting the environment to use Level-Zero on Aurora","text":"<p>The Intel Programming Environment is the main environment on Aurora. The Intel Compute Runtime is part of this environment and grants access to Level-Zero. The Intel Compute Runtime is loaded by default in your environment.</p> <pre><code>&gt; module list\n\nCurrently Loaded Modules:\n  1) gcc/11.2.0                    3) intel_compute_runtime/release/agama-devel-551   5) libfabric/1.15.2.0   7) cray-libpals/1.3.3\n  2) mpich/51.2/icc-all-pmix-gpu   4) oneapi/eng-compiler/2022.12.30.003              6) cray-pals/1.3.3\n</code></pre>"},{"location":"aurora/programming-models/level-0/#building-on-aurora","title":"Building on Aurora","text":"<p>Level-Zero is a C API that can be used in your application by including the <code>ze_api.h</code> file:</p> <pre><code>#include &lt;ze_api.h&gt;\n</code></pre> <p>Applications that use the Level-Zero API need to be linked to the Level-Zero loader library by using the <code>-lze_loader</code> linker flag.</p>"},{"location":"aurora/programming-models/level-0/#level-zero-documentation","title":"Level-Zero Documentation","text":"<p>The Level-Zero documentation can be found here: Level-Zero Specification.</p>"},{"location":"aurora/programming-models/opencl-aurora/","title":"OpenCL","text":""},{"location":"aurora/programming-models/opencl-aurora/#overview","title":"Overview","text":"<p>OpenCL\u2122 (Open Computing Language) is an open, royalty-free standard for cross-platform, parallel programming of diverse accelerators found in supercomputers, cloud servers, personal computers, mobile devices, and embedded platforms. OpenCL greatly improves the speed and responsiveness of a wide spectrum of applications in numerous market categories, including professional creative tools, scientific and medical software, vision processing, and neural network training and inferencing.</p>"},{"location":"aurora/programming-models/opencl-aurora/#setting-the-environment-to-use-opencl-on-aurora","title":"Setting the environment to use OpenCL on Aurora","text":"<p>The Intel Programming Environment is the main environment on Aurora. The Intel Compute Runtime is part of this environment and grants access to OpenCL. The Intel Compute Runtime is loaded by default in your environment.</p> <pre><code>&gt; module list\n\nCurrently Loaded Modules:\n  1) gcc/11.2.0                    3) intel_compute_runtime/release/agama-devel-551   5) libfabric/1.15.2.0   7) cray-libpals/1.3.3\n  2) mpich/51.2/icc-all-pmix-gpu   4) oneapi/eng-compiler/2022.12.30.003              6) cray-pals/1.3.3\n</code></pre>"},{"location":"aurora/programming-models/opencl-aurora/#building-on-aurora","title":"Building on Aurora","text":"<p>OpenCL is a C API that can be used in your application by including the <code>CL/opencl.h</code> file:</p> <pre><code>#include &lt;CL/opencl.h&gt;\n</code></pre> <p>Applications that use the OpenCL API need to be linked to the OpenCL loader library by using the <code>-lOpenCL</code> linker flag when using Make. For CMake-based builds, you can find the OpenCL package and then link it to your targets as shown below:</p> <pre><code>find_package(OpenCL REQUIRED)\ntarget_link_libraries(my_target PRIVATE OpenCL::OpenCL)\n</code></pre> <p>During the configure step, CMake may need help finding the OpenCL library. You can provide hints to CMake by setting the <code>OpenCL_LIBRARY</code> and <code>OpenCL_INCLUDE_DIR</code> variables. If you use <code>icx</code> or <code>icpx</code> on Aurora, you can do the following during the configure step:</p> <pre><code>export OPENCL_BASE_DIR=$(dirname $(which icx))/..\ncmake -DOpenCL_LIBRARY=${OPENCL_BASE_DIR}/lib/libOpenCL.so \\\n      -DOpenCL_INCLUDE_DIR=${OPENCL_BASE_DIR}/include/sycl \\\n      &lt;other_cmake_options&gt;\n</code></pre> <p>C++ bindings exist and can be used in C++ applications by including the <code>CL/opencl.hpp</code> file:</p> <pre><code>#include &lt;CL/opencl.hpp&gt;\n</code></pre>"},{"location":"aurora/programming-models/opencl-aurora/#opencl-documentation","title":"OpenCL Documentation","text":"<p>The OpenCL Specification and the OpenCL Reference Pages are provided by Khronos.</p> <p>Documentation for the C++ bindings is available here: OpenCL C++ Bindings.</p>"},{"location":"aurora/programming-models/openmp-aurora/","title":"OpenMP on Aurora","text":""},{"location":"aurora/programming-models/openmp-aurora/#overview","title":"Overview","text":"<p>The OpenMP API is an open standard for parallel programming. The specification document can be found here: OpenMP Specification. The specification describes directives, runtime routines, and environment variables that allow an application developer to express parallelism (e.g., shared memory multiprocessing and device offloading). Many compiler vendors provide implementations of the OpenMP specification (OpenMP Specifications).</p>"},{"location":"aurora/programming-models/openmp-aurora/#setting-the-environment-to-use-openmp-on-aurora","title":"Setting the environment to use OpenMP on Aurora","text":"<p>The Intel oneAPI Programming Environment is the main environment on Aurora to maximally use the hardware. oneAPI has OpenMP support for both CPU threads and GPU devices. The oneAPI module is loaded by default in your environment:</p> <pre><code>&gt; module list\n\nCurrently Loaded Modules:\n  1) gcc/11.2.0                    3) intel_compute_runtime/release/agama-devel-551   5) libfabric/1.15.2.0   7) cray-libpals/1.3.3\n  2) mpich/51.2/icc-all-pmix-gpu   4) *oneapi/eng-compiler/2022.12.30.003*              6) cray-pals/1.3.3\n</code></pre> <p>However, additional versions of oneAPI with newer compiler versions can be found by adding additional modules to your path:</p> <pre><code>&gt; module use /soft/modulefiles/\n&gt; module avail oneapi\n\n-------------------------------------------------------------------------------- /soft/modulefiles ---------------------------------------------------------------------------------\n   oneapi/eng-compiler/2023.05.15.003    oneapi/eng-compiler/2023.10.15.002        oneapi/release/2023.10.15.001        spack-pe-oneapi/0.5-rc1 (D)\n   oneapi/eng-compiler/2023.05.15.006    oneapi/eng-compiler/2023.12.15.002 (D)    oneapi/release/2023.12.15.001 (D)\n   oneapi/eng-compiler/2023.05.15.007    oneapi/release/2023.05.15.001             spack-pe-oneapi/0.4-rc1\n\n------------------------------------------------------------------------- /opt/aurora/23.073.0/modulefiles -------------------------------------------------------------------------\n   oneapi/eng-compiler/2022.12.30.003 (L)    oneapi/release/2022.12.30.001\n</code></pre> <p>The additional oneAPI modules can be loaded with <code>module load oneapi/eng-compiler/2023.10.15.002</code>, for example.</p>"},{"location":"aurora/programming-models/openmp-aurora/#building-on-aurora","title":"Building on Aurora","text":"<p>The following table shows the compiler and flags:</p> Language MPI Wrapper Compiler (Underlying Compiler) Flag to Turn on OpenMP Support and Target CPU Threads Additional Flags to Target GPU Devices Fortran mpifort (ifx) <code>-fiopenmp</code> <code>-fopenmp-targets=spir64_gen -Xs \"-device pvc\"</code> C mpicc (icx) <code>-fiopenmp</code> <code>-fopenmp-targets=spir64_gen -Xs \"-device pvc\"</code> C++ mpicxx (icpx) <code>-fiopenmp</code> <code>-fopenmp-targets=spir64_gen -Xs \"-device pvc\"</code>"},{"location":"aurora/programming-models/openmp-aurora/#running-on-aurora","title":"Running on Aurora","text":"<p>To run, you can execute the produced executable or use <code>mpiexec</code> in a job script, and then submit the script to an Aurora queue, like:</p> <pre><code>$ cat submit.sh\n#!/bin/bash -l\n#PBS -l select=1\n#PBS -l walltime=0:30:00\n#PBS -l filesystems=&lt;fs1:fs2&gt;\n#PBS -q &lt;queue&gt; \n#PBS -A &lt;ProjectName&gt;\n\ncd ${PBS_O_WORKDIR}\nmpiexec -n 1 ./executable\n$ # submit to the queue:\n$ qsub -l select=1 -l walltime=0:30:00 -q EarlyAppAccess -A Project ./submit.sh\n</code></pre> <p>In the above, having the PBS options in the script and on the command line is redundant, but we put it there to show both ways of launching. This submits the script to one node in the <code>EarlyAppAccess</code> queue on Aurora, requesting 30 minutes. It will charge project <code>Project</code> for the time. You should replace it with your project name.</p> <p>More details for setting up the job script are in the Job Scheduling and Execution section.</p>"},{"location":"aurora/programming-models/openmp-aurora/#example","title":"Example","text":"<pre><code>$ cat hello.cpp\n#include &lt;stdio.h&gt;\n#include &lt;omp.h&gt;\n\nint main(int argc, char** argv) {\n  printf(\"Number of devices: %d\\n\", omp_get_num_devices());\n\n  #pragma omp target\n  {\n    if (!omp_is_initial_device())\n      printf(\"Hello world from accelerator.\\n\");\n    else\n      printf(\"Hello world from host.\\n\");\n  }\n  return 0;\n}\n</code></pre> <pre><code>$ cat hello.F90\nprogram main\n  use omp_lib\n  implicit none\n  integer flag\n\n  write(*,*) \"Number of devices:\", omp_get_num_devices()\n\n  !$omp target map(from:flag)\n    if (.not. omp_is_initial_device()) then\n      flag = 1\n    else\n      flag = 0\n    endif\n  !$omp end target\n\n  if (flag == 1) then\n    print *, \"Hello world from accelerator\"\n  else\n    print *, \"Hello world from host\"\n  endif\nend program main\n</code></pre>"},{"location":"aurora/programming-models/openmp-aurora/#to-compile","title":"To compile","text":"<pre><code>$ mpicxx -fiopenmp -fopenmp-targets=spir64_gen -Xs \"-device pvc\" hello.cpp -o c_test\n$ mpifort -fiopenmp -fopenmp-targets=spir64_gen -Xs \"-device pvc\" hello.F90 -o f_test\n</code></pre>"},{"location":"aurora/programming-models/openmp-aurora/#to-run","title":"To run","text":"<pre><code>$ mpiexec -n 1 ./c_test\nNumber of devices: 6\nHello world from accelerator.\n$ mpiexec -n 1 ./f_test\nNumber of devices:            6\nHello world from accelerator\n</code></pre>"},{"location":"aurora/programming-models/sycl-aurora/","title":"SYCL on Aurora","text":""},{"location":"aurora/programming-models/sycl-aurora/#overview","title":"Overview","text":"<p>SYCL is an open, royalty-free, cross-platform abstraction layer that enables code for heterogeneous and offload processors to be written using modern ISO C++. It provides APIs and abstractions to find devices (CPUs, GPUs, FPGAs, etc.) on which code can be executed and to manage data resources and code execution on those devices.</p> <p>The specification can be found here: SYCL 2020 Specification</p>"},{"location":"aurora/programming-models/sycl-aurora/#setting-the-environment-to-use-sycl-on-aurora","title":"Setting the environment to use SYCL on Aurora","text":"<p>The Intel oneAPI Programming Environment is the main environment on Aurora. oneAPI has SYCL support. The oneAPI module is loaded by default in your environment:</p> <pre><code>$ module list\n\nCurrently Loaded Modules:\n  1) gcc-runtime/12.2.0-267awrk   5) gcc/12.2.0                             9) libfabric/1.20.1\n  2) gmp/6.2.1-yctcuid            6) intel_compute_runtime/release/996.26  10) cray-pals/1.4.0\n  3) mpfr/4.2.1-fhgnwe7           7) oneapi/eng-compiler/2024.07.30.002    11) cray-libpals/1.4.0\n  4) mpc/1.3.1-ygprpb4            8) mpich/icc-all-pmix-gpu/20240717\n</code></pre>"},{"location":"aurora/programming-models/sycl-aurora/#building-on-aurora","title":"Building on Aurora","text":"<p>Simply use <code>-fsycl</code>. For CMake, use <code>find_package(IntelSYCL REQUIRED)</code>. See <code>cat $CMPLR_ROOT/lib/cmake/IntelSYCL/IntelSYCLConfig.cmake</code> for more details.</p>"},{"location":"aurora/programming-models/sycl-aurora/#example","title":"Example","text":"<pre><code>$ cat hello_sycl.cpp\n#include &lt;sycl/sycl.hpp&gt;\nint main(int argc, char **argv) {\n  int global_range = 10;\n  // Default Queue\n  sycl::queue Q;\n  // Queue introspection\n  std::cout &lt;&lt; \"Running on \" &lt;&lt; Q.get_device().get_info&lt;sycl::info::device::name&gt;() &lt;&lt; std::endl;\n\n  // Allocate device memory\n  int *A = sycl::malloc_device&lt;int&gt;(global_range, Q);\n  // Blocking kernel that uses the memory\n  Q.parallel_for(global_range, [=](auto id) { A[id] = id; }).wait();\n  // Allocate Host Memory\n  std::vector&lt;int&gt; A_host(global_range);\n  // Blocking copy the device memory to the host\n  Q.copy(A, A_host.data(), global_range).wait();\n  // Free Device Memory\n  sycl::free(A, Q);\n\n  for (size_t i = 0; i &lt; global_range; i++)\n    std::cout &lt;&lt; \"A_host[ \" &lt;&lt; i &lt;&lt; \" ] = \" &lt;&lt; A_host[i] &lt;&lt; std::endl;\n  return 0;\n}\n$ icpx -fsycl hello_sycl.cpp\n$ ./a.out\n</code></pre> <p>More examples can be found here: SYCL Training Examples</p>"},{"location":"aurora/services/gitlab-ci/","title":"Continuous Integration via GitLab-CI For Aurora","text":""},{"location":"aurora/services/gitlab-ci/#as-of-febuary-25-2025-no-changes-from-the-general-documentation-for-gitlab-ci-are-required-for-aurora","title":"As of Febuary 25 2025, no changes from the general documentation for GitLab-CI are required for Aurora.","text":""},{"location":"aurora/visualization/","title":"Visualization on Aurora","text":"<p>These are the visualization tools currently available on Aurora.  </p> <p>ParaView: ParaView is an open-source visualization engine that seamlessly integrates with your existing tools and workflows. It allows you to construct visualization pipelines for quick data analysis. Whether interactively exploring large datasets in 3D or performing batch processing programmatically, ParaView provides versatile capabilities. For additional information, visit the Kitware website.</p> <p>VisIt: VisIt is an open-source, interactive, and scalable visualization, animation, and analysis tool. Users can rapidly generate visualizations, animate them over time, apply various operators and mathematical expressions, and save resulting images and animations for presentations. VisIt supports a diverse range of visualization features, enabling users to view data, including scalar and vector fields, on 2D and 3D structured, adaptive, and unstructured meshes. Thanks to its customizable plugin design, VisIt can visualize data from over 120 different scientific data formats. For more information, check the VisIt project GitHub page.</p>"},{"location":"aurora/visualization/paraview-manual-launch/","title":"Manually launching a ParaView server on Aurora","text":"<p>Sometimes it is convenient to manually launch an instance of the ParaView server. In this section, we will explain an alternative method to run the ParaView server on Polaris using an interactive job, where the user can launch the ParaView server from the command line interface.</p> <p>Note: this method is better suited for experienced users. If you are just starting with ParaView, we recommend the client/server mode as your primary method for using this tool.</p>"},{"location":"aurora/visualization/paraview-manual-launch/#setting-up-paraview","title":"Setting up ParaView","text":"<p>From your local client, select Connect, either from the File menu or by clicking on the icon circled below:</p> <p> </p> <p>A new window will open where you can configure a server. Click on Add Server:</p> <p></p> <p>Give your server a name, select Client/Server, localhost, and a TCP port (8000 in this example).</p> <p></p> <p>Click \"Configure\". In the next window, there is an option to set up how the ParaView server will be launched, and the default is \"Manual\". Leave it on \"Manual\" and click \"Save\".</p> <p>You will use these settings when establishing the connection.</p>"},{"location":"aurora/visualization/paraview-manual-launch/#launching-the-paraview-server-on-aurora","title":"Launching the ParaView server on Aurora","text":"<p>You can launch an interactive session on Aurora compute nodes with the following command (adjust parameters as needed to match your allocation, desired number of nodes, queue, walltime, and filesystems):</p> <pre><code>qsub -l walltime=01:00:00 -l select=2 -A yourallocation -q debug -I -l filesystems=home:flare\n</code></pre> <p>When the job starts, you will receive a prompt on your head node like this:</p> <pre><code>username@x4706c7s4b0n0:~&gt;\n</code></pre> <p>Make a note of the node hostname (<code>x4706c7s4b0n0</code> in the example above). You can also get this information from <code>qstat -fx jobID</code>.</p> <p>Now load the ParaView module:</p> <pre><code>username@x4706c7s4b0n0:~&gt; module use /soft/modulefiles \nusername@x4706c7s4b0n0:~&gt; module load paraview/paraview-5.13.2\n</code></pre> <p>and launch the ParaView server with:</p> <pre><code>username@x4706c7s4b0n0:~&gt; mpiexec -n 8 pvserver --server-port=8000\nWaiting for client...\nConnection URL: cs://x4706c7s4b0n0:8000\nAccepting connection(s): x4706c7s4b0n0:8000\n</code></pre> <p>In this case, <code>pvserver</code> will be listening on TCP port 8000 of your head node. You can change this port if you want.</p>"},{"location":"aurora/visualization/paraview-manual-launch/#creating-a-tunnel-over-ssh","title":"Creating a tunnel over ssh","text":"<p>We need to establish an ssh tunnel to connect the client to the server. On your local machine, open a new terminal and type:</p> <pre><code>ssh -v -N -L 8000:x4706c7s4b0n0:8000 aurora.alcf.anl.gov\n</code></pre> <p>where 8000 is a TCP port and <code>x4706c7s4b0n0</code> is the name of your head node. Adjust these values accordingly.</p> <p>Among multiple lines with debug information, you should see something like:</p> <pre><code>debug1: Local connections to LOCALHOST:8000 forwarded to remote address x4706c7s4b0n0:8000\n</code></pre> <p>Keep this terminal open for the duration of your session to keep the ssh tunnel active.</p> <p>Now you are ready to launch your ParaView client locally. Keep in mind that client and server versions must match. The ParaView version currently deployed on Aurora is 5.13.2.</p>"},{"location":"aurora/visualization/paraview-manual-launch/#connecting-to-paraview-server","title":"Connecting to ParaView server","text":"<p>Connect your ParaView client to the server configuration you created above. You can select Connect, either from the File menu or the icon circled in the figure:</p> <p> </p> <p>and select the configuration you created in a previous step.</p> <p>The connection should point to:</p> <pre><code>localhost:8000\n</code></pre> <p>In the terminal where you launched the server, you will see now that the connection is established. Note that ParaView may take a few seconds to connect. This is normal behavior.</p> <pre><code>username@x4706c7s4b0n0:~&gt; mpiexec -n 8 pvserver --server-port=8000\nWaiting for client...\nConnection URL: cs://x4706c7s4b0n0:8000\nAccepting connection(s): x4706c7s4b0n0:8000\nClient connected.\n</code></pre> <p>At this point, you can use ParaView normally.</p>"},{"location":"aurora/visualization/paraview/","title":"ParaView on Aurora","text":"<p>The recommended way of running ParaView on Aurora is in client/server mode. This consists of running the ParaView client on your local resource and the ParaView server on the Aurora compute nodes. The ParaView client needs to first be installed on your local resource and must match the version that you run on Aurora.</p> <p>There may be multiple versions of ParaView installed on Aurora. To find the versions of ParaView currently available on Aurora, run the following command on a login node:  <pre><code>module use /soft/modulefiles\nmodule avail paraview\n</code></pre></p> <p>Binary and source packages of the ParaView client for Linux, macOS, and Windows are available from the ParaView Download Page. </p>"},{"location":"aurora/visualization/paraview/#connecting-to-the-paraview-server-on-aurora","title":"Connecting to the ParaView server on Aurora","text":"<p>This section describes how to launch the ParaView server on Aurora from a local ParaView client.</p>"},{"location":"aurora/visualization/paraview/#start-paraview-client","title":"Start ParaView Client","text":"<p>First, launch the ParaView client on your local resource. You will need to configure some server settings in the client. This initial setup should only need to be done once and can be reused each time you want to run ParaView on Aurora.</p>"},{"location":"aurora/visualization/paraview/#server-configuration","title":"Server Configuration","text":""},{"location":"aurora/visualization/paraview/#1-select-connect","title":"1. Select Connect","text":"<p>From the ParaView client, choose to connect to a server by either clicking on the \"Connect\" icon in the menu bar</p> <p> </p> <p>or selecting File-&gt;Connect from the main menu.</p> <p></p>"},{"location":"aurora/visualization/paraview/#2-set-up-servers-first-time-only","title":"2. Set Up Servers (first time only)","text":"<p>The first time you want to run a server on Aurora and have it connect to your local ParaView client, you will need to set up a server. Once this server is set up, you can reuse it each time you run the ParaView client with the ParaView server on Aurora.</p> <p>Kitware, the developers of ParaView, maintain a database of server configurations that you can retrieve through the ParaView client.</p> <p>NOTE</p> <p>At this time, there are no specific files for Aurora available from Kitware. We will update this page when the files are available. In the meantime, you can download configuration files here and import them with the <code>Load Servers</code> option. Please use the <code>Save link as</code> option in your browser. Mac/Linux  |  Windows</p>"},{"location":"aurora/visualization/paraview/#3-use-paraview","title":"3. Use ParaView","text":"<p>After the previous step, you can now select AURORA@ANL in the File-&gt;Connect menu and press Connect.</p> <p></p> <p>At this point, a new window will pop up.</p> <p></p> <p>There are a number of parameters that you must enter manually here:</p> <p>Xterm executable: the path of a terminal on your system. The figure shows the case of a Mac with XQuartz. You may need to change these values for Windows or Linux.</p> <p>SSH executable: the name of your SSH command. It may be different on Windows depending on the SSH client installed (e.g., PuTTY).</p> <p>Remote machine: leave this value at aurora.alcf.anl.gov.</p> <p>Username: your ALCF username.</p> <p>ParaView version: the version of ParaView that you want to use. Verify first that this version is installed on the system (as described at the top of this document).</p> <p>Example: <pre><code>5.13.2\n</code></pre></p> <p>-Client port: it is safe to use the default value.</p> <p>-Server port: it is safe to use the default value.</p> <p>-Number of nodes to reserve: enter the number of Aurora compute nodes you want to use for your job.</p> <p>-Number of ranks per node: enter the number of ranks per node.</p> <p>-Number of minutes to reserve: the duration of your job in minutes.</p> <p>-Account: enter here the name of your ALCF allocation.</p> <p>-Queue: the name of the Aurora queue you would like to use (e.g., <code>debug</code>, <code>debug-scaling</code>, <code>prod</code>, <code>prod-large</code>).</p> <p>-File Systems: enter here the file systems you need for your job, separated with colons, no spaces. Keep in mind that your job may not run if one of these file systems is not available at that time, so enter these values carefully.</p> <p>-Job name: safe to use the default value. The PBS scheduler will assign this name to your job.</p> <p>Now you can press OK to establish the connection with a ParaView server on Aurora.</p> <p>An SSH connection will be established with a Aurora login node, and a password will be requested in a terminal, similar to the process you normally use to connect and work on the system.</p> <p>After you enter your password, a job will be queued, and you will see a window like this:</p> <p></p> <p>When the job is launched on the compute nodes, the previous window will go away, and ParaView will show it is connected to Aurora in its Pipeline Browser:</p> <p></p> <p>At this point, you can open datasets stored on the ALCF file systems and use ParaView normally.</p>"},{"location":"aurora/visualization/paraview/#additional-information","title":"Additional Information","text":"<ul> <li>ParaView Documentation</li> <li>ParaView Community Support</li> </ul>"},{"location":"aurora/visualization/visit/","title":"VisIt on Aurora","text":""},{"location":"aurora/visualization/visit/#getting-started","title":"Getting Started","text":"<p>As of June 2025, the latest VisIt version installed on Aurora is 3.4.2.</p> <p>Follow these steps to install VisIt on your local machine:</p> <ul> <li>Download and install VisIt for your local platform (macOS, Windows, Linux). The version you download must match the server version installed on Polaris. Use this page</li> <li>Download the Aurora host profile for VisIt (you may need to right-click and choose \"Save link as...\" or \"Save target as...\")</li> <li>Copy this file to a file called <code>~/.visit/hosts/host_anl_aurora.xml</code> on Mac or Linux. For Windows, specify the equivalent path.</li> </ul> <p>Note: VisIt allows the user to download host profiles for ANL, but all these settings are outdated. We are working with the VisIt developers to update the ANL host list.</p> <p>Additional information for using VisIt in client/server mode is available here.</p>"},{"location":"aurora/visualization/visit/#running-visit","title":"Running VisIt","text":"<ul> <li>Start up VisIt on your local machine.</li> <li>Click File -&gt; Open File and choose \"ANL Aurora\" from the \"Host\" dropdown.</li> </ul> <ul> <li>You'll be prompted for your password; enter your ALCF authenticator app response.</li> <li>When you open a selected file, it will launch a job on Aurora.</li> <li>You will need to specify the \"Bank\" (Project) to use when VisIt submits jobs to the queue on Aurora. Specify a project in the Options box.</li> <li>If your environment doesn't get sourced correctly with non-interactive SSH, you can set the default project to use under Options -&gt; Host profiles.</li> </ul> <p>Warning</p> <p>Don't change the contents of the \"Machine file\" field (it should be <code>$PBS_NODEFILE</code>).</p> <p>Tip</p> <p>The default Launch Profile is set to serial. We recommend leaving this setting in its default value, but using the parallel method to launch jobs on Aurora.</p> <p>Warning</p> <p>Don't change the contents of \"launchMethod\". It must be <code>qsub/aprun</code> even though Aurora does not use <code>aprun</code>.</p> <ul> <li>The Aurora host profile linked above contains an empty user name. Make sure to update with your user name.</li> <li>If you'd like to change other job parameters (like the number of processes, nodes, and walltime), you can do so. Please enter time in the format required by the PBS scheduler (i.e., 1:00:00 for one hour).</li> <li>If you'd like these changes to be used as your default, be sure to save them using Save Settings under the Options menu.</li> </ul>"},{"location":"aurora/visualization/visit/#additional-information","title":"Additional Information","text":"<ul> <li>VisIt user manual</li> <li>VisIt wiki</li> </ul>"},{"location":"aurora/workflows/adios/","title":"ADIOS2","text":"<p>The Adaptable Input/Output (I/O) System (ADIOS2) is a framework for I/O and streaming of scientific data developed as part of the U.S. DOE Exascale Computing Project. ADIOS2 conveniently provides C, C++, Fortran, and Python APIs for traditional file system I/O, as well as APIs for transporting data between applications running concurrently on HPC systems. Data transport with ADIOS2 can be performed via the file system, wide-area networks (WAN), remote direct memory access (RDMA), or MPI to construct a variety of workflows, such as in-situ (or in-transit) visualization, data analysis, and ML training and inference from ongoing simulations.</p> <p>Users are invited to find more information about ADIOS2 on their GitHub page and their documentation.</p>"},{"location":"aurora/workflows/adios/#accessing-adios2-on-aurora","title":"Accessing ADIOS2 on Aurora","text":"<p>Pre-built modules are available to all users, enabling access to the latest version of ADIOS2 (v2.10). These modules can be displayed with <code>module avail adios2</code> and comprise a CPU-only build and a SYCL build of the library, with the SYCL build being the default. Note that both ADIOS2 modules also load a Spack installation of Python 3.10 with the <code>numpy</code>, <code>mpi4py</code>, and <code>adios2</code> packages. For instance, the default SYCL build can be loaded by executing</p> <pre><code>module load adios2\n</code></pre> <p>A custom build of ADIOS2 is also possible on Aurora. In this case, we recommend users start with the following install script for a base build:</p> install_adios2.sh<pre><code>export CRAYPE_LINK_TYPE=dynamic\ngit clone https://github.com/ornladios/ADIOS2.git ADIOS2\nmkdir adios2-build &amp;&amp; cd adios2-build\ncmake \\\n    -DCMAKE_INSTALL_PREFIX=${PWD}/install \\\n    -DADIOS2_BUILD_EXAMPLES=ON \\\n    -DADIOS2_USE_MPI=ON \\\n    -DADIOS2_HAVE_MPI_CLIENT_SERVER=ON \\\n    -DADIOS2_USE_SST=ON \\\n    -DADIOS2_USE_SSC=ON \\\n    -DADIOS2_USE_Python=OFF \\\n    -DADIOS2_USE_HDF5=OFF \\\n    -DADIOS2_USE_BZip2=OFF \\\n    -DCMAKE_BUILD_TYPE=RelWithDebInfo \\\n    ../ADIOS2 2&gt;&amp;1 | tee adios2_config.log\nmake -j 8 2&gt;&amp;1 | tee adios2_build.log\nmake install 2&gt;&amp;1 | tee adios2_install.log\ncd ..\n</code></pre> <p>Building the Python bindings</p> <p>The Python bindings for ADIOS2 can be built by setting <code>ADIOS2_USE_Python=ON</code>; however, this requires a Python 3 installation to be found. We recommend users load the Python AI/ML module with <code>module load frameworks</code> and build ADIOS2 under this environment. This will require users to augment their Python path with <code>export PYTHONPATH=$PYTHONPATH:/path/to/adios2-build/install/lib/python3.10/site-packages</code> in order to use the <code>adios2</code> package. Alternatively, users can use a custom Python installation, but note that ADIOS2 requires <code>numpy</code> and <code>mpi4py</code> as well.</p> <p>A full list of CMake options is available in the documentation.</p>"},{"location":"aurora/workflows/adios/#mixed-c-and-python-hello-world-example","title":"Mixed C++ and Python Hello World Example","text":"<p>Here we show a basic example of using ADIOS2 to stream data between a C++ data producer (e.g., a simulation) and a Python data consumer (e.g., a data analysis or ML component). Both applications are MPI programs. In this simple workflow, each application loops over a workflow iteration loop, in which the producer writes data to the stream and the consumer reads the data. The ADIOS2 IO engine is set to SST for data streaming, and the engine parameters are set to force the producer to pause execution until the consumer has read the data for a given step. This is not a requirement and can be modified with the <code>RendezvousReaderCount</code>, <code>QueueFullPolicy</code>, and <code>QueueLimit</code> parameters. More information on the SST engine can be found in the documentation as well as in the provided examples.</p> producer.cpp<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;adios2.h&gt;\n#include &lt;mpi.h&gt;\n#include &lt;unistd.h&gt;\n\ntemplate &lt;class T&gt;\nvoid PrintData(const std::vector&lt;T&gt; &amp;data, const int rank, const size_t step)\n{\n    std::cout &lt;&lt; \"\\tProducer Rank[\" &lt;&lt; rank &lt;&lt; \"]: send data [\";\n    for (size_t i = 0; i &lt; data.size(); ++i)\n    {\n        std::cout &lt;&lt; data[i] &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; \"]\" &lt;&lt; std::endl;\n}\n\nint main(int argc, char *argv[])\n{\n\n    // MPI_THREAD_MULTIPLE is only required if you enable the SST MPI_DP\n    int rank, size, provide;\n    MPI_Init_thread(&amp;argc, &amp;argv, MPI_THREAD_MULTIPLE, &amp;provide);\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n    // Create a new communicator\n    int color = 3130, arank, asize;\n    MPI_Comm app_comm;\n    MPI_Comm_split(MPI_COMM_WORLD, color, rank, &amp;app_comm);\n    MPI_Comm_rank(app_comm, &amp;arank);\n    MPI_Comm_size(app_comm, &amp;asize);\n\n    // ADIOS IO Setup\n    adios2::ADIOS adios(app_comm);\n    adios2::IO sstIO = adios.DeclareIO(\"myIO\");\n    sstIO.SetEngine(\"Sst\");\n    adios2::Params params;\n    params[\"RendezvousReaderCount\"] = \"1\";\n    params[\"QueueFullPolicy\"] = \"Block\";\n    params[\"QueueLimit\"] = \"1\";\n    params[\"DataTransport\"] = \"RDMA\";\n    params[\"OpenTimeoutSecs\"] = \"600\";\n    sstIO.SetParameters(params);\n\n    // Setup the data to send\n    std::vector&lt;float&gt; myArray = {0.0, 1.0, 2.0, 3.0, 4.0};\n    const std::size_t Nx = myArray.size();\n    for (size_t k = 0; k &lt; myArray.size(); ++k) {\n        myArray[k] = myArray[k] + static_cast&lt;float&gt;(Nx * arank);\n    }\n    const float increment = (float)(Nx * asize * 1.0);\n\n    // Define variable and local size\n    auto bpFloats = sstIO.DefineVariable&lt;float&gt;(\"y\", {asize * Nx}, {arank * Nx}, {Nx});\n\n    int workflow_steps = 2;\n    adios2::Engine sstWriter = sstIO.Open(\"data_stream\", adios2::Mode::Write);\n    for (size_t i = 0; i &lt; workflow_steps; ++i) {\n        sleep(3);\n        if (arank == 0)\n            std::cout &lt;&lt; \"\\n Iteration \" &lt;&lt; i &lt;&lt; std::endl;\n        sstWriter.BeginStep();\n        sstWriter.Put&lt;float&gt;(bpFloats, myArray.data());\n        PrintData(myArray, rank, i);\n        sstWriter.EndStep();\n        for (size_t k = 0; k &lt; myArray.size(); ++k) {\n            myArray[k] += increment;\n        }\n    }\n    sstWriter.Close();\n\n    MPI_Finalize();\n\n    return 0;\n}\n</code></pre> consumer.py<pre><code>from mpi4py import MPI\nimport numpy as np\nfrom adios2 import Stream, Adios, bindings\n\n# MPI Init\nCOMM = MPI.COMM_WORLD\nRANK = COMM.Get_rank()\nSIZE = COMM.Get_size()\n\nif __name__ == '__main__':\n    # Create new communicator (needed for launch on MPMD mode)\n    color = 3230\n    app_comm = COMM.Split(color, RANK)\n    asize = app_comm.Get_size()\n    arank = app_comm.Get_rank()\n    adios = Adios(app_comm)\n\n    # ADIOS IO Setup\n    io = adios.declare_io(\"myIO\")\n    io.set_engine(\"SST\")\n    parameters = {\n        'RendezvousReaderCount': '1', # options: 1 for sync, 0 for async\n        'QueueFullPolicy': 'Block', # options: Block, Discard\n        'QueueLimit': '1', # options: 0 for no limit\n        'DataTransport': 'RDMA', # options: MPI, WAN, UCX, RDMA\n        'OpenTimeoutSecs': '600', # number of seconds SST is to wait for a peer connection on Open()\n    }\n    io.set_parameters(parameters)\n\n    # Loop over workflow steps and read data at each step\n    workflow_steps = 2\n    with Stream(io, \"data_stream\", \"r\", app_comm) as stream:\n        for istep in range(workflow_steps):\n            stream.begin_step()\n            var = stream.inquire_variable(\"y\")\n            shape = var.shape()\n            count = int(shape[0] / asize)\n            start = count * arank\n            if arank == asize - 1:\n                count += shape[0] % asize\n            data = stream.read(\"y\", [start], [count])\n            print(f\"\\tConsumer [{arank}]: received data {data}\",flush=True)\n            stream.end_step()\n</code></pre> <p>To build the C++ producer, use the following CMake file:</p> CMakeLists.txt<pre><code>cmake_minimum_required(VERSION 3.12)\nproject(ADIOS2HelloExample)\n\nif(NOT TARGET adios2_core)\n  set(_components CXX)\n\n  find_package(MPI COMPONENTS C)\n  if(MPI_FOUND)\n    # Workaround for various MPI implementations forcing the link of C++ bindings\n    add_definitions(-DOMPI_SKIP_MPICXX -DMPICH_SKIP_MPICXX)\n\n    list(APPEND _components MPI)\n  endif()\n\n  find_package(ADIOS2 REQUIRED COMPONENTS ${_components})\nendif()\n\nadd_executable(producer producer.cpp)\ntarget_link_libraries(producer adios2::cxx11_mpi MPI::MPI_CXX)\n\ninstall(TARGETS producer RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR})\n</code></pre> <p>and execute the following commands:</p> <pre><code>module load adios2\nmodule load cmake\n\ncmake ./\nmake\n</code></pre> <p>The example can be run from an interactive session with the following script, which runs the producer and consumer with two ranks per node and places the producer on socket 0 and the consumer on socket 1 of each node. The producer and consumer can also be run on separate nodes by specifying the <code>--hostfile</code> or <code>--hostlist</code> in the <code>mpiexec</code> commands.</p> run_adios_example.sh<pre><code>#!/bin/bash\n\nmodule load adios2\n\nexport OMP_PROC_BIND=spread\nexport OMP_PLACES=threads\n\nNODES=$(cat $PBS_NODEFILE | wc -l)\nPROCS_PER_NODE=2\nPROCS=$((NODES * PROCS_PER_NODE))\n\n# Run Python example\nmpiexec -n $PROCS --ppn $PROCS_PER_NODE --cpu-bind list:1:2 producer &amp;\nmpiexec -n $PROCS --ppn $PROCS_PER_NODE --cpu-bind list:53:54 python consumer.py\nwait\n</code></pre> <p>Selecting the SST Data Transport Plane</p> <p>The SST data transport plane can be selected with the parameter <code>DataTransport</code>. We recommend using RDMA; however, note that it requires running the applications on more than one node. The WAN data plane can also be used, but it may result in slower data transfer performance at scale. The MPI data plane is currently not available, but we are working on resolving the issue with the ADIOS2 team.</p>"},{"location":"aurora/workflows/balsam/","title":"Balsam on Aurora","text":"<p>Balsam is a toolkit for managing large computational campaigns on HPC systems. Balsam helps users execute large numbers of jobs with inter-job dependencies, track job outcomes, and manage post-processing analysis. The command line interface and Python API make it easy for users to adopt: after wrapping the command line for an application in a few lines of Python code, users can describe jobs with accompanying options. These jobs are stored persistently in the Balsam database. Balsam is especially well-suited for executing large ensembles of MPI tasks with a variety of sizes.</p> <p>A user's Balsam service consists of a Balsam Site process that runs on a login node that orchestrates the execution of work, and a Balsam Site directory space where job and workflow results are stored. When the user submits a batch job to PBS through Balsam, the Site process pulls Balsam jobs from the database and executes them within the PBS batch job, achieving high throughput while incurring only a single wait-time in the queue.</p> <p>The full Balsam documentation covers all functionality for users, including additional examples, and describes the Balsam architecture for potential developers.</p>"},{"location":"aurora/workflows/balsam/#setup-and-installation","title":"Setup and installation","text":"<p>Balsam requires Python 3.7+. To install Balsam on Aurora, first set up a virtual Python environment:</p> <pre><code>module load frameworks\npython -m venv _env\nsource _env/bin/activate\npip install --upgrade pip\npip install --pre balsam\n</code></pre> <p>Alternatively, Balsam can be installed in a conda environment also with pip.</p> <p>The Balsam command line tool will now be in your path. To get information on how to use the command line tool, you can type <code>balsam --help</code> in your shell.</p> <p>To use Balsam, users need an account on the Balsam server. Users can get an account by contacting the ALCF Help Desk. Once a user has an account, they can log in and make a new site. A Balsam site is a project space for your workflow. You will be prompted to select what machine (Aurora) you are working on when creating a new site:</p> <pre><code>balsam login\nbalsam site init -n new-site new-site\ncd new-site\nbalsam site start\n</code></pre>"},{"location":"aurora/workflows/balsam/#aurora-specific-notes","title":"Aurora specific notes","text":"<p>In the Balsam configuration for Aurora, a Balsam <code>gpu</code> refers to an Aurora node GPU tile. Setting the Balsam job option <code>gpus_per_rank = 1</code> will place one rank per GPU tile. Setting <code>gpus_per_rank = 2</code> will place one rank per GPU.</p>"},{"location":"aurora/workflows/balsam/#simple-mpi-ensemble-on-aurora-with-balsam","title":"Simple MPI ensemble on Aurora with Balsam","text":"<p>Here is an example that runs an application <code>hello_affinity</code> from our getting started guide in <code>mpi-mode</code>, which will execute the application with <code>mpiexec</code>. We also show an example of executing an echo command that takes an argument and runs on a single GPU tile.</p> <p>Warning</p> <p>Ensembles of tasks launched with <code>mpiexec</code> on multiple nodes are currently limited to 1000 total tasks run per batch job. This means when <code>mpiexec</code> calls return, the nodes they used can refill only a limited number of times, rather than an arbitrary number of times like on Polaris. This is due to a known issue with Slingshot and will be fixed in the future. Users running MPI application ensembles on Aurora with Balsam should take this into account when configuring their workflows.</p> balsam_job_ensemble.py<pre><code>from balsam.api import ApplicationDefinition, Job\n\n# Define an application that runs an echo command and takes an input\nclass EchoHello(ApplicationDefinition):\n    site = \"test_aurora\"\n    command_template = \"echo Hello, {{ say_hello_to }}! ZE_AFFINITY_MASK=$ZE_AFFINITY_MASK OMP_NUM_THREADS=$OMP_NUM_THREADS\"\nEchoHello.sync()\n\n# Define an application that runs a compiled executable and is wrapped by the gpu affinity script\nclass HelloAffinity(ApplicationDefinition):\n    site = \"test_aurora\"\n    command_template = \"$HOME/GettingStarted/HelperScripts/Aurora/set_affinity_gpu_aurora.sh $HOME/GettingStarted/Examples/Aurora/affinity_gpu/sycl/hello_affinity\"\nHelloAffinity.sync()\n\n# Create a Balsam job that runs hello_affinity on one node with twelve ranks per node\naffinity_job = Job(site_name=\"test_aurora\",\n                   app_id=\"HelloAffinity\",\n                   workdir=f\"demo/hello_affinity\",\n                   tags={\"workflow\":\"demo\"},\n                   num_nodes=1,\n                   node_packing_count=1,\n                   ranks_per_node=12,\n                   gpus_per_rank=1)\n\n# This call saves a single Balsam job to the database\naffinity_job.save()\n\n# Create many Balsam jobs that run the EchoHello app each on a single tile\necho_jobs = [Job( site_name=\"test_aurora\", \n         app_id=\"EchoHello\", \n         workdir=f\"demo/echo_hello{n}\", \n         parameters={\"say_hello_to\": f\"world {n}!\"},\n         tags={\"workflow\":\"demo\"}, \n         node_packing_count=12, # this allows for 12 of these jobs to run concurrently on a node\n         gpus_per_rank=1,\n         ranks_per_node=1,)       \n    for n in range(24)\n]\n\n# This call saves a list of jobs to the database\necho_jobs = Job.objects.bulk_create(echo_jobs)\n</code></pre> <p>After execution of this script, your site will have two registered apps and several Balsam jobs. Use the Balsam CLI tool to query them:</p> <p>To check apps registered in a site: <pre><code>balsam app ls\n</code></pre></p> <p>To check the status of jobs in the site: <pre><code>balsam job ls\n</code></pre></p> <p>To submit a batch job to PBS to execute the Balsam jobs in your site, you can do so at the command line from within your site directory: <pre><code>balsam queue submit -n 2 -t 10 -q debug-scaling -A &lt;project_name&gt; -j mpi\n</code></pre> This will submit a 2-node job (<code>-n</code> option) to the <code>debug-scaling</code> queue in mpi mode (<code>-j</code> option). MPI-mode batch jobs like this one will execute applications with <code>mpiexec</code>.  The time limit for the batch job is set to 10 minutes (<code>-t</code> option).</p> <p>You can also submit jobs with the Python API: submit_mpi_mode.py<pre><code>from balsam.api import BatchJob, Site\n\n# Get the site id\nsite = Site.objects.get(\"test_aurora\")\nsite_id = site.id\n\n# Submit batch job to PBS\nBatchJob.objects.create(\n   site_id=site_id,\n   num_nodes=2,\n   wall_time_min=10,\n   job_mode=\"mpi\", # This mode will execute the application with mpiexec\n   queue=\"debug-scaling\",\n   project=\"Aurora_deployment\", # put your &lt;project_name&gt; here\n)\n</code></pre></p> <p>To check the status of batch jobs that Balsam is tracking: <pre><code>balsam queue ls\n</code></pre> and batch jobs it has completed: <pre><code>balsam queue ls --history\n</code></pre></p> <p>The standard output (stdout) will be written to each job's workdir in the data directory to a file called <code>job.out</code> and can be accessed like this: <pre><code>cat data/demo/*/job.out\n</code></pre></p> <p>Batch jobs created by Balsam will have a name beginning with <code>qlaunch</code> when queried with the <code>PBS</code> command <code>qstat</code>.</p> <p>Balsam has additional features that will submit work to PBS elastically, a special app type for native Python code, and a <code>serial</code> job mode for executing tasks that are single core/GPU that do not require MPI launching. More information can be found in the Balsam documentation.</p>"},{"location":"aurora/workflows/balsam/#troubleshooting","title":"Troubleshooting","text":"<p>If Balsam is failing to submit batch jobs to PBS, check the <code>settings.yml</code> file in the Balsam site directory and look for the section <code>allowed_queues</code>.  The queue you are submitting to must appear in this section of the settings.  If it does not, add it and restart the site process with: <pre><code>balsam site stop\nbalsam site start\n</code></pre></p> <p>If the queue does appear, get more information about the batch jobs Balsam is submitting to PBS with: <pre><code>balsam queue ls -v --history\n</code></pre></p>"},{"location":"aurora/workflows/libensemble/","title":"libEnsemble on Aurora","text":"<p>libEnsemble is a Python toolkit for running dynamic ensembles of calculations.</p> <p>Users provide generator and simulator functions to express their ensembles, where the generator can steer the ensemble based on previous results. These functions can portably submit user executables at any scale.</p> <p>System details are detected, and dynamic resource management is provided. This includes automatically detecting, assigning, and reassigning GPUs for ensemble members.</p> <p>libEnsemble can be used in a consistent manner on laptops, clusters, and supercomputers with minimal required dependencies.</p>"},{"location":"aurora/workflows/libensemble/#configuring-python-and-installation","title":"Configuring Python and Installation","text":"<p>To obtain Python and create a virtual environment:</p> <pre><code>module load frameworks\npython -m venv /path/to-venv --system-site-packages\n. /path/to-venv/bin/activate\n</code></pre> <p>where <code>/path/to-venv</code> can be anywhere you have write access. For future sessions, just load the frameworks module and run the activate line.</p> <p>To obtain libEnsemble, execute:</p> <pre><code>pip install libensemble\n</code></pre> <p>See the ALCF docs for more details on using Python on Aurora.</p>"},{"location":"aurora/workflows/libensemble/#example","title":"Example","text":"<p>To run the forces_gpu tutorial on Aurora.</p> <p>To obtain the example, you can clone the <code>libEnsemble</code> repository--- although only the <code>forces</code> sub-directory is needed:</p> <pre><code>git clone https://github.com/Libensemble/libensemble\ncd libensemble/libensemble/tests/scaling_tests/forces/forces_app\n</code></pre> <p>To compile <code>forces</code> (a C application with OpenMP target):</p> <pre><code>mpicc -DGPU -O3 -fiopenmp -fopenmp-targets=spir64 -o forces.x forces.c\n</code></pre> <p>Now go to the <code>forces_gpu</code> directory:</p> <pre><code>cd ../forces_gpu\n</code></pre> <p>To use all available GPUs, open <code>run_libe_forces.py</code> and adjust the exit criteria to perform more simulations. The following will run two simulations per worker:</p> <pre><code># Instruct libEnsemble to exit after this many simulations\nensemble.exit_criteria = ExitCriteria(sim_max=nsim_workers*2)\n</code></pre> <p>Now grab an interactive session on two nodes (or use the batch script at <code>../submission_scripts/submit_pbs_aurora.sh</code>):</p> <pre><code>qsub -A &lt;myproject&gt; -l select=2 -l walltime=15:00 -lfilesystems=home:flare -q debug -I\n</code></pre> <p>Once in the interactive session, you may need to reactivate your virtual environment:</p> <pre><code>cd $PBS_O_WORKDIR\n. /path/to-venv/bin/activate\n</code></pre> <p>Then, run:</p> <pre><code>python run_libe_forces.py -n 13\n</code></pre> <p>This provides twelve workers for running simulations (one for each GPU across two nodes). An extra worker runs the persistent generator. GPU settings for each worker simulation are printed.</p> <p>Looking at <code>libE_stats.txt</code> will provide a summary of the runs.</p> <p>Try running</p> <pre><code>./cleanup.sh\npython run_libe_forces.py -n 7\n</code></pre> <p>And you will see it runs with two cores (MPI ranks) and two GPUs are used per worker.</p>"},{"location":"aurora/workflows/libensemble/#live-viewing-gpu-usage","title":"Live viewing GPU usage","text":"<p>To see GPU usage, SSH into a compute node you are on in another window and run:</p> <pre><code>module load xpu-smi\nwatch -n 0.1 xpu-smi dump -d -1 -m 0 -n 1\n</code></pre>"},{"location":"aurora/workflows/libensemble/#using-tiles-as-gpus","title":"Using Tiles as GPUs","text":"<p>To treat each tile as its own GPU, add the <code>use_tiles_as_gpus=True</code> option to the <code>libE_specs</code> block in <code>run_libe_forces.py</code>:</p> <pre><code>ensemble.libE_specs = LibeSpecs(\n    num_resource_sets=nsim_workers,\n    sim_dirs_make=True,\n    use_tiles_as_gpus=True,\n)\n</code></pre> <p>Now, rerun with twice the workers:</p> <pre><code>python run_libe_forces.py -n 25\n</code></pre> <p>The <code>forces</code> example will automatically use the GPUs available to each worker (one MPI rank per GPU). If fewer workers are provided, multiple GPUs will be used per simulation.</p> <p>Also, see <code>forces_gpu_var_resources</code> and <code>forces_multi_app</code> examples for cases using varying processor/GPU counts per simulation.</p>"},{"location":"aurora/workflows/libensemble/#running-generator-on-the-manager","title":"Running generator on the manager","text":"<p>An alternative is to run the generator on a thread on the manager. The number of workers can then be set to the number of simulation workers.</p> <p>Change the <code>libE_specs</code> in run_libe_forces.py as follows:</p> <pre><code>nsim_workers = ensemble.nworkers\n\n# Persistent gen does not need resources\nensemble.libE_specs = LibeSpecs(\n    gen_on_manager=True,\n</code></pre> <p>then the first run we did will use 12 instead of 13 workers:</p> <pre><code>python run_libe_forces.py -n 12\n</code></pre>"},{"location":"aurora/workflows/libensemble/#dynamic-resource-assignment","title":"Dynamic resource assignment","text":"<p>In the forces directory you will also find:</p> <ul> <li><code>forces_gpu_var_resources</code> uses varying processor/GPU counts per simulation.</li> <li><code>forces_multi_app</code> uses varying processor/GPU counts per simulation and also uses two different user executables, one which is CPU-only and one which uses GPUs. This allows highly efficient use of nodes for multi-application ensembles.</li> </ul>"},{"location":"aurora/workflows/libensemble/#demonstration","title":"Demonstration","text":"<p>A video demonstration of the <code>forces_gpu</code> example on Frontier is available. The workflow is identical when running on Aurora, except for different compiler options and numbers of workers due to differing GPU counts per node.</p> <p>More details:</p> <ul> <li>libEnsemble Documentation</li> <li>libEnsemble GitHub page</li> <li>libEnsemble Documentation Aurora page</li> </ul>"},{"location":"aurora/workflows/parsl/","title":"Parsl on Aurora","text":"<p>Parsl is a parallel programming library for Python.  It can be used to deploy large numbers of tasks in parallel and with complex dependencies on ALCF machines, and is particularly well suited to run high-throughput workflows.  While Parsl is a Python library, it can execute tasks that run any compiled application.  Parsl can also execute tasks that run mpi applications.</p> <p>Parsl uses Python's concurrent futures module to create functions that return a Python futures object.  A Parsl workflow operates by creating futures for tasks that the Parsl executor will then fulfill by running them on available compute resources.</p> <p>A Parsl workflow contains two parts:</p> <ul> <li>The workflow logic of applications, tasks and task dependencies</li> <li>The configuration of compute resources that execute tasks</li> </ul> <p>Here we sketch out some possible configurations for executing workflows on Aurora.  </p> <p>These docs were written for Parsl 2025.1.13.</p>"},{"location":"aurora/workflows/parsl/#installation-and-setup","title":"Installation and Setup","text":"<p>Parsl is a Python library and can be installed with <code>pip</code>.  For example, in a Python virtual environment:</p> <pre><code>python -m venv $HOME/_env\nsource $HOME/_env/bin/activate\npip install parsl\n</code></pre> <p>Python on Aurora</p> <p>To get Python on Aurora, users can either load the AI frameworks module with <code>module load frameworks</code> or the basic Python 3.10 module with <code>module load python/3.10.13</code></p> <p>When using Parsl to distribute work over many PBS Jobs (first two examples below), your workflow script will be executed on a login node and will not return until all tasks are completed.  In this situation, it is advisable to run your script in a screen session on the login node.</p>"},{"location":"aurora/workflows/parsl/#parsl-config-for-a-large-ensemble-of-single-tile-tasks-run-over-many-pbs-jobs","title":"Parsl Config for a Large Ensemble of Single Tile tasks run over many PBS Jobs","text":"<p>A common use case is to run a large ensemble of tasks that each require one GPU tile on Aurora and to spread this workload over multiple PBS Jobs.  The reason for spreading this workload over many PBS Jobs may be the size of the ensemble and/or the runtime of the tasks.</p> <p>The <code>Config</code> object for this case is defined like this:</p> config.py<pre><code># config.py\nimport os\nfrom parsl.config import Config\n\n# PBSPro is the right provider for ALCF:\nfrom parsl.providers import PBSProProvider\n# The high throughput executor is for scaling large single core/tile/gpu tasks on HPC system:\nfrom parsl.executors import HighThroughputExecutor\n# Use the MPI launcher to launch worker processes:\nfrom parsl.launchers import MpiExecLauncher\n\n# These options will run work in 1 node batch jobs run one at a time\nnodes_per_job = 1\nmax_num_jobs = 1\ntile_names = [f'{gid}.{tid}' for gid in range(6) for tid in range(2)]\n\n# The config will launch workers from this directory\nexecute_dir = os.getcwd()\n\naurora_single_tile_config = Config(\n    executors=[\n        HighThroughputExecutor(\n            # Ensures one worker per GPU tile on each node\n            available_accelerators=tile_names,\n            max_workers_per_node=12,\n            # Distributes threads to workers/tiles in a way optimized for Aurora\n            cpu_affinity=\"list:1-8,105-112:9-16,113-120:17-24,121-128:25-32,129-136:33-40,137-144:41-48,145-152:53-60,157-164:61-68,165-172:69-76,173-180:77-84,181-188:85-92,189-196:93-100,197-204\",\n            # Increase if you have many more tasks than workers\n            prefetch_capacity=0,\n            # Options that specify properties of PBS Jobs\n            provider=PBSProProvider(\n                # Project name\n                account=\"Aurora_deployment\",\n                # Submission queue\n                queue=\"debug\",\n                # Commands run before workers launched\n                # Make sure to activate your environment where Parsl is installed\n                worker_init=f'''source $HOME/_env/bin/activate; cd {execute_dir}''',\n                # Wall time for batch jobs\n                walltime=\"0:30:00\",\n                # Change if data/modules located on other filesystem\n                scheduler_options=\"#PBS -l filesystems=home:flare\",\n                # Ensures 1 manger per node; the manager will distribute work to its 12 workers, one per tile\n                launcher=MpiExecLauncher(bind_cmd=\"--cpu-bind\", overrides=\"--ppn 1\"),\n                # options added to #PBS -l select aside from ncpus\n                select_options=\"\",\n                # Number of nodes per PBS job\n                nodes_per_block=nodes_per_job,\n                # Minimum number of concurrent PBS jobs running workflow\n                min_blocks=0,\n                # Maximum number of concurrent PBS jobs running workflow\n                max_blocks=max_num_jobs,\n                # Hardware threads per node\n                cpus_per_node=208,\n            ),\n        ),\n    ],\n    # How many times to retry failed tasks\n    # this is necessary if you have tasks that are interrupted by a PBS job ending\n    # so that they will restart in the next job\n    retries=1,\n)\n</code></pre> <p>Import this <code>Config</code> object and use in a workflow script, e.g.:</p> <p>my_parsl_workflow.py<pre><code># my_parsl_workflow.py\nimport os\nimport parsl\nfrom parsl import bash_app, python_app\n\nfrom config import aurora_single_tile_config\n\n# Bash apps are for executing compiled applications or other shell commands\n@bash_app\ndef hello_affinity(stdout='hello.stdout', stderr='hello.stderr'):\n    return f'$HOME/GettingStarted/Examples/Aurora/affinity_gpu/sycl/hello_affinity'\n\n# Python apps are for executing native python functions\n@python_app\ndef hello_world(message, sleep_time=1):\n    import time\n    time.sleep(sleep_time)\n    return f\"Hello {message}\"\n\nworking_directory = os.getcwd()\n\nprint(\"Starting my_parsl_workflow\")\n\nwith parsl.load(aurora_single_tile_config):\n\n    # Create 12 hello_world tasks\n    hello_world_futures = [hello_world(f\"Aurora {i}\") for i in range(12)]\n    print(f\"Created {len(hello_world_futures)} hello_world tasks\")\n\n    # Create 12 hello_affinity tasks\n    hello_affinity_futures = [hello_affinity(stdout=f\"{working_directory}/output/hello_{i}.stdout\",\n                                             stderr=f\"{working_directory}/output/hello_{i}.stderr\")\n                              for i in range(12)]\n    print(f\"Created {len(hello_world_futures)} hello_affinity tasks\")\n\n    # This line will block until all hello_world results are returned\n    hello_world_results = [tf.result() for tf in hello_world_futures]\n    print(\"hello_world tasks complete\")\n    print(f\"python apps like hello_world return the function result, e.g. {hello_world_results[0]=}\")\n\n    # This line will block until all hello_affinity results are returned\n    hello_affinity_results = [tf.result() for tf in hello_affinity_futures]\n    print(\"hello_affinity tasks complete\")\n    print(f\"bash apps like hello_affinity return the return code of the executable, e.g. {hello_affinity_results[0]=}\")\n\n    print(f\"Read results of hello_affinity from stdout file:\")\n    for i,tf in enumerate(hello_affinity_futures):\n        with open(f\"{working_directory}/output/hello_{i}.stdout\", \"r\") as f:\n            outputs = f.readlines()\n            print(outputs)\n\n    print(\"Tasks done!\")\n</code></pre> Note that a Parsl workflow script must block at some point on the result of all tasks that are created in order to ensure that the tasks complete.</p> <p>To run this workflow script: <pre><code>source $HOME/_env/bin/activate\npython my_parsl_workflow.py\n</code></pre></p> <p>When executing this script, the script will block until all tasks are completed. You may wish to check the scheduler to verify that Parsl queues a job to execute the tasks.</p>"},{"location":"aurora/workflows/parsl/#parsl-config-for-ensemble-of-multinode-mpi-tasks-tasks-run-over-many-pbs-jobs","title":"Parsl Config for Ensemble of Multinode MPI tasks tasks run over many PBS Jobs","text":"<p>In the previous example, <code>mpiexec</code> was used as a launcher, rather than an executor.  In order to run applications that have MPI communication, <code>mpiexec</code> has to be used a different way by Parsl.  To run MPI applications, use the <code>SimpleLauncher</code> and the <code>MPIExecutor</code>.  Note that the configuration has to set <code>max_workers_per_block</code> to align with the resource needs of the application.  The <code>MPIExecutor</code> can only run tasks that use more than one node.</p> <p>Warning</p> <p>Ensembles of tasks launched with <code>mpiexec</code> on multiple nodes are currently limited to 1000 total tasks run per batch job.  This means when <code>mpiexec</code> calls return, the nodes they used can refill only a limited number of times, rather than an arbitrary number of times like on Polaris.  This is due to a known issue with Slingshot and will be fixed in the future.  Users running MPI application ensembles on Aurora with Parsl should take this into account when configuring their workflows.</p> <p>This example <code>Config</code> object can be used to execute MPI tasks that use two nodes each:</p> config.py<pre><code>import parsl\nimport os\nfrom parsl.config import Config\n# PBSPro is the right provider for ALCF:\nfrom parsl.providers import PBSProProvider\n# The MPIExecutor is for running MPI applications:\nfrom parsl.executors import MPIExecutor\n# Use the Simple launcher\nfrom parsl.launchers import SimpleLauncher\n\n# These options will run work in 10 node batch jobs run one at a time\nnodes_per_task = 2\nnodes_per_job = 10\nmax_num_jobs = 1\n\n# We will save outputs in the current working directory\nworking_directory = os.getcwd()\n\nmpi_ensemble_config = Config(\n    executors=[\n        MPIExecutor(\n            # This creates 1 worker for each multinode task slot\n            max_workers_per_block=nodes_per_job//nodes_per_task,\n            provider=PBSProProvider(\n                account=\"Aurora_deployment\",\n                worker_init=f\"\"\"source $HOME/_env/bin/activate; \\\n                                cd {working_directory}\"\"\",\n                walltime=\"0:30:00\",\n                queue=\"lustre_scaling\",\n                scheduler_options=\"#PBS -l filesystems=home:flare\",\n                launcher=SimpleLauncher(),\n                select_options=\"\",\n                nodes_per_block=nodes_per_job,\n                max_blocks=1,\n                cpus_per_node=208,\n            ),\n        ),\n    ],\n    retries=1,\n)\n</code></pre> <p>This example workflow uses this <code>Config</code> to run an ensemble of 2-node MPI tasks:</p> my_parsl_workflow.py<pre><code># my_parsl_workflow.py\nimport os\nimport parsl\nfrom parsl import bash_app\n\nfrom config import mpi_ensemble_config\n\n# This app will run the hello_affinity application with mpiexec\n# Using the set_affinity_gpu_aurora.sh script will bind each mpi rank to a gpu tile\n@bash_app\ndef mpi_hello_affinity(parsl_resource_specification, depth=8, stdout='mpi_hello.stdout', stderr='mpi_hello.stderr'):\n    APP_DIR = \"$HOME/GettingStarted\"\n    # PARSL_MPI_PREFIX will resolve to `mpiexec -n num_ranks -ppn ranks_per_node -hosts NODE001,NODE002`\n    return f\"$PARSL_MPI_PREFIX --cpu-bind depth --depth={depth} {APP_DIR}/HelperScripts/Aurora/set_affinity_gpu_aurora.sh {APP_DIR}/Examples/Aurora/affinity_gpu/sycl/hello_affinity\"\n\nprint(\"Starting my_parsl_workflow\")\n\nworking_directory = os.getcwd()\n\nwith parsl.load(mpi_ensemble_config):\n\n    task_futures = []\n\n    # Create 2-node tasks\n    # We set 12 ranks per node to match the number of gpu tiles on an aurora node\n    resource_specification = {'num_nodes': 2, # Number of nodes required for the application instance\n                              'ranks_per_node': 12, # Number of ranks / application elements to be launched per node\n                              'num_ranks': 24, # Number of ranks in total\n                             }\n\n    print(f\"Creating mpi tasks with {resource_specification['num_nodes']} nodes per task, {resource_specification['num_ranks']} ranks per task, and {resource_specification['ranks_per_node']} ranks per node\")\n    task_futures += [mpi_hello_affinity(\n                            parsl_resource_specification=resource_specification,\n                            stdout=f\"{working_directory}/mpi_output/{i}/hello.stdout\",\n                            stderr=f\"{working_directory}/mpi_output/{i}/hello.stderr\")\n                        for i in range(10)]\n\n    # This loop will block until all task results are returned\n    print(f\"{len(task_futures)} tasks created, wating for completion\")\n    for tf in task_futures:\n        tf.result()\n\n    print(\"Tasks done!\")\n</code></pre>"},{"location":"aurora/workflows/parsl/#run-parsl-workflow-within-a-single-pbs-job","title":"Run Parsl Workflow within a single PBS Job","text":"<p>If your tasks can be run within a single PBS job, Parsl can be configured to run inside the PBS job, instead of submitting multiple jobs to the scheduler as shown in the examples above.</p> <p>To run the single tile task ensemble from above in this alternate mode, use this <code>Config</code> object in the workflow script: config.py<pre><code># config.py\nimport os\nfrom parsl.config import Config\n\n# Use LocalProvider to launch workers within a submitted batch job\nfrom parsl.providers import LocalProvider\n# The high throughput executor is for scaling large single core/tile/gpu tasks on HPC system:\nfrom parsl.executors import HighThroughputExecutor\n# Use the MPI launcher to launch worker processes:\nfrom parsl.launchers import MpiExecLauncher\n\ntile_names = [f'{gid}.{tid}' for gid in range(6) for tid in range(2)]\n\n# The config will launch workers from this directory\nexecute_dir = os.getcwd()\n\n# Get the number of nodes:\nnode_file = os.getenv(\"PBS_NODEFILE\")\nwith open(node_file,\"r\") as f:\n    node_list = f.readlines()\n    num_nodes = len(node_list)\n\naurora_single_tile_config = Config(\n    executors=[\n        HighThroughputExecutor(\n            # Ensures one worker per GPU tile on each node\n            available_accelerators=tile_names,\n            max_workers_per_node=12,\n            # Distributes threads to workers/tiles in a way optimized for Aurora\n            cpu_affinity=\"list:1-8,105-112:9-16,113-120:17-24,121-128:25-32,129-136:33-40,137-144:41-48,145-152:53-60,157-164:61-68,165-172:69-76,173-180:77-84,181-188:85-92,189-196:93-100,197-204\",\n            # Increase if you have many more tasks than workers\n            prefetch_capacity=0,\n            # Options that specify properties of PBS Jobs\n            provider=LocalProvider(\n                # Number of nodes job\n                nodes_per_block=num_nodes,\n                launcher=MpiExecLauncher(bind_cmd=\"--cpu-bind\", overrides=\"--ppn 1\"),\n                init_blocks=1,\n                max_blocks=1,\n            ),\n        ),\n    ],\n)\n</code></pre></p> <p>Then submit the the workflow with a PBS batch script: <pre><code>#!/bin/bash -l\n#PBS -l select=1\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -q debug\n#PBS -A &lt;ProjectName&gt;\n\ncd ${PBS_O_WORKDIR}\n\nsource $HOME/_env/bin/activate\npython my_workflow_script.py\n</code></pre></p> <p>Note that if the workflow does not complete before the end of the PBS job, outstanding tasks will not complete.</p>"},{"location":"aurora/workflows/parsl/#known-issues","title":"Known Issues","text":"<p>Warning</p> <p>Starting in October 2025, users testing parsl in single node jobs may encounter an error that makes reference to <code>OSError: AF_UNIX path too long</code>.  To fix this, include in the <code>worker_init</code> when using the <code>PBSProProvider</code> or in the job script for cases using the <code>LocalProvider</code> this environment variable setting: <code>export TMPDIR=/tmp</code></p>"},{"location":"aurora/workflows/smartsim/","title":"SmartSim and SmartRedis","text":"<p>SmartSim is an open-source tool developed by Hewlett Packard Enterprise (HPE) designed to facilitate the integration of traditional HPC simulation applications with machine learning workflows. There are two core components to SmartSim:</p> <ul> <li>Infrastructure Library (IL)</li> <li>Provides an API to start, stop, and monitor HPC applications from Python</li> <li>Interfaces with the PBSpro scheduler to launch jobs</li> <li>Deploys a distributed in-memory database called the Orchestrator</li> <li>SmartRedis Client Library</li> <li>Provides clients that connect to the Orchestrator from Fortran, C, C++, and Python code</li> <li>The client API library enables data transfer to/from the database and the ability to load and run JIT-traced Python and ML runtimes acting on stored data</li> </ul> <p>For more resources on SmartSim, follow the links below:</p> <ul> <li>Source code</li> <li>Documentation</li> <li>Zoo of examples</li> <li>Fall 2023 ALCF User Hands-On Workshop</li> <li>NekRS-ML</li> </ul>"},{"location":"aurora/workflows/smartsim/#installation","title":"Installation","text":"<p>Create a Python virtual environment based on the ML frameworks module (note that git-lfs is also needed):</p> <pre><code>module load frameworks\nmodule load git-lfs\npython -m venv --clear /path/to/_ssim_env --system-site-packages\nsource /path/to/_ssim_env/bin/activate\n</code></pre> <p>It is recommended that the venv is installed in a user's project space on the Flare parallel file system.</p> <p>Install SmartSim:</p> <pre><code>git clone https://github.com/rickybalin/SmartSim.git\ncd SmartSim\ngit checkout rollback_aurora\npip install -e .\ncd ..\n</code></pre> <p>Install the RedisAI PyTorch backend for the CPU:</p> <pre><code>export TORCH_CMAKE_PATH=$( python -c 'import torch;print(torch.utils.cmake_prefix_path)' )\nexport TORCH_PATH=$( python -c 'import torch; print(torch.__path__[0])' )\nexport LD_LIBRARY_PATH=$TORCH_PATH/lib:$LD_LIBRARY_PATH\nsmart build -v --device cpu --torch_dir $TORCH_CMAKE_PATH --no_tf\nsmart validate --device cpu\n</code></pre> <p>Install the SmartRedis library:</p> <pre><code>git clone https://github.com/rickybalin/SmartRedis.git\ncd SmartRedis\npip install -e .\nmake lib\ncd ..\n</code></pre> <p>Running with SmartSim</p> <p>When running a workload with SmartSim, please include the following in your run or submit scripts: <pre><code>export TORCH_PATH=$( python -c 'import torch; print(torch.__path__[0])' )\nexport LD_LIBRARY_PATH=$TORCH_PATH/lib:$LD_LIBRARY_PATH\n</code></pre></p> <p>Known Issues</p> <ul> <li>Pip installing SmartSim returns some warnings which can be safely ignored.</li> <li>The <code>smart build -v --device cpu</code> command builds the RedisAI backend for the CPU. This enables ML model inferencing on the CPU with SmartSim and SmartRedis. Due to a limitation with RedisAI, the backend cannot be built for the Intel Max 1550 GPU.</li> <li>The RedisAI backend requires an older version of TensorFlow relative to what is loaded with the frameworks module on Aurora. If you need the TensorFlow backend, please contact us at support@alcf.anl.gov.</li> </ul>"},{"location":"crux/","title":"Crux Machine Overview","text":"<p>Crux is an HPE Cray EX Liquid Cooled system with a peak performance of 1.18 PF, comprised of 64 compute blades connected via Slingshot. Each blade has 4 compute nodes for a total of 256 nodes in the system. Each compute node has dual AMD EPYC 7742 (Rome) 64-core processors. Each CPU core supports up to two hyperthreads for a total of 256 threads possible per node. Each CPU has 128 GB of DDR4 memory for a total of 256 GB per node.</p> <p>The User Access Nodes (UANs) consist of dual-socket AMD EPYC 7543 (Milan) 32-core processors.</p>"},{"location":"crux/#node-architecture","title":"Node Architecture","text":"<p>The output of <code>numactl --hardware</code> is very helpful in understanding the connectivity of the CPU cores in each compute node. Each of the CPUs consists of four NUMA domains containing 16 cores and connected directly to 1/4 of the DDR channels. The following information will be useful in understanding how best to affinitize processes to CPUs on each node. For example, users running multiple applications per node will likely want to localize within a set of NUMA domains in a CPU.</p> <p>For CPU 0:</p> <ul> <li>NUMA 0: cores 0-15,128-143</li> <li>NUMA 1: cores 16-31,144-159</li> <li>NUMA 2: cores 32-47,160-175</li> <li>NUMA 3: cores 48-63,176-191</li> </ul> <p>For CPU 1:</p> <ul> <li>NUMA 4: cores 64-79,192-207</li> <li>NUMA 5: cores 80-95,208-223</li> <li>NUMA 6: cores 96-111,224-239</li> <li>NUMA 7: cores 112-127,240-255</li> </ul>"},{"location":"crux/getting-started/","title":"Getting Started on Crux","text":""},{"location":"crux/getting-started/#logging-into-crux","title":"Logging Into Crux","text":"<p>To log into Crux: <pre><code>ssh &lt;username&gt;@crux.alcf.anl.gov\n</code></pre> Then, type in the password from your CRYPTOCard/MobilePASS+ token. Once logged in, you land on one of the Crux login nodes (<code>crux-login-01</code>, <code>crux-login-02</code>).</p>"},{"location":"crux/getting-started/#hardware-overview","title":"Hardware Overview","text":"<p>An overview of the Crux system, including details on the compute node architecture, is available on the Machine Overview page.</p>"},{"location":"crux/getting-started/#compiling-applications","title":"Compiling Applications","text":"<p>For all code building and development, please use Crux compute nodes, especially for large parallel builds. Please read through the Compiling and Linking Overview page and corresponding pages depending on the target compiler and programming model.</p>"},{"location":"crux/getting-started/#accessing-additional-software","title":"Accessing Additional Software","text":"<p>ALCF installs additional software in <code>/soft</code>, which can be accessed via module commands by altering your <code>$MODULEPATH</code>: <pre><code>module use /soft/modulefiles\n</code></pre> The available software can then be queried with <code>module avail</code>. In particular, loading the <code>spack-pe-base</code> module provides access to additional software and build tools. For example, <code>cmake</code> is available via the following:</p> <pre><code>module use /soft/modulefiles\nmodule load spack-pe-base\nmodule load cmake\n</code></pre>"},{"location":"crux/getting-started/#submitting-and-running-jobs","title":"Submitting and Running Jobs","text":"<p>Please read through the Running Jobs with PBS at the ALCF page for information on using the PBS scheduler and preparing job submission scripts.</p> <p>For more information on Crux queues and job submission, visit: Running Jobs on Crux.</p>"},{"location":"crux/getting-started/#lustre-file-striping","title":"Lustre File Striping","text":"<p>In addition to the content above, here is a document on Lustre File Striping Basics:</p> <ul> <li>Lustre File Striping Basics</li> </ul>"},{"location":"crux/getting-started/#proxy","title":"Proxy","text":"<p>If the node you are on doesn\u2019t have outbound network connectivity, add the following to your <code>~/.bash_profile</code> file to access the proxy host:</p> <pre><code># proxy settings\nexport HTTP_PROXY=\"http://proxy.alcf.anl.gov:3128\"\nexport HTTPS_PROXY=\"http://proxy.alcf.anl.gov:3128\"\nexport http_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport https_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport ftp_proxy=\"http://proxy.alcf.anl.gov:3128\"\n</code></pre>"},{"location":"crux/getting-started/#getting-assistance","title":"Getting Assistance","text":"<p>Please direct all questions, requests, and feedback to support@alcf.anl.gov.</p>"},{"location":"crux/getting-started/#-","title":"---","text":""},{"location":"crux/compiling-and-linking/compiling-and-linking-overview/","title":"Compiling and Linking on Crux","text":""},{"location":"crux/compiling-and-linking/compiling-and-linking-overview/#overview","title":"Overview","text":"<p>Crux has AMD processors on the login nodes (crux-login-01,02) and AMD processors on the compute nodes (see Machine Overview page). The login nodes can be used to compile software, create containers, and launch jobs. For larger, parallel builds, it will be beneficial to compile those directly on the compute nodes.</p> <p>To launch an interactive job and acquire a compute node for compiling, use:</p> <pre><code>qsub -I -q workq -A myProjectShortName -n 1 -t HH:MM:SS\n</code></pre> <p>The default programming environment on the Crux compute nodes is currently Cray: <code>PrgEnv-cray</code>. The GNU programming environment <code>PrgEnv-gnu</code> is also available to users. It is recommended that the Cray MPI wrappers are used for building applications.</p> <ul> <li><code>cc</code> - C compiler</li> <li><code>CC</code> - C++ compiler</li> <li><code>ftn</code> - Fortran compiler</li> </ul> <p>Each of these wrappers will select the corresponding vendor compiler based on the PrgEnv module loaded in the environment. The following are some helpful options to understand what the compiler wrapper is invoking:</p> <ul> <li><code>--craype-verbose</code>: Print the command which is forwarded to the compiler invocation</li> <li><code>--cray-print-opts=libs</code>: Print library information</li> <li><code>--cray-print-opts=cflags</code>: Print include information</li> </ul> <p>Further documentation and options are available via <code>man cc</code> and similar.</p>"},{"location":"crux/compiling-and-linking/compiling-and-linking-overview/#modules-on-crux","title":"Modules on Crux","text":"<p>Available modules can be listed via the command:</p> <pre><code>module avail\n</code></pre> <p>Loaded modules in your environment can be listed via the command:</p> <pre><code>module list\n</code></pre> <p>To load new modules, use:</p> <pre><code>module load &lt;module_name&gt;\n</code></pre>"},{"location":"crux/containers/containers/","title":"Containers on Crux","text":"<p>Apptainer will be supported on Crux at a future date.</p>"},{"location":"crux/containers/containers/#available-containers","title":"Available Containers","text":"<ul> <li>Examples for running MPICH containers can be found here.</li> <li>Examples for running databases can be found here.</li> <li>Examples for using SHPC (containers as modules) can be found here.</li> </ul>"},{"location":"crux/containers/containers/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":"<ul> <li>Permission Denied: Check your quota, clean Apptainer cache (<code>~/.apptainer/cache</code>), or set directories to local scratch (<code>/local/scratch/</code>).</li> <li>MPI Issues: Ensure MPI compatibility by following MPI container registry docs.</li> <li>libmpi.so.40 not found: Use MPICH-compatible base images.</li> <li>Disabled Network Virtualization: Network virtualization is disabled due to security constraints (details).</li> <li>Starter-suid Error: Always use the <code>--fakeroot</code> flag on Polaris compute nodes.</li> </ul> <p>For further assistance, contact ALCF support: <code>support@alcf.anl.gov</code>.</p>"},{"location":"crux/data-science/python/","title":"Python","text":"<p>At a future date, we will provide prebuilt <code>conda</code> environments containing CPU-optimized builds of <code>torch</code>, <code>tensorflow</code> (both with <code>horovod</code> support for multi-node calculations), <code>jax</code>, and many other commonly used Python modules.</p> <p>In the meantime, users should be able to create their own local environments to begin work on Crux. In this example, <code>mpi4py</code> is installed.</p> <pre><code>python3 -m venv ~/_test_env\n. ~/_test_env/bin/activate\npip install mpi4py\n</code></pre> <p>This new virtual environment can then be used in a batch job as in this simple <code>hello_world.py</code> example available in the GettingStarted repository: hello_world.py<pre><code>from mpi4py import MPI\nimport sys\nimport socket\n\ncomm = MPI.COMM_WORLD\nrank = comm.Get_rank()\nsize = comm.Get_size()\n\nprint(\"Hello World from rank {} of {} on {}\".format(rank, size, socket.gethostname()))\n\nsys.exit()\n</code></pre></p> <pre><code>$ qsub ./submit.sh\n12345.crux-pbs-0001.head.cm.crux.alcf.anl.gov\n\n$ cat submit.sh.o12345\nNUM_OF_NODES= 2 TOTAL_NUM_RANKS= 8 RANKS_PER_NODE= 4 THREADS_PER_RANK= 1\nHello World from rank 0 of 8 on x1000c0s0b1n1\nHello World from rank 1 of 8 on x1000c0s0b1n1\nHello World from rank 2 of 8 on x1000c0s0b1n1\nHello World from rank 3 of 8 on x1000c0s0b1n1\nHello World from rank 4 of 8 on x1000c0s1b0n0\nHello World from rank 5 of 8 on x1000c0s1b0n0\nHello World from rank 6 of 8 on x1000c0s1b0n0\nHello World from rank 7 of 8 on x1000c0s1b0n0\n</code></pre>"},{"location":"crux/queueing-and-running-jobs/running-jobs/","title":"Running Jobs on Crux","text":""},{"location":"crux/queueing-and-running-jobs/running-jobs/#queues","title":"Queues","text":"<p>There are four production queues you can target in your qsub (<code>-q &lt;queue name&gt;</code>):</p> Queue Name Node Min Node Max Time Min Time Max Notes debug 1 8 5 min 2 hr 8 nodes are exclusive workq-route 1 184 5 min 24 hrs Routing queue; 100 jobs max per project; See below for its execution queue preemptable 1 10 5 min 72 hrs Please be aware that jobs in the preemptable queue can be killed at any time if jobs are submitted to the demand queue. Max 20 jobs running/accruing/queued per-project; see Note below demand 1 64 5 min 1 hr By request only (email support@alcf.anl.gov) to submit a request <p>Note: Please be aware that jobs in the preemptable queue can be killed at any time if jobs are submitted to the demand queue. Jobs in the demand queue take priority over jobs in the preemptable queue. This means jobs in the preemptable queue may be preempted (killed without any warning) if there are jobs in the demand queue. Unfortunately, there's always an inherent risk of jobs being killed when using the preemptable queue.  Please use the following command to view details of a queue: <code>qstat -Qf &lt;queuename&gt;</code></p> <p>To make your job rerunnable, add the following PBS directive: <code>#PBS -r y</code>. This will ensure your job will restart once the demand job is complete. </p> <p><code>workq-route</code> is a routing queue and routes your job to the following execution queue:</p> Queue Name Node Min Node Max Time Min Time Max Notes workq 1 184 5 min 24 hrs 20 jobs queue or running/10 jobs running per project"},{"location":"crux/queueing-and-running-jobs/running-jobs/#running-mpiopenmp-applications","title":"Running MPI+OpenMP Applications","text":"<p>Note: For OpenMP-enabled applications, it is extremely important to set the number of OpenMP threads to an appropriate value. As on most systems, the default value for <code>OMP_NUM_THREADS</code> is set to the maximum possible, which is 256 on the Crux compute nodes.</p> <p>Once a submitted job is running, calculations can be launched on the compute nodes using <code>mpiexec</code> to start an MPI application. Documentation is accessible via <code>man mpiexec</code>, and some helpful options follow.</p> <ul> <li><code>-n</code> total number of MPI ranks</li> <li><code>-ppn</code> number of MPI ranks per node</li> <li><code>--cpu-bind</code> CPU binding for application</li> <li><code>--depth</code> number of CPUs per rank (useful with <code>--cpu-bind</code>)</li> <li><code>--env</code> set environment variables (<code>--env OMP_NUM_THREADS=2</code>)</li> <li><code>--hostfile</code> indicate file with hostnames (the default is <code>--hostfile $PBS_NODEFILE</code>)</li> </ul> <p>A sample submission script with directives is below for a 4-node job with 8 MPI ranks on each node and 8 OpenMP threads per rank. Each hardware thread runs a single OpenMP thread since there are 64 hardware threads on the CPU (2 per core). You can download and compile <code>hello_affinity</code> from this link.</p> <pre><code>#!/bin/bash -l\n#PBS -N AFFINITY\n#PBS -l select=4:system=crux\n#PBS -l place=scatter\n#PBS -l walltime=0:10:00\n#PBS -q debug\n#PBS -A Catalyst  # Replace with your project\n#PBS -l filesystems=home:eagle\n\n# MPI+OpenMP example w/ 64 MPI ranks per node and threads spread evenly across cores\n# There are two 32-core CPUs on each node. This will run 32 MPI ranks per CPU, 2 OpenMP threads per rank, and each thread bound to a single core.\n\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=64 # Number of MPI ranks to spawn per node\nNDEPTH=2 # Number of hardware threads per rank (i.e. spacing between MPI ranks)\nNTHREADS=2 # Number of software threads per rank to launch (i.e. OMP_NUM_THREADS)\n\nNTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))\n\necho \"NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}\"\n\n# Change the directory to work directory, which is the directory you submit the job.\ncd $PBS_O_WORKDIR\n\nMPI_ARGS=\"-n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth \"\nOMP_ARGS=\"--env OMP_NUM_THREADS=${NTHREADS} --env OMP_PROC_BIND=true --env OMP_PLACES=cores \"\n\nmpiexec ${MPI_ARGS} ${OMP_ARGS} ./hello_affinity\n</code></pre> <p>The <code>hello_affinity</code> program is a compiled C++ code, which is built via <code>make clean ; make</code> in the linked directory after cloning the Getting Started repository.</p>"},{"location":"crux/queueing-and-running-jobs/running-jobs/#running-multiple-mpi-applications-on-a-single-node","title":"Running Multiple MPI Applications on a Single Node","text":"<p>Multiple applications can be run simultaneously on a node by launching several <code>mpiexec</code> commands and backgrounding them. For performance, it will likely be necessary to ensure that each application runs on a distinct set of CPU resources. One can provide a list of CPUs using the <code>--cpu-bind</code> option to explicitly assign CPU resources on a node to each application. Output from the <code>numactl --hardware</code> command is useful for understanding how to localize applications within NUMA domains on the two CPUs of each node.</p> <p>In the example below, eight instances of the application are simultaneously running on a single node, with each application localized to a single NUMA domain. Each application here is bound to 16 CPU cores with a single process running on each core (i.e. no hyperthreads). In the first instance, the application is spawning 16 MPI ranks on cores 0-15 in the first CPU.</p> <pre><code>  MPI_ARG=\"-n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE}\"\n  OMP_ARG=\"--env OMP_NUM_THREADS=${NTHREADS} \"\n\n  # Socket 0\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:0:1:2:3:4:5:6:7:8:9:10:11:12:13:14:15 ./hello_affinity &amp;\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31 ./hello_affinity &amp;\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:32:33:34:35:36:37:38:39:40:41:42:43:44:45:46:47 ./hello_affinity &amp;\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:48:49:50:51:52:53:54:55:56:57:58:59:60:61:62:63 ./hello_affinity &amp;\n\n  # Socket 1\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:64:65:66:67:68:69:70:71:72:73:74:75:76:77:78:79 ./hello_affinity &amp;\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:80:81:82:83:84:85:86:87:88:89:90:91:92:93:94:95 ./hello_affinity &amp;\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:96:97:98:99:100:101:102:103:104:105:106:107:108:109:110:111 ./hello_affinity &amp;\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:112:113:114:115:116:117:118:119:120:121:122:123:124:125:126:127 ./hello_affinity &amp;\n\nwait\n</code></pre>"},{"location":"crux/queueing-and-running-jobs/running-jobs/#running-multiple-mpi-applications-on-multiple-nodes","title":"Running Multiple MPI Applications on Multiple Nodes","text":"<p>An important detail missing from the prior example was specifying the hostfile. When not specified, the default hostfile ${PBS_NODEFILE} is used for all invocations of <code>mpiexec</code>, meaning all applications will include identical sets of nodes. This is fine for single-node jobs, but appropriate hostfiles need to be created and passed to <code>mpiexec</code> when running applications across subsets of nodes in a large job.</p> <p>The following example first splits the hostfile ${PBS_NODEFILE} into separate hostfiles each containing the requested number of nodes (in this case just 1 per file). The separate hostfiles are then used in each batch of <code>mpiexec</code> calls to launch applications on different compute nodes.</p> <pre><code># MPI example w/ multiple runs per batch job\nNNODES=`wc -l &lt; $PBS_NODEFILE`\n\n# Settings for each run: 8 runs each with 16 MPI ranks per node spread evenly across specified subset of cores\nNUM_NODES_PER_MPI=1\nNRANKS_PER_NODE=16\nNTHREADS=1\n\nNTOTRANKS=$(( NUM_NODES_PER_MPI * NRANKS_PER_NODE ))\necho \"NUM_OF_NODES= ${NNODES} NUM_NODES_PER_MPI= ${NUM_NODES_PER_MPI} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}\"\n\n# Increase value of suffix-length if more than 99 jobs\nsplit --lines=${NUM_NODES_PER_MPI} --numeric-suffixes=1 --suffix-length=2 $PBS_NODEFILE local_hostfile.\n\nfor lh in local_hostfile*\ndo\n  echo \"Launching mpiexec w/ ${lh}\"\n  MPI_ARG=\"-n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --hostfile ${lh} \"\n  OMP_ARG=\"--env OMP_NUM_THREADS=${NTHREADS} \"\n\n  # Socket 0\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:0:1:2:3:4:5:6:7:8:9:10:11:12:13:14:15 ./hello_affinity &amp;\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31 ./hello_affinity &amp;\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:32:33:34:35:36:37:38:39:40:41:42:43:44:45:46:47 ./hello_affinity &amp;\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:48:49:50:51:52:53:54:55:56:57:58:59:60:61:62:63 ./hello_affinity &amp;\n\n  # Socket 1\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:64:65:66:67:68:69:70:71:72:73:74:75:76:77:78:79 ./hello_affinity &amp;\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:80:81:82:83:84:85:86:87:88:89:90:91:92:93:94:95 ./hello_affinity &amp;\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:96:97:98:99:100:101:102:103:104:105:106:107:108:109:110:111 ./hello_affinity &amp;\n  mpiexec ${MPI_ARG} ${OMP_ARG} --cpu-bind list:112:113:114:115:116:117:118:119:120:121:122:123:124:125:126:127 ./hello_affinity &amp;\n\n  sleep 1s\ndone\n\nwait\n\nrm -f local_hostfile.*\n</code></pre> <p>Ensemble <code>examples</code> for several cases are provided to help users with crafting job submission scripts.</p>"},{"location":"crux/queueing-and-running-jobs/running-jobs/#compute-node-access-to-the-internet","title":"Compute Node Access to the Internet","text":"<p>Currently, the only access to the internet is via a proxy. Here are the proxy environment variables for Crux:</p> <pre><code>export http_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport https_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport ftp_proxy=\"http://proxy.alcf.anl.gov:3128\"\n</code></pre>"},{"location":"data-management/","title":"Data Management","text":"<p>See the following links for information on file systems, tape storage, and SSDs. Information on data transfer and data sharing can also be found below.</p> <ul> <li>Filesystem &amp; Storage</li> <li>Data Transfer &amp; Sharing</li> </ul>"},{"location":"data-management/acdc/","title":"ALCF Community Data Co-Op (ACDC)","text":""},{"location":"data-management/acdc/#overview-of-the-alcf-community-data-co-op-acdc","title":"Overview of the ALCF Community Data Co-Op (ACDC)","text":"<p>The ALCF Community Data Co-Op (ACDC) powers data-driven research by providing a platform for data access and sharing, and value-added services for data discovery and analysis.</p> <p>A fundamental aspect of ACDC is a data fabric that allows programmatic data access and straightforward large-scale data sharing with collaborators via Globus services. This provides a platform to build out different modalities for data access and use, such as indexing of data for discovery, data portals for interactive search and access, and accessible analysis services. ACDC will continue to be expanded to deliver ALCF users the platform to build customizable and accessible services towards the goal of supporting data-driven discoveries.</p>"},{"location":"data-management/acdc/#data-access-and-sharing","title":"Data access and sharing","text":"<p>ALCF project PIs can share data on Eagle with their collaborators, making facility accounts unnecessary. With this service, the friction of data sharing amongst collaborators is eliminated \u2013 there is no need to create copies of data for sharing, or allocation and accounts just to access data. ALCF PIs can grant access to data, at read-only or read/write access levels. Non-ALCF users throughout the scientific community, who have been granted permissions, can access the data on the Eagle filesystem using Globus.</p> <p>Access to the data for ALCF users and collaborators is supported via bulk transfer (Globus transfer) or direct browser-based access (HTTP/S). Direct connections to high-speed external networks permit data access at many gigabytes per second. Management of permissions and access is via a web application or command line clients, or directly via an Application Programming Interface (APIs). The interactivity permitted by the APIs distinguishes ACDC from the ALCF\u2019s previous storage systems and presents users with many possibilities for data control and distribution.</p>"},{"location":"data-management/acdc/#data-portal-for-discovery-and-access","title":"Data portal for discovery and access","text":"<p>ACDC\u2019s fully supported production environment is the next step in the expansion of edge services that blur the boundaries between experimental laboratories and computing facilities. The use and prominence of such services at the ALCF are only expected to increase as they become more integral to the facility\u2019s ability to deliver data-driven scientific discoveries.</p> <p>ACDC includes several project-specific data portals that enable search and discovery of the data hosted on Eagle. The portals allow users to craft queries and filters to find specific sets of data that match their criteria and use faceted search for the discovery of data. Portals also provide the framework for other interfaces including data processing capabilities, all secured with authentication and configured authorization policy.</p> <p>The ACDC portal is a deployment of Django Globus Portal Framework customized for a variety of different projects. For most of these projects, the search metadata links directly to data on Eagle, with browser-based download, preview, and rendering of files, and bulk data access.</p>"},{"location":"data-management/acdc/#getting-started","title":"Getting Started","text":"<ol> <li>Request an allocation: Researchers or PIs request an allocation on Eagle, and a project allocation is created upon request acceptance.</li> <li>Manage Access: PIs can manage the space independently or assign other users to manage the space, as well as provide other users with read or read/write access for folders in the space. Globus groups and identities are used to manage such access.</li> <li>Authentication: Globus is used for authentication and identity needed to access the system. As Globus has built-in support for federated logins, users can access ACDC using their campus or institution federated username and passcode.</li> </ol> <p>If you are new to the ALCF, follow these instructions on how to transfer your data to ACDC: Globus</p> <p>If you already have an ALCF account, follow these instructions on how to share your data: Sharing Data to Eagle</p>"},{"location":"data-management/acdc/eagle-data-sharing/","title":"Sharing Data on Eagle Using Globus Guest Collections","text":""},{"location":"data-management/acdc/eagle-data-sharing/#overview","title":"Overview","text":"<p>Collaborators throughout the scientific community have the ability to write data to and read scientific data from the Eagle filesystem using Globus sharing capability. This capability provides PIs with a natural and convenient storage space for collaborative work.</p> <p>Note</p> <p>The project PI needs to have an active ALCF account to set up Globus guest collections on Eagle and set permissions for collaborators to access data. If the PI does not have an account or has an inactive account, they will not be able to create a Globus guest collection. If a PI's account goes inactive after the Globus guest collection was created and shared, the collection will become inaccessible until the PI's account is reactivated. Only the project PI has the ability to create a collection; project proxies cannot create a collection.</p> <p>Globus is a service that provides research data management, including managed transfer and sharing. It makes it easy to move, sync, and share large amounts of data. Globus will manage file transfers, monitor performance, retry failures, recover from faults automatically when possible, and report the status of your data transfer. Globus supports GridFTP for bulk and high-performance file transfer, and direct HTTPS for download. The service allows the user to submit a data transfer request and performs the transfer asynchronously in the background. For more information, see Globus data transfer and Globus data sharing.</p>"},{"location":"data-management/acdc/eagle-data-sharing/#logging-into-globus-with-your-alcf-login","title":"Logging into Globus with your ALCF Login","text":"<p>ALCF researchers can use their ALCF Login username and password to access Globus. Go to the Globus website and click on Log In in the upper right corner of the page.</p> <p></p> <p>Logging into Globus</p> <p>Type or scroll down to \"Argonne LCF\" in the \"Use your existing organizational login\" box, and then click \"Continue\".</p> <p></p> <p>Select Organization Argonne LCF</p> <p>You will be taken to a familiar-looking page for ALCF login. Enter your ALCF login username and password.</p>"},{"location":"data-management/acdc/eagle-data-sharing/#accessing-your-eagle-project-directory","title":"Accessing your Eagle Project Directory","text":"<p>Note</p> <p>Specifically for PIs with Eagle 'Data-Only' projects (no compute allocations), logging in through Globus is the only way to access the project directory.</p> <p>PIs with data and compute allocations will have access to the required compute-system login nodes (along with the Globus Web Interface) to access their project directory.</p>"},{"location":"data-management/acdc/eagle-data-sharing/#creating-a-guest-collection","title":"Creating a Guest Collection","text":"<p>A project PI needs to have an 'active' ALCF account in place to create and share guest collections with collaborators. Please note that ONLY a PI has the ability to create guest collections.</p> <p>Info</p> <p>PIs with an \"Inactive/Deleted\" ALCF account should submit a reactivation request by filling out this form: Re-activation Form</p> <p>Info</p> <p>PIs without an ALCF account should submit an ALCF account request by filling out this form: Account Request Form</p>"},{"location":"data-management/acdc/eagle-data-sharing/#navigate-to-the-collections-tab","title":"Navigate to the Collections tab","text":"<p>There are multiple ways to navigate to the Collections tab in \"Endpoints\":</p> <ol> <li>Click the link to get started. It will take you to the Collections tab for Eagle. OR</li> <li>Click on 'Endpoints' located in the left panel of the Globus web app. Type \"alcf#dtn_eagle\" (for Eagle) in the search box located at the top of the page and click the magnifying glass to search. Click on the Managed Public Endpoint \"alcf#dtn_eagle\" from the search results. Click on the Collections tab. OR</li> <li>Click on 'File Manager' located in the left panel of the Globus web app. Search for 'alcf#dtn_eagle' and select it in the Collection field. Select your project directory or a subdirectory that you would like to share with collaborators as a Globus guest collection. Click on 'Share' on the right side of the panel, which will take you to the Collections tab.</li> </ol> <p>Note: When you select an endpoint to transfer data to/from, you may be asked to authenticate with that endpoint. Follow the instructions on screen to activate the endpoint and to authenticate. You may also have to provide Authentication/Consent for the Globus web app to manage collections on this endpoint.</p>"},{"location":"data-management/acdc/eagle-data-sharing/#adding-a-guest-collection","title":"Adding a Guest Collection","text":"<p>In the Collections tab, click 'Add a Guest Collection' located at the top right-hand corner.</p> <ol> <li> <p>Fill out the form:</p> <ol> <li>If the path to the directory is not pre-populated, click the browse button, navigate and select the directory. Note that you can create a single guest collection and set permissions for folders within a guest collection. There is no reason to create multiple guest collections to share for a single project.</li> <li>Give the collection a Display Name (choose a descriptive name)</li> </ol> </li> <li> <p>Click \"Create Collection\"</p> </li> </ol> <p></p> <p>Create New Guest Collection</p>"},{"location":"data-management/acdc/eagle-data-sharing/#sharing-data-with-collaborators-using-guest-collections","title":"Sharing Data with Collaborators Using Guest Collections","text":"<p>Your data in the Guest Collections can be easily shared with collaborators at ALCF or elsewhere. You have full control over which files your collaborators can access, and whether they have read-only or read-write permissions.</p> <p>To share data with collaborators (that either have a Globus account or an ALCF account), click on 'Endpoints', select your newly created Guest Collection (as described in the section above), and go to the 'Permissions' tab. Click on 'Add Permissions - Share With':</p> <p></p> <p>Add Permissions</p> <p>You can share with other Globus users or Globus Groups (for more information on Groups, scroll down to Groups). You can give the collaborators read, write, or read+write permissions. Once the options have been selected, click 'Add Permission'.</p> <p></p> <p>Add Permissions - Share With</p> <p>PI can also choose to share their data with 'Public' with anonymous read access (and anonymous write disabled). This allows anyone that has access to the data to read and/or download it without authorizing the request.</p> <p></p> <p>Add Permissions - Share With</p> <p>You should then see the share and the people you have shared it with. You can repeat this process for any number of collaborators. At any time, you can terminate access to the directory by clicking the trash can next to the user.</p> <p></p> <p>List of people that you have shared with</p>"},{"location":"data-management/acdc/eagle-data-sharing/#additional-information-on-globus-guest-collections","title":"Additional information on Globus Guest Collections","text":"<ol> <li>ONLY a project PI can create guest collections and make them accessible to collaborators. Project proxies cannot create guest collections.</li> <li>You can only share directories, not individual files.</li> <li>Globus allows directory trees to be shared as either read or read/write. This means that any subdirectories within that tree also have the same permissions. Globus supports setting permissions at a folder level, so there is no need to create multiple guest collections for a project. You can create a guest collection at the top level and share sub-directories with the collaborators by assigning the appropriate permissions.</li> <li>When you create a guest collection endpoint and give access to one or more Globus users, you can select whether each person has read or read/write access. If they have write access, they can also delete files within that directory tree, so you should be careful about providing write access.</li> <li>Globus guest collections are created and managed by project PIs. If the PI of a project changes, the new PI will have to create a new guest collection and share them with the users. Contact ALCF Support (support@alcf.anl.gov) in such cases. Globus guest collections' ownership cannot be transferred.</li> <li>Guest collections are active as long as the project directory is available and the PI's ALCF account is active. If the PI's ALCF account goes inactive, the collections become inaccessible to all its collaborators. Access is restored once the PI's account is reactivated.</li> <li>All RW actions are performed as the PI when using Guest Collections. If a PI does not have permissions to read or write a file or a directory, then the Globus guest collection users won't either.</li> </ol>"},{"location":"data-management/acdc/eagle-data-sharing/#creating-a-group","title":"Creating a group","text":"<ol> <li>Go to Groups on the left panel</li> <li>Click on \u2018Create a new group\u2019 at the top</li> <li>Give the group a descriptive name and add a Description for more information</li> <li>Make sure you select the \u2018group members only\u2019 radio button</li> <li>Click on \u2018Create Group\u2019</li> </ol> <p>Create new group</p>"},{"location":"data-management/acdc/eagle-data-sharing/#transferring-data-from-eagle","title":"Transferring data from Eagle","text":"<p>Log in to Globus using your ALCF credentials. After authenticating, you will be taken to the Globus File Manager tab. In the 'Collection' box, type the name of the Eagle managed endpoint (<code>alcf#dtn_eagle</code>). Navigate to the folder/file you want to transfer. HTTPS access (read-only) is enabled so you can download files by clicking the \"Download\" button.</p> <p>Click on 'Download' to download the required file.</p> <p></p> <p>Download the required file</p> <p>To transfer files to another Globus endpoint, in the \"collection\" search box in the RHS panel, enter the destination endpoint (which could also be your Globus Connect Personal endpoint).</p> <p></p> <p>Transferring files to another Globus endpoint</p> <p>To transfer files, select a file or directory on one endpoint, and click the blue 'Start' button.</p> <p></p> <p>Transferring files</p> <p>If the transfer is successful, you should see the following message:</p> <p></p> <p>A Successful Transfer</p> <p>Click on 'View details' to display task detail information.</p> <p></p> <p>Transfer completed</p> <p>You will also receive an email when the transfer is complete.</p> <p></p> <p>Email confirmation</p>"},{"location":"data-management/acdc/eagle-data-sharing/#deleting-a-guest-collection","title":"Deleting a guest collection","text":"<p>To see all guest collections you have shared, go to 'Endpoints' in the left-hand navigation bar, then 'Administered by You'. Select the guest collection endpoint you wish to delete, and click on 'Delete endpoint'.</p> <p></p> <p>Deleting a guest collection</p>"},{"location":"data-management/acdc/eagle-data-sharing/#what-to-tell-your-collaborators","title":"What to tell your Collaborators","text":"<p>If you set up a shared endpoint and want your collaborator to download the data, this is what you need to tell them.</p> <p>First, the collaborator needs to get a Globus account. The instructions for setting up a Globus account are as described above. This account is free. They may already have Globus access via their institution.</p> <p>If the collaborator is downloading the data to his/her personal workstation, they need to install the Globus Connect client. Globus connect clients are available for Mac, Windows, or Linux systems and are free.</p> <p>If you clicked on the 'notify users via email' button when you added access for this user, they should have received a message that looks like this:</p> <p></p> <p>Click on the 'notify users via email' button for collaborators to receive an email</p> <p>You can, of course, also send an email to your collaborators yourself, telling them you've shared a folder with them. The collaborator should click on the link, which will require logging in with their institutional or Globus login username and password. They should then be able to see the files you shared with them. External collaborator's view of the shared collection is shown below:</p> <p></p> <p>Collaborator transfer or sync to</p> <p>They should click on the files they want to transfer, then 'Transfer or Sync to', enter their own endpoint name and desired path, and click the 'Start' button near the bottom to start the transfer.</p> <p></p> <p>Choosing transfer path</p>"},{"location":"data-management/acdc/eagle-data-sharing/#encryption-and-security","title":"Encryption and Security","text":"<p>Data can be encrypted during Globus file transfers. In some cases, encryption cannot be supported by an endpoint, and Globus Online will signal an error.</p> <p>For more information, see How does Globus ensure my data is secure?</p> <p>In the Transfer Files window, click on 'More options' at the bottom of the 2 panes. Check the 'encrypt transfer' checkbox in the options.</p> <p></p> <p>Encrypting the transfer</p> <p>Alternatively, you can encrypt the files before transfer using any method on your local system, then transfer them using Globus, then unencrypt on the other end.</p> <p>Danger</p> <p>Encryption and verification will slow down the data transfer.</p>"},{"location":"data-management/acdc/eagle-data-sharing/#faqs","title":"FAQs","text":""},{"location":"data-management/acdc/eagle-data-sharing/#general-faqs","title":"General FAQs:","text":"<p>1. What is the Eagle file system?</p> <p>They are Lustre file systems residing on an HPE ClusterStor E1000 platform equipped with 100 Petabytes of usable capacity across 8480 disk drives. Each ClusterStor platform also provides 160 Object Storage Targets and 40 Metadata Targets with an aggregate data transfer rate of 650GB/s.</p> <p>2. What is the difference between a Guest, Shared, and Mapped collection?</p> <ul> <li>Guest collections: A Guest collection is a logical construct that a PI sets up on their project directory in Globus that makes it accessible to collaborators. The PI creates a guest collection at or below their project and shares it with the Globus account holders.</li> <li>Shared collection: A guest collection becomes a shared collection when it is shared with a user/group.</li> <li>Mapped Collections: Mapped Collections are created by the endpoint administrators. In the case of Eagle, these are created by ALCF.</li> </ul> <p>3. Who can create Guest collections?</p> <p>ONLY a project PI (or project owner) can create guest collections and make them accessible to collaborators.</p> <p>Project Proxy (on the POSIX side) or Access Manager (on the Globus side) do not have the ability to create guest collections.</p> <p>4. Who is an Access Manager?</p> <p>Access Manager is someone who can act as a Proxy on behalf of the PI to manage the collection. The Access Manager has the ability to add users, remove users, grant or revoke read/write access privileges for those users on that particular guest collection. However, Access Managers DO NOT have permissions to create guest collections.</p> <p>5. What are Groups?</p> <p>Groups are constructs that enable multi-user data collaboration. A PI (and an Access Manager) can create new groups, add members to them, and share a guest collection with a group of collaborators.</p> <p>Note: Members of groups do not need to have ALCF accounts.</p> <p>6. What are some of the Common Errors you see and what do they mean?</p> <pre><code>- EndpointNotFound   -  Wrong endpoint name \n- PermissionDenied    -  If you do not have permissions to view or modify the collection on &lt;endpoint&gt;\n- ServiceUnavailable  -  If the service is down for maintenance\n</code></pre>"},{"location":"data-management/acdc/eagle-data-sharing/#pi-faqs","title":"PI FAQs:","text":"<p>1. How can a PI request for a data-only, Eagle storage allocation?</p> <p>A project PI can request an allocation by filling out the Director\u2019s Discretionary Allocation Request form: Request an allocation. The allocations committee reviews the proposals and provides its decision in 1-2 weeks.</p> <p>2. Does a PI need to have an ALCF account to create a Globus guest collection?</p> <p>Yes. The PI needs to have an 'active' ALCF account in place to create and share guest collections with collaborators.</p> <ul> <li>PIs with an \"Inactive/Deleted\" ALCF account should submit a reactivation request by filling out this form: Re-activation Form</li> <li>PIs without an ALCF account should submit an ALCF account request by filling out this form: Account Request Form</li> </ul> <p>3. What endpoint should the PI use?</p> <p><code>alcf#dtn_eagle</code> (project on Eagle)</p> <p>4. What are the actions a PI can perform?</p> <ul> <li>Create and delete guest collections, groups</li> <li>Create, delete, and share the data with ALCF users and external collaborators</li> <li>Specify someone as a Proxy (Access Manager) for the guest collections</li> <li>Transfer data between the guest collection on Eagle and other Globus endpoints/collections</li> </ul> <p>5. How can a PI specify someone as a Proxy on the Globus side?</p> <p>Go to <code>alcf#dtn_eagle</code> -&gt; collections -&gt; shared collection -&gt; roles -&gt; select 'Access Manager'</p> <p></p> <p>To specify someone as a Proxy, click on \"Roles\"</p> <p></p> <p>Choose Access Manager and \"Add Role\"</p> <p>6. What is the high-level workflow for setting up a guest collection?</p> <ol> <li>PI requests a compute or data-only allocation project.</li> <li>Once the request is approved, ALCF staff sets up a project, unixgroup, and project directory.</li> <li>A Globus sharing policy is created for the project with appropriate access controls, provided the PI has an active ALCF account.</li> <li> <p>PI creates a guest collection for the project, using the Globus mapped collection for the file system (<code>alcf#dtn_eagle</code>)</p> <ul> <li>Note: PI needs to have an active ALCF Account and will need to log in to Globus using their ALCF credentials.</li> <li>If PI has an existing Globus account, it needs to be linked to their ALCF account.</li> </ul> </li> <li> <p>PI adds collaborators to the guest collection. Collaborators can be ALCF users and external collaborators and can be added with Read only or Read-Write permissions</p> </li> </ol> <p>7. How can project members with ALCF accounts access the project directory via Globus?</p> <p>Users that have active ALCF accounts and are part of the project in the ALCF Account and Project Management system will automatically have access to the project directory which they can access by browsing the Globus endpoint <code>alcf#dtn_eagle</code>. If they want to access the files using the Globus guest collection set up by the PI, the PI will need to explicitly give them permissions to that guest collection. The purpose of Globus guest collections is to share the data with collaborators that don't have ALCF accounts or are not part of the project in the ALCF Account and Project Management system.</p> <p>8. Who has the permissions to create a guest collection?</p> <p>Only the PI has the ability to create a guest collection. The Access Manager, along with the PI, has permissions to share it with collaborators (R-only or R-W permissions as needed).</p> <p>9. I am the project PI. Why do I see a \"Permission Denied\" error when I try to CREATE a guest collection?</p> <p>If you are a PI and you see this error, it could mean that a sharing policy for the project is missing. Please contact support@alcf.anl.gov so they can set one up.</p> <p>10. If a PI added a member as a project proxy on the POSIX-side, is it safe to assume that the Proxy can create guest collections?</p> <p>No, project proxies cannot create guest collections, only the PI can.</p> <p>11. Who can create groups?</p> <p>A PI (and an Access Manager) can create new groups, add members to them, and share a guest collection with a group of collaborators. For more information, refer to: Creating a group</p> <p>12. What happens when the PI of a project changes? What happens to the guest collection endpoint?</p> <p>The new PI will need to create new guest collections and share it with collaborators again. Guest collections are tied to a PI's account and cannot be transferred.</p> <p>13. I noticed that I am the owner of all the files that were transferred by external collaborators using the guest collection. Why is that?</p> <p>When collaborators read files from or write files to the guest collection, they do so on behalf of the PI. All writes show up as having been carried by the PI. Additionally, if the PI does not have permission to read or write to a file or folder in the directory, then the collaborators will not have those permissions either.</p> <p>14. What happens to the guest collections when the PI's account goes inactive?</p> <p>The collections go inactive and will remain in that state until the PI's account is re-activated.</p> <p>15. How long does it take for the endpoint to become accessible to collaborators after a PI's account is re-activated?</p> <p>Right away. The page needs to be refreshed and sometimes you may have to log out and log back in.</p>"},{"location":"data-management/acdc/eagle-data-sharing/#access-manager-faqs","title":"Access Manager FAQs:","text":"<p>1. What are the actions an Access Manager can perform?</p> <p>Access Manager should be able to see the collection under \"Shared with you\" and \"Shareable by you\" tabs. They have permissions to add and/or delete collaborators on the shared collection and restrict their R-W access as needed.</p> <p>2. Does an Access Manager need to have an ALCF account?</p> <p>Not necessary. However, if they need to manage the membership on the POSIX side (or in the ALCF Account and Project Management system), they will need an ALCF account and be a Proxy on the project.</p> <p>3. What is the difference between an ALCF project Proxy and a guest collection Access Manager?</p> <p>An ALCF Project Proxy has permissions to manage project membership on the POSIX side whereas a guest collection Access Manager has permissions to manage the project membership specific to that guest collection, created by the PI, on the Globus side.</p> <p>4. I am an 'Access Manager' on the collection. Why do I see a 'Permission Denied' error when I try to SHARE a guest collection created by the PI?</p> <p>If you are a non-PI who is able to access the guest collection but unable to share it, it means that your role on this guest collection is limited to a \"Member\". If you want the ability to share folders and sub-folders from the collections that are shared with you, please talk to the PI. They will need to set your role to an \"Access Manager\" for the collection within Globus.</p> <p>5. Can an Access Manager give external collaborators access to the collections that are shared with them?</p> <p>Yes, an Access Manager will see the \"Permissions\" tab at the top of the shared collection page and can share it with collaborators and/or a group.</p> <p>6. Can an Access Manager create collections using the shared endpoint?</p> <p>No. An access manager cannot create a collection, only a PI can do that. The access manager can however share folders and sub-folders from the collections that are shared with them.</p> <p>7. Can an Access Manager leave a globus group or withdraw membership request for collaborators?</p> <p>Yes. Go to <code>alcf#dtn_eagle</code> -&gt; Groups &gt; group_name -&gt; Members -&gt; click on specific user -&gt; Role &amp; Status -&gt; Set the appropriate status.</p> <p></p> <p>If you get this error, you do not have read permissions.</p> <p>8. Can an Access Manager delete guest collections created by PI?</p> <p>No. Access managers cannot delete guest collections.</p> <ol> <li> <p>If the PI has read permissions for those files on the POSIX side and the collaborator is given read permissions in Globus for the guest collection.\u00a0\u21a9</p> </li> <li> <p>If the PI has write permissions for those files on the POSIX side and the collaborator is given write permissions in Globus for the guest collection.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"data-management/acdc/eagle-data-sharing/#guest-collection-collaborators-faqs","title":"Guest Collection Collaborators FAQs:","text":"<p>1. What actions can collaborators perform?</p> <ol> <li>Collaborators can read files from a collection<sup>1</sup></li> <li>Collaborators can write to a collection<sup>2</sup></li> <li>Collaborators can delete files in a collection<sup>2</sup></li> </ol> <p>2. I am a collaborator. Why do I see a 'Permission Denied' error when I try to ACCESS a guest collection created by the PI?</p> <p>If you are a non-PI and you see this error while trying to access the collection, it means that you do not have read permissions to access the guest collection. Please contact the PI for required access.</p> <p></p> <p>If you get this error, you do not have read permissions.</p>"},{"location":"data-management/data-transfer/sftp-scp/","title":"SFTP and SCP","text":"<p>These standard utilities are available for local area transfers of small files. They are not recommended for use with large data transfers due to poor performance and excess resource utilization on the login nodes.</p> <p>See Globus for performing large data transfers.</p>"},{"location":"data-management/data-transfer/sftp-scp/#scp-examples","title":"<code>scp</code>: Examples","text":"<p>Examples sourced from this page</p> <ul> <li> <p>Copy a local file to a remote host:</p> <pre><code>scp path/to/local_file remote_host:path/to/remote_file\n</code></pre> </li> <li> <p>Use a specific port when connecting to the remote host:</p> <pre><code>scp -P port path/to/local_file remote_host:path/to/remote_file\n</code></pre> </li> <li> <p>Copy a file from a remote host to a local directory:</p> <pre><code>scp remote_host:path/to/remote_file path/to/local_directory\n</code></pre> </li> <li> <p>Recursively copy the contents of a directory from a remote host to a local directory:</p> <pre><code>scp -r remote_host:path/to/remote_directory path/to/local_directory\n</code></pre> </li> <li> <p>Copy a file between two remote hosts transferring through the local host:</p> <pre><code>scp -3 host1:path/to/remote_file host2:path/to/remote_directory\n</code></pre> </li> <li> <p>Use a specific username when connecting to the remote host:</p> <pre><code>scp path/to/local_file remote_username@remote_host:path/to/remote_directory\n</code></pre> </li> <li> <p>Use a specific SSH private key for authentication with the remote host:</p> <pre><code>scp -i ~/.ssh/private_key path/to/local_file remote_host:path/to/remote_file\n</code></pre> </li> <li> <p>Use a specific proxy when connecting to the remote host:</p> <pre><code>scp -J proxy_username@proxy_host path/to/local_file remote_host:path/to/remote_file\n</code></pre> </li> </ul>"},{"location":"data-management/data-transfer/using-globus/","title":"Using Globus","text":"<p>Globus addresses the challenges faced by researchers in moving, sharing, and archiving large volumes of data among distributed sites. With Globus, you hand off data movement tasks to a hosted service that manages the entire operation. It monitors performance and errors, retries failed transfers, corrects problems automatically whenever possible, and reports status to keep you informed and focused on your research.</p> <p>Command line and web-based interfaces are available. The command line interface, which requires only SSH to be installed on the client, is the method of choice for script-based workflows. Globus also provides a REST-style transfer API for advanced use cases that require scripting and automation.</p>"},{"location":"data-management/data-transfer/using-globus/#getting-started","title":"Getting Started","text":"<p>Basic documentation for getting started with Globus can be found at the following URL: https://docs.globus.org/how-to/</p>"},{"location":"data-management/data-transfer/using-globus/#data-transfer-node","title":"Data Transfer Node","text":"<p>Several data transfer nodes (DTNs) for <code>/home</code>, Eagle, Grand, and HPSS are available to ALCF users, allowing users to perform wide and local area data transfers. Access to the DTNs is provided via the following Globus endpoints.</p>"},{"location":"data-management/data-transfer/using-globus/#alcf-globus-endpoints","title":"ALCF Globus Endpoints","text":"<p>The Globus endpoint and the path to use depend on where your data resides. If your data is on:</p> <ul> <li><code>/home</code>, which is where your home directory resides for Polaris, Sophia, and Crux systems: <code>alcf#dtn_home</code> for accessing <code>/home</code> (i.e., home directories on the agile-home filesystem). Use the path <code>/&lt;username&gt;</code></li> <li>HPSS: <code>alcf#dtn_hpss</code></li> <li>Eagle filesystem: <code>alcf#dtn_eagle</code> for accessing <code>/lus/eagle/projects</code> or <code>/eagle</code> (i.e., project directories on the Eagle filesystem). Use the path <code>/eagle/&lt;project name&gt;</code></li> <li>Grand filesystem: <code>alcf#dtn_grand</code> for accessing <code>/lus/grand/projects</code> or <code>/grand</code> (i.e., project directories on the Grand filesystem). Use the path <code>/grand/&lt;project name&gt;</code></li> <li>Flare filesystem: <code>alcf#dtn_flare</code> for accessing <code>/lus/flare/projects</code> or <code>/flare</code> (i.e., project directories on the Flare filesystem) on Aurora. Use the path <code>/&lt;project name&gt;</code></li> </ul> <p>After registering, simply use the appropriate ALCF endpoint, as well as other sources or destinations. Use your ALCF credentials (your OTP generated by the CryptoCARD token with PIN or Mobilepass app) to activate the ALCF endpoint.</p> <p>Globus Connect Personal allows users to add laptops or desktops as an endpoint to Globus in just a few steps. After you set up Globus Connect Personal, Globus can be used to transfer files to and from your computer.</p>"},{"location":"data-management/data-transfer/using-globus/#references","title":"References","text":"<p>Research Data Management with Globus (2019) </p>"},{"location":"data-management/filesystem-and-storage/","title":"ALCF File Systems and Storage","text":""},{"location":"data-management/filesystem-and-storage/#disk-storage","title":"Disk Storage","text":"<p>Our HPC systems store project data in file systems called Eagle and Flare. Eagle and Flare are Lustre file systems mounted as <code>/eagle</code> and <code>/flare</code>, respectively. For more information on the Lustre file systems, consult this document on Lustre File Striping Basics.</p> <p>For information on the AI Testbed storage systems, refer to the AI Testbed Data Management page.</p> <p>Our HPC systems also mount a Lustre home file system, either agile-home or gecko-home. The home file system is mounted as <code>/home</code> and should generally be used for small files and any binaries to be run on Polaris or Aurora. The performance of this file system is reasonable, but using it for intensive I/O from the compute nodes is discouraged because I/O from the compute nodes uses the project data file systems, which are fast parallel systems and have far more storage space and greater I/O performance than the home directory space.</p> <p>The agile-home file system is regularly backed up to tape. The data file system is not backed up. It is the user\u2019s responsibility to ensure that copies of any critical data on the data file system have either been archived to tape or stored elsewhere.</p> Name Accessible From Type Path Production Backed-up Usage agile-home Polaris, Crux, Sophia Lustre <code>/home</code> or <code>/lus/agile/home</code> Yes Yes General use eagle Polaris, Crux, Sophia Lustre <code>/eagle</code> or <code>/lus/eagle/projects</code> Yes No Community sharing via Globus;  Intensive job output, large files Node SSD  (Compute node only) Polaris xfs <code>/local/scratch</code> Yes No Local node scratch during run gecko-home Aurora Lustre <code>/home</code> or <code>/lus/gecko/home</code> Yes No General use flare Aurora Lustre <code>/flare</code> or <code>/lus/flare/projects</code> Yes No Intensive job output, large files"},{"location":"data-management/filesystem-and-storage/#available-directories","title":"Available Directories","text":""},{"location":"data-management/filesystem-and-storage/#home-directories","title":"Home Directories","text":"<ul> <li>Created when an account is created</li> <li>Located under <code>/home</code></li> <li>Each home directory is subject to a quota based on user file ownership. The default quota is 50 GB</li> </ul>"},{"location":"data-management/filesystem-and-storage/#sharing-home-directory-files-or-subdirectories-with-others","title":"Sharing Home Directory Files or Subdirectories with Others","text":"<p>If you need to share files or subdirectories (folders) under your home directory with collaborators (other ALCF users), you need to change file permissions from their defaults. You must change permissions of your top-level <code>/home/username</code> directory, even if you only want to share certain files/directories within it. Using normal Linux file permissions control is good enough to give access to all other users and is simple. For more fine-grained control over specific users, you need to use Linux access control list (ACL) commands.</p>"},{"location":"data-management/filesystem-and-storage/#simple-method-permission-to-all-users","title":"Simple Method: Permission to All Users","text":"<p>First, a one-time-only change to your top-level <code>/home/username</code> directory.</p> <pre><code>chmod o+x /home/username\n</code></pre> <p>Then you may permission individual files and/or subdirectories with read access. For example, to recursively change permissions on <code>/home/username/subdirectoryname</code> so that all files in that subdirectory and any subdirectory trees within it are world-readable, you would use</p> <pre><code>chmod -R o+Xr /home/username/subdirectoryname\n</code></pre>"},{"location":"data-management/filesystem-and-storage/#refined-method-use-acl-to-give-permission-to-specific-users","title":"Refined Method: Use ACL to Give Permission to Specific Users","text":"<p>First, a one-time-only change to your top-level <code>/home/username</code> directory. To share files/directories with user <code>gilgamesh</code>, for example:</p> <pre><code>setfacl -m u:gilgamesh:X /home/username\n</code></pre> <p>Then you may permission individual files and/or subdirectories with read access. For example, to recursively change permissions on <code>/home/username/subdirectoryname</code> so that all files in that subdirectory and any subdirectory trees within it are readable to user gilgamesh, you would use</p> <pre><code>setfacl -R -m u:gilgamesh:rX /home/username/subdirectoryname\n</code></pre>"},{"location":"data-management/filesystem-and-storage/#project-directories","title":"Project Directories","text":"<ul> <li>Directories on Eagle or Flare are created when an allocation (INCITE, ALCC, Discretionary, etc.) is awarded. Directories can be created as stand-alone allocations. Use the allocation request form to submit requests for an allocation on Eagle. </li> <li>Directory paths:<ul> <li>Eagle: <code>/eagle</code> or <code>/lus/eagle/projects</code></li> <li>Flare: <code>/flare</code> or <code>/lus/flare/projects</code></li> </ul> </li> </ul> <p>These project spaces do not have user quotas but a directory quota, meaning that ALL files contained within a project directory, regardless of the username, cannot exceed the disk space allocation granted to the project. For more information on quotas, see the Disk Quota page.</p>"},{"location":"data-management/filesystem-and-storage/#local-node-ssd","title":"Local Node SSD","text":"<p>Access to SSDs is enabled by default on Polaris.</p>"},{"location":"data-management/filesystem-and-storage/#ssd-information","title":"SSD Information","text":"<ul> <li>Local scratch SSD storage on compute nodes for running jobs</li> <li>Completely local non-parallel filesystem</li> <li>Located at <code>/local/scratch</code> on Polaris computes</li> <li>Wiped between Cobalt/PBS Pro jobs</li> <li>No automatic backups provided</li> <li>Information on the current SSD drives in use is below:</li> </ul> <p>Polaris SSD Specs</p> <p>Model PM1725a drives specifications</p> Model PM1725a drives ------- Capacity 1.6 TB Sequential Read 3300 MB/s Sequential Write 3300 MB/s"},{"location":"data-management/filesystem-and-storage/#tape-storage","title":"Tape Storage","text":"<p>ALCF operates three 10,000-slot Spectralogic tape libraries. We are currently running a combination of LTO6 and LTO8 tape technology. The LTO tape drives have built-in hardware compression which typically achieves compression ratios between 1.25:1 and 2:1 depending on the data, yielding an effective capacity of approximately 65 PB.</p>"},{"location":"data-management/filesystem-and-storage/disk-quota/","title":"Disk Quota","text":""},{"location":"data-management/filesystem-and-storage/disk-quota/#overview","title":"Overview","text":"<p>Disk quotas are enabled on project directories. ALCF's HPC systems use the agile-home file system located at <code>/lus/agile/home</code>, where quotas are also enforced. Details on the home file system are listed in file systems. Below are descriptions and examples for the home file system, as well as the Eagle project filesystems.</p>"},{"location":"data-management/filesystem-and-storage/disk-quota/#home-directory-quotas","title":"Home Directory Quotas","text":"<p>By default, each home directory is assigned a quota of 50 GB. File ownership determines disk space usage.</p> <p>To check the home directory usage, enter this command:</p> <pre><code>myquota\n</code></pre> <pre><code>Name                           Type     Filesystem        Used               Quota          Grace\n=========================================================================================================\nuserX                         User     /lus/agile         44.13G          50.00G             none\n</code></pre>"},{"location":"data-management/filesystem-and-storage/disk-quota/#project-directory-quotas","title":"Project Directory Quotas","text":"<p>The amount of data stored under <code>/lus/grand/projects/PROJECT_NAME</code> cannot exceed the approved project quota limit set during the allocation period. The total data usage under the project directory is used to calculate the disk quota.</p> <p>To check project quota usage on the file systems, enter this command:</p> <pre><code>myprojectquotas\n</code></pre> <pre><code>Lustre : Current Project Quota information for projects you're a member of:\n\nName                       Type        Filesystem          Used             Quota           Grace\n==============================================================================================================\nprojectX                  Project      eagle                1.87T             1000T            -\n</code></pre>"},{"location":"data-management/filesystem-and-storage/disk-quota/#requesting-a-new-eagle-allocation","title":"Requesting a New Eagle Allocation","text":"<p>To request a new project with an allocation on Eagle (with or without a compute allocation), please fill out the Director's Discretionary allocation form. Note that all new compute projects will have the default file system.</p>"},{"location":"data-management/filesystem-and-storage/disk-quota/#extending-a-quota","title":"Extending a Quota","text":"<p>If you need to extend an expiring quota for your project directory, please send an email to support@alcf.anl.gov with the project name, filesystem, requested extension length, and reason for the extension.</p>"},{"location":"data-management/filesystem-and-storage/disk-quota/#quota-increases","title":"Quota Increases","text":"<p>If you need a quota increase for your project directory, please send an email to support@alcf.anl.gov with the project name, filesystem, new quota amount, and reason for the increase.</p>"},{"location":"data-management/filesystem-and-storage/hpss/","title":"Using HPSS","text":""},{"location":"data-management/filesystem-and-storage/hpss/#overview","title":"Overview","text":"<p>HPSS is a data archive and retrieval system that manages large amounts of data on disk and robotic tape libraries. It provides hierarchical storage management services that allow it to migrate data between those storage platforms.</p> <p>HPSS is currently configured with a disk and tape tier. The disk tier has a capacity of 1.2PB on a DataDirect Networks SFA12K-40 storage array. By default, all archived data is initially written to the disk tier. The tape tier consists of 3 SpectraLogic T950 robotic tape libraries containing a total of 72 LTO6 tape drives with a total uncompressed capacity of 64 PB. Archived data is migrated to the tape tier at regular intervals, then deleted from the disk tier to create space for future archives.</p> <p>Access to HPSS is provided by various client components. Currently, ALCF supports access through two command-line clients: HSI and HTAR. These are installed on the login nodes of Polaris and other machines. In order for the client to authenticate with HPSS, the user must have a keytab file that should be located in their home directory under the subdirectory <code>.hpss</code>. The file name will be in the format <code>.ktb_&lt;userid&gt;</code>.</p>"},{"location":"data-management/filesystem-and-storage/hpss/#hsi-general-usage","title":"HSI General Usage","text":"<p>HSI can be invoked by simply entering <code>hsi</code> at your normal shell prompt. Once authenticated, you will enter the HSI command shell environment: ```console lineums=\"1\"</p> <p>hsi [HSI]/home/username-&gt; <pre><code>You may enter \"help\" to display a brief description of available commands.\n\nExample archive:\n```console lineums=\"1\"\n[HSI]/home/username-&gt; put mydatafile                # same name on HPSS\n[HSI]/home/username-&gt; put local.file : hpss.file    # different name on HPSS\n</code></pre></p> <p>Example retrieval: ```console lineums=\"1\" [HSI]/home/username-&gt; get mydatafile [HSI]/home/username-&gt; get local.file : hpss.file <pre><code>Most of the usual shell commands will work as expected in the HSI command environment.\n\nFor example, checking what files are archived:\n```console lineums=\"1\"\n[HSI]/home/username-&gt; ls -l\n</code></pre></p> <p>And organizing your archived files: <code>console lineums=\"1\" [HSI]/home/username-&gt; mkdir dataset1 [HSI]/home/username-&gt; mv hpss.file dataset1 [HSI]/home/username-&gt; ls dataset1 [HSI]/home/username-&gt; rm dataset1/hpss.file <pre><code>It may be necessary to use single or double quotes around metacharacters to avoid having the shell prematurely expand them.\n\nFor example:\n```console lineums=\"1\"\n[HSI]/home/username-&gt; get *.c\n</code></pre> will not work, but</code>console lineums=\"1\" [HSI]/home/username-&gt; get \"*.c\" <pre><code>will retrieve all files ending in `.c`.\n\nFollowing normal shell conventions, other special characters in filenames such as whitespace and semicolon also need to be escaped with \"\\\\\" (backslash). For example:\n```console lineums=\"1\"\n[HSI]/home/username-&gt; get \"data\\ file\\ \\;\\ version\\ 1\"\n</code></pre> retrieves the file named \"data file ; version 1\".</p> <p>HSI can also be run as a command line or embedded in a script as follows: <pre><code>hsi -O log.file \"put local.file\"\n</code></pre></p>"},{"location":"data-management/filesystem-and-storage/hpss/#htar-general-usage","title":"HTAR General Usage","text":"<p>HTAR is a <code>tar</code>-like utility that creates <code>tar</code>-format archive files directly in HPSS. It can be run as a command line or embedded in a script.</p> <p>Example archive: <pre><code>htar -cf hpssfile.tar localfile1 localfile2 localfile3\n</code></pre></p> <p>Example retrieval: <pre><code>htar -xf hpssfile.tar localfile2\n</code></pre></p> <p>Info</p> <p>The current version of HTAR has a 64 GB file size limit as well as a path length limit. The recommended client is HSI.</p>"},{"location":"data-management/filesystem-and-storage/hpss/#globus","title":"Globus","text":"<p>In addition, HPSS is accessible through the Globus endpoint <code>alcf#dtn_hpss</code>. As with HSI and HTAR, you must have a keytab file before using this endpoint. For more information on using Globus, please see Using Globus.</p>"},{"location":"data-management/filesystem-and-storage/hpss/#common-problems","title":"Common Problems","text":""},{"location":"data-management/filesystem-and-storage/hpss/#keytab-file-missing","title":"Keytab File Missing","text":"<p>If you see an error like this: <pre><code>*** HSI: (KEYTAB auth method) - keytab file missing or inaccessible: /\n home/username/.hpss/.ktb_username\n Error - authentication/initialization failed\n</code></pre> it means that your account is not enabled to use the HPSS yet. Please contact support to have it set up.</p>"},{"location":"machines/","title":"Machines","text":"<p>ALCF resources include leadership-class supercomputers, visualization clusters, AI testbed resources, advanced data storage systems, high-performance networking capabilities, and a wide variety of software tools and services to help facility users achieve their science goals. Click on the system specific links under \"Machines\" in the left-hand navigation menu to learn more.</p>"},{"location":"polaris/","title":"Polaris Machine Overview","text":"<p>Polaris is a 560-node HPE Apollo 6500 Gen 10+ based system. Each node has a single 2.8 GHz AMD EPYC Milan 7543P 32-core CPU with 512 GB of DDR4 RAM, four NVIDIA A100 GPUs connected via NVLink, a pair of local 1.6TB SSDs in RAID0 for user use, and a pair of Slingshot 11 network adapters. There are two nodes per chassis, seven chassis per rack, and 40 racks for a total of 560 nodes. More detailed specifications are as follows:</p>"},{"location":"polaris/#polaris-compute-nodes","title":"Polaris Compute Nodes","text":"POLARIS COMPUTE DESCRIPTION PER NODE AGGREGATE Processor (Note 1) 2.8 GHz 7543P 1 560 Cores/Threads AMD Zen 3 (Milan) 32/64 17,920/35,840 RAM (Note 2) DDR4 512 GiB 280 TiB GPUs NVIDIA A100 4 2,240 Local SSD 1.6 TB 2/3.2 TB 1,120/1.8 PB <ul> <li>Note 1: 256 MB shared L3 cache, 512 KB L2 cache per core, 32 KB L1 cache per core</li> <li>Note 2: 8 memory channels rated at 204.8 GiB/s</li> </ul>"},{"location":"polaris/#polaris-a100-gpu-information","title":"Polaris A100 GPU Information","text":"DESCRIPTION A100 PCIe A100 HGX (Polaris) GPU Memory 40 GiB HBM2 160 GiB HBM2 GPU Memory BW 1.6 TB/s 6.4 TB/s Interconnect PCIe Gen4 64 GB/s NVLink 600 GB/s FP 64 9.7 TF 38.8 TF FP64 Tensor Core 19.5 TF 78 TF FP 32 19.5 TF 78 TF BF16 Tensor Core 312 TF 1.3 PF FP16 Tensor Core 312 TF 1.3 PF INT8 Tensor Core 624 TOPS 2,496 TOPS Max TDP Power 250 W 400 W"},{"location":"polaris/#polaris-device-affinity-information","title":"Polaris Device Affinity Information","text":"CPU Affinity NUMA Affinity GPU0 GPU1 GPU2 GPU3 mlx5_0 mlx5_1 24-31,56-63 3 GPU0 X NV4 NV4 NV4 SYS SYS 16-23,48-55 2 GPU1 NV4 X NV4 NV4 SYS PHB 8-15,40-47 1 GPU2 NV4 NV4 X NV4 SYS SYS 0-7,32-39 0 GPU3 NV4 NV4 NV4 X PHB SYS mlx5_0 SYS SYS SYS PHB X SYS mlx5_1 SYS PHB SYS SYS SYS X <p>Legend</p> <ul> <li>X = Self</li> <li>SYS = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)</li> <li>NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node</li> <li>PHB = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)</li> <li>PXB = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)</li> <li>PIX = Connection traversing at most a single PCIe bridge</li> <li>NV# = Connection traversing a bonded set of # NVLinks</li> </ul> <p>Links to detailed NVIDIA A100 documentation:</p> <ul> <li>NVIDIA A100 Tensor Core GPU Architecture</li> <li>NVIDIA Ampere Architecture In-Depth</li> </ul>"},{"location":"polaris/#login-nodes","title":"Login Nodes","text":"<p>There are four login nodes available to users for editing code, building code, submitting/monitoring jobs, checking usage (<code>sbank</code>), etc. Their full hostnames are <code>polaris-login-N.hsn.cm.polaris.alcf.anl.gov</code> for <code>N</code> equal to <code>01</code> through <code>04</code>; there are an additional two login nodes that are not user-accessible, which are used for running services such as JupyterHub. The various compilers and libraries are present on the logins, so most users should be able to build their code. However, if your build requires the physical presence of the GPU, you will need to build on a compute node.</p> <p>All users share the same login nodes, so please be courteous and respectful of your fellow users. For example, please do not run computationally or I/O intensive pre- or post-processing on the logins and keep the parallelism of your builds to a reasonable level.</p> POLARIS LOGIN DESCRIPTION PER NODE AGGREGATE Processor (Note 1) 2.0 GHz 7713 2 12 Cores/Threads AMD Zen 3 (Milan) 128/256 768/1,536 RAM (Note 2) DDR4 512 GiB 3 TiB GPUs (Note 3) No GPUs 0 0 Local SSD None 0 0 <ul> <li>Note 1: 256 MB shared L3 cache, 512 KB L2 cache per core, 32 KB L1 cache per core</li> <li>Note 2: 8 memory channels rated at 204.8 GiB/s per socket</li> <li>Note 3: If your build requires the physical presence of a GPU, you will need to build on a compute node.</li> </ul>"},{"location":"polaris/#gateway-nodes","title":"Gateway Nodes","text":"<p>There are 50 gateway nodes. These nodes are not user-accessible but are used transparently for access to the storage systems. Each node has a single 200 Gbps HDR IB card for access to the storage area network. This gives a theoretical peak bandwidth of 1,250 GB/s, which is approximately the aggregate bandwidth of the global file systems (1,300 GB/s).</p>"},{"location":"polaris/#storage","title":"Storage","text":"<p>Polaris has access to the ALCF global file systems. Details on storage can be found here.</p>"},{"location":"polaris/getting-started/","title":"Getting Started on Polaris","text":""},{"location":"polaris/getting-started/#logging-into-polaris","title":"Logging Into Polaris","text":"<p>To log into Polaris: <pre><code>ssh &lt;username&gt;@polaris.alcf.anl.gov\n</code></pre> Then, type in the password from your CRYPTOCard/MobilePASS+ token.</p>"},{"location":"polaris/getting-started/#hardware-overview","title":"Hardware Overview","text":"<p>An overview of the Polaris system, including details on the compute node architecture, is available on the Machine Overview page.</p>"},{"location":"polaris/getting-started/#compiling-applications","title":"Compiling Applications","text":"<p>Users are encouraged to read through the Compiling and Linking Overview page and corresponding pages depending on the target compiler and programming model.</p>"},{"location":"polaris/getting-started/#accessing-additional-software","title":"Accessing Additional Software","text":"<p>In addition to the Cray PE, ALCF installs software in <code>/soft</code>, which can be accessed via module commands by altering your <code>$MODULEPATH</code>: <pre><code>module use /soft/modulefiles\n</code></pre> The available software can then be queried with <code>module avail</code>.</p> <p>Additionally, a suite of software packages is provided via Spack deployments, detailed on the Spack PE page.</p>"},{"location":"polaris/getting-started/#submitting-and-running-jobs","title":"Submitting and Running Jobs","text":"<p>Users are encouraged to read through the Running Jobs with PBS at the ALCF page for information on using the PBS scheduler and preparing job submission scripts. Some example job submission scripts are available on the Example Job Scripts page as well.</p>"},{"location":"polaris/getting-started/#lustre-file-striping","title":"Lustre File Striping","text":"<p>In addition to the content above, here is a document on Lustre File Striping Basics:</p> <ul> <li>Lustre File Striping Basics</li> </ul>"},{"location":"polaris/getting-started/#proxy","title":"Proxy","text":"<p>If the node you are on doesn't have outbound network connectivity, add the following to your <code>~/.bash_profile</code> file to access the proxy host:</p> <pre><code># proxy settings\nexport HTTP_PROXY=\"http://proxy.alcf.anl.gov:3128\"\nexport HTTPS_PROXY=\"http://proxy.alcf.anl.gov:3128\"\nexport http_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport https_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport ftp_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport no_proxy=\"admin,polaris-adminvm-01,localhost,*.cm.polaris.alcf.anl.gov,polaris-*,*.polaris.alcf.anl.gov,*.alcf.anl.gov\"\n</code></pre>"},{"location":"polaris/getting-started/#getting-assistance","title":"Getting Assistance","text":"<p>Please direct all questions, requests, and feedback to support@alcf.anl.gov.</p>"},{"location":"polaris/known-issues/","title":"Known Issues","text":"<p>This is a collection of known issues that have been encountered on Polaris. Documentation will be updated as issues are resolved. Users are encouraged to email support@alcf.anl.gov to report issues.</p>"},{"location":"polaris/known-issues/#submitting-jobs","title":"Submitting Jobs","text":"<ol> <li> <p>For batch job submissions, if the parameters within your submission script do not meet the parameters of any of the execution queues (<code>small</code>, ..., <code>backfill-large</code>), you might not receive the \"Job submission\" error on the command line at all, and the job will never appear in the history <code>qstat -xu &lt;username&gt;</code> (current bug in PBS). For example, if a user submits a script to the <code>prod</code> routing queue requesting 10 nodes for 24 hours, exceeding the \"Time Max\" of 6 hours of the <code>small</code> execution queue (which handles jobs with 10-24 nodes), then it may behave as if the job was never submitted.</p> </li> <li> <p>Job scripts are copied to temporary locations after <code>qsub</code>, and any changes to the original script while the job is queued will not be reflected in the copied script. Furthermore, <code>qalter</code> requires <code>-A &lt;allocation name&gt;</code> when changing job properties. Currently, there is a request for a <code>qalter</code>-like command to trigger a re-copy of the original script to the temporary location.</p> </li> </ol>"},{"location":"polaris/known-issues/#compiling-running-applications","title":"Compiling &amp; Running Applications","text":"<ol> <li>If your job fails to start with an <code>RPC launch</code> message like the one below, please forward the complete messages to support@alcf.anl.gov.    <pre><code>launch failed on x3104c0s1b0n0: Couldn't forward RPC launch(ab751d77-e80a-4c54-b1c2-4e881f7e8c90) to child x3104c0s31b0n0.hsn.cm.polaris.alcf.anl.gov: Resource temporarily unavailable\n</code></pre></li> <li>The message below is an XALT-related warning that can be ignored when running <code>apptainer</code>. For other commands, please forward the complete message to support@alcf.anl.gov so we are aware of your use case.    <pre><code>ERROR: ld.so: object '/soft/xalt/3.0.2-202408282050/lib64/libxalt_init.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n</code></pre></li> </ol>"},{"location":"polaris/known-issues/#sshing-between-polaris-compute-nodes","title":"<code>ssh</code>'ing between Polaris Compute Nodes","text":"<ol> <li> <p>You should be able to <code>ssh</code> freely (without needing a password) between your assigned compute nodes on Polaris. If you are running into <code>ssh</code> issues, check for the following causes:</p> </li> <li> <p>Your <code>/home/&lt;username&gt;</code> directory permissions should be set to <code>700</code> (<code>chmod 700 /home/&lt;username&gt;</code>).</p> </li> <li>Confirm the following files exist in your <code>.ssh</code> directory and the permissions are set to the following:<ol> <li><code>-rw-------  (600)  authorized_keys</code></li> <li><code>-rw-r--r--  (644)  config</code></li> <li><code>-rw-------  (600)  id_rsa</code></li> <li><code>-rw-r--r--  (644)  id_rsa.pub</code></li> </ol> </li> <li>If you do not have the files mentioned above, you will need to create them.<ol> <li>You can generate an <code>id_rsa</code> file with the following command: <code>ssh-keygen -t rsa</code></li> </ol> </li> <li>Copy the contents of your <code>.ssh/id_rsa.pub</code> file to <code>.ssh/authorized_keys</code>.</li> </ol>"},{"location":"polaris/known-issues/#set-tmpdir-to-avoid-af_unix-path-too-long-error","title":"Set <code>TMPDIR</code> to avoid <code>AF_UNIX path too long</code> error","text":"<p>Software that relies on the setting of <code>TMPDIR</code> to create socket files may encouter the linux error <code>AF_UNIX path too long</code> when running in processes launched with <code>mpiexec</code> on a single node.  This issue has arisen in software using the <code>python</code> <code>multiprocessing</code> library for this purpose, including some use cases of <code>pytorch</code> and <code>parsl</code>.</p> <p>The solution for this error is to manually set <code>TMPDIR</code> before launching the application, e.g.</p> <pre><code>export TMPDIR=/tmp\n</code></pre> <p>Alternatively, it can be set with the <code>mpiexec</code> command, e.g.</p> <pre><code>mpiexec --env TMPDIR=/tmp -n 1 --ppn 1 ...\n</code></pre>"},{"location":"polaris/system-updates/","title":"Polaris System Updates","text":""},{"location":"polaris/system-updates/#2025-10-24","title":"2025-10-24","text":"<p><code>conda/2025-09-25</code> is now the default module loaded by \"module load conda\" on Polaris. The previous default, <code>conda/2024-04-29</code>, remains available for now. The old module may be removed entirely in the future (advanced notice will be given).</p>"},{"location":"polaris/system-updates/#2025-10-10","title":"2025-10-10","text":"<p>Following the system HPCM upgrade in August, the new <code>conda/2025-09-25</code> module is now available to users on Polaris; it is recommended that all users of the previous <code>conda/2024-04-29</code> module switch as soon as possible. While the old module remains the default if <code>module load conda</code> is used, the default will change in two weeks. The old module may be removed entirely in the future (advanced notice will be given).</p> <p>The new module restores functionality broken by the system upgrade and updates the following major libraries and package versions:</p> <ul> <li>PyTorch 2.8</li> <li>TensorFlow pre-release 2.21.0</li> <li>DeepSpeed 0.17.6</li> <li>CUDA 12.9.1</li> <li>cuDNN 9.13.0</li> <li>NCCL 2.28.3</li> <li>cuSPARSELt 0.8.1.1</li> <li>NVSHMEM 3.3.9</li> </ul> <p>Some highlights of changes relative to previous versions of this module:</p> <ul> <li>Miniforge (conda-forge, libmamba/mamba) replaces Miniconda</li> <li>Horovod is no longer included in the base environment</li> <li>vLLM, verl, mamba-ssm, megatron-core, SGLang, uv, FlashInfer, and other packages added</li> <li>Improved PyTorch compatibility with mpi4py and Cray MPICH</li> </ul> <p>Note</p> <p>The Anaconda defaults channel has been removed from the package manager\u2019s list of channels. No packages in the base environment come from the defaults channel. We recommend that users avoid both re-adding defaults and installing any packages from the Anaconda distribution due to a change in their licensing model. </p>"},{"location":"polaris/system-updates/#2025-08-29","title":"2025-08-29","text":"<p>Polaris HPCM upgrade involves the following key version software changes:</p> <ul> <li>SUSE 15 SP6 (a major kernel change)</li> <li>Slingshot host stack 12.0.0, with improvements to handling nvidia/nccl/etc and updates to libfabric</li> <li>Update NVIDIA driver version (565.57.01) (CUDA driver API 12.7)</li> <li>Default base nvidia-hpc_sdk is now at 24.11 (CUDA toolkit 12.6)</li> <li>Updated Cray Programming Environment (PE) release 25.03, includes support for older releases of 23.12, 24.03, 24.07, 24.11</li> <li>Lustre updated to B21</li> <li>USS 1.3.1 / PALS updates to 1.6.1</li> <li>PBS update to 2025.2.0</li> </ul> <p>IMPORTANT NOTE: The upgrades to the OS, libfabric, and CUDA drivers represent major changes and may break compatibility with older versions. Users are strongly encouraged to recompile code to avoid issues.</p>"},{"location":"polaris/system-updates/#2024-09-09","title":"2024-09-09","text":""},{"location":"polaris/system-updates/#xalt","title":"XALT","text":"<p>The XALT library tracking software has been enabled for all Polaris users. More information can be found on the XALT page.</p>"},{"location":"polaris/system-updates/#2024-04-22","title":"2024-04-22","text":"<p>The management software on Polaris has been upgraded to HPCM 1.10. The following version changes are in place with the upgrade to HPCM 1.10:</p> <ul> <li>HPE Cray Programming Environment (CPE) 23.12</li> <li>SlingShot version 2.1.2</li> <li>NVIDIA SDK 23.9</li> <li>NVIDIA driver version 535.154.05</li> <li>CUDA 12.2</li> <li>SUSE 15 SP5</li> </ul>"},{"location":"polaris/system-updates/#releasing-jobs","title":"Releasing Jobs","text":"<p>Jobs that were queued before the upgrade have been restored to the appropriate queues but are placed on user hold. Jobs are not expected to complete successfully due to the changes made to the system and software environments resulting from the upgrade. We recommend you review your jobs and either release the hold (<code>qrls &lt;jobid&gt;</code>) or delete it (<code>qdel &lt;jobid&gt;</code>) and resubmit as appropriate.</p> <ul> <li>Users need to rebuild for the new PE environment and major OS upgrade. Existing binaries are unlikely to run successfully.</li> <li>We have held all jobs submitted prior to the upgrade as a user hold. Users may release their existing jobs with <code>qrls</code> to run after they have rebuilt their binaries.</li> <li>PBS does cache the job execution script. If a change to the script is required due to a path changing post-rebuild, the job will have to be resubmitted.</li> <li>All application binaries should be rebuilt prior to further job submissions.</li> </ul>"},{"location":"polaris/system-updates/#re-building-user-codes","title":"Re-building User Codes","text":"<p>Many user codes will need to be re-built and/or re-linked against the newer version of the programming environment (23.12) and Spack-provided dependencies.</p>"},{"location":"polaris/system-updates/#changes-to-the-user-software-environment","title":"Changes to the User Software Environment","text":"<p>In addition to the system upgrades, several changes have been made to the user software environment which may impact user workflows.</p>"},{"location":"polaris/system-updates/#older-pe-versions-removed","title":"Older PE Versions Removed","text":"<p>Older versions of the Cray PE (older than 23.12) are deprecated as they are incompatible with the upgraded system stack and are no longer available for use.</p>"},{"location":"polaris/system-updates/#datascience-anaconda-module-updates","title":"Datascience Anaconda Module Updates","text":"<p>We have updated the datascience Anaconda module and built various packages and libraries with CUDA 12.4.1 to be compatible with the new Polaris NVIDIA GPU hardware driver (CUDA 12.2) and to use the latest MPI, NCCL, cuDNN, TensorRT, etc. libraries. PyTorch 2.3.0 and TensorFlow 2.16.1 are now available as part of this module.</p> <p>To use the new environment, type: <pre><code>module use /soft/modulefiles \nmodule load conda; conda activate\n</code></pre></p>"},{"location":"polaris/system-updates/#soft-refresh-and-default-modulepath-change","title":"<code>/soft</code> Refresh and Default <code>$MODULEPATH</code> Change","text":"<p>Due to the new system software stack, <code>/soft</code> has been purged to allow for software to be rebuilt. In addition, <code>/soft/modulefiles</code> is no longer in the default <code>$MODULEPATH</code>. To access modules installed in <code>/soft</code>, users should run <code>module use /soft/modulefiles</code>.</p> <p>Adding <code>module use /soft/modulefiles</code> to your profile should approximate the old behavior.</p>"},{"location":"polaris/system-updates/#modules-removed","title":"Modules Removed","text":"<p>The following modules have been removed:</p> <pre><code>   aocl/3.2.0                                                        hpctoolkit/2022.07.27\n   aocl/4.0                                                   (D)    hpctoolkit/2023.03.27                                                    (D)\n   ascent/develop/2024-01-08-492f9b0                                 imagemagick/imagemagick-7.1.1-11\n   boost/1.80.0                                                      kokkos/kokkos-3.6.01\n   boost/1.81.0                                               (D)    kokkos/3.7.00-cuda\n   cabana/cabana-20220723                                            kokkos/3.7.00-sycl\n   cabana/PrgEnv-gnu/8.3.3/gnu/11.2.0/cuda_cudatoolkit_11.8.0 (D)    kokkos/3.7.01-cuda\n   cmake/3.23.2                                                      kokkos/4.2.00/shared/PrgEnv-gnu/8.3.3/gnu/11.2.0/cuda_cudatoolkit_11.8.0 (D)\n   conda/2022-07-19                                                  llvm/release-15.0.0\n   conda/2022-09-08-hvd-nccl                                         llvm/release-16.0.0\n   conda/2022-09-08                                                  magma/2.6.2\n   conda/2023-01-10-unstable                                         magma/2.7.0                                                              (D)\n   conda/2023-10-04-openmpi                                          mpiwrappers/cray-mpich-oneapi                                            (D)\n   conda/2023-10-04                                           (D)    oneapi/release/2023.2.1\n   cudatoolkit-standalone/11.2.2                                     oneapi/release/2024.0\n   cudatoolkit-standalone/11.4.4                                     oneapi/upstream\n   cudatoolkit-standalone/11.6.2                                     paraview/paraview-5.11.1-mesa\n   cudatoolkit-standalone/11.7.1                                     paraview/paraview-5.11.2-EGL-test\n   cudatoolkit-standalone/12.0.0                                     paraview/paraview-5.11.2-mesa\n   e4s/22.05/mvapich2                                                paraview/paraview-5.12.0-RC1-mesa\n   e4s/22.05/PrgEnv-gnu                                       (D)    paraview/paraview-5.12.0-mesa                                            (D)\n   e4s/22.08/mvapich2                                                singularity/3.8.7\n   e4s/22.08/PrgEnv-gnu                                       (D)    tau/2.31.1\n   ffmpeg/ffmpeg-6.0                                                 tau/2.32\n   forge/23.0.4                                                      tau/2.33.1                                                               (D)\n   ginkgo/mpi/20230314/ginkgo                                        visit/visit\n   ginkgo/20230314/ginkgo                                     (D)    vmd/vmd-1.9.4a55\n   gnu-parallel/2021-09-22                                           xalt/3.0.1-202308151751\n   gsl/2.7                                                           xalt/3.0.1-202308261842                                                  (D)\n</code></pre>"},{"location":"polaris/system-updates/#modules-newly-installed","title":"Modules Newly Installed","text":"<p>The following modules have been newly installed:</p> <pre><code>   cabana/dev-9a1ad605/kokv/4.2.01/PrgEnv-gnu/8.5.0/gnu/12.3/cuda_cudatoolkit_12.2.91\n   cuda-PrgEnv-nvidia/12.2.91\n   cudatoolkit-standalone/12.2.2                                                      (D)\n   cudatoolkit-standalone/12.3.2\n   cudatoolkit-standalone/12.4.0\n   cudnn/9.0.0\n   forge/23.1.2\n   kokkos/4.2.01/shared/PrgEnv-gnu/8.5.0/gnu/12.3/cuda_cudatoolkit_12.2.91\n   spack-pe-base/0.6.1\n   spack-pe-gnu/0.6.1\n</code></pre> <p>Note that <code>spack-pe-base</code> and <code>spack-pe-gnu</code> are metamodules which contain further software offerings. See the Spack section below for details.</p>"},{"location":"polaris/system-updates/#spack","title":"Spack","text":"<p>We have newly installed Spack deployments in <code>/soft</code>. Spack is an HPC-oriented package manager which ALCF uses to install software for the user environment. However, no knowledge of Spack is necessary to use these software offerings. All ALCF-managed software is accessible to users via modules.</p> <p>The base suite of software tools and libraries can be accessed by loading the <code>spack-pe-base</code> module. This adds a path to <code>$MODULEPATH</code> which contains numerous modules.</p> <p>For example, to load <code>cmake</code> starting from the default environment, a user should run the following commands: <pre><code>module use /soft/modulefiles\nmodule load spack-pe-base\nmodule load cmake\n</code></pre> Other modules in <code>spack-pe-base</code> can be browsed by running <code>module avail</code> or <code>module --show-hidden avail</code>. The latter shows hidden modules which are installed as dependencies of the un-hidden modules.</p> <p>In addition to the base stack, a suite of higher-level libraries are installed in the <code>spack-pe-gnu</code> module. These are built with and are dependent on <code>PrgEnv-gnu</code>. A <code>PrgEnv-nvidia</code>-compatible stack will be available in the future.</p> <p>Note that not all software is installed through Spack; many applications and libraries are installed as standalone packages in <code>/soft</code>. Users are encouraged to browse the available modules with <code>module avail</code> to see what software is installed on the system.</p>"},{"location":"polaris/system-updates/#paraview-and-visit","title":"ParaView and VisIt","text":"<p>The ParaView module has been updated. For more information, see ParaView Documentation and ParaView Manual Launch.</p> <p>The VisIt module is in the process of being updated.</p>"},{"location":"polaris/system-updates/#changes-to-memory-limits-on-login-nodes","title":"Changes to Memory Limits on Login Nodes","text":"<p>Memory limits were lowered on the login nodes due to resource contention to 8GB of memory and 8 cores per user. This might result in error messages indicating abnormal process termination for user processes run on logins.</p> <p>Examples of the error messages people might see are:</p> <ul> <li><code>nvcc error   : 'cudafe++' died due to signal 9 (Kill signal)</code></li> <li><code>g++-12: fatal error: Killed signal terminated program cc1plus</code></li> </ul> <p>These errors are likely due to exhausting the per-user resources on a login node as each user is allocated 8 cores and 8GB memory. To avoid this, you can either:</p> <ul> <li>Reduce the parallelism of your compile, such as using <code>-j</code> or <code>-j4</code> flags</li> <li>Request a debug node and run your compile there where you will have the full resources of the node at your disposal</li> </ul>"},{"location":"polaris/applications-and-libraries/applications/QMCPACK/","title":"QMCPACK","text":""},{"location":"polaris/applications-and-libraries/applications/QMCPACK/#qmcpack-on-polaris","title":"QMCPACK on Polaris","text":"<p>QMCPACK is a modern high-performance open-source Quantum Monte Carlo (QMC) simulation code. Its main applications are electronic structure calculations of molecular, quasi-2D, and solid-state systems. Variational Monte Carlo (VMC), diffusion Monte Carlo (DMC), and a number of other advanced QMC algorithms are implemented. Orbital space auxiliary field QMC (AFQMC) has recently been added. By directly solving the Schr\u00f6dinger equation, QMC methods offer greater accuracy than methods such as density functional theory, but at the trade-off of much greater computational expense.</p> <p>Prebuilt executables are provided at <code>/soft/applications/qmcpack</code>. The directory of each installation also includes a job submission script example <code>qmcpack-polaris.job</code>. An updated build recipe is provided on GitHub.</p>"},{"location":"polaris/applications-and-libraries/applications/QuantumESPRESSO/","title":"Quantum ESPRESSO","text":""},{"location":"polaris/applications-and-libraries/applications/QuantumESPRESSO/#quantum-espresso-on-polaris","title":"Quantum ESPRESSO on Polaris","text":"<p>Quantum ESPRESSO is an integrated suite of open-source computer codes for electronic-structure calculations and materials modeling at the nanoscale. It is based on density-functional theory, plane waves, and pseudopotentials.</p> <p>Prebuilt executables are provided at <code>/soft/applications/quantum_espresso</code>. The directory of each installation also includes a job submission script example <code>job.sub</code> and a <code>README</code> file documenting the actual build recipe. We only support building QE using CMake.</p>"},{"location":"polaris/applications-and-libraries/applications/amber/","title":"Amber on Polaris","text":""},{"location":"polaris/applications-and-libraries/applications/amber/#what-is-amber","title":"What is Amber?","text":"<p>Amber is a suite of biomolecular simulation programs. Amber is distributed in two parts: AmberTools24 and Amber24. Please visit the Amber website for additional information on capabilities and licensing.</p>"},{"location":"polaris/applications-and-libraries/applications/amber/#using-amber-at-alcf","title":"Using Amber at ALCF","text":"<p>ALCF offers assistance with building binaries and compiling instructions for Amber. For questions, contact us at support@alcf.anl.gov.</p>"},{"location":"polaris/applications-and-libraries/applications/amber/#building-amber","title":"Building Amber","text":"<p>The following build instructions can be applied to both free and licensed versions of Amber.</p> <ol> <li>Download AmberTools24 and Amber24 from the Amber website. Note that they are two separate downloads. Copy the tarballs <code>AmberTools24.tar.bz2</code> and <code>Amber24.tar.bz2</code> into a home or project directory (e.g., <code>$HOME/Amber</code>).</li> </ol> <pre><code>$ cd Amber\n$ tar -xf AmberTools24.tar.bz2\n$ tar -xf Amber24.tar.bz2\n$ cd amber24_src\n</code></pre> <ol> <li> <p>Download and install the bzip2 library. Insert <code>-fPIC</code> into the <code>CFLAGS</code> variable in the Makefile and build with installation to a local directory (e.g., <code>make install PREFIX=$HOME/bzip2</code>).</p> </li> <li> <p>Download and install the FFTW3 library, extract the tarball, and rename it as <code>fftw</code>. Proceed to build with installation to a local directory (e.g., <code>./configure --prefix=$HOME/fftw ; make ; make install</code>).</p> </li> <li> <p>Update the user environment to include the newly installed <code>bzip2</code> and <code>fftw</code> and use the GNU programming environment.</p> </li> </ol> <pre><code>export PATH=\"/PATH-TO/bzip2/lib:$PATH\"\nexport PATH=\"/PATH-TO/bzip2:$PATH\"\nexport PATH=\"/PATH-TO/bzip2/include:$PATH\"\nexport PATH=\"/PATH-TO/fftw:$PATH\"\nexport PATH=\"/PATH-TO/fftw/lib:$PATH\"\nexport PATH=\"/PATH-TO/fftw/include:$PATH\"\n\nmodule use /soft/modulefiles\nmodule load PrgEnv-gnu/8.5.0\nmodule load cudatoolkit-standalone/12.4.0\n</code></pre> <ol> <li>Proceed with building Amber binaries by first modifying <code>run_cmake</code> and setting the following:</li> <li><code>-DMPI=TRUE</code></li> <li><code>-DCUDA=TRUE</code></li> <li><code>-DCOMPILER=MANUAL</code></li> <li><code>-DDISABLE_TOOLS=FEW</code></li> <li><code>-DCMAKE_C_COMPILER=gcc-12</code></li> <li><code>-DCMAKE_CXX_COMPILER=g++-12</code></li> <li><code>-DCMAKE_Fortran_COMPILER=gfortran-12</code></li> </ol> <pre><code>cd build\n./run_cmake\nmake install -j 8\n</code></pre> <p>All Amber binaries will be installed to the <code>amber24</code> folder.</p>"},{"location":"polaris/applications-and-libraries/applications/gromacs/","title":"Gromacs on Polaris","text":""},{"location":"polaris/applications-and-libraries/applications/gromacs/#what-is-gromacs","title":"What is Gromacs?","text":"<p>GROMACS is a versatile package to perform molecular dynamics, i.e., simulate the Newtonian equations of motion for systems with hundreds to millions of particles. It is primarily designed for biochemical molecules like proteins, lipids, and nucleic acids that have a lot of complicated bonded interactions. However, since GROMACS is extremely fast at calculating the nonbonded interactions (which usually dominate simulations), many groups are also using it for research on non-biological systems, e.g., polymers.</p>"},{"location":"polaris/applications-and-libraries/applications/gromacs/#using-gromacs-at-alcf","title":"Using GROMACS at ALCF","text":"<p>ALCF offers assistance with building binaries and compiling instructions for GROMACS. For questions, contact us at support@alcf.anl.gov.</p>"},{"location":"polaris/applications-and-libraries/applications/gromacs/#building-gromacs","title":"Building Gromacs","text":"<ol> <li>Download the latest source code: GROMACS Download</li> <li>Extract the tarball: <code>tar -xzf gromacs-2022.1.tar.gz</code></li> <li>Swap programming environments: <code>module swap PrgEnv-nvidia PrgEnv-gnu</code></li> <li>Load the CUDA toolkit: <code>module load cudatoolkit-standalone/11.2.2</code></li> <li>Load GCC: <code>module load gcc/10.3.0</code></li> <li>Load CMake: <code>module load cmake</code></li> <li>Change directory: <code>cd gromacs-2022.1</code></li> <li>Create a build directory: <code>mkdir build</code></li> <li>Configure the build:    <pre><code>cmake -DCMAKE_C_COMPILER=cc -DCMAKE_CXX_COMPILER=CC \\\n      -DBUILD_SHARED_LIBS=OFF -DGMX_BUILD_OWN_FFTW=ON \\\n      -DCMAKE_INSTALL_PREFIX=/path-to/gromacs-2022.1/build \\\n      -DGMX_MPI=ON -DGMX_OPENMP=ON -DGMX_GPU=CUDA \\\n      -DCUDA_TOOLKIT_ROOT_DIR=/soft/compilers/cudatoolkit/cuda-11.2.2\n</code></pre></li> <li>Compile the code: <code>make -j 8</code></li> <li>Install the binaries: <code>make install</code></li> <li>The installed binary is <code>build/bin/gmx_mpi</code>.</li> </ol>"},{"location":"polaris/applications-and-libraries/applications/gromacs/#running-gromacs-on-polaris","title":"Running Gromacs on Polaris","text":"<p>Prebuilt GROMACS binaries can be found in the directory <code>/soft/applications/Gromacs/gromacs-2022.1</code>.</p> <p>A sample PBS script follows that will run GROMACS on two nodes, using 4 MPI ranks per node, and each rank with four OpenMP threads. The PME kernel owns one MPI rank and one GPU per node, while the nonbonded kernel uses 3 MPI ranks and 3 GPUs per node.</p> <pre><code>#!/bin/sh\n#PBS -l select=2:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -q debug\n#PBS -A PROJECT\n#PBS -l filesystems=home:eagle\n\ncd ${PBS_O_WORKDIR}\n\nmodule swap PrgEnv-nvidia PrgEnv-gnu\nmodule load cudatoolkit-standalone/11.2.2\n\nexport OMP_NUM_THREADS=4\n\nmpirun --np 8 /soft/applications/Gromacs/gromacs-2022.1/gmx_mpi \\\n      mdrun -gputasks 0123 -nb gpu -pme gpu -npme 1 -ntomp 4 \\\n      -dlb yes -resethway -pin on -v deffnm step5_1 -g test.log\n</code></pre> <p>We strongly suggest that users try combinations of different numbers of nodes, MPI ranks per node, number of GPU tasks/devices, GPU task decomposition between nonbonded and PME kernels, and OMP threads per rank to find the optimal throughput for their particular workload.</p>"},{"location":"polaris/applications-and-libraries/applications/lammps/","title":"LAMMPS","text":""},{"location":"polaris/applications-and-libraries/applications/lammps/#overview","title":"Overview","text":"<p>LAMMPS is a general-purpose molecular dynamics software package for massively parallel computers. It is written in an exceptionally clean style that makes it one of the more popular codes for users to extend, and it currently has dozens of user-developed extensions.</p> <p>For details about the code and its usage, see the LAMMPS home page. This page provides information specific to running on Polaris at the ALCF.</p>"},{"location":"polaris/applications-and-libraries/applications/lammps/#using-lammps-at-alcf","title":"Using LAMMPS at ALCF","text":"<p>ALCF provides assistance with build instructions, compiling executables, submitting jobs, and providing prebuilt binaries (upon request). A collection of Makefiles and submission scripts are available in the ALCF GettingStarted repo here. For questions, contact us at support@alcf.anl.gov.</p>"},{"location":"polaris/applications-and-libraries/applications/lammps/#how-to-obtain-the-code","title":"How to Obtain the Code","text":"<p>LAMMPS is an open-source code, which can be downloaded from the LAMMPS website.</p>"},{"location":"polaris/applications-and-libraries/applications/lammps/#setting-up-gnu-environment","title":"Setting up GNU environment","text":"<p>The following modules are useful for building LAMMPS. The initial <code>module restore</code> is just setting the default environment as the starting point. Users may find it useful to copy these module commands into a small helper script to assist with compiling and running LAMMPS (e.g., <code>setup_lammps_gnu.sh</code>). </p> <pre><code>module restore\n\n# use -target-accel=nvidia90 in compiler/link flags\n#module load craype-accel-nvidia90\n\nmodule swap PrgEnv-nvidia PrgEnv-gnu\nmodule swap gcc-native/14.2 gcc-native/12.3\n\nmodule use /soft/modulefiles\nmodule load cudatoolkit-standalone\n\nmodule load spack-pe-base cmake\nmodule load cray-fftw\n</code></pre>"},{"location":"polaris/applications-and-libraries/applications/lammps/#building-with-kokkos-package-on-polaris","title":"Building with KOKKOS package on Polaris","text":"<p>Users are encouraged to use CMake to build LAMMPS using the GNU host compilers. An example helper script is provided where CMake is used to build LAMMPS using the KOKKOS package for GPU acceleration.</p> <pre><code>BASE=/path_to_lammps/\n\ncd ${BASE}\nmkdir build\ncd build\n\n. /home/knight/public/lammps/polaris/setup_lammps_gnu.sh \n\nexport NVCC_WRAPPER_DEFAULT_COMPILER=CC\n\ncmake \\\n    -D CMAKE_BUILD_TYPE=Release \\\n    -D CMAKE_INSTALL_PREFIX=$(pwd) \\\n    -D CMAKE_CXX_STANDARD=17 \\\n    -D CMAKE_CXX_STANDARD_REQUIRED=ON \\\n    -D BUILD_MPI=ON \\\n    -D BUILD_SHARED_LIBS=ON \\\n    -D PKG_KOKKOS=ON \\\n    -D PKG_MOLECULE=ON \\\n    -D PKG_ML-SNAP=ON \\\n    -D PKG_KSPACE=ON \\\n    -D Kokkos_ENABLE_CUDA=ON \\\n    -D FFT_KOKKOS=CUFFT \\\n    -D FFT_SINGLE=yes \\\n    -D Kokkos_ENABLE_OPENMP=ON \\\n    -D CMAKE_CXX_COMPILER=$(pwd)/../lib/kokkos/bin/nvcc_wrapper \\\n    -D CMAKE_EXE_LINKER_FLAGS=\"-target-accel=nvidia90\" \\\n    -D Kokkos_ARCH_AMDAVX=ON \\\n    ../cmake\n\nmake -j 4\n</code></pre> <p>Compilation on the Polaris login nodes should be restricted to 4 processes so as to not exhaust per-user resource limits. If building LAMMPS in an interactive job on a compute node, then <code>make -j 32</code> could be used to speedup up compilation. The <code>${BASE}/build/lmp</code> executable should be present when compilation succeeds.</p>"},{"location":"polaris/applications-and-libraries/applications/lammps/#building-with-gpu-package-on-polaris","title":"Building with GPU package on Polaris","text":"<p>Users are encouraged to use CMake to build LAMMPS using the GNU host compilers. An example helper script is provided where CMake is used to build LAMMPS using the KOKKOS package for GPU acceleration.</p> <pre><code>BASE=/path_to_lammps/\n\ncd ${BASE}\nmkdir build\ncd build\n\n. /home/knight/public/lammps/polaris/setup_lammps_gnu.sh \n\ncmake \\\n    -D CMAKE_BUILD_TYPE=Release \\\n    -D CMAKE_INSTALL_PREFIX=$(pwd) \\\n    -D CMAKE_CXX_STANDARD=17 \\\n    -D CMAKE_CXX_STANDARD_REQUIRED=ON \\\n    -D BUILD_MPI=ON \\\n    -D BUILD_SHARED_LIBS=ON \\\n    -D PKG_OPENMP=ON \\\n    -D PKG_GPU=ON \\\n    -D GPU_API=CUDA \\\n    -D GPU_ARCH=sm_90 \\\n    -D CUDA_MPS_SUPPORT=yes \\\n    -D PKG_MOLECULE=ON \\\n    -D PKG_KSPACE=ON \\\n    -D FFT_SINGLE=yes \\\n    -D CMAKE_CXX_COMPILER=CC \\\n    -D CMAKE_EXE_LINKER_FLAGS=\"-target-accel=nvidia90\" \\\n    ../cmake\n\nmake -j 4\n</code></pre> <p>Compilation on the Polaris login nodes should be restricted to 4 processes so as to not exhaust per-user resource limits. If building LAMMPS in an interactive job on a compute node, then <code>make -j 32</code> could be used to speedup up compilation. The <code>${BASE}/build/lmp</code> executable should be present when compilation succeeds.</p>"},{"location":"polaris/applications-and-libraries/applications/lammps/#running-jobs-on-polaris","title":"Running Jobs on Polaris","text":"<p>An example submission script for running a 64-node KOKKOS-enabled LAMMPS executable is below as an example. Additional information on LAMMPS application flags and options is described on the LAMMPS website.</p> <pre><code>#!/bin/sh\n#PBS -l select=64:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:15:00\n#PBS -l filesystems=home:eagle\n#PBS -q prod\n#PBS -A Catalyst\n\nexport MPICH_GPU_SUPPORT_ENABLED=1\n\nNNODES=`wc -l &lt; $PBS_NODEFILE`\n\n# per-node settings\nNRANKS=4\nNDEPTH=8\nNTHREADS=1\nNGPUS=4\n\nNTOTRANKS=$(( NNODES * NRANKS ))\n\n. /home/knight/public/lammps/polaris/setup_lammps_gnu.sh\n\nEXE=/path_to_lammps/build/lmp\nEXE_ARG=\"-in in.lj \"\n\n# Kokkos package settings\nEXE_ARG+=\" -k on g ${NGPUS} -sf kk -pk kokkos neigh half neigh/qeq full newton on \"\n\n# GPU package settings\n#EXE_ARG+=\" -pk gpu ${NGPUS} -sf hybrid gpu omp \"\n\n# MPI+OMP settings\nMPI_ARG=\" -n ${NTOTRANKS} --ppn ${NRANKS} --depth=${NDEPTH} --cpu-bind depth \"\nOMP_ARG=\" --env OMP_NUM_THREADS=${NTHREADS} --env OMP_PROC_BIND=spread --env OMP_PLACES=cores \"\n\nCOMMAND=\"mpiexec ${MPI_ARG} ${OMP_ARG} ${EXE} ${EXE_ARG}\"\necho \"COMMAND= ${COMMAND}\"\n${COMMAND}\n</code></pre>"},{"location":"polaris/applications-and-libraries/applications/lammps/#building-lammps-with-makefiles","title":"Building LAMMPS with Makefiles","text":"<p>Support for building LAMMPS via Makefiles will be deprecated soon in favor of CMake. Recent Makefiles are available, if needed, for building LAMMPS in the following directory.</p> <pre><code>knight@x3004c0s7b1n0:~/public/lammps/polaris&gt; pwd\n/home/knight/public/lammps/polaris\n\nknight@x3004c0s7b1n0:~/public/lammps/polaris&gt; ls Makefile.polaris_gnu*\nMakefile.polaris_gnu  Makefile.polaris_gnu_kokkos\n</code></pre> <p>Please contact us at support@alcf.anl.gov for assistance if you require building LAMMPS with Makefiles.</p>"},{"location":"polaris/applications-and-libraries/applications/lammps/#performance-notes","title":"Performance Notes","text":"<p>Some useful information on accelerator packages and expectations can be found on the LAMMPS website here.</p>"},{"location":"polaris/applications-and-libraries/applications/namd/","title":"NAMD on Polaris","text":""},{"location":"polaris/applications-and-libraries/applications/namd/#what-is-namd","title":"What is NAMD?","text":"<p>NAMD, recipient of a 2002 Gordon Bell Award, a 2012 Sidney Fernbach Award, and a 2020 Gordon Bell Prize, is a parallel molecular dynamics code designed for high-performance simulation of large biomolecular systems. Based on Charm++ parallel objects, NAMD scales to hundreds of cores for typical simulations and beyond 50,000 cores for the largest simulations. NAMD uses the popular molecular graphics program VMD for simulation setup and trajectory analysis, but is also file-compatible with AMBER, CHARMM, and X-PLOR.</p>"},{"location":"polaris/applications-and-libraries/applications/namd/#using-namd-at-alcf","title":"Using NAMD at ALCF","text":"<p>ALCF offers assistance with building binaries and compiling instructions for NAMD. For questions, contact us at support@alcf.anl.gov.</p>"},{"location":"polaris/applications-and-libraries/applications/namd/#running-namd-on-polaris","title":"Running NAMD on Polaris","text":"<p>Prebuilt releases of NAMD binaries can be found in the directory <code>/soft/applications/namd</code>.  * <code>Linux-x86_64-netlrts-smp-CUDA</code> supports GPU-resident runs.  * <code>Linux-x86_64-ofi-smp-CUDA</code> supports general GPU-offload runs. * <code>Linux-x86_64-ofi-smp-CUDA-memopt</code> supports memory-optimized input files and parallel I/O for the largest simulations (~100 million atoms or more).</p> <p>NAMD supports two types of parallelized simulations: single instance strong-scaling and multiple-copy weak-scaling (i.e., replica exchange). For more functionality details, please visit the NAMD website.</p>"},{"location":"polaris/applications-and-libraries/applications/namd/#gpu-resident-runs","title":"GPU-resident runs","text":"<p>A sample PBS script follows for GPU-resident runs on Polaris.</p> <pre><code>#!/bin/sh -l\n#PBS -l select=1:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -q debug\n#PBS -A PROJECT\n#PBS -l filesystems=home:eagle\n\nEXE=/PATH-TO/namd3\n\ncd ${PBS_O_WORKDIR}\n\nmpiexec -n 1 --ppn 1 --depth=16 --cpu-bind=depth $EXE +p 15 +devices 3,2,1,0 stmv.namd &gt; stmv.output\n</code></pre> <p>Measured performance for a ~1,000,000 atom system generated with the above submission script run under NPT conditions and a timestep of 2 fs was <code>16 CPUs 0.00381933 s/step 45.2435 ns/day</code>.</p> <p>Note, the GPU-resident version only runs on a single node currently, and some important functions remain to be implemented with it. A user is strongly encouraged to ensure the updated GPU-resident version fully supports the planned simulation in advance.</p>"},{"location":"polaris/applications-and-libraries/applications/namd/#multiple-copy-gpu-resident-runs","title":"Multiple-copy GPU-resident runs","text":"<p>A sample PBS script for multiple-copy GPU-resident runs follows.</p> <pre><code>#!/bin/sh -l\n#PBS -l select=4:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -q debug-scaling\n#PBS -A PROJECT\n#PBS -l filesystems=home:eagle\n\nEXE=/PATH-TO/namd3\nCHARMRUN=/PATH-TO/charmrum\n\ncd ${PBS_O_WORKDIR}\n\n$CHARMRUN ++mpiexec ++np 16 ++ppn 8 $EXE +replicas 16 init.conf --source rest2_remd.namd +pemap 0-31 +setcpuaffinity +devices 0,1,2,3 +stdout rest2_output/%d/job0.%d.log +devicesperreplica 1\n</code></pre> <p>This sample script launches a solute-tempering replica-exchange simulation with 16 replicas on 4 Polaris nodes. Each node accommodates 4 replicas, and each replica uses 8 CPU cores and binds to 1 GPU device.</p>"},{"location":"polaris/applications-and-libraries/applications/namd/#gpu-offload-run-on-multiple-nodes","title":"GPU-offload run on multiple nodes","text":"<p>A sample PBS script for a GPU-offload run follows.</p> <pre><code>#!/bin/sh -l\n#PBS -l select=64:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -q prod\n#PBS -A PROJECT\n#PBS -l filesystems=home:eagle\n\nEXE=/PATH-TO/namd3\n\ncd ${PBS_O_WORKDIR}\n\naprun -N 4 -n 256 --cc core --cpus-per-pe 8 $EXE +p 6 +setcpuaffinity +devices 3,2,1,0 stmv.namd &gt; stmv_64nodes.output\n</code></pre> <p>Measured performance for a ~1,000,000 atom system generated with the above submission script run under NPT conditions and a timestep of 2 fs was <code>1536 CPUs 0.00151797 s/step 113.724 ns/day</code>.</p>"},{"location":"polaris/applications-and-libraries/applications/namd/#multiple-copy-gpu-offload-run","title":"Multiple-copy GPU-offload run","text":"<p>A sample PBS script for multiple-copy GPU-offload runs follows.</p> <pre><code>#!/bin/sh -l\n#PBS -l select=4:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -q debug-scaling\n#PBS -A PROJECT\n#PBS -l filesystems=home:eagle\n\nEXE=/PATH-TO/namd3\n\ncd ${PBS_O_WORKDIR}\n\naprun -N 4 -n 16 --cc=core --cpus-per-pe 8 $EXE +replicas 16 init.conf --source rest2_remd.namd +setcpuaffinity +stdout rest2_output/%d/job0.%d.log +devicesperreplica 1\n</code></pre>"},{"location":"polaris/applications-and-libraries/applications/namd/#building-namd","title":"Building NAMD","text":"<p>We recommend using the provided NAMD binaries.</p> <p>The following instructions are for building the GPU-offload version on top of a Slingshot-11-optimized Charm++ library:</p> <ol> <li><code>module swap PrgEnv-nvidia PrgEnv-gnu</code></li> <li>Download NAMD source code build_namd.sh<pre><code>tar -xzf NAMD_3.0_Source.tar.gz\ncd NAMD_3.0_Source\ntar xvf charm-8.0.0.tar\ncd charm-8.0.0\n./buildold charm++ ofi-crayshasta cxi slurmpmi2cray smp --with-production -j8 -DCMK_OBJIC_COLLECTION_BITS=8 -DCMK_OBJID_HOME_BITS=20\ncd ..\nwget http://www.ks.uiuc.edu/Research/namd/libraries/fftw-linux-x86_64.tar.gz\nwget http://www.ks.uiuc.edu/Research/namd/libraries/tcl8.6.13-linux-x86_64.tar.gz\nwget http://www.ks.uiuc.edu/Research/namd/libraries/tcl8.6.13-linux-x86_64-threaded.tar.gz\ntar xzf fftw-linux-x86_64.tar.gz\ntar xzf tcl8.6.13-linux-x86_64.tar.gz\ntar xzf tcl8.6.13-linux-x86_64-threaded.tar.gz\nmv linux-x86_64 fftw\nmv tcl8.6.13-linux-x86_64 tcl\nmv tcl8.6.13-linux-x86_64-threaded tcl-threaded \n./config Linux-x86_64-g++  --charm-base ./charm-8.0.0 --charm-arch ofi-crayshasta-cxi-slurmpmi2cray-smp --with-cuda --cuda-prefix /soft/compilers/cudatoolkit/cuda-12.2.2\ncd Linux-x86_64-g++\nmake -j8\n</code></pre></li> </ol> <p>The NAMD binary is <code>namd3</code>. To build a memory-optimized version, the flag <code>--with-memopt</code> needs to be inserted as a config argument.</p> <p>The configure steps above can be replaced with the following to build the GPU-resident version of NAMD.</p> <pre><code>./build charm++ netlrts-linux-x86_64 gcc smp -j8  --with-production\n./config Linux-x86_64-g++  --charm-base ./charm-8.0.0 --charm-arch netlrts-linux-x86_64-smp-gcc --with-cuda --with-single-node-cuda --cuda-prefix /soft/compilers/cudatoolkit/cuda-12.2.2\n</code></pre>"},{"location":"polaris/applications-and-libraries/applications/nekrs/","title":"nekRS","text":""},{"location":"polaris/applications-and-libraries/applications/nekrs/#overview","title":"Overview","text":"<p>nekRS is a fast and scalable computational fluid dynamics (CFD) software package targeting massively parallel computers. It is based on the high-order spectral element method and is capable of solving incompressible and low Mach-number fluid flow problems.  nekRS uses the OCCA portability layer for offloading compute kernels to GPU devices.</p> <p>For details about the code and its usage, see the nekRS home page. This page provides information specific to running on Polaris at the ALCF.</p>"},{"location":"polaris/applications-and-libraries/applications/nekrs/#using-nekrs-at-alcf","title":"Using nekRS at ALCF","text":"<p>ALCF provides assistance with build instructions, compiling executables, submitting jobs, and providing prebuilt binaries (upon request). For questions, contact us at support@alcf.anl.gov.</p>"},{"location":"polaris/applications-and-libraries/applications/nekrs/#how-to-obtain-the-code","title":"How to Obtain the Code","text":"<p>nekRS is an open-source code and can be downloaded from the website. Alternatively, the user can clone from the nekRS GitHub repository. We recommend using the next branch since it is the most updated branch with some of the latest features, including the in-situ visualization capability. </p> <p><pre><code>git clone https://github.com/Nek5000/nekRS.git\ngit checkout next\n</code></pre> The rest of this documentation is based on building and running using the <code>next</code> branch. Users who are interested in running the default <code>master</code> branch can contact support@alcf.anl.gov for additional support. </p>"},{"location":"polaris/applications-and-libraries/applications/nekrs/#building-on-polaris","title":"Building on Polaris","text":"<p>nekRS uses CMake to build and install the software package. After nekRS has been downloaded or cloned on an ALCF filesystem, users should see a directory with the name <code>nekRS</code>. Inside this directory, the user will find a file named <code>nrsconfig</code> that can be used to configure and customize the CMake build options. The user should remove previous build and installation directories whenever there is an update.</p>"},{"location":"polaris/applications-and-libraries/applications/nekrs/#building-using-gnu-compilers","title":"Building using GNU compilers","text":"<p>The following modules are to be loaded for this particular build. <pre><code>module restore\nmodule load craype-accel-nvidia80\nmodule swap PrgEnv-nvidia PrgEnv-gnu\n\nmodule use /soft/modulefiles\nmodule load cudatoolkit-standalone/12.4.0\n\nmodule load spack-pe-base cmake\n</code></pre></p> <p>To build and install the code, run: <pre><code>CC=cc CXX=CC FC=ftn ./build.sh -DCMAKE_INSTALL_PREFIX=/path/to/installation/directory\n</code></pre> During the installation process, you will be prompted to verify the configuration options. If everything was done correctly, you should see the correct compilers and the <code>Default backend : CUDA</code> in the <code>Summary</code> section of the output. If you see this, press <code>Enter</code> to continue with the build and installation process.</p> <p>After installation, execute the following commands to set up the environment.  <pre><code>export NEKRS_HOME=/path/to/installation/directory\nexport PATH=$NEKRS_HOME/bin:$PATH\n</code></pre></p> <p>Alternatively, you may add the above lines to your <code>$HOME/.bashrc</code> and type <code>source $HOME/.bashrc</code> in the current terminal window.</p>"},{"location":"polaris/applications-and-libraries/applications/nekrs/#building-using-nvidia-compilers","title":"Building using NVIDIA compilers","text":"<p>The following modules are to be loaded for this particular build. The initial <code>module restore</code> is just setting the default environment as the starting point. <pre><code>module restore\nmodule load craype-accel-nvidia80\n\nmodule use /soft/modulefiles\nmodule load spack-pe-base cmake\n</code></pre></p>"},{"location":"polaris/applications-and-libraries/applications/nekrs/#running-jobs-on-polaris","title":"Running Jobs on Polaris","text":"<p>An example submission script for running a 2-node nekRS job is shown below as an example. Additional information on nekRS input files and application setup options is described here. The correct options to execute the script are as follows:</p> <p>NEKRS_HOME=  PROJ_ID= QUEUE= ./run.sh  <p>Users can copy the script below into a file <code>run.sh</code> and execute it using the command above. run.sh<pre><code>#!/bin/bash\n: ${PROJ_ID:=\"\"}\n\n: ${QUEUE:=\"prod\"} # debug, debug-scaling, prod\n: ${NEKRS_HOME:=\"$HOME/.local/nekrs\"}\n: ${NEKRS_CACHE_BCAST:=1}\n: ${NEKRS_SKIP_BUILD_ONLY:=0}\n\nif [ $# -ne 3 ]; then\n  echo \"usage: [PROJ_ID] [QUEUE] $0 &lt;casename&gt; &lt;number of compute nodes&gt; &lt;hh:mm:ss&gt;\"\n  exit 0\nfi\n\nif [ -z \"$PROJ_ID\" ]; then\n  echo \"ERROR: PROJ_ID is empty\"\n  exit 1\nfi\n\nif [ -z \"$QUEUE\" ]; then\n  echo \"ERROR: QUEUE is empty\"\n  exit 1\nfi\n\nbin=${NEKRS_HOME}/bin/nekrs\ncase=$1\nnodes=$2\ngpu_per_node=4\ncores_per_numa=8\nlet nn=$nodes*$gpu_per_node\nlet ntasks=nn\ntime=$3\n\nbackend=CUDA\nNEKRS_GPU_MPI=1\n\nif [ ! -f $bin ]; then\n  echo \"Cannot find\" $bin\n  exit 1\nfi\n\nif [ ! -f $case.par ]; then\n  echo \"Cannot find\" $case.par\n  exit 1\nfi\n\nif [ ! -f $case.udf ]; then\n  echo \"Cannot find\" $case.udf\n  exit 1\nfi\n\nif [ ! -f $case.re2 ]; then\n  echo \"Cannot find\" $case.re2\n  exit 1\nfi\n\nstriping_unit=16777216\nmax_striping_factor=128\nlet striping_factor=$nodes/2\nif [ $striping_factor -gt $max_striping_factor ]; then\n  striping_factor=$max_striping_factor\nfi\nif [ $striping_factor -lt 1 ]; then\n  striping_factor=1\nfi\n\nMPICH_MPIIO_HINTS=\"*:striping_unit=${striping_unit}:striping_factor=${striping_factor}:romio_cb_write=enable:romio_ds_write=disable:romio_no_indep_rw=true\"\n\n# sbatch\nSFILE=s.bin\necho \"#!/bin/bash\" &gt; $SFILE\necho \"#PBS -A $PROJ_ID\" &gt;&gt;$SFILE\necho \"#PBS -N nekRS_$case\" &gt;&gt;$SFILE\necho \"#PBS -q $QUEUE\" &gt;&gt;$SFILE\necho \"#PBS -l walltime=$time\" &gt;&gt;$SFILE\necho \"#PBS -l filesystems=home:eagle\" &gt;&gt;$SFILE\necho \"#PBS -l select=$nodes:system=polaris\" &gt;&gt;$SFILE\necho \"#PBS -l place=scatter\" &gt;&gt;$SFILE\necho \"#PBS -k doe\" &gt;&gt;$SFILE #write directly to the destination, doe=direct, output, error\necho \"#PBS -j eo\" &gt;&gt;$SFILE  #oe=merge stdout/stderr to stdout\n\n# job to \u201crun\u201d from your submission directory\necho \"cd \\$PBS_O_WORKDIR\" &gt;&gt; $SFILE\n\necho \"module use /soft/modulefiles\" &gt;&gt; $SFILE\necho \"module use /opt/cray/pe/lmod/modulefiles/mix_compilers\" &gt;&gt; $SFILE\necho \"module load libfabric\" &gt;&gt; $SFILE\necho \"module load cpe-cuda\" &gt;&gt; $SFILE\necho \"module load PrgEnv-gnu\" &gt;&gt; $SFILE\necho \"module load nvidia-mixed\" &gt;&gt; $SFILE\necho \"module load cmake\" &gt;&gt; $SFILE\necho \"module list\" &gt;&gt; $SFILE\n\necho \"nvidia-smi\" &gt;&gt; $SFILE\necho \"ulimit -s unlimited \" &gt;&gt;$SFILE\n\necho \"export NEKRS_HOME=$NEKRS_HOME\" &gt;&gt;$SFILE\necho \"export NEKRS_GPU_MPI=$NEKRS_GPU_MPI\" &gt;&gt;$SFILE\n\necho \"export MPICH_MPIIO_HINTS=$MPICH_MPIIO_HINTS\" &gt;&gt;$SFILE\necho \"export MPICH_MPIIO_STATS=1\" &gt;&gt;$SFILE\n\necho \"export NEKRS_CACHE_BCAST=$NEKRS_CACHE_BCAST\" &gt;&gt;$SFILE\necho \"export NEKRS_LOCAL_TMP_DIR=/local/scratch\" &gt;&gt;$SFILE\n\necho \"export MPICH_GPU_SUPPORT_ENABLED=1\" &gt;&gt; $SFILE\necho \"export MPICH_OFI_NIC_POLICY=NUMA\" &gt;&gt; $SFILE\n\n# https://github.com/Nek5000/Nek5000/issues/759\necho \"export FI_OFI_RXM_RX_SIZE=32768\" &gt;&gt; $SFILE # &gt;=lelt, large mpi-messsage for restart\n\nif [ $NEKRS_SKIP_BUILD_ONLY -eq 0 ]; then\necho \"mpiexec -n 1 $bin --setup ${case} --backend ${backend} --device-id 0 --build-only $nn\" &gt;&gt;$SFILE\nfi\n\nCMD=.lhelper\necho \"#!/bin/bash\" &gt;$CMD\necho \"gpu_id=\\$((${gpu_per_node} - 1 - \\${PMI_LOCAL_RANK} % ${gpu_per_node}))\" &gt;&gt;$CMD\necho \"export CUDA_VISIBLE_DEVICES=\\$gpu_id\" &gt;&gt;$CMD\necho \"$bin --setup ${case} --backend ${backend} --device-id 0\" &gt;&gt;$CMD\nchmod 755 $CMD\n\necho \"mpiexec -n $nn -ppn $gpu_per_node -d $cores_per_numa --cpu-bind depth ./$CMD\" &gt;&gt;$SFILE\n\nqsub -q $QUEUE $SFILE\n\n# clean-up\n#rm -rf $SFILE $ROMIO_HINTS .lhelper\n</code></pre></p>"},{"location":"polaris/applications-and-libraries/applications/nekrs/#just-in-time-jit-compilation","title":"Just-in-time (JIT) compilation","text":"<p>nekRS uses the OCCA library to translate, compile, and run GPU-targeted functions and kernels. Some useful notes on the cached object files can be found here.</p>"},{"location":"polaris/applications-and-libraries/applications/nekrs/#discussion-group","title":"Discussion Group","text":"<p>Users can visit the GitHub Discussions page to seek help, find solutions, share ideas, and follow discussions on several application-specific topics.</p>"},{"location":"polaris/applications-and-libraries/applications/openmm/","title":"OpenMM on Polaris","text":""},{"location":"polaris/applications-and-libraries/applications/openmm/#what-is-openmm","title":"What is OpenMM?","text":"<p>OpenMM is a high-performance toolkit for molecular simulations that can be used as a stand-alone application or as a library. It provides a combination of flexibility (through custom forces and integrators), openness, and high performance (especially on recent GPUs).</p>"},{"location":"polaris/applications-and-libraries/applications/openmm/#using-openmm-at-alcf","title":"Using OpenMM at ALCF","text":"<p>ALCF offers assistance with building binaries and compiling instructions for OpenMM. For questions, contact us at support@alcf.anl.gov.</p>"},{"location":"polaris/applications-and-libraries/applications/openmm/#building-openmm-using-conda-module","title":"Building OpenMM using Conda module","text":"<ol> <li>Update environment     <pre><code>$ module load conda/2022-07-19\n</code></pre></li> <li>Install OpenMM     <pre><code>$ mkdir conda\n$ conda create --prefix /path-to/conda/openmm_env\n$ conda activate /path-to/conda/openmm_env\n$ conda install -c conda-forge openmm cudatoolkit=11.4\n$ conda deactivate /path-to/conda/openmm_env\n</code></pre></li> <li> <p>Validate installation: If successful, information on code version, platform types, CUDA initialization, and force error tolerance will be shown.</p> <pre><code>$ cd /path-to/conda/openmm_env/share/openmm/examples\n$ python -m openmm.testInstallation\n</code></pre> </li> <li> <p>Benchmark testing using the PBS job script below.</p> <pre><code>$ cd /path-to/conda/openmm_env/share/openmm/examples\n$ qsub ./submit.sh\n</code></pre> </li> </ol>"},{"location":"polaris/applications-and-libraries/applications/openmm/#running-openmm-benchmark-on-polaris","title":"Running OpenMM Benchmark on Polaris","text":"<p>A sample PBS script follows that will run the OpenMM benchmark on one node.</p> <pre><code>#!/bin/sh\n#PBS -l select=1:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -q debug\n#PBS -A PROJECT\n#PBS -l filesystems=home:eagle\n\ncd ${PBS_O_WORKDIR}\n\nmodule load cudatoolkit-standalone/11.4.4\n\npython benchmark.py --platform=CUDA --test=pme --precision=mixed --seconds=30 --heavy-hydrogens &gt; test.output\n</code></pre>"},{"location":"polaris/applications-and-libraries/applications/openmm/#building-openmm-from-source","title":"Building OpenMM from Source","text":"<ol> <li>Update environment     <pre><code>$ module load cudatoolkit-standalone/11.4.4\n$ module load cray-python/3.9.12.1\n</code></pre></li> <li>Download OpenMM     <pre><code>$ git clone https://github.com/openmm/openmm.git\n$ cd openmm ; mkdir build\n</code></pre></li> <li>Download and build Doxygen     <pre><code>$ git clone https://github.com/doxygen/doxygen.git\n$ cd doxygen ; cmake . ; make ; make install ; cd ../\n</code></pre></li> <li>Download and install SWIG in the OpenMM directory.     <pre><code>$ tar xzf swig-4.0.2.tar.gz\n$ cd swig-4.0.2\n$ ./configure --prefix=/path-to/openmm/swig-4.0.2 ; make -j 8 ; make install\n</code></pre></li> <li>Build OpenMM     <pre><code>$ cmake -DDOXYGEN_EXECUTABLE=/path-to/openmm/doxygen/bin/doxygen \\\n        -DSWIG_EXECUTABLE=/path-to/openmm/swig-4.0.2/bin/swig \\\n        -DCMAKE_INSTALL_PREFIX=/path-to/openmm/build \\\n        -DCUDA_HOME=/soft/compilers/cudatoolkit/cuda-11.4.4 \\\n        -DCUDA_INCLUDE_DIR=/soft/compilers/cudatoolkit/cuda-11.4.4/include \\\n        -DCUDA_LIB_DIR=/soft/compilers/cudatoolkit/cuda-11.4.4/lib64\n$ make -j 8\n$ make install\n</code></pre></li> <li> <p>Validate installation: If successful, information on code version, platform types, CUDA initialization, and force error tolerance will be shown.</p> <pre><code>$ cd /path-to/openmm/examples\n$ python -m openmm.testInstallation\n</code></pre> </li> <li> <p>Benchmark testing using the PBS job script above.</p> <pre><code>$ cd /path-to/openmm/examples\n$ qsub ./submit.sh\n</code></pre> </li> </ol>"},{"location":"polaris/applications-and-libraries/applications/vasp/","title":"VASP","text":""},{"location":"polaris/applications-and-libraries/applications/vasp/#what-is-vasp","title":"What is VASP?","text":"<p>The Vienna Ab initio Simulation Package (VASP) is a software package for performing electronic structure calculations with periodic boundary conditions. It is most commonly used to perform density functional theory (DFT) calculations in a plane wave basis using the projector augmented wave (PAW) method. A more complete description of VASP can be found here: https://www.vasp.at</p>"},{"location":"polaris/applications-and-libraries/applications/vasp/#using-vasp-at-alcf","title":"Using VASP at ALCF","text":"<p>VASP is commercial software. Access to binaries compiled by ALCF can only be granted after the user requesting access has been verified to be on the VASP license by an official VASP license distributor.</p> <p>To access the VASP binary at ALCF, please email the details listed directly below to support@alcf.anl.gov. It can take up to 5\u201310 business days to verify a VASP license.</p> <p>Information to provide:</p> <ul> <li>User\u2019s full name:</li> <li>User\u2019s ALCF username:</li> <li>Name of the organization that purchased the VASP license:</li> <li>VASP license purchased from (University of Vienna or MaterialsDesign):</li> <li>Principal investigator who is the POC for the VASP license:</li> <li>VASP license number:</li> <li>Version of VASP requested (VASP 6.4.x, VASP 6.5.x):</li> </ul>"},{"location":"polaris/applications-and-libraries/applications/vasp/#vasp-support-policy","title":"VASP support policy","text":"<p>ALCF compiles the latest release of VASP on a per-request basis. We do not offer support for compiling customized versions of VASP with plugins. We are able to provide Makefiles and step-by-step build instructions to users with a verified VASP license. Support for scientific runs that encounter performance or numerical issues should be directed to the official VASP support mailing list or the VASP user forum. Limited support is available for fatal errors encountered at runtime.</p> <p>Once the user licence is validated, they will be added to the UNIX groups: <code>vasp65</code> or <code>vasp6</code> , and get access to the subdirectories in <code>/soft/applications/vasp</code>.</p>"},{"location":"polaris/applications-and-libraries/applications/vasp/#how-to-obtain-the-code","title":"How to obtain the code","text":"<p>The VASP source can only be obtained from an official license reseller of VASP. This is either the University of Vienna or Material Designs, Inc.</p>"},{"location":"polaris/applications-and-libraries/applications/vasp/#vasp-64x-or-65x-in-polaris-nvhpcopenaccopenmpcuda-mathcraympi","title":"VASP 6.4.x or 6.5.x in Polaris (NVHPC+OpenACC+OpenMP+CUDA math+CrayMPI)","text":""},{"location":"polaris/applications-and-libraries/applications/vasp/#general-compilinginstalling-instructions-provided-by-vasp-support","title":"General compiling/installing instructions provided by VASP support","text":"<p>Instructions and samples of <code>makefile.include</code> can be found on the <code>vasp.at</code> wiki page.</p> <p>The following <code>makefile.include</code> was tailored for Polaris, originally taken from here.</p> <pre><code># Precompiler options\nCPP_OPTIONS= -DHOST=\\\"LinuxNV_CrayMPICH\\\" \\\n             -DMPI -DMPI_BLOCK=8000 -Duse_collective \\\n             -DscaLAPACK \\\n             -DCACHE_SIZE=4000 \\\n             -Davoidalloc \\\n             -Dvasp6 \\\n             -Dtbdyn \\\n             -Dqd_emulate \\\n             -Dfock_dblbuf \\\n             -DACC_OFFLOAD \\\n             -D_OPENMP \\\n             -D_OPENACC \\\n             -DNVCUDA \\\n             -DUSENCCL\n\nCPP        = nvfortran -Mpreprocess -Mfree -Mextend -E $(CPP_OPTIONS) $*$(FUFFIX)  &gt; $*$(SUFFIX)\nFC         = ftn -acc -gpu=cc80 -mp -target-accel=nvidia80\nFCL        = ftn -acc -gpu=cc80 -c++libs -target-accel=nvidia80\nFREE       = -Mfree\n\nFFLAGS     = -Mbackslash -Mlarge_arrays\nOFLAG      = -fast\nDEBUG      = -Mfree -O0 -traceback\n\n# Specify your NV HPC-SDK installation, try to set NVROOT automatically\n# ...or set NVROOT manually\nNVROOT     =$(shell which nvfortran | awk -F /compilers/bin/nvfortran '{ print $$1 }')\n\n# Use NV HPC-SDK provided BLAS and LAPACK libraries\nLIBAOCL=/soft/libraries/aocl/3.2.0\n#BLAS       = -L/soft/applications/vasp/aol-libs/amd-blis/lib/ILP64 -lblis-mt\n#LAPACK     = -L/soft/applications/vasp/aol-libs/amd-libflame/lib/ILP64 -lflame\nBLAS       = /soft/applications/vasp/aol-libs/3.2/amd-blis/lib/LP64/libblis-mt.aLAPACK     = /soft/applications/vasp/aol-libs/3.2/amd-libflame/lib/LP64/libflame.a\n\nBLACS      =\nSCALAPACK  =\n#SCALAPACK  = -Mscalapack\n#SCALAPACK  = ${LIBAOCL}/lib/libscalapack.a\n\nCUDA       = -cudalib=cublas,cusolver,cufft,nccl -cuda\n\nLLIBS      = $(SCALAPACK) $(LAPACK) $(BLAS) $(CUDA)\n\n# Software emulation of quadruple precision\nQD         ?= $(NVROOT)/compilers/extras/qd\nLLIBS      += -L$(QD)/lib -lqdmod -lqd -Wl,-rpath=$(QD)/lib\nINCS       += -I$(QD)/include/qd\nLLIBS      += -L$(NVROOT)/math_libs/lib64 -Wl,-rpath=$(NVROOT)/math_libs/lib64\n\n#INCS       += -I/usr/include/linux\n#INCS       += -I/usr/include/c++/7/tr1\n#INCS       += -I/usr/include/c++/7\n#INCS       += -I/usr/include/x86_64-linux-gnu/c++/7\n#INCS       += -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/lib/gcc/x86_64-pc-linux-gnu/10.2.0/include/\n\n# Use the FFTs from fftw\nFFTW       = /soft/applications/vasp/aol-libs/3.2/amd-fftw\nLLIBS      += -L$(FFTW)/lib -lfftw3 -lfftw3_omp -lomp\n#INCS       += -I/soft/libraries/aocl/3.2.0/include_LP64/\nINCS       += -I$(FFTW)/include\n\n#OBJECTS    = fftmpiw.o fftmpi_map.o fftw3d.o fft3dlib.o\n\n# Redefine the standard list of O1 and O2 objects\nSOURCE_O1  := pade_fit.o\nSOURCE_O2  := pead.o\n\n# For what used to be vasp.5.lib\nCPP_LIB    = $(CPP)\nFC_LIB     = nvfortran\nCC_LIB     = nvc -w\nCFLAGS_LIB = -O\nFFLAGS_LIB = -O1 -Mfixed\nFREE_LIB   = $(FREE)\n\nOBJECTS_LIB= linpack_double.o\n\n# For the parser library\nes15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/include/c++/10.2.0/x86_64-pc-linux-gnu -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/lib/gcc/x86_64-pc-linux-gnu/10.2.0/include -I/lus/theta-fs0/software/spack/spack-dev/opt/spack/linux-sles15-x86_64/gcc-9.3.0/gcc-10.2.0-r7v3naxd5xgzzaqxoe73jj2ytwuddamr/lib/gcc/x86_64-pc-linux-gnu/10.2.0/include-fixed/\nCXX_PARS   = nvc++ --no_warnings\n\n# Normally no need to change this\nSRCDIR     = ../../src\nBINDIR     = ../../bin\n</code></pre>"},{"location":"polaris/applications-and-libraries/applications/vasp/#setting-up-compiler-and-libraries-with-module","title":"Setting up compiler and libraries with <code>module</code>","text":"<p>The following modules will update the include and library paths used by the Cray compiler wrapper <code>ftn</code> to load additional math libraries for the CPU.</p> <pre><code>module restore\nmodule load cray-libsci\n\nexport NVROOT=${NVIDIA_PATH}\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$NVROOT/compilers/extras/qd/lib\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-blis/lib/ILP64/\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-libflame/lib/ILP64/\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-fftw/lib\n</code></pre>"},{"location":"polaris/applications-and-libraries/applications/vasp/#compiling-vasp","title":"Compiling VASP","text":"<p>Once the <code>modules</code> are loaded and a <code>makefile.include</code> is in the <code>vasp</code> folder, compiling all the object files and binaries is done with:</p> <pre><code>make -j1\n</code></pre>"},{"location":"polaris/applications-and-libraries/applications/vasp/#running-vasp-in-polaris","title":"Running VASP in Polaris","text":"<p>An example of a submission script can be found here <code>/soft/applications/vasp/script.sh</code>, which would look something similar to:</p> script.sh<pre><code>#!/bin/sh\n#PBS -l select=1:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -l filesystems=home:grand:eagle\n#PBS -q debug\n#PBS -A myproject\n\nunset LD_PRELOAD\nmodule rm xalt\n\nmodule load cray-libsci\n\nNVROOT=/opt/nvidia/hpc_sdk/Linux_x86_64/24.11\n\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$NVROOT/compilers/extras/qd/lib\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-blis/lib/ILP64/\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-libflame/lib/ILP64/\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/soft/applications/vasp/aol-libs/3.2/amd-fftw/lib\n\nexport MPICH_GPU_SUPPORT_ENABLED=1\n\n# uncomment for more than one node\n#export NCCL_NET_GDR_LEVEL=PHB\n#export NCCL_CROSS_NIC=1\n#export NCCL_COLLNET_ENABLE=1\n#export NCCL_NET=\"AWS Libfabric\"\n#export LD_LIBRARY_PATH=/soft/libraries/hwloc/lib/:$LD_LIBRARY_PATH\n#export LD_LIBRARY_PATH=/lus/eagle/projects/catalyst/world-shared/avazquez/aws-ofi-install/lib:$LD_LIBRARY_PATH\n#export NCCL_SOCKET_IFNAME=hsn\n\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS=$(nvidia-smi -L | wc -l)\nNDEPTH=8\nNTHREADS=1\n\nNTOTRANKS=$(( NNODES * NRANKS ))\nbin=/soft/applications/vasp/vasp.6.4.3/bin/vasp_std\n#IF you hold a license for 6.5\nbin=/soft/applications/vasp/vasp.6.5.1/bin/vasp_std\n\n\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS} --depth ${NDEPTH} --cpu-bind depth --env OMP_NUM_THREADS=${NTHREADS} /lus/eagle/projects/catalyst/world-shared/avazquez/affinity.sh  $bin\n</code></pre> <p>Submission scripts should have executable attributes to be used with <code>qsub</code> script mode.</p> <pre><code>chmod +x script.sh\nqsub script.sh\n</code></pre>"},{"location":"polaris/applications-and-libraries/libraries/cabana-polaris/","title":"Cabana","text":""},{"location":"polaris/applications-and-libraries/libraries/cabana-polaris/#cabana_1","title":"Cabana","text":"<p>Cabana is built atop Kokkos. It provides class templates useful for implementing particle codes.</p>"},{"location":"polaris/applications-and-libraries/libraries/cabana-polaris/#cabana-documentation","title":"Cabana Documentation","text":"<ul> <li>Cabana Wiki</li> <li>Cabana GitHub</li> </ul>"},{"location":"polaris/applications-and-libraries/libraries/cabana-polaris/#cabana-on-polaris","title":"Cabana on Polaris","text":"<p>Following the Polaris upgrade to HPCM 1.10, the module setup to use the prebuilt Kokkos has changed.</p> <p>Built against the prebuilt Kokkos on Polaris, the prebuilt Cabana includes three backends: Serial and OpenMP for CPU execution, and CUDA for GPU execution. To use it, run:</p> <pre><code>module load craype-x86-milan\nmodule load craype-accel-nvidia80\nmodule swap PrgEnv-nvidia PrgEnv-gnu\nmodule use /soft/modulefiles\nmodule load cuda-PrgEnv-nvidia/12.2.91\nmodule load kokkos cabana\n</code></pre> <p>Cabana is a headers-only package; there are no actual libraries installed.</p>"},{"location":"polaris/applications-and-libraries/libraries/math-libraries/","title":"Math Libraries","text":""},{"location":"polaris/applications-and-libraries/libraries/math-libraries/#blas-lapack-and-scalapack-for-cpus","title":"BLAS, LAPACK, and ScaLAPACK for CPUs","text":"<p>Some math libraries targeting CPUs are made available as part of the <code>nvidia</code> modules and are based on the OpenBLAS project. Additional documentation is available from NVIDIA.</p> <ul> <li>BLAS &amp; LAPACK can be found in the <code>$NVIDIA_PATH/compilers/lib</code> directory.</li> <li>ScaLAPACK can be found in the <code>$NVIDIA_PATH/comm_libs</code> directory.</li> <li>The GNU Scientific Library, GSL-2.7, is available as <code>module help math_libs/gsl</code>.</li> <li>AMD Optimizing CPU Libraries, AOCL v4.2, is available as <code>module help math_libs/aocl</code>.</li> <li>Other Cray-based math libs such as Libsci and FFTW are made available by <code>module load cray-libsci</code> &amp; <code>module load cray-fftw</code>.</li> </ul>"},{"location":"polaris/applications-and-libraries/libraries/math-libraries/#nvidia-math-libraries-for-gpus","title":"NVIDIA Math Libraries for GPUs","text":"<p>Math libraries from NVIDIA are made available via the <code>nvidia</code> modules. Many of the libraries users typically use can be found in the <code>$NVIDIA_PATH/math_libs</code> directory. Some examples follow, and additional documentation is available from NVIDIA.</p> <ul> <li>libcublas</li> <li>libcufft</li> <li>libcurand</li> <li>libcusolver</li> <li>libcusparse</li> </ul>"},{"location":"polaris/applications-and-libraries/libraries/nccl/","title":"NCCL","text":"<p>NVIDIA NCCL (pronounced \"Nickel\") is a standalone library of standard communication routines for GPUs, implementing all-reduce, all-gather, reduce, broadcast, reduce-scatter, as well as any send/receive-based communication pattern. It has been optimized to achieve high bandwidth on platforms using PCIe, NVLink, NVswitch, as well as networking using InfiniBand Verbs or TCP/IP sockets. NCCL supports an arbitrary number of GPUs installed in a single node or across multiple nodes and can be used in either single- or multi-process (e.g., MPI) applications.</p> <p>NCCL is a key library for scaling AI applications on NVIDIA systems. The Anaconda modules on Polaris are built with NCCL as the communication backend for distributed training of deep learning models. However, HPC applications can also choose NCCL for communication over MPI. The library is available in the following folder: <code>/soft/libraries/nccl</code>.</p> <p>We have done extensive performance tests and identified the following best environment setup.</p> <p><pre><code>export NCCL_NET_GDR_LEVEL=PHB\nexport NCCL_CROSS_NIC=1\nexport NCCL_COLLNET_ENABLE=1\nexport NCCL_NET=\"AWS Libfabric\"\nexport LD_LIBRARY_PATH=/soft/libraries/aws-ofi-nccl/v1.9.1-aws/lib:$LD_LIBRARY_PATH\nexport LD_LIBRARY_PATH=/soft/libraries/hwloc/lib/:$LD_LIBRARY_PATH\nexport FI_CXI_DISABLE_HOST_REGISTER=1\nexport FI_MR_CACHE_MONITOR=userfaultfd\nexport FI_CXI_DEFAULT_CQ_SIZE=131072\n</code></pre> The key here is to enable the AWS plugin (https://github.com/aws/aws-ofi-nccl). AWS OFI NCCL is a plugin that enables EC2 developers to use libfabric as a network provider while running NVIDIA's NCCL-based applications.</p> <p>This setup can lead to a 2-3x performance improvement for some communication workloads. For details, please refer to: https://github.com/argonne-lcf/alcf-nccl-tests.</p> <p>Warning</p> <p>For some applications such as Megatron-DeepSpeed, enabling the AWS plugin will cause a hang or NCCL timeout issue. If so, please disable it by: <pre><code>unset NCCL_NET_GDR_LEVEL NCCL_CROSS_NIC NCCL_COLLNET_ENABLE NCCL_NET\n</code></pre></p>"},{"location":"polaris/applications-and-libraries/libraries/spack-pe/","title":"Spack PE","text":"<p>Spack is an HPC-oriented package manager that ALCF uses to install software for the user environment.</p> <p>Users should depend on libraries in the Spack PE over libraries on the system when possible, as system libraries may slightly differ between compute nodes and login nodes.</p> <p>ALCF's Spack PE is a Spack-managed software stack that provides various build tools, utilities, and libraries. It consists of a base stack (<code>spack-pe-base</code>) and PrgEnv-dependent stacks (currently <code>spack-pe-gnu</code>).</p> <p><code>spack-pe-base</code> contains commonplace software compiled for CPU with the system GCC compilers. Accordingly, the software in <code>spack-pe-base</code> can be used regardless of the programming environment.</p> <p><code>spack-pe-gnu</code> is based on the E4S Project and provides performant HPC libraries built with <code>PrgEnv-gnu</code> and the <code>nvcc</code> CUDA compiler driver for GPU code. <code>spack-pe-gnu</code> is dependent on both <code>spack-pe-base</code> and <code>PrgEnv-gnu</code>.</p>"},{"location":"polaris/applications-and-libraries/libraries/spack-pe/#using-software-from-the-spack-pe","title":"Using software from the Spack PE","text":"<p>The base suite of software tools and libraries can be accessed by loading the <code>spack-pe-base</code> module. This adds a path to <code>$MODULEPATH</code> which contains numerous modules.</p> <p>For example, to load <code>cmake</code> starting from the default environment, a user should run the following commands:</p> <pre><code>module use /soft/modulefiles\nmodule load spack-pe-base\nmodule load cmake\n</code></pre> <p>The <code>spack-pe-base</code> module adds paths to the user's <code>MODULEPATH</code>; individual packages are subsequently loaded through the newly available modules. The full list of available packages can be viewed by running <code>module avail</code> or <code>module --show-hidden avail</code> for a complete listing. Packages are loaded in the same way from <code>spack-pe-gnu</code>.</p>"},{"location":"polaris/applications-and-libraries/libraries/spack-pe/#inspecting-packages","title":"Inspecting packages","text":"<p>When a module in the Spack PE is loaded, several environment variables are updated to integrate the package into the user's environment. Additionally, the <code>PACKAGE_ROOT</code> variable is set to the path to the installation prefix of the package. For example, after loading <code>cmake</code> as above:</p> <pre><code>$ echo $CMAKE_ROOT\n/soft/spack/gcc/0.6.1/install/linux-sles15-x86_64/gcc-12.3.0/cmake-3.27.7-a435jtzvweeos2es6enirbxdjdqhqgdp/\n$ ls -a $CMAKE_ROOT\n.  ..  bin  doc  share  .spack\n</code></pre> <p>This variable can be used to inspect software installations and find header or library paths. Additionally, Spack packages have a <code>.spack</code> directory in the installation prefix which contains build information and logs.</p>"},{"location":"polaris/applications-and-libraries/libraries/spack-pe/#building-software-with-spack","title":"Building software with Spack","text":"<p>Spack is a powerful package manager designed for HPC. The Spack PE is installed and managed with Spack; users can also install Spack in their own home or project directory to manage their software builds. Spack has a steep learning curve, but it may benefit workflows involving frequent builds with complex dependencies.</p> <p>For users who wish to use Spack to install their own software, we provide configuration files corresponding to the Spack PE deployments. These configuration files can be found in <code>config</code> directories in <code>/soft/spack</code> within the respective Spack PE installation directories. For example, the <code>spack-pe-base/0.6.1</code> configurations are in <code>/soft/spack/gcc/0.6.1/config</code>. Not all of these settings will be useful for all builds, and it is not recommended to adopt these wholesale as global settings. The recommended method is to include these settings ad hoc in a Spack environment to control what information Spack uses for its builds.</p> <p>Support requests and feedback should be directed to support@alcf.anl.gov. For general Spack questions, users are encouraged to consult the following resources:</p> <ul> <li>Spack development website</li> <li>Spack documentation</li> <li>Spack tutorial</li> <li>Spack Slack channel</li> </ul>"},{"location":"polaris/applications-and-libraries/libraries/xalt/","title":"XALT","text":""},{"location":"polaris/applications-and-libraries/libraries/xalt/#what-is-xalt","title":"What is XALT?","text":"<p>XALT is a user build and execution tracking framework; it is installed at ALCF on Polaris to track library usage.</p> <p>When XALT is enabled during builds:</p> <ul> <li>An XALT watermark is added to the ELF binary of the executable(s).</li> <li>An XALT link record containing information about the build is created.</li> </ul> <p>When XALT is enabled during application executions:</p> <ul> <li>An XALT start run record containing information about the execution is created; some link data is also included if the executable was built with XALT.</li> <li>If the execution exits normally, an XALT end run record containing information about the end of the process is created; if the process exits abnormally, no end run record is created.</li> <li>For MPI jobs, XALT run records are produced only for rank 0.</li> </ul>"},{"location":"polaris/applications-and-libraries/libraries/xalt/#xalt-implementation-details","title":"XALT implementation details","text":"<ul> <li>XALT uses an <code>ld</code> wrapper script to add the watermark to executables.</li> <li>XALT interposes an <code>LD_PRELOAD</code> library into the execution of the user's application. XALT runs as the user, with the user's primary and supplementary groups.</li> </ul>"},{"location":"polaris/applications-and-libraries/libraries/xalt/#how-to-disable-xalt","title":"How to disable XALT","text":"<ul> <li>Execute the command <code>module unload xalt</code>.</li> <li>If you disable XALT, please send an email to support@alcf.anl.gov detailing the reason you are disabling it.</li> </ul>"},{"location":"polaris/build-tools/cmake-polaris/","title":"CMake","text":""},{"location":"polaris/build-tools/cmake-polaris/#cmake_1","title":"CMake","text":"<p>CMake is a build configuration system that uses higher-level description files to automatically generate Makefiles.</p>"},{"location":"polaris/build-tools/cmake-polaris/#cmake-documentation","title":"CMake Documentation","text":"<ul> <li>CMake website</li> </ul>"},{"location":"polaris/build-tools/cmake-polaris/#cmake-on-polaris","title":"CMake on Polaris","text":"<p>To use CMake on Polaris, run:</p> <pre><code>module use /soft/modulefiles\nmodule load spack-pe-base cmake\n</code></pre>"},{"location":"polaris/compiling-and-linking/","title":"Compiling and Linking Overview on Polaris","text":""},{"location":"polaris/compiling-and-linking/#compiling-on-polaris-login-and-compute-nodes","title":"Compiling on Polaris Login and Compute Nodes","text":"<p>Most build systems for GPU applications do not require the use a GPU to compile and link the binary. In such cases, the compilation of GPU-accelerated codes is generally expected to work well on the Polaris login nodes. If your build system does require usable GPUs, you cannot yet compile on the Polaris login nodes. They each currently have a single A100 installed on each, but user processes are forbidden from executing on these GPUs. In this case, you may compile your applications on the Polaris compute nodes. Do this by submitting an interactive single-node job or running your build system in a batch job.</p>"},{"location":"polaris/compiling-and-linking/#home-file-system","title":"Home File System","text":"<p>It is helpful to realize that there is a single <code>HOME</code> filesystem for users that can be accessed from the login and compute nodes of each production resource at ALCF. Thus, users should be mindful of modifications to their environments (e.g., <code>.bashrc</code>) that may cause issues to arise due to differences between the systems.</p>"},{"location":"polaris/compiling-and-linking/#cray-programming-environment","title":"Cray Programming Environment","text":"<p>Info</p> <p>Beginning in CPE 24.11, the NVHPC modules (<code>PrgEnv-nvhpc</code>, <code>nvhpc</code>, <code>nvhpc-mixed</code>) are no longer offered. The NVIDIA modules (<code>PrgEnv-nvidia</code>, <code>nvidia</code>, <code>nvidia-mixed</code>) are now the sole option for modules regarding the NVIDIA programing environment. The move to the NVIDIA modules is to complete the alignment of CPE module flows. The module flow for all environments is as follows: - Load an environment meta module (e.g. <code>PrgEnv-nvidia</code>) - Environment meta module loads a compiler (e.g. <code>nvidia</code>) - User can choose to load a toolkit (<code>cuda</code>, <code>cudatoolkit</code>)</p> <p>The Cray Programming Environment (PE) uses three compiler wrappers for building software. These compiler wrappers should be used when building MPI-enabled applications.</p> <ul> <li><code>cc</code> - C compiler</li> <li><code>CC</code> - C++ compiler</li> <li><code>ftn</code> - Fortran compiler</li> </ul> <p>Each of these wrappers can select a specific vendor compiler based on the PrgEnv module loaded in the environment. The following are some helpful options to understand what the compiler wrapper is invoking.</p> <ul> <li><code>--craype-verbose</code>: Print the command which is forwarded to the compiler invocation</li> <li><code>--cray-print-opts=libs</code>: Print library information</li> <li><code>--cray-print-opts=cflags</code>: Print include information</li> </ul> <p>The output from these commands may be useful in build scripts where a compiler other than that invoked by a compiler wrapper is desired. Defining some variables as such may prove useful in those situations.</p> <pre><code>CRAY_CFLAGS=$(cc --cray-print-opts=cflags)\nCRAY_LIB=$(cc --cray-print-opts=libs)\n</code></pre> <p>Further documentation and options are available via <code>man cc</code> and similar.</p>"},{"location":"polaris/compiling-and-linking/#compilers-provided-by-cray-programming-environments","title":"Compilers Provided by Cray Programming Environments","text":"<p>The default programming environment on Polaris is currently <code>NVIDIA</code>. The <code>GNU</code> compilers are available via another programming environment. The following sequence of <code>module</code> commands can be used to switch to the <code>GNU</code> programming environment (<code>gcc</code>, <code>g++</code>, <code>gfortran</code>) and also have <code>NVIDIA</code> compilers available in your path.</p> <pre><code>module swap PrgEnv-nvidia PrgEnv-gnu\nmodule load nvidia-mixed\n</code></pre> <p>The compilers invoked by the Cray MPI wrappers are listed for each programming environment in the following table.</p> Module C C++ Fortran MPI Compiler Wrapper cc CC ftn PrgEnv-nvidia nvc nvc++ nvfortran PrgEnv-gnu gcc g++ gfortran <p>Note, while gcc and g++ may be available in the default environment, the <code>PrgEnv-gnu</code> module is needed to provide gfortran.</p>"},{"location":"polaris/compiling-and-linking/#additional-compilers-provided-by-alcf","title":"Additional Compilers Provided by ALCF","text":"<p>The ALCF additionally provides compilers to enable the OpenMP and SYCL programming models for GPUs via <code>LLVM</code> as documented here.</p> <p>Additional documentation for using compilers is available on the respective programming model pages: OpenMP and SYCL.</p>"},{"location":"polaris/compiling-and-linking/#linking","title":"Linking","text":"<p>Dynamic linking of libraries is currently the default on Polaris. The Cray MPI wrappers will handle this automatically.</p>"},{"location":"polaris/compiling-and-linking/#notes-on-default-modules","title":"Notes on Default Modules","text":"<ul> <li> <p><code>craype-accel-nvidia80</code>: This module adds compiler flags to enable GPU acceleration for <code>NVIDIA</code> compilers along with GPU-aware MPI libraries, as it is assumed that the majority of applications to be compiled on Polaris will target the GPUs for acceleration. Users building CPU-only applications may find it useful to unload this module to silence \"GPU code generation\" warnings.</p> </li> <li> <p><code>xalt</code>: This module enables library tracking; it helps ALCF identify software important to our users. More information can be found on the XALT page.</p> </li> </ul>"},{"location":"polaris/compiling-and-linking/#mixed-cc-fortran-applications","title":"Mixed C/C++ &amp; Fortran Applications","text":"<p>For applications consisting of a mix of C/C++ and Fortran that also use MPI, it is suggested that the programming environment chosen for Fortran be used to build the full application because of mpi.mod (and similar) incompatibilities.</p>"},{"location":"polaris/compiling-and-linking/#compiling-for-gpus","title":"Compiling for GPUs","text":"<p>It is assumed the majority of applications to be built on Polaris will make use of the GPUs. As such, the <code>craype-accel-nvidia80</code> module is in the default environment. This has the effect of the Cray compiler wrappers adding <code>-gpu</code> to the compiler invocation along with additional include paths and libraries. Additional compiler flags may be needed depending on the compiler and GPU programming model used (e.g., <code>-cuda</code>, <code>-acc</code>, or <code>-mp=gpu</code>).</p> <p>This module also adds GPU Transport Layer (GTL) libraries to the link-line to support GPU-aware MPI applications.</p>"},{"location":"polaris/compiling-and-linking/#man-pages","title":"Man Pages","text":"<p>For additional information on the Cray wrappers, please refer to the man pages.</p> <pre><code>man cc\nman CC\nman ftn\n</code></pre>"},{"location":"polaris/compiling-and-linking/cce-compilers-polaris/","title":"CCE Compilers on Polaris","text":"<p>The Cray Compiling Environment (CCE) compilers are available on Polaris via the <code>PrgEnv-cray</code> module.</p> <p>The CCE compilers currently on Polaris only support AMD GPU targets for HIP and are thus not usable with the A100 GPUs.</p> <p>The <code>nvhpc</code> and <code>llvm</code> compilers can be used for compiling GPU-enabled applications.</p>"},{"location":"polaris/compiling-and-linking/gnu-compilers-polaris/","title":"GNU Compilers on Polaris","text":"<p>The GNU compilers are available on Polaris via the <code>PrgEnv-gnu</code> and <code>gcc-mixed</code> modules. The <code>gcc-mixed</code> module can be useful when, for example, the <code>PrgEnv-nvidia</code> compilers are used to compile C/C++ MPI-enabled code and the <code>gfortran</code> compiler is needed.</p> <p>The GNU compilers currently on Polaris do not support GPU code generation and thus can only be used for compiling CPU codes.</p> <p>The <code>nvhpc</code> and <code>llvm</code> compilers can be used for compiling GPU-enabled applications.</p>"},{"location":"polaris/compiling-and-linking/llvm-compilers-polaris/","title":"LLVM Compilers on Polaris","text":"<p>This page is not about LLVM-based Cray Compiling Environment (CCE) compilers from <code>PrgEnv-cray</code> but about open-source LLVM compilers.</p> <p>If LLVM compilers are needed without MPI support, simply load the <code>llvm</code> module.</p> <p>The Cray Programming Environment does not offer LLVM compiler support. Thus, cc/CC/ftn compiler wrappers using LLVM compilers currently are not available. To use Clang with MPI, one can load the <code>mpiwrappers/cray-mpich-llvm</code> module, which loads the following modules:</p> <ul> <li><code>llvm</code>, upstream LLVM compilers</li> <li><code>cray-mpich</code>, MPI compiler wrappers mpicc/mpicxx/mpif90. mpif90 uses gfortran because flang is not ready for production use.</li> <li><code>cray-pals</code>, MPI launchers mpiexec/aprun/mpirun</li> </ul> <p>Limitation: There is no GPU-aware MPI library linking support by default. If needed, users should manually add the GTL (GPU Transport Layer) library to the application link line.</p> <p>Update 04/25/2024: To access LLVM modules, <code>module use /soft/modulefiles</code> is required.</p>"},{"location":"polaris/compiling-and-linking/llvm-compilers-polaris/#openmp-offload","title":"OpenMP offload","text":"<p>When targeting the OpenMP or CUDA programming models for GPUs, the <code>cudatoolkit-standalone</code> module should also be loaded.</p>"},{"location":"polaris/compiling-and-linking/nvidia-compiler-polaris/","title":"NVIDIA Compilers on Polaris","text":"<p>The NVIDIA compilers (<code>nvc</code>, <code>nvc++</code>, <code>nvcc</code>, and <code>nvfortran</code>) are available on Polaris via the <code>PrgEnv-nvidia</code> module.</p> <p>The Cray compiler wrappers map to NVIDIA compilers as follows:</p> <pre><code>cc -&gt; nvc\nCC -&gt; nvc++\nftn -&gt; nvfortran\n</code></pre> <p>Users are encouraged to look through NVIDIA's documentation for the NVHPC SDK and specific information on the compilers, tools, and libraries.</p>"},{"location":"polaris/compiling-and-linking/nvidia-compiler-polaris/#notes-on-nvidia-compilers","title":"Notes on NVIDIA Compilers","text":""},{"location":"polaris/compiling-and-linking/nvidia-compiler-polaris/#pgi-compilers","title":"PGI compilers","text":"<p>The NVIDIA programming environments make available compilers from the NVIDIA HPC SDK. While the PGI compilers are available in this programming environment, it should be noted they are actually symlinks to the corresponding NVIDIA compilers.</p> <pre><code>pgcc -&gt; nvc\npgc++ -&gt; nvc++\npgf90 -&gt; nvfortran\npgfortran -&gt; nvfortran\n</code></pre> <p>While <code>nvcc</code> is the traditional CUDA C and CUDA C++ compiler for NVIDIA GPUs, the <code>nvc</code>, <code>nvc++</code>, and <code>nvfortran</code> compilers additionally target CPUs.</p>"},{"location":"polaris/compiling-and-linking/nvidia-compiler-polaris/#nvhpc-sdk-directory-structure","title":"NVHPC SDK Directory Structure","text":"<p>Users migrating from CUDA toolkits to the NVHPC SDK may find it beneficial to review the directory structure of the <code>hpc-sdk</code> directory to find the location of commonly used libraries (including math libraries for the CPU). With the <code>PrgEnv-nvidia</code> module loaded, the <code>NVIDIA_PATH</code> environment variable can be used to locate the path to various NVIDIA tools, libraries, and examples.</p> <ul> <li><code>compiler/bin</code> - cuda-gdb, ncu, nsys, ...</li> <li><code>examples</code> - CUDA-Fortran, OpenMP, ...</li> <li><code>comm_libs</code> - nccl, nvshmem, ...</li> <li><code>compiler/libs</code> - blas, lapack, ...</li> <li><code>cuda/lib64</code> - cudart, OpenCL, ...</li> <li><code>math_libs/lib64</code> - cublas, cufft, ...</li> </ul>"},{"location":"polaris/compiling-and-linking/nvidia-compiler-polaris/#differences-between-nvcc-and-nvcnvc","title":"Differences between nvcc and nvc/nvc++","text":"<p>For users that want to continue using <code>nvcc</code>, it is important to be mindful of differences with the newer <code>nvc</code> and <code>nvc++</code> compilers. For example, the <code>-cuda</code> flag instructs <code>nvcc</code> to compile <code>.cu</code> input files to <code>.cu.cpp.ii</code> output files, which are to be separately compiled, whereas the same <code>-cuda</code> flag instructs <code>nvc</code>, <code>nvc++</code>, and <code>nvfortran</code> to enable CUDA C/C++ or CUDA Fortran code generation. The resulting output file in each case is different (text vs. object), and one may see an <code>unrecognized format error</code> when <code>-cuda</code> is incorrectly passed to <code>nvcc</code>.</p>"},{"location":"polaris/compiling-and-linking/nvidia-compiler-polaris/#known-issues-and-workarounds","title":"Known Issues and Workarounds","text":"<p>If you are using <code>nvcc</code> to invoke <code>nvc++</code> and compiling C++17 code, and are seeing the following warning and unable to compile C++17 constructs:</p> <pre><code>polaris-login-01(~)&gt; nvcc --std=c++17 -ccbin nvc++ ~/smalltests/bool_constant.cpp\nnvcc warning : The -std=c++17 flag is not supported with the configured host compiler. Flag will be ignored.\n\"/home/zippy/smalltests/bool_constant.cpp\", line 10: error: namespace \"std\" has no member class \"bool_constant\"\n      : std::bool_constant&lt;(UnaryPred&lt;Ts&gt;::value || ...)&gt; {};\n             ^\n\n\"/home/zippy/smalltests/bool_constant.cpp\", line 10: error: class or struct definition is missing\n      : std::bool_constant&lt;(UnaryPred&lt;Ts&gt;::value || ...)&gt; {};\n                          ^\n\n2 errors detected in the compilation of \"/home/zippy/smalltests/bool_constant.cpp\".\npolaris-login-01(~)&gt;\n</code></pre> <p>you will need to work around it by loading the latest <code>cudatoolkit</code> module atop <code>PrgEnv-nvidia</code>:</p> <pre><code>module load cudatoolkit-standalone/11.6.2\n</code></pre>"},{"location":"polaris/compiling-and-linking/oneapi-compiler/","title":"oneAPI Compilers and Support","text":"<p>The Intel oneAPI compiler and Codeplay plugins for Nvidia GPUs are available on Polaris. The oneAPI compilers are not enabled under the Cray Programming Environment system but can be used separately. Two oneAPI variants are provided, the first being a \"release\" version based on Intel's officially released oneAPI toolkit. Intel Release Notes</p> <p>Note</p> <p>The 2023.2.1 release of the oneAPI Toolkit does not yet support oneDPL on Nvidia devices, though oneMKL is now added from the 2023.2.1 release onwards.</p>"},{"location":"polaris/compiling-and-linking/oneapi-compiler/#components","title":"Components","text":"<ul> <li>The following is a list of components associated with this module:</li> </ul> User Application Component Compilers DPC++ oneMKL Interfaces oneMKL <p>The other variant is a build from the open-source. This variant will be more up-to-date at the risk of bugs and breakages based on code that has not undergone a full release cycle. The documentation is located on the SYCL page. The most notable differences are that <code>icx/icpx</code> are the names of C/C++ compilers, respectively, when using the release version of the module, whereas <code>clang/clang++</code> are for the open-source variant.</p>"},{"location":"polaris/compiling-and-linking/oneapi-compiler/#compile-and-link","title":"Compile and Link","text":"<p>oneAPI uses the clang (or icx/icpx wrapper) for compiling and linking for the Nvidia A100 SM80 architecture.</p> <pre><code>module load oneapi/release\nicpx -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 test.cpp\n</code></pre> <pre><code>harms@polaris-login-04:~/working/polaris/oneapi&gt; icpx -v\nIntel(R) oneAPI DPC++/C++ Compiler 2023.2.0 (2023.2.0.20230721)\nTarget: x86_64-unknown-linux-gnu\nThread model: posix\nInstalledDir: /soft/compilers/oneapi/release/2023.2/compiler/2023.2.1/linux/bin-llvm\nConfiguration file: /soft/compilers/oneapi/release/2023.2/compiler/2023.2.1/linux/bin-llvm/../bin/icpx.cfg\nFound candidate GCC installation: /usr/lib64/gcc/x86_64-suse-linux/7\nSelected GCC installation: /usr/lib64/gcc/x86_64-suse-linux/7\nCandidate multilib: .;@m64\nSelected multilib: .;@m64\nFound CUDA installation: /opt/nvidia/hpc_sdk/Linux_x86_64/21.9/cuda/11.4, version 11.4\n</code></pre>"},{"location":"polaris/compiling-and-linking/oneapi-compiler/#running","title":"Running","text":"<p>The library should select the GPU by default, but the selection of the GPUs can be forced via the ONEAPI_DEVICE_SELECTOR.</p> <pre><code>$ ONEAPI_DEVICE_SELECTOR=cuda:gpu ./a.out\n</code></pre> <p>or a specific GPU.</p> <pre><code>$ ONEAPI_DEVICE_SELECTOR=cuda:gpu:3 ./a.out\n</code></pre>"},{"location":"polaris/compiling-and-linking/oneapi-compiler/#sycl-ls","title":"sycl-ls","text":"<p>Expected output of sycl-ls and which platforms are available.</p> <pre><code>harms@x3004c0s7b0n0:~&gt; which sycl-ls\n/soft/compilers/oneapi/release/2023.2/compiler/2023.2.1/linux/bin/sycl-ls\n\nharms@x3004c0s7b0n0:~&gt; sycl-ls\n[opencl:acc:0] Intel(R) FPGA Emulation Platform for OpenCL(TM), Intel(R) FPGA Emulation Device 1.2 [2023.16.7.0.21_160000]\n[opencl:cpu:1] Intel(R) OpenCL, AMD EPYC 7543P 32-Core Processor                3.0 [2023.16.7.0.21_160000]\n[ext_oneapi_cuda:gpu:0] NVIDIA CUDA BACKEND, NVIDIA A100-SXM4-40GB 8.8 [CUDA 11.4]\n[ext_oneapi_cuda:gpu:1] NVIDIA CUDA BACKEND, NVIDIA A100-SXM4-40GB 8.8 [CUDA 11.4]\n[ext_oneapi_cuda:gpu:2] NVIDIA CUDA BACKEND, NVIDIA A100-SXM4-40GB 8.8 [CUDA 11.4]\n[ext_oneapi_cuda:gpu:3] NVIDIA CUDA BACKEND, NVIDIA A100-SXM4-40GB 8.8 [CUDA 11.4]\n</code></pre>"},{"location":"polaris/compiling-and-linking/polaris-example-program-makefile/","title":"Example Programs and Makefiles for Polaris","text":"<p>Several simple examples of building CPU and GPU-enabled codes on Polaris are available in the ALCF GettingStarted repo for several programming models. If building your application is problematic for some reason (e.g., absence of a GPU), then users are encouraged to build and test applications directly on one of the Polaris compute nodes via an interactive job. The discussion below makes use of the <code>NVHPC</code> compilers in the default environment as illustrative examples. Similar examples for other compilers on Polaris are available in the ALCF GettingStarted repo.</p>"},{"location":"polaris/compiling-and-linking/polaris-example-program-makefile/#cpu-mpiopenmp-example","title":"CPU MPI+OpenMP Example","text":"<p>One of the first useful tasks with any new machine, scheduler, and job launcher is to ensure one is binding MPI ranks and OpenMP threads to the host CPU as intended. A simple HelloWorld MPI+OpenMP example is available here to get started with.</p> <p>The application can be straightforwardly compiled using the Cray compiler wrappers. <pre><code>CC -fopenmp main.cpp -o hello_affinity\n</code></pre></p> <p>The executable <code>hello_affinity</code> can then be launched in a job script (or directly in the shell of an interactive job) using <code>mpiexec</code> as discussed here.</p> <pre><code>#!/bin/sh\n#PBS -l select=1:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -l filesystems=home\n\n# MPI example w/ 16 MPI ranks per node spread evenly across cores\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=16\nNDEPTH=4\nNTHREADS=1\n\nNTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))\necho \"NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}\"\n\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth ./hello_affinity\n</code></pre>"},{"location":"polaris/compiling-and-linking/polaris-example-program-makefile/#cuda","title":"CUDA","text":"<p>Several variants of C/C++ and Fortran CUDA examples are available here that include MPI and multi-GPU examples.</p> <p>One can use the Cray compiler wrappers to compile GPU-enabled applications as well. This example of simple vector addition uses the NVIDIA compilers.</p> <pre><code>CC -g -O3 -std=c++0x -cuda main.cpp -o vecadd\n</code></pre> <p>The <code>craype-accel-nvidia80</code> module in the default environment will add the <code>-gpu</code> compiler flag for <code>nvhpc</code> compilers along with appropriate include directories and libraries. It is left to the user to provide an additional flag to the <code>nvhpc</code> compilers to select the target GPU programming model. In this case, <code>-cuda</code> is used to indicate compilation of CUDA code. The application can then be launched within a batch job submission script or as follows on one of the compute nodes.</p> <pre><code>$ ./vecadd \n# of devices= 4\n  [0] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]\n  [1] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]\n  [2] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]\n  [3] Platform[ Nvidia ] Type[ GPU ] Device[ NVIDIA A100-SXM4-40GB ]\nRunning on GPU 0!\nUsing single-precision\n\n  Name= NVIDIA A100-SXM4-40GB\n  Locally unique identifier= \n  Clock Frequency(KHz)= 1410000\n  Compute Mode= 0\n  Major compute capability= 8\n  Minor compute capability= 0\n  Number of multiprocessors on device= 108\n  Warp size in threads= 32\n  Single precision performance ratio= 2\n\nResult is CORRECT!! :)\n</code></pre>"},{"location":"polaris/compiling-and-linking/polaris-example-program-makefile/#gpu-openacc","title":"GPU OpenACC","text":"<p>A simple MPI-parallel OpenACC example is available here. Compilation proceeds similar to the above CUDA example except for the use of the <code>-acc=gpu</code> compiler flag to indicate compilation of OpenACC code for GPUs. <pre><code>CC -g -O3 -std=c++0x -acc=gpu -gpu=cc80,cuda11.0 main.cpp -o vecadd\n</code></pre> In this example, each MPI rank sees all four GPUs on a Polaris node and GPUs are bound to MPI ranks round-robin within the application.</p> <p><pre><code>$ mpiexec -n 4 ./vecadd\n# of devices= 4\nUsing single-precision\n\nRank 0 running on GPU 0!\nRank 1 running on GPU 1!\nRank 2 running on GPU 2!\nRank 3 running on GPU 3!\n\nResult is CORRECT!! :)\n</code></pre> If the application instead relies on the job launcher to bind MPI ranks to available GPUs, then a small helper script can be used to explicitly set <code>CUDA_VISIBLE_DEVICES</code> appropriately for each MPI rank. One example is available here where each MPI rank is similarly bound to a single GPU with round-robin assignment. The binding of MPI ranks to GPUs is discussed in more detail here.</p>"},{"location":"polaris/compiling-and-linking/polaris-example-program-makefile/#gpu-opencl","title":"GPU OpenCL","text":"<p>A simple OpenCL example is available here. The OpenCL headers and library are available in the NVHPC SDK and CUDA toolkits. The environment variable <code>NVIDIA_PATH</code> is defined for the <code>PrgEnv-nvidia</code> programming environment.  <pre><code>CC -o vecadd -g -O3 -std=c++0x  -I${NVIDIA_PATH}/cuda/include main.o -L${NVIDIA_PATH}/cuda/lib64 -lOpenCL\n</code></pre></p> <p>This simple example can be run on a Polaris compute node as follows. <pre><code>$ ./vecadd\nRunning on GPU!\nUsing single-precision\n\n    CL_DEVICE_NAME: NVIDIA A100-SXM4-40GB\n    CL_DEVICE_VERSION: OpenCL 3.0 CUDA\n    CL_DEVICE_OPENCL_C_VERSION: OpenCL C 1.2 \n    CL_DEVICE_MAX_COMPUTE_UNITS: 108\n    CL_DEVICE_MAX_CLOCK_FREQUENCY: 1410\n    CL_DEVICE_MAX_WORK_GROUP_SIZE: 1024\n\nResult is CORRECT!! :)\n</code></pre></p>"},{"location":"polaris/compiling-and-linking/polaris-example-program-makefile/#gpu-openmp","title":"GPU OpenMP","text":"<p>A simple MPI-parallel OpenMP example is available here. Compilation proceeds similar to the above examples except for the use of the <code>-mp=gpu</code> compiler flag to indicate compilation of OpenMP code for GPUs.</p> <pre><code>CC -g -O3 -std=c++0x -mp=gpu -gpu=cc80,cuda11.0 -c main.cpp -o vecadd\n</code></pre> <p>Similar to the OpenACC example above, this code binds MPI ranks to GPUs in a round-robin fashion.  <pre><code>$ mpiexec -n 4 ./vecadd\n# of devices= 4\nRank 0 running on GPU 0!\nRank 1 running on GPU 1!\nRank 2 running on GPU 2!\nRank 3 running on GPU 3!\n\nResult is CORRECT!! :)\n</code></pre></p>"},{"location":"polaris/compiling-and-linking/polaris-programming-models/","title":"Programming Models on Polaris","text":"<p>The software environment on Polaris supports several parallel programming models targeting the CPUs and GPUs.</p>"},{"location":"polaris/compiling-and-linking/polaris-programming-models/#cpu-parallel-programming-models","title":"CPU Parallel Programming Models","text":"<p>The Cray compiler wrappers <code>cc</code>, <code>CC</code>, and <code>ftn</code> are recommended for MPI applications as they provide the needed include paths and libraries for each programming environment. A summary of available CPU parallel programming models and relevant compiler flags is shown below. Users are encouraged to review the corresponding man pages and documentation.</p> Programming Model GNU NVHPC LLVM OpenMP <code>-fopenmp</code> <code>-mp</code> <code>-fopenmp</code> OpenACC -- <code>-acc=multicore</code> -- <p>Higher-level programming models such as Kokkos and Raja may also be used for CPU programming.</p>"},{"location":"polaris/compiling-and-linking/polaris-programming-models/#gpu-programming-models","title":"GPU Programming Models","text":"<p>A summary of available GPU programming models and relevant compiler flags is shown below for compilers that generate offloadable code. Users are encouraged to review the corresponding man pages and documentation.</p> Programming Model GNU NVHPC LLVM ONEAPI CUDA -- <code>-cuda [-gpu=cuda8.0,cc11.0]</code> -- -- HIP<sup>1</sup> <code>--gpu-architecture=compute_80 --gpu-code=sm_80</code> -- -- -- OpenACC -- <code>-acc</code> -- -- OpenCL<sup>2</sup> -- -- -- -- OpenMP -- <code>-mp=gpu</code> <code>--offload-arch=sm_80</code> -- SYCL -- -- -- <code>-fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80</code> <ul> <li>Note, the <code>llvm</code> and <code>oneapi</code> modules are provided by ALCF, not HPE, in order to complement the compilers provided by the Cray PE on Polaris.</li> <li>Higher-level programming models such as Kokkos and Raja may also be used for GPU programming.</li> <li>Abstraction-based performance portability programming models, such as Kokkos, can be built on top of several of these lower-level programming models (see below).</li> </ul>"},{"location":"polaris/compiling-and-linking/polaris-programming-models/#mapping-programming-models-to-polaris-modules","title":"Mapping Programming Models to Polaris Modules","text":"<p>The table below offers some suggestions for how to get started setting up your environment on Polaris depending on the programming language and model. Note, mixed C/C++ and Fortran applications should choose the programming environment for the Fortran compiler because of <code>mpi.mod</code> and similar incompatibilities between Fortran-generated files from different compilers. Several simple examples for testing the software environment on Polaris for different programming models are available in the ALCF GettingStarted repo.</p> Programming Language GPU Programming Model Likely used Modules/Compilers Notes C/C++ CUDA PrgEnv-nvidia, PrgEnv-gnu, llvm NVIDIA (nvcc, nvc, nvc++) and clang compilers do GPU code generation C/C++ HIP N/A need to install with support for A100 C/C++ Kokkos See CUDA HIP, OpenMP, and SYCL/DPC++ also candidates C/C++ OpenACC PrgEnv-nvidia C/C++ OpenCL PrgEnv-nvidia, PrgEnv-gnu, llvm JIT GPU code generation C/C++ OpenMP PrgEnv-nvidia, llvm C/C++ RAJA See CUDA HIP, OpenMP, and SYCL/DPC++ also candidates C/C++ SYCL/DPC++ llvm-sycl Fortran CUDA PrgEnv-nvidia NVIDIA compiler (nvfortran) does GPU code generation; <code>gfortran</code> can be loaded via <code>gcc-mixed</code> Fortran HIP N/A need to install with support for A100 Fortran OpenACC PrgEnv-nvidia Fortran OpenCL PrgEnv-nvidia, PrgEnv-gnu JIT GPU code generation Fortran OpenMP PrgEnv-nvidia <ol> <li> <p>Run <code>module load rocm</code> to use this. It is only compatible with <code>PrgEnv-gnu</code> \u21a9</p> </li> <li> <p>OpenCL is supported, but does not require specific compiler flags per se, as the offloaded kernels are just-in-time (JIT) compiled.\u00a0\u21a9</p> </li> </ol>"},{"location":"polaris/containers/containers/","title":"Containers on Polaris","text":"<p>Polaris, equipped with NVIDIA A100 GPUs, leverages container-based workloads for seamless compatibility across NVIDIA systems. This guide provides detailed instructions on using containers on Polaris, including setup, container creation, large-scale execution, and troubleshooting common issues.</p>"},{"location":"polaris/containers/containers/#apptainer-setup","title":"Apptainer Setup","text":"<p>Polaris uses Apptainer (formerly Singularity) for container management. Request a compute node as follows:</p> <pre><code>qsub -I -A &lt;PROJECT_NAME&gt; -q debug -l select=1 -l walltime=01:00:00 -l filesystems=home:grand:eagle -l singularity_fakeroot=true # Debug queue for 1 hour\n</code></pre> <p>After connecting to the compute node, load Apptainer and necessary modules:</p> <pre><code>ml use /soft/modulefiles\nml spack-pe-base\nml apptainer\n\nexport BASE_SCRATCH_DIR=/local/scratch/ # For Polaris\nexport APPTAINER_TMPDIR=$BASE_SCRATCH_DIR/apptainer-tmpdir\nmkdir -p $APPTAINER_TMPDIR\n\nexport APPTAINER_CACHEDIR=$BASE_SCRATCH_DIR/apptainer-cachedir\nmkdir -p $APPTAINER_CACHEDIR\n\n# For internet access\nexport HTTP_PROXY=http://proxy.alcf.anl.gov:3128\nexport HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\nexport http_proxy=http://proxy.alcf.anl.gov:3128\nexport https_proxy=http://proxy.alcf.anl.gov:3128\n\napptainer version # should return 1.4.1\n</code></pre> <p>Detailed Apptainer documentation is available here.</p>"},{"location":"polaris/containers/containers/#building-containers-from-docker-or-argonne-github-container-registry","title":"Building Containers from Docker or Argonne GitHub Container Registry","text":"<p>Containers can be built by: - Creating Dockerfiles locally and publishing to DockerHub, then converting to Apptainer. - Building directly on ALCF nodes using Apptainer recipe files.</p> <p>To convert a Docker container to Apptainer on Polaris, use:</p> <pre><code>apptainer build --fakeroot pytorch:22.06-py3.sing docker://nvcr.io/nvidia/pytorch:22.06-py3\n</code></pre> <p>Find prebuilt NVIDIA PyTorch containers here. TensorFlow containers are here. Search the full container registry here. Custom containers tailored for Polaris are available in ALCF's GitHub container registry.</p> <p>Note: Container build and execution are only supported on Polaris compute nodes.</p>"},{"location":"polaris/containers/containers/#running-containers-on-polaris","title":"Running Containers on Polaris","text":"<p>Use the submission script detailed here. Example job script:</p> <pre><code>#!/bin/sh\n#PBS -l select=2:system=polaris\n#PBS -q debug\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -l filesystems=home:eagle\n#PBS -A &lt;project_name&gt;\ncd ${PBS_O_WORKDIR}\n\nml use /soft/modulefiles\nml spack-pe-base\nml apptainer\n\nexport BASE_SCRATCH_DIR=/local/scratch/\nexport APPTAINER_TMPDIR=$BASE_SCRATCH_DIR/apptainer-tmpdir\nmkdir -p $APPTAINER_TMPDIR\nexport APPTAINER_CACHEDIR=$BASE_SCRATCH_DIR/apptainer-cachedir\nmkdir -p $APPTAINER_CACHEDIR\n\n# Proxy setup for internet access\nexport HTTP_PROXY=http://proxy.alcf.anl.gov:3128\nexport HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\nexport http_proxy=http://proxy.alcf.anl.gov:3128\nexport https_proxy=http://proxy.alcf.anl.gov:3128\n\n# Environment variables for MPI\nexport ADDITIONAL_PATH=/opt/cray/pe/pals/1.2.12/lib\nmodule load cray-mpich-abi\nexport APPTAINERENV_LD_LIBRARY_PATH=\"$CRAY_LD_LIBRARY_PATH:$LD_LIBRARY_PATH:$ADDITIONAL_PATH\"\n\n# Set MPI ranks\nNODES=$(wc -l &lt; $PBS_NODEFILE)\nPPN=16\nPROCS=$((NODES * PPN))\necho \"NUM_OF_NODES=${NODES}, TOTAL_NUM_RANKS=${PROCS}, RANKS_PER_NODE=${PPN}\"\n\n# Launch the container\nmpiexec -hostfile $PBS_NODEFILE -n $PROCS -ppn $PPN apptainer exec --fakeroot -B /opt -B /var/run/palsd/ $CONTAINER /usr/source/mpi_hello_world\n\n# Python example\nmpiexec -hostfile $PBS_NODEFILE -n $PROCS -ppn $PPN apptainer exec --fakeroot -B /opt -B /var/run/palsd/ $CONTAINER python3 /usr/source/mpi_hello_world.py\n</code></pre> <p>Submit jobs using:</p> <pre><code>qsub -v CONTAINER=mpich-4_latest.sif job_submission.sh\n</code></pre>"},{"location":"polaris/containers/containers/#available-containers","title":"Available Containers","text":"<ul> <li>Examples for running MPICH containers can be found here.</li> <li>Examples for running databases can be found here.</li> <li>Examples for using SHPC (containers as modules) can be found here.</li> </ul>"},{"location":"polaris/containers/containers/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":"<ul> <li>Permission Denied: Check your quota, clean Apptainer cache (<code>~/.apptainer/cache</code>), or set directories to local scratch (<code>/local/scratch/</code>).</li> <li>MPI Issues: Ensure MPI compatibility by following MPI container registry docs.</li> <li>libmpi.so.40 not found: Use MPICH-compatible base images.</li> <li>Disabled Network Virtualization: Network virtualization is disabled due to security constraints (details).</li> <li>Starter-suid Error: Always use the <code>--fakeroot</code> flag on Polaris compute nodes.</li> </ul> <p>For further assistance, contact ALCF support: <code>support@alcf.anl.gov</code>.</p>"},{"location":"polaris/data-science/profiling_dl/","title":"Profiling Deep Learning Applications","text":"<p>We can use both a framework-specific (for example, PyTorch-specific) native profiler and the vendor-specific NVIDIA Nsys profiler to get high-level profiling information and a timeline of execution for an application. For kernel-level information, we may use Nsight Compute profiler. Refer to the respective documentation for more details:</p> <ul> <li>Nsight System User Guide</li> <li>Nsight Compute Documentation</li> <li>Nsight Compute CLI</li> <li>PyTorch Profiler</li> </ul>"},{"location":"polaris/data-science/profiling_dl/#example-usage","title":"Example Usage","text":"<p>Both the <code>nsys</code> and <code>ncu</code> profiler commands take the following generic structure:</p> <pre><code>nsys profile -o profile python application.py\n</code></pre> <p>If we want to launch the profiled application with MPI, then <code>mpiexec</code> must be used:</p> <pre><code>mpiexec ... nsys profile ... python application.py ... \n</code></pre> <p>These two commands show the basic command-line structure of deploying the profilers. Below we discuss important use cases that are relevant in large-scale distributed profiling.</p> <p>We can use <code>nsys</code> to trace an application running on multiple ranks and multiple nodes. A simple example, where we use a wrapper script to trace the rank 0 on each node of a 2-node job running a PyTorch application, is below:</p> nsys_wrapper.sh<pre><code>#!/bin/bash\n## This wrapper should be used with nsys profiler to trace in any number of nodes\n## The script is set up to trace rank 0 of the first 2 Nodes in the case of\n## profiling a job running on more than 2 nodes.\nFNAME_EXT=$(basename \"$2\")\nFNAME=\"${FNAME_EXT%%.*}\"\n\nNNODES=`wc -l &lt; $PBS_NODEFILE`\n\nWORK_DIR=/path/to/the/Python/application\nDTAG=$(date +%F_%H%M%S)\nPROFILER_OUTDIR=${WORK_DIR}/profiles/choice_of_name_nsys_n${NNODES}_${DTAG}/${FNAME}_n${NNODES}_${DTAG}\nRUN_ID=choice_of_name_nsys_n${NNODES}_${DTAG}\n\nmkdir -p ${PROFILER_OUTDIR}\nNSYS_OPTS=\" -o ${PROFILER_OUTDIR}/${RUN_ID}_%q{PMI_RANK} --stats=true --show-output=true \"\n\nPROFRANK=0\nRANKCUTOFF=8\n\nif [[ $PALS_LOCAL_RANKID -eq $PROFRANK ]] &amp;&amp; [[ $PMI_RANK -lt $RANKCUTOFF ]]; then\n  echo \"On rank ${PMI_RANK}, collecting traces \"\n  nsys profile $NSYS_OPTS \"$@\"\nelse\n  \"$@\"\nfi\n</code></pre> <p>There are a few important things to notice in the wrapper.</p> <ul> <li> <p><code>NSYS_OPTS</code>: These are the options that <code>nsys</code> uses to trace data at different levels. An exhaustive list of options can be found in the nsys user guide. Note that <code>%q{PMI_RANK}</code> is essential to get a per-rank profile.</p> </li> <li> <p><code>PROFRANK</code>: As implemented, this variable is set by the user to trace the rank of choice. For example, this wrapper will trace the rank 0 on each node.</p> </li> <li> <p><code>RANKCUTOFF</code>: This variable is Polaris specific. As we can run as many as 4 ranks per node (without using MPS), the first 2 nodes of a job will have 8 ranks running. This provides the upper cutoff of the label (in number) of ranks, beyond which <code>nsys</code> will not trace any rank. A user can change the number according to the number of maximum ranks running per node to set up how many ranks to be traced. <code>nsys</code> will produce a profile (<code>nsys-rep</code> file, by default) per traced rank.</p> </li> </ul> <p>To view the produced trace files, we need to use NVIDIA's Nsight Systems on the local machine.</p> <p>Getting Started, Download Nsys</p>"},{"location":"polaris/data-science/profiling_dl/#deployment","title":"Deployment","text":"<p>The wrapper above can be deployed using the following PBS job script:</p> pbs_jobscript_nsys.sh<pre><code>#!/bin/bash -l\n#PBS -l select=2:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:05:00\n#PBS -q debug-scaling\n#PBS -l filesystems=home:eagle\n#PBS -A YOUR ALLOCATION\n\n# What's the working directory for the benchmark?\nWORK_DIR=/path/to/the/Python/program\nTEMPORARY_DIR=/path/to/a/temporary/directory/for/`nsys`/to/use\nNSYS_WRAPPER=${WORK_DIR}/nsys_wrapper.sh\n\n# MPI and OpenMP settings\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=4\n\nlet NRANKS=${NNODES}*${NRANKS_PER_NODE}\n\nmodule use /soft/modulefiles/\nmodule load conda/2024-04-29\nconda activate\n\nmpiexec -n ${NRANKS} -ppn ${NRANKS_PER_NODE} --env TMPDIR=${TEMPORARY_DIR} -l --line-buffer \\\n${NSYS_WRAPPER} python ${WORK_DIR}/application.py\n</code></pre> <p>Note that <code>--env TMPDIR=${TEMPORARY_DIR}</code> is essential for <code>nsys</code> to function correctly.</p> <p>We can get kernel-level information (for example, roofline, Tensor Core usage) using NVIDIA's Nsight Compute profiler. Below is a simple wrapper script to show the usage.</p> ncu_wrapper.sh<pre><code>#!/bin/bash\nFNAME_EXT=$(basename \"$2\")\nFNAME=\"${FNAME_EXT%%.*}\"\n\nNNODES=`wc -l &lt; $PBS_NODEFILE`\n\nWORK_DIR=/path/to/the/Python/program\nDTAG=$(date +%F_%H%M%S)\nPROFILER_OUTDIR=${WORK_DIR}/profiles/choice_of_name_ncu_n${NNODES}_${DTAG}/${FNAME}_n${NNODES}_${DTAG}\nRUN_ID=choice_of_name_ncu_n${NNODES}_${DTAG}\n\nmkdir -p ${PROFILER_OUTDIR}\n#KERNEL_NAME=ampere_sgemm_128x128_tn\nKERNEL_NAME=ampere_bf16_s16816gemm_bf16_128x256_ldg8_f2f_stages_64x3_tn\n#NCU_OPTS_DETAILED=\" --set detailed -k ${KERNEL_NAME} -o ${PROFILER_OUTDIR}/${RUN_ID}_%q{PMI_RANK} \"\nNCU_OPTS_ROOFLINE=\" --set roofline -k ${KERNEL_NAME} -o ${PROFILER_OUTDIR}/${RUN_ID}_%q{PMI_RANK} \"\n#NCU_OPTS_FULL=\" --set full -k ${KERNEL_NAME} -o ${PROFILER_OUTDIR}/${RUN_ID}_%q{PMI_RANK} \"\n\nPROFRANK=0\nRANKCUTOFF=8\n\nif [[ $PALS_LOCAL_RANKID -eq $PROFRANK ]] &amp;&amp; [[ $PMI_RANK -lt $RANKCUTOFF ]]; then\n  echo \"On rank ${PMI_RANK}, collecting traces \"\n  ncu $NCU_OPTS_DETAILED \"$@\"\nelse\n  \"$@\"\nfi\n</code></pre> <p>This wrapper can be deployed as the <code>nsys</code> example above. In the <code>ncu</code> wrapper, we explicitly set the name of the kernel that we want to analyze (a GEMM kernel in this case). The exhaustive list of options to set the amount of data collection can be found in the command line section of the documentation. Here we only show standard options; either of the three could be chosen. Note that invoking each option will lead to varying amounts of time the profiler needs to run. This will be important in setting the requested walltime for your batch job.</p> <p><code>ncu</code> will generate <code>ncu-rep</code> files for each traced rank, and we will need NVIDIA's Nsight Compute system on the local machine.</p> <p>Download Nsight Compute</p> <p>The next step is to load the <code>nsys-rep</code> files in the Nsight Systems GUI, and the <code>ncu-rep</code> files to the Nsight Compute GUI.</p>"},{"location":"polaris/data-science/profiling_dl/#single-rank-run","title":"Single Rank Run","text":""},{"location":"polaris/data-science/profiling_dl/#nsys-profiles","title":"<code>nsys</code> profiles","text":"<p>In the single rank case, we go to the top left, go <code>file</code> --&gt; <code>open</code> and select the file that we want to look at. For this particular example, we have focused on the GPU activities. This activity is shown on the second column from the left, named as <code>CUDA HW ...</code>. If we expand the <code>CUDA HW ...</code> tab, we find an <code>NCCL</code> tab. This tab shows the communication library calls.</p>"},{"location":"polaris/data-science/profiling_dl/#ncu-profiles","title":"<code>ncu</code> profiles","text":"<p>The primary qualitative distinction between the <code>nsys-rep</code> files and the <code>ncu-rep</code> files is that the <code>nsys-rep</code> file presents data for the overall execution of the application, whereas the <code>ncu-rep</code> file presents data for the execution of one particular kernel. Our setup here traces only one kernel, but multiple kernels could be traced at a time, but that can become a time-consuming process.</p> <p>We use the <code>--stats=true --show-output=true</code> (see <code>nsys_wrapper.sh</code>) options while collecting the <code>nsys</code> data. As a result, we get a system-wide summary in our <code>.OU</code> files (if run with a job submission script, otherwise on the terminal), and find the names of the kernels that have been called/used for compute and communication. Often we would start with investigating the kernels that have been called the most times or the ones where we spent the most time executing them. In this particular instance, we chose to analyze the <code>gemm</code> kernels, which are related to the matrix multiplication. The full name of this kernel is passed to the <code>ncu</code> profiler with the option <code>-k</code> (see <code>ncu_wrapper.sh</code>).</p> <p>Loading the <code>ncu-rep</code> files works similarly as the <code>nsys-rep</code> files. Here, the important tab is the <code>Details</code> tab. We find that at the 3rd row from the top. Under that tab, we have the <code>GPU Speed of Light Throughput</code> section. In this section, we can find plots showing GPU compute and memory usage. On the right-hand side of the tab, there is a menu bar which gives us the option to select which plot to display, either the roofline plot or the compute-memory throughput chart.</p>"},{"location":"polaris/data-science/profiling_dl/#for-a-multi-rank-run","title":"For a Multi-Rank Run","text":""},{"location":"polaris/data-science/profiling_dl/#nsys-profiles_1","title":"<code>nsys</code> profiles","text":"<p>In the case where we have traced multiple ranks, whether from a single node or multiple nodes, <code>nsys</code> GUI allows us to view the reports in a combined fashion on a single timeline (same time-axis for both reports). This is done through the \"multi-report view\", <code>file</code> --&gt; <code>New multi-report view</code> or <code>file</code> --&gt; <code>Open</code> and selecting however many reports we would like to see in a combined timeline, <code>nsys</code> prompts the user to allow for a \"multi-report view\". These can also be viewed separately.</p>"},{"location":"polaris/data-science/profiling_dl/#profiler-options","title":"Profiler Options","text":"<p>In both cases, <code>nsys</code> and <code>ncu</code>, we have used the standard option sets to generate the profiles. The exhaustive list could be found in the respective documentation pages:</p> <ul> <li>Nsight System User Guide</li> <li>Nsight Compute Documentation</li> <li>Nsight Compute CLI</li> </ul> <p>There is much other information provided through these reports. Here we have discussed the way to view the high-level information.</p>"},{"location":"polaris/data-science/profiling_dl/#pytorch-profiler","title":"PyTorch Profiler","text":"<p>Using the PyTorch profiler requires changes in the application source code. A simple example is the following:</p> pytorch_profiler_example.py<pre><code>from torch.profiler import profile, record_function, ProfilerActivity\n\n# A tracer decorator for a function to be traced\ndef trace_func(func):\n   def wrapper(*args, **kwargs):\n      try:\n         function_name = func.__func__.__qualname__\n      except:\n         function_name = func.__qualname__\n      with record_function(function_name):\n         return func(*args, **kwargs)\n   return wrapper\n\n@trace_func\ndef trace_this_function(a, b, c):\n    ...\n    ...\n    return x, y, z\n\nactivities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]\n\nwith profile(activities=activities, record_shapes=True) as prof:\n    result = trace_this_function(a, b, c)\nprof.export_chrome_trace(f\"{/path/to/the/trace/dir}/{name/of/the/trace}-{rank}-of-{world_size}.json\")\n</code></pre> <p>The procedure described above works for both single and multi-rank deployments.</p>"},{"location":"polaris/data-science/python/","title":"Python","text":"<p>We provide prebuilt <code>conda</code> environments containing GPU-supported builds of <code>torch</code>, <code>tensorflow</code> (both with <code>horovod</code> support for multi-node calculations), <code>jax</code>, and many other commonly-used Python modules.</p> <p>Users can activate this environment by first loading the <code>conda</code> module and then activating the base environment.</p> <p>Explicitly (either from an interactive job or inside a job script):</p> <pre><code>module use /soft/modulefiles; module load conda; conda activate base\n</code></pre> <p>This will load and activate the base environment.</p> <p>Tip</p> <p>We encourage users to use the pre-installed conda environment. Any custom environments are supported on a best-effort basis only.</p> <p>For Python issues or questions, please see the Technical Support page.</p>"},{"location":"polaris/data-science/python/#virtual-environments-via-venv","title":"Virtual environments via <code>venv</code>","text":"<p>To install additional packages that are missing from the <code>base</code> environment, we can build a <code>venv</code> on top of it.</p> <p>Conda <code>base</code> environment + <code>venv</code></p> <p>If you need a package that is not already installed in the <code>base</code> environment, this is generally the recommended approach.</p> <p>We can create a <code>venv</code> on top of the base Anaconda environment (with <code>--system-site-packages</code> to inherit the <code>base</code> packages):</p> <pre><code>module use /soft/modulefiles; module load conda; conda activate base\nCONDA_NAME=$(echo ${CONDA_PREFIX} | tr '\\/' '\\t' | sed -E 's/mconda3|\\/base//g' | awk '{print $NF}')\nVENV_DIR=\"$(pwd)/venvs/${CONDA_NAME}\"\nmkdir -p \"${VENV_DIR}\"\npython -m venv \"${VENV_DIR}\" --system-site-packages\nsource \"${VENV_DIR}/bin/activate\"\n</code></pre> <p>You can always retroactively change the <code>--system-site-packages</code> flag state for this virtual environment by editing <code>${VENV_DIR}/pyvenv.cfg</code> and changing the value of the line <code>include-system-site-packages=false</code>.</p> <p>To install a different version of a package that is already installed in the base environment, you can use:</p> <pre><code>python3 -m pip install --ignore-installed &lt;package&gt; # or -I\n</code></pre> <p>The shared base environment is not writable, so it is impossible to remove or uninstall packages from it. The packages installed with the above <code>pip</code> command should shadow those installed in the base environment.</p>"},{"location":"polaris/data-science/python/#cloning-the-base-anaconda-environment","title":"Cloning the base Anaconda environment","text":"<p>Warning</p> <p>This approach is generally not recommended as it can be quite slow and can use significant storage space.</p> <p>If you need more flexibility, you can clone the conda environment into a custom path, which would then allow for root-like installations via <code>conda install &lt;module&gt;</code> or <code>pip install &lt;module&gt;</code>.</p> <p>Unlike the <code>venv</code> approach, using a cloned Anaconda environment requires you to copy the entirety of the base environment, which can use significant storage space.</p> <p>To clone the <code>base</code> environment:</p> <pre><code>module load conda; conda activate base\nconda create --clone base --prefix /path/to/envs/base-clone\nconda activate /path/to/envs/base-clone\n</code></pre> <p>where <code>/path/to/envs/base-clone</code> should be replaced by a suitable path. The cloning process can be quite slow.</p>"},{"location":"polaris/data-science/python/#using-pip-install-user","title":"Using <code>pip install --user</code>","text":"<p>Danger</p> <p>This is typically not recommended.</p> <p>With the conda environment setup, one can install common Python modules using <code>python3 -m pip install --user '&lt;module-name&gt;'</code>, which will install packages in <code>$PYTHONUSERBASE/lib/pythonX.Y/site-packages</code>.</p> <p>The <code>$PYTHONUSERBASE</code> environment variable is automatically set when you load the base conda module and is equal to <code>/home/$USER/.local/polaris/conda/YYYY-MM-DD</code>.</p> <p>Note, Python modules installed this way that contain command line binaries will not have those binaries automatically added to the shell's <code>$PATH</code>. To manually add the path:</p> <pre><code>export PATH=\"$PYTHONUSERBASE/bin:$PATH\"\n</code></pre> <p>Be sure to remove this location from <code>$PATH</code> if you deactivate the base Anaconda environment or unload the module.</p> <p>Cloning the Anaconda environment or using <code>venv</code> are both more flexible and transparent when compared to <code>--user</code> installs.</p>"},{"location":"polaris/data-science/python/#existing-issue-and-solution","title":"Existing issue and solution","text":"<p>There is an issue with the current conda environment. One may encounter the following error message:</p> <pre><code>aborting job:\nMPIDI_CRAY_init: GPU_SUPPORT_ENABLED is requested, but GTL library is not linked\n</code></pre> <p>To address this, please add the following line at the very beginning of your Python script.</p> <pre><code>from mpi4py import MPI\n</code></pre>"},{"location":"polaris/data-science/python/#creating-a-jupyter-kernel","title":"Creating a Jupyter Kernel","text":"<p>If you need to use your Python <code>venv</code> on JupyterHub, you will need to create a custom Jupyter kernel for it.</p>"},{"location":"polaris/data-science/applications/gpt-neox/","title":"Instructions for <code>gpt-neox</code>:","text":"<p>We include below a set of instructions to get <code>EleutherAI/gpt-neox</code> running on Polaris.</p> <p>A batch submission script for the following example is available here.</p> <p>Warning</p> <p>The instructions below should be run directly from a compute node.</p> <p>Explicitly, to request an interactive job (from <code>polaris-login</code>): <pre><code>$ qsub -A &lt;project&gt; -q debug-scaling -l select=2 -l walltime=01:00:00\n</code></pre></p> <p>Refer to job scheduling and execution for additional information.</p> <ol> <li> <p>Load and activate the base <code>conda</code> environment:    <pre><code>module load conda\nconda activate base\n</code></pre></p> </li> <li> <p>We've installed the requirements for running <code>gpt-neox</code> into a virtual environment. To activate this environment:    <pre><code>source /soft/datascience/venvs/polaris/2022-09-08/bin/activate\n</code></pre></p> </li> <li> <p>Clone the <code>EleutherAI/gpt-neox</code> repository if it doesn't already exist:    <pre><code>git clone https://github.com/EleutherAI/gpt-neox\n</code></pre></p> </li> <li> <p>Navigate into the <code>gpt-neox</code> directory:    <pre><code>cd gpt-neox\n</code></pre></p> <p>Note</p> <p>The remaining instructions assume you're inside the <code>gpt-neox</code> directory.</p> </li> <li> <p>Create a DeepSpeed compliant <code>hostfile</code> (each line is formatted as <code>hostname, slots=N</code>):    <pre><code>cat $PBS_NODEFILE &gt; hostfile\nsed -e 's/$/ slots=4/' -i hostfile\nexport DLTS_HOSTFILE=hostfile \n</code></pre></p> </li> <li> <p>Create a <code>.deepspeed_env</code> file to ensure a consistent environment across all workers:    <pre><code>echo \"PATH=${PATH}\" &gt; .deepspeed_env\necho \"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\" &gt;&gt; .deepspeed_env\necho \"http_proxy=${http_proxy}\" &gt;&gt; .deepspeed_env\necho \"https_proxy=${https_proxy}\" &gt;&gt; .deepspeed_env\n</code></pre></p> </li> <li> <p>Prepare data:    <pre><code>python3 prepare_data.py -d ./data\n</code></pre></p> </li> <li> <p>Train:    <pre><code>python3 ./deepy.py train.py -d configs small.yml local_setup.yml\n</code></pre></p> </li> </ol> <p>Danger</p> <p>If your training seems to be getting stuck at</p> <pre><code>Using /home/user/.cache/torch_extensions as PyTorch extensions root...\n</code></pre> <p>there may be a leftover <code>.lock</code> file from an aborted build. Cleaning either the whole <code>.cache</code> or the extensions' sub-directory should force a clean build on the next attempt.</p>"},{"location":"polaris/data-science/applications/megatron-deepspeed/","title":"Megatron-DeepSpeed","text":"<p>We describe below the instructions for launching distributed training with Microsoft's Megatron-DeepSpeed and briefly describe some parallelism strategies and various optimizations that are supported.</p> <p>Note</p> <p>We maintain a forked version at <code>argonne-lcf/Megatron-DeepSpeed</code> that has some helper scripts for launching and setting various training options.</p>"},{"location":"polaris/data-science/applications/megatron-deepspeed/#setup","title":"Setup","text":"<ol> <li> <p>Load <code>conda</code> and activate the base environment:</p> <pre><code># load conda + activate base env\nmodule load conda/2023-10-04 ; conda activate base\n</code></pre> </li> <li> <p>Clone    <code>argonne-lcf/Megatron-DeepSpeed</code>    and navigate into it:</p> <pre><code># clone + navigate into Megatron-DeepSpeed repo\ngit clone https://github.com/argonne-lcf/Megatron-DeepSpeed\ncd Megatron-DeepSpeed\n</code></pre> </li> <li> <p>Make a virtual environment (on top of base conda):</p> <pre><code># make virtual environment (on top of base conda)\nmkdir -p venvs/polaris/2023-10-04\npython3 -m venv venvs/polaris/2023-10-04 --system-site-packages\nsource venvs/polaris/2023-10-04/bin/activate\n</code></pre> </li> <li> <p>Install the missing dependency:</p> <pre><code># install missing dependency\npython3 -m pip install \"git+https://github.com/saforem2/ezpz\"\n</code></pre> </li> <li> <p>Launch training:</p> <pre><code># ---- launch training -----------------------\n# - MODEL_SIZE_KEY: defined in ALCF/model.sh\n# - other args: defined in ALCF/args.sh\n# ---------------------------------------------\nMODEL_SIZE_KEY=\"GPT25B\" \\\n    SEQ_LEN=4096 \\\n    USE_FLASH_ATTN_V2=1 \\\n    MICRO_BATCH=1 \\\n    GAS=1 \\\n    SP_TYPE=\"megatron\" \\\n    ZERO_STAGE=1 \\\n    ./ALCF/train-gpt3.sh\n</code></pre> </li> </ol>"},{"location":"polaris/data-science/applications/megatron-deepspeed/#helper-scripts","title":"Helper Scripts","text":"<p><code>ALCF/train-gpt3.sh</code></p> <p>:   Main entry point for training. This script will automatically source the rest of the required ALCF/*.sh scripts below.</p> <p><code>ALCF/model.sh</code></p> <p>:   Contains some example model architectures for GPT3-style models.</p> <p><code>ALCF/args.sh</code></p> <p>:   Logic for parsing and setting up runtime options for Megatron and DeepSpeed.</p> <p><code>ALCF/setup.sh</code></p> <p>:   Locate and activate the virtual environment to be used, ensuring MPI variables are set properly.</p> <p><code>ALCF/launch.sh</code></p> <p>:   Identify available resources and build the command to be run, i.e., figure out how many: <code>{nodes, GPUs per node, GPUs total}</code>, to pass to <code>mpi{run,exec}</code> then, use this to build <code>mpiexec &lt;mpiexec-args&gt; python3 pretrain_gpt.py</code>.</p>"},{"location":"polaris/data-science/frameworks/deepspeed/","title":"DeepSpeed","text":"<p>The base <code>conda</code> environment on Polaris comes with Microsoft's DeepSpeed pre-installed. Instructions for using/cloning the base environment can be found here.</p> <p>A batch submission script for the following example is available here.</p> <p>We describe below the steps needed to get started with DeepSpeed on Polaris.</p> <p>We focus on the <code>cifar</code> example provided in the DeepSpeedExamples repository, though this approach should be generally applicable for running any model with DeepSpeed support.</p>"},{"location":"polaris/data-science/frameworks/deepspeed/#running-deepspeed-on-polaris","title":"Running DeepSpeed on Polaris","text":"<p>Note</p> <p>The instructions below should be run directly from a compute node.</p> <p>Explicitly, to request an interactive job (from <code>polaris-login</code>): <pre><code>qsub -A &lt;project&gt; -q debug-scaling -l select=2 -l walltime=01:00:00 -I\n</code></pre></p> <p>Refer to job scheduling and execution for additional information.</p> <ol> <li> <p>Load <code>conda</code> module and activate base environment:</p> <pre><code>module load conda ; conda activate base\n</code></pre> </li> <li> <p>Clone microsoft/DeepSpeedExamples and navigate into the directory:</p> <pre><code>git clone https://github.com/microsoft/DeepSpeedExamples.git\ncd DeepSpeedExamples/cifar\n</code></pre> </li> </ol> <p>Launching DeepSpeed</p> Launching with MPICHLaunching with DeepSpeed <ol> <li> <p>Get the total number of available GPUs:</p> <ol> <li>Count the number of lines in <code>$PBS_NODEFILE</code> (1 host per line)</li> <li>Count the number of GPUs available on the current host</li> <li><code>NGPUS=\"$((${NHOSTS}*${NGPU_PER_HOST}))\"</code> <pre><code>NHOSTS=$(wc -l &lt; \"${PBS_NODEFILE}\")\nNGPU_PER_HOST=$(nvidia-smi -L | wc -l)\nNGPUS=\"$((${NHOSTS}*${NGPU_PER_HOST}))\"\n</code></pre></li> </ol> </li> <li> <p>Launch with <code>mpiexec</code>: <pre><code>mpiexec \\\n  --verbose \\\n  --envall \\\n  -n \"${NGPUS}\" \\\n  --ppn \"${NGPU_PER_HOST}\" \\\n  --hostfile=\"${PBS_NODEFILE}\" \\\n  python3 \\\n    cifar10_deepspeed.py \\\n    --deepspeed_config ds_config.json\n</code></pre></p> </li> </ol> <ol> <li> <p>Create a DeepSpeed compliant <code>hostfile</code>, specifying the <code>hostname</code> and number of GPUs (<code>slots</code>) for each of our available workers: <pre><code>cat $PBS_NODEFILE &gt; hostfile\nsed -e 's/$/ slots=4/' -i hostfile\n</code></pre></p> </li> <li> <p>Create a <code>.deepspeed_env</code> containing the environment variables our workers will need access to: <pre><code>echo \"PATH=${PATH}\" &gt;&gt; .deepspeed_env\necho \"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\" &gt;&gt; .deepspeed_env\necho \"http_proxy=${http_proxy}\" &gt;&gt; .deepspeed_env\necho \"https_proxy=${https_proxy}\" &gt;&gt; .deepspeed_env\n</code></pre></p> </li> </ol> <p>Warning</p> <p>The <code>.deepspeed_env</code> file expects each line to be of the form <code>KEY=VALUE</code>. Each of these will then be set as environment variables on each available worker specified in our <code>hostfile</code>.</p> <p>We can then run the <code>cifar10_deepspeed.py</code> module using DeepSpeed: <pre><code>deepspeed --hostfile=hostfile cifar10_deepspeed.py \\\n    --deepspeed \\\n    --deepspeed_config ds_config.json\n</code></pre></p> <code>AssertionError: Micro batch size per gpu: 0 has to be greater than 0</code> <p>Depending on the details of your specific job, it may be necessary to modify the provided <code>ds_config.json</code>.</p> <p>If you encounter an error: <pre><code>x3202c0s31b0n0: AssertionError: Micro batch size per gpu: 0 has to be greater than 0\n</code></pre> you can modify the <code>\"train_batch_size\": 16</code> variable in the provided <code>ds_config.json</code> to the (total) number of available GPUs, and explicitly set <code>\"gradient_accumulation_steps\": 1</code>, as shown below. <pre><code>$ export NHOSTS=$(wc -l &lt; \"${PBS_NODEFILE}\")\n$ export NGPU_PER_HOST=$(nvidia-smi -L | wc -l)\n$ export NGPUS=\"$((${NHOSTS}*${NGPU_PER_HOST}))\"\n$ echo $NHOSTS $NGPU_PER_HOST $NGPUS\n24 4 96\n$ # replace \"train_batch_size\" with $NGPUS in ds_config.json\n$ # and write to `ds_config-polaris.json`\n$ sed \\\n    \"s/$(cat ds_config.json| grep batch | cut -d ':' -f 2)/ ${NGPUS},/\" \\\n    ds_config.json \\\n    &gt; ds_config-polaris.json\n$ cat ds_config-polaris.json\n{\n    \"train_batch_size\": 96,\n    \"gradient_accumulation_steps\": 1,\n    ...\n}\n</code></pre></p>"},{"location":"polaris/data-science/frameworks/gpytorch/","title":"GPyTorch on Polaris","text":""},{"location":"polaris/data-science/frameworks/gpytorch/#1-login-and-queue-a-job","title":"1. Login and queue a job","text":"<p>Login to Polaris <pre><code>ssh alcfusername@polaris.alcf.anl.gov\n</code></pre></p> <p>Note</p> <p>The instructions below should be run directly from a compute node.</p> <p>Explicitly, to request an interactive job (from <code>polaris-login</code>): <pre><code>qsub -A &lt;project&gt; -q debug-scaling -l select=2 -l walltime=01:00:00 -I\n</code></pre></p> <p>Refer to job scheduling and execution for additional information.</p>"},{"location":"polaris/data-science/frameworks/gpytorch/#2-load-modules","title":"2. Load Modules","text":"<p>Load the Anaconda environment module, which contains a PyTorch installation, since GPyTorch has PyTorch as a dependency: <pre><code>module use /soft/modulefiles\nmodule load conda\nconda activate\n</code></pre> * Notice that we can check the available modules with \"module avail\" and check the loaded modules with \"module list.\"</p> <p>Create a virtual environment with Python and activate it: <pre><code>python -m venv --system-site-packages path_to_myenv\nsource path_to_myenv/bin/activate\n</code></pre> Now the bash prompt should show that we're in the environment we just created, and we're good to use pip install: <pre><code>pip install gpytorch==version\n</code></pre></p>"},{"location":"polaris/data-science/frameworks/gpytorch/#loading-environment-in-future-sessions","title":"Loading environment in future sessions","text":"<p>After the first time, to run the files, simply activate the Python virtual environment on a compute node with: <pre><code>module use /soft/modulefiles\nmodule load conda\nsource path_to_myenv/bin/activate\n</code></pre></p>"},{"location":"polaris/data-science/frameworks/gpytorch/#3-using-jupyter-notebook-to-run-gpytorch-on-polaris","title":"3. Using Jupyter Notebook to Run GPyTorch on Polaris","text":"<p>Here is the guide:</p>"},{"location":"polaris/data-science/frameworks/gpytorch/#approach-1-use-alcf-jupyterhub","title":"Approach 1 - Use ALCF JupyterHub","text":"<ol> <li>Go to Jupyter Hub of ALCF, click Login Polaris.</li> <li>Queue up on a debug node.</li> </ol> <p>For the first time only, one needs to set up the environment and kernel by following these extra steps:</p> <ol> <li>Once Jupyter Notebook is launched on a compute node, click \"New\" and open a terminal.</li> <li>Run: <pre><code>module use /soft/modulefiles\nmodule load conda\nconda activate\nsource &lt;path_to_previously_created_python_venv&gt;/bin/activate\npython -m ipykernel install --user --name python_venv\n</code></pre> Note: Depending on the system and environment, you might need to install the \"ipykernel\" package first. The <code>python_venv</code> that I just created has the <code>ipykernel</code> module.</li> </ol> <p>Go back to your <code>.ipynb</code> file, change the kernel to <code>python_venv</code> from the dropdown menu, and we'll be good to run GPyTorch!</p>"},{"location":"polaris/data-science/frameworks/gpytorch/#approach-2-use-ssh-tunnel","title":"Approach 2 - Use SSH Tunnel","text":"<p>To use an SSH tunnel, we first need to be in an interactive session on a compute node. See Part 1, \"Login and queue a job\" for more details on this.</p> <p>On a compute node, follow these steps: 1. On the compute node terminal, do: <pre><code>module use /soft/modulefiles\nmodule load conda\nconda activate\njupyter notebook\n</code></pre> You should see a line like <code>http://localhost:XXXX/</code>, where <code>XXXX</code> is the port number that Jupyter Notebook is launched on the compute node, usually the default 8888. If it is not 8888, replace 8888 in the following with your port number.</p> <ol> <li>Then, on a new, local terminal, do: <pre><code>export PORT_NUM=8889\nssh -L $PORT_NUM:localhost:8888 &lt;yourusername@polaris.alcf.anl.gov&gt;\nssh -L 8888:localhost:8888 your_compute_node\nnavigate to localhost:8889 in your browser\n</code></pre></li> </ol> <p>You should see a Jupyter Notebook. Notice that for the first time doing this, one might need to input some password or key. Just follow the directions on that page.</p> <p>(Essentially, the above steps, using SSH, set the local port 8889 to listen to the allocated compute node port 8888 where we initiated a Jupyter Notebook.)</p> <p>For the first time only, one needs to set up the environment and kernel by following these extra steps:</p> <p>Click \"New\" and open a terminal, and run: <pre><code>module use /soft/modulefiles\nmodule load conda\nconda activate\nsource &lt;path_to_previously_created_python_venv&gt;/bin/activate\npython -m ipykernel install --user --name python_venv\n</code></pre> Note: Depending on the system and environment, you might need to install the \"ipykernel\" package first. The <code>python_venv</code> that I just created has the <code>ipykernel</code> module.</p> <p>Go back to your <code>.ipynb</code> file, change the kernel to <code>python_venv</code> from the dropdown menu, and we'll be good to run GPyTorch!</p>"},{"location":"polaris/data-science/frameworks/jax/","title":"JAX","text":"<p>JAX is another popular Python package for accelerated computing. JAX is built on XLA (the same XLA TensorFlow uses) as well as AutoGrad, and additionally has acceleration tools that operate on functions such as <code>vmap</code>, <code>jit</code>, etc. JAX is not as widespread in machine learning as TensorFlow and PyTorch for traditional models (Computer Vision, Language Models), though it is quickly gaining prominence. JAX is very powerful when a program needs non-traditional autodifferentiation or vectorization, such as forward-mode AD, higher-order derivatives, Jacobians, Hessians, or any combination of the above. Users of JAX on Polaris are encouraged to read the user documentation in detail, particularly the details about pure-functional programming, no in-place operations, and the common mistakes in writing functions for the <code>@jit</code> decorator.</p>"},{"location":"polaris/data-science/frameworks/jax/#jax-on-polaris","title":"JAX on Polaris","text":"<p>JAX is installed on Polaris via the <code>jax</code> module, available with: <pre><code>module use /soft/modulefiles; module load jax\n</code></pre></p> <p>Then, you can load JAX in <code>python</code> as usual (below showing results from the <code>conda/2024-04-29</code> module):</p> <pre><code>&gt;&gt;&gt; import jax\n&gt;&gt;&gt; jax.__version__\n'0.4.26'\n&gt;&gt;&gt;\n</code></pre>"},{"location":"polaris/data-science/frameworks/jax/#notes-on-jax-0426","title":"Notes on JAX 0.4.26","text":"<p>On Polaris, due to a bug, an environment variable must be set to use JAX on GPUs. The following code will crash: <pre><code>import jax.numpy as numpy\na = numpy.zeros(1000)\n</code></pre> outputting an error that looks like: <pre><code>jaxlib.xla_extension.XlaRuntimeError: UNKNOWN: no kernel image is available for execution on the device\n</code></pre></p> <p>You can fix this by setting an environment variable: <pre><code>export XLA_FLAGS=\"--xla_gpu_force_compilation_parallelism=1\"\n</code></pre></p>"},{"location":"polaris/data-science/frameworks/jax/#scaling-jax-to-multiple-gpus-and-multiple-nodes","title":"Scaling JAX to multiple GPUs and multiple Nodes","text":"<p>JAX has intrinsic scaling tools to use multiple GPUs on a single node, via the <code>pmap</code> function. If this is sufficient for your needs, excellent. If not, another alternative is to use the newer package mpi4jax.</p> <p>mpi4jax is a relatively new project and requires setting some environment variables for good performance and usability: - Set <code>MPI4JAX_USE_CUDA_MPI=1</code> to use CUDA-Aware MPI, supported in the <code>conda</code> module, to do operations directly from the GPU. - Set <code>MPICH_GPU_SUPPORT_ENABLED=1</code> to use CUDA-Aware MPI.</p> <p>The following code, based on a test script from the mpi4jax repository, can help you verify you are using mpi4jax properly:</p> <pre><code>import os\nfrom mpi4py import MPI\nimport jax\nimport jax.numpy as jnp\nimport mpi4jax\n\ncomm = MPI.COMM_WORLD\nrank = comm.Get_rank()\nlocal_rank = int(os.environ[\"PMI_LOCAL_RANK\"])\n\navailable_devices = jax.devices(\"gpu\")\nif len(available_devices) &lt;= local_rank:\n    raise Exception(\"Could not find enough GPUs\")\n\ntarget_device = available_devices[local_rank]\n\n\n@jax.jit\ndef foo(arr):\n    arr = arr + rank\n    arr_sum, _ = mpi4jax.allreduce(arr, op=MPI.SUM, comm=comm)\n    return arr_sum\n\nwith jax.default_device(target_device):\n    a = jnp.zeros((3, 3))\n    print(f\"Rank {rank}, local rank {local_rank}, a.device is {a.device()}\")\n    result = foo(a)\n    print(f\"Rank {rank}, local rank {local_rank}, result.device is {result.device()}\")\n\n    import time\n    print(\"Sleeping for 5 seconds if you want to look at nvidia-smi ... \")\n    time.sleep(5)\n    print(\"Done sleeping\")\n\nif rank == 0:\n    print(result)\n</code></pre> <p>JAX and mpi4jax are both still somewhat early in their software lifecycles. Updates are frequent, and if you require assistance please contact support@alcf.anl.gov.</p>"},{"location":"polaris/data-science/frameworks/libtorch/","title":"LibTorch C++ Library","text":"<p>LibTorch is a C++ library for Torch, with many of the APIs that are available in PyTorch. Users can find more information in the PyTorch documentation. This is useful for integrating the Torch ML framework into traditional HPC simulation codes and therefore enables training and inference of ML models. During compilation, Intel optimizations will be activated automatically once the IPEX dynamic library is linked.</p>"},{"location":"polaris/data-science/frameworks/libtorch/#environment-setup","title":"Environment Setup","text":"<p>To use LibTorch on Polaris, load the ML frameworks module: <pre><code>module use /soft/modulefiles\nmodule load conda/2024-04-29\nconda activate\n</code></pre> This will also load <code>PrgEnv-gnu/8.5.0</code> and <code>cmake</code>.</p>"},{"location":"polaris/data-science/frameworks/libtorch/#torch-libraries","title":"Torch Libraries","text":"<p>With the ML frameworks module loaded as shown above, run: <pre><code>python -c 'import torch; print(torch.__path__[0])'\npython -c 'import torch; print(torch.utils.cmake_prefix_path)'\n</code></pre> to find the path to the Torch libraries, include files, and CMake files.</p>"},{"location":"polaris/data-science/frameworks/libtorch/#linking-the-torch-libraries","title":"Linking the Torch Libraries","text":"<p>When using the CMake build system, the LibTorch libraries can be linked to an example C++ application using the following <code>CMakeLists.txt</code> file: <pre><code>cmake_minimum_required(VERSION 3.5 FATAL_ERROR)\ncmake_policy(SET CMP0074 NEW)\nproject(project-name)\n\nfind_package(Torch REQUIRED)\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${TORCH_CXX_FLAGS} -Wl,--no-as-needed\")\nset(TORCH_LIBS ${TORCH_LIBRARIES})\n\nadd_executable(exe main.cpp)\ntarget_link_libraries(exe ${TORCH_LIBS})\n\nset_property(TARGET exe PROPERTY CXX_STANDARD 17)\n</code></pre></p> <p>and configuring the build with: <pre><code>cmake \\\n    -DCMAKE_PREFIX_PATH=`python -c 'import torch; print(torch.utils.cmake_prefix_path)'` \\\n    ./\nmake\n</code></pre></p>"},{"location":"polaris/data-science/frameworks/libtorch/#device-introspection","title":"Device Introspection","text":"<p>Similar to PyTorch, LibTorch provides APIs to perform introspection on the devices available on the system. The simple code below shows how to check if CUDA devices are available, how many are present, and how to loop through them to discover some properties.</p> <pre><code>#include &lt;torch/torch.h&gt;\n\nint main(int argc, const char* argv[])\n{\n  torch::DeviceType device;\n  int num_devices = 0;\n  if (torch::cuda::is_available()) {\n    std::cout &lt;&lt; \"CUDA devices detected\" &lt;&lt; std::endl;\n    device = torch::kCUDA;\n\n    num_devices = torch::cuda::device_count();\n    std::cout &lt;&lt; \"Number of CUDA devices: \" &lt;&lt; num_devices &lt;&lt; std::endl;\n  } else {\n    device = torch::kCPU;\n    std::cout &lt;&lt; \"No CUDA devices detected, setting device to CPU\" &lt;&lt; std::endl;\n  }\n\n  return 0;\n}\n</code></pre>"},{"location":"polaris/data-science/frameworks/libtorch/#model-inferencing-using-the-torch-api","title":"Model Inferencing Using the Torch API","text":"<p>This example shows how to perform inference with the ResNet50 model using LibTorch. First, get a JIT-traced version of the model by executing <code>python resnet50_trace.py</code> (shown below) on a compute node. <pre><code>import torch\nimport torchvision\nfrom time import perf_counter\n\ndevice = 'cuda'\n\nmodel = torchvision.models.resnet50()\nmodel.to(device)\nmodel.eval()\n\ndummy_input = torch.rand(1, 3, 224, 224).to(device)\n\nmodel_jit = torch.jit.trace(model, dummy_input)\ntic = perf_counter()\npredictions = model_jit(dummy_input)\ntoc = perf_counter()\nprint(f\"Inference time: {toc-tic}\")\n\ntorch.jit.save(model_jit, f\"resnet50_jit.pt\")\n</code></pre></p> <p>Then, build <code>inference-example.cpp</code> (shown below): <pre><code>#include &lt;torch/torch.h&gt;\n#include &lt;torch/script.h&gt;\n\nint main(int argc, const char* argv[]) {\n  torch::jit::script::Module model;\n  try {\n    model = torch::jit::load(argv[1]);\n    std::cout &lt;&lt; \"Loaded the model\\n\";\n  }\n  catch (const c10::Error&amp; e) {\n    std::cerr &lt;&lt; \"Error loading the model\\n\";\n    return -1;\n  }\n\n  model.to(torch::Device(torch::kCUDA));\n  std::cout &lt;&lt; \"Model offloaded to GPU\\n\\n\";\n\n  auto options = torch::TensorOptions()\n                      .dtype(torch::kFloat32)\n                      .device(torch::kCUDA);\n  torch::Tensor input_tensor = torch::rand({1,3,224,224}, options);\n  assert(input_tensor.dtype() == torch::kFloat32);\n  assert(input_tensor.device().type() == torch::kCUDA);\n  std::cout &lt;&lt; \"Created the input tensor on GPU\\n\";\n\n  torch::Tensor output = model.forward({input_tensor}).toTensor();\n  std::cout &lt;&lt; \"Performed inference\\n\\n\";\n\n  std::cout &lt;&lt; \"Slice of predicted tensor is : \\n\";\n  std::cout &lt;&lt; output.slice(/*dim=*/1, /*start=*/0, /*end=*/10) &lt;&lt; '\\n';\n\n  return 0;\n}\n</code></pre></p> <p>and execute it with <code>./inference-example ./resnet50_jit.pt</code>.</p>"},{"location":"polaris/data-science/frameworks/pytorch/","title":"PyTorch on Polaris","text":"<p>PyTorch is a popular, open-source deep learning framework developed and released by Facebook. The PyTorch home page has more information about PyTorch, which you can refer to. For troubleshooting on Polaris, please contact support@alcf.anl.gov.</p>"},{"location":"polaris/data-science/frameworks/pytorch/#installation-on-polaris","title":"Installation on Polaris","text":"<p>PyTorch is installed on Polaris already, available in the <code>conda</code> module. To use it from a compute node, please do:</p> <pre><code>module use /soft/modulefiles\nmodule load conda\nconda activate\n</code></pre> <p>Then, you can load PyTorch in <code>python</code> as usual (below showing results from the <code>conda/2024-04-29</code> module):</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; torch.__version__\n'2.3.0'\n&gt;&gt;&gt;\n</code></pre> <p>This installation of PyTorch was built from source, and the CUDA libraries it uses are found via the <code>CUDA_HOME</code> environment variable (below showing results from the <code>conda/2024-04-29</code> module):</p> <pre><code>$ echo $CUDA_HOME\n/soft/compilers/cudatoolkit/cuda-12.4.1/\n</code></pre> <p>If you need to build applications that use this version of PyTorch and CUDA, we recommend using these CUDA libraries to ensure compatibility. We periodically update the PyTorch release, though updates will come in the form of new versions of the <code>conda</code> module.</p> <p>PyTorch is also available through NVIDIA containers that have been translated to Apptainer containers. For more information about containers, please see the containers documentation page.</p>"},{"location":"polaris/data-science/frameworks/pytorch/#pytorch-best-practices-on-polaris","title":"PyTorch Best Practices on Polaris","text":""},{"location":"polaris/data-science/frameworks/pytorch/#single-node-performance","title":"Single Node Performance","text":"<p>When running PyTorch applications, we have found the following practices to be generally, if not universally, useful and encourage you to try some of these techniques to boost the performance of your own applications.</p> <ol> <li> <p>Use Reduced Precision. Reduced Precision is available on A100 via tensor cores and is supported with PyTorch operations. In general, the way to do this is via the PyTorch Automatic Mixed Precision package (AMP), as described in the mixed precision documentation. In PyTorch, users generally need to manage casting and loss scaling manually, though context managers and function decorators can provide easy tools to do this.</p> </li> <li> <p>PyTorch has a <code>JIT</code> module as well as backends to support op fusion, similar to TensorFlow's <code>tf.function</code> tools. However, PyTorch JIT capabilities are newer and may not yield performance improvements. Please see TorchScript for more information.</p> </li> </ol>"},{"location":"polaris/data-science/frameworks/pytorch/#multi-gpu-multi-node-scale-up","title":"Multi-GPU / Multi-Node Scale up","text":"<p>PyTorch is compatible with scaling up to multiple GPUs per node, and across multiple nodes. Good scaling performance has been seen up to the entire Polaris system, &gt; 2048 GPUs. Good performance with PyTorch has been seen with both DDP and Horovod. For details, please see the Horovod documentation or the Distributed Data Parallel documentation. Some Polaris-specific details that may be helpful to you:</p> <ol> <li> <p>CPU affinity can improve performance, particularly for data loading processes. In particular, we encourage users to try their scaling measurements by manually setting the CPU affinity via mpiexec, such as with <code>--cpu-bind verbose,list:0,8,16,24</code> or <code>--cpu-bind depth -d 16</code>.</p> </li> <li> <p>NCCL settings:  We have done extensive performance tests and identified the following best environment setup.</p> </li> </ol> <p><pre><code>export NCCL_NET_GDR_LEVEL=PHB\nexport NCCL_CROSS_NIC=1\nexport NCCL_COLLNET_ENABLE=1\nexport NCCL_NET=\"AWS Libfabric\"\nexport LD_LIBRARY_PATH=/soft/libraries/aws-ofi-nccl/v1.9.1-aws/lib:$LD_LIBRARY_PATH\nexport LD_LIBRARY_PATH=/soft/libraries/hwloc/lib/:$LD_LIBRARY_PATH\nexport FI_CXI_DISABLE_HOST_REGISTER=1\nexport FI_MR_CACHE_MONITOR=userfaultfd\nexport FI_CXI_DEFAULT_CQ_SIZE=131072\n</code></pre> The key here is to enable the AWS plugin (https://github.com/aws/aws-ofi-nccl). AWS OFI NCCL is a plugin that enables EC2 developers to use libfabric as a network provider while running NVIDIA's NCCL-based applications.</p> <p>This setup can lead to a 2-3x performance improvement for some communication workloads. For details, please refer to: https://github.com/argonne-lcf/alcf-nccl-tests.</p> <p>Warning</p> <p>For some applications such as Megatron-DeepSpeed, enabling the AWS plugin will cause a hang or NCCL timeout issue. If so, please disable it by: <pre><code>unset NCCL_NET_GDR_LEVEL NCCL_CROSS_NIC NCCL_COLLNET_ENABLE NCCL_NET\n</code></pre></p> <ol> <li>CUDA device setting: it works best when you limit the visible devices to only one GPU. Note that if you import <code>mpi4py</code> or <code>horovod</code>, and then do something like <code>os.environ[\"CUDA_VISIBLE_DEVICES\"] = hvd.local_rank()</code>, it may not actually work! You must set the <code>CUDA_VISIBLE_DEVICES</code> environment variable prior to doing <code>MPI.COMM_WORLD.init()</code>, which is done in <code>horovod.init()</code> as well as implicitly in <code>from mpi4py import MPI</code>. On Polaris specifically, you can use the environment variable <code>PMI_LOCAL_RANK</code> (as well as <code>PMI_LOCAL_SIZE</code>) to learn information about the node-local MPI ranks.  </li> </ol>"},{"location":"polaris/data-science/frameworks/pytorch/#deepspeed","title":"DeepSpeed","text":"<p>DeepSpeed is also available and usable on Polaris. For more information, please see the DeepSpeed documentation directly.</p>"},{"location":"polaris/data-science/frameworks/pytorch/#pytorch-dataloader-and-multi-node-horovod","title":"PyTorch <code>DataLoader</code> and multi-node Horovod","text":"<p>For best performance, it is crucial to enable multiple workers in the data loader to avoid compute and I/O overlap and concurrent loading of the dataset. This can be set by tuning the \"num_workers\" parameter in <code>DataLoader</code> (see https://pytorch.org/docs/stable/data.html). According to our experience, generally, one can set 4 or 8 for best performance. Due to the total number of CPU cores available on a node, the maximum number of workers one can choose is 16. It is always best to tune this value and find the optimal setup for your own application.</p> <p>Aside from this, one also has to make sure that the worker threads spread over different CPU cores. To do this, one has to specify the CPU binding to be <code>depth</code> and choose a depth value larger than <code>num_workers</code> through the following flag in the <code>mpiexec</code> command:</p> <pre><code>mpiexec -np $NUM_GPUS -ppn 4 --cpu-bind depth -d 16 python3 ...\n</code></pre> <p>Before 2024, enabling multiple workers would cause a fatal hang, but this has been addressed after an OS upgrade on Polaris.</p>"},{"location":"polaris/data-science/frameworks/tensorflow/","title":"TensorFlow on Polaris","text":"<p>TensorFlow is a popular, open-source deep learning framework developed and released by Google. The TensorFlow home page has more information about TensorFlow, which you can refer to. For troubleshooting on Polaris, please contact support@alcf.anl.gov.</p>"},{"location":"polaris/data-science/frameworks/tensorflow/#installation-on-polaris","title":"Installation on Polaris","text":"<p>TensorFlow is already pre-installed on Polaris, available in the <code>conda</code> module. To use it from a compute node, please do:</p> <pre><code>module load conda\nconda activate\n</code></pre> <p>Then, you can load TensorFlow in <code>python</code> as usual (below showing results from the <code>conda/2024-04-29</code> module):</p> <pre><code>&gt;&gt;&gt; import tensorflow as tf\n&gt;&gt;&gt; tf.__version__\n'2.16.1'\n&gt;&gt;&gt;\n</code></pre> <p>This installation of TensorFlow was built from source, and the CUDA libraries it uses are found via the <code>CUDA_HOME</code> environment variable (below showing results from the <code>conda/2024-04-29</code> module):</p> <pre><code>$ echo $CUDA_HOME\n/soft/compilers/cudatoolkit/cuda-12.4.1/\n</code></pre> <p>If you need to build applications that use this version of TensorFlow and CUDA, we recommend using these CUDA libraries to ensure compatibility. We periodically update the TensorFlow release, though updates will come in the form of new versions of the <code>conda</code> module.</p> <p>TensorFlow is also available through NVIDIA containers that have been translated to Apptainer containers. For more information about containers, please see the Containers documentation page.</p>"},{"location":"polaris/data-science/frameworks/tensorflow/#tensorflow-best-practices-on-polaris","title":"TensorFlow Best Practices on Polaris","text":""},{"location":"polaris/data-science/frameworks/tensorflow/#single-node-performance","title":"Single Node Performance","text":"<p>When running TensorFlow applications, we have found the following practices to be generally, if not universally, useful and encourage you to try some of these techniques to boost the performance of your own applications.</p> <ol> <li> <p>Use Reduced Precision. Reduced Precision is available on A100 via tensor cores and is supported with TensorFlow operations. In general, the way to do this is via the <code>tf.keras.mixed_precision</code> Policy, as described in the mixed precision documentation. If you use a custom training loop (and not <code>keras.Model.fit</code>), you will also need to apply loss scaling.</p> </li> <li> <p>Use TensorFlow's graph API to improve the efficiency of operations. TensorFlow is, in general, an imperative language, but with function decorators like <code>@tf.function</code>, you can trace functions in your code. Tracing replaces your Python function with a lower-level, semi-compiled TensorFlow Graph. More information about the <code>tf.function</code> interface is available here. When possible, use jit_compile, but be aware of sharp bits when using <code>tf.function</code>: Python expressions that aren't tensors are often replaced as constants in the graph, which may or may not be your intention.</p> </li> <li> <p>Use XLA compilation on your code. XLA is the Accelerated Linear Algebra library that is available in TensorFlow and critical in software like JAX. XLA will compile a <code>tf.Graph</code> object, generated with <code>tf.function</code> or similar, and perform optimizations like operation-fusion. XLA can give impressive performance boosts with almost no user changes except to set an environment variable <code>TF_XLA_FLAGS=--tf_xla_auto_jit=2</code>. If your code is complex or has dynamically sized tensors (tensors where the shape changes every iteration), XLA can be detrimental: the overhead for compiling functions can be large enough to mitigate performance improvements. XLA is particularly powerful when combined with reduced precision, yielding speedups &gt; 100% in some models.</p> </li> </ol>"},{"location":"polaris/data-science/frameworks/tensorflow/#multi-gpu-multi-node-scale-up","title":"Multi-GPU / Multi-Node Scale up","text":"<p>TensorFlow is compatible with scaling up to multiple GPUs per node and across multiple nodes. Good scaling performance has been seen up to the entire Polaris system, &gt; 2048 GPUs. Good performance with TensorFlow has been seen with Horovod in particular. For details, please see the Horovod documentation. Some Polaris-specific details that may be helpful to you:</p> <ol> <li> <p>CPU affinity can improve performance, particularly for data loading processes. In particular, we encourage users to try their scaling measurements by manually setting the CPU affinity via mpiexec, such as with <code>--cpu-bind verbose,list:0,8,16,24</code> or <code>--cpu-bind depth -d 16</code>.</p> </li> <li> <p>NCCL settings:  We have done extensive performance tests and identified the following best environment setup.</p> </li> </ol> <p><pre><code>export NCCL_NET_GDR_LEVEL=PHB\nexport NCCL_CROSS_NIC=1\nexport NCCL_COLLNET_ENABLE=1\nexport NCCL_NET=\"AWS Libfabric\"\nexport LD_LIBRARY_PATH=/soft/libraries/aws-ofi-nccl/v1.9.1-aws/lib:$LD_LIBRARY_PATH\nexport LD_LIBRARY_PATH=/soft/libraries/hwloc/lib/:$LD_LIBRARY_PATH\nexport FI_CXI_DISABLE_HOST_REGISTER=1\nexport FI_MR_CACHE_MONITOR=userfaultfd\nexport FI_CXI_DEFAULT_CQ_SIZE=131072\n</code></pre> The key here is to enable the AWS plugin (https://github.com/aws/aws-ofi-nccl). AWS OFI NCCL is a plugin that enables EC2 developers to use libfabric as a network provider while running NVIDIA's NCCL-based applications.</p> <p>This setup can lead to a 2-3x performance improvement for some communication workloads. For details, please refer to: https://github.com/argonne-lcf/alcf-nccl-tests.</p> <p>Warning</p> <p>For some applications such as Megatron-DeepSpeed, enabling the AWS plugin will cause a hang or NCCL timeout issue. If so, please disable it by: <pre><code>unset NCCL_NET_GDR_LEVEL NCCL_CROSS_NIC NCCL_COLLNET_ENABLE NCCL_NET\n</code></pre></p> <ol> <li>CUDA device setting: it works best when you limit the visible devices to only one GPU. Note that if you import <code>mpi4py</code> or <code>horovod</code>, and then do something like <code>os.environ[\"CUDA_VISIBLE_DEVICES\"] = hvd.local_rank()</code>, it may not actually work! You must set the <code>CUDA_VISIBLE_DEVICES</code> environment variable prior to doing <code>MPI.COMM_WORLD.init()</code>, which is done in <code>horovod.init()</code> as well as implicitly in <code>from mpi4py import MPI</code>. On Polaris specifically, you can use the environment variable <code>PMI_LOCAL_RANK</code> (as well as <code>PMI_LOCAL_SIZE</code>) to learn information about the node-local MPI ranks.  </li> </ol>"},{"location":"polaris/data-science/frameworks/tensorflow/#tensorflow-dataloaders","title":"TensorFlow Dataloaders","text":"<p>It is crucial to enable multiple workers in the data pipeline for best performance. For details, please refer to TensorFlow Data Performance Guide.</p>"},{"location":"polaris/debugging-tools/CUDA-GDB/","title":"CUDA-GDB","text":""},{"location":"polaris/debugging-tools/CUDA-GDB/#references","title":"References","text":"<p>NVIDIA CUDA-GDB Documentation</p>"},{"location":"polaris/debugging-tools/CUDA-GDB/#introduction","title":"Introduction","text":"<p>CUDA-GDB is the NVIDIA tool for debugging CUDA applications running on Polaris. CUDA-GDB is an extension to GDB, the GNU Project debugger. The tool provides developers with a mechanism for debugging CUDA applications running on actual hardware. This enables developers to debug applications without the potential variations introduced by simulation and emulation environments.</p>"},{"location":"polaris/debugging-tools/CUDA-GDB/#step-by-step-guide","title":"Step-by-step guide","text":""},{"location":"polaris/debugging-tools/CUDA-GDB/#debug-compilation","title":"Debug Compilation","text":"<p>NVCC, the NVIDIA CUDA compiler driver, provides a mechanism for generating the debugging information necessary for CUDA-GDB to work properly. The <code>-g -G</code> option pair must be passed to NVCC when an application is compiled for ease of debugging with CUDA-GDB; for example, <pre><code>nvcc -g -G foo.cu -o foo\n</code></pre> Using this line to compile the CUDA application <code>foo.cu</code>: * Forces <code>-O0</code> compilation, with the exception of very limited dead-code eliminations and register-spilling optimizations. * Makes the compiler include debug information in the executable.</p>"},{"location":"polaris/debugging-tools/CUDA-GDB/#running-cuda-gdb-on-polaris-compute-nodes","title":"Running CUDA-GDB on Polaris compute nodes","text":"<p>Start an interactive job mode on Polaris as follows: <pre><code>$ qsub -I -l select=1 -l walltime=1:00:00\n\n$ cuda-gdb --version\nNVIDIA (R) CUDA Debugger\n11.4 release\nPortions Copyright (C) 2007-2021 NVIDIA Corporation\nGNU gdb (GDB) 10.1\nCopyright (C) 2020 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\n$ cuda-gdb foo\n</code></pre></p>"},{"location":"polaris/debugging-tools/CUDA-GDB/#a-quick-example-with-a-stream-benchmark-on-a-polaris-compute-node","title":"A quick example with a stream benchmark on a Polaris compute node","text":"<pre><code>jkwack@polaris-login-02:~&gt; qsub -I -l select=1 -l walltime=1:00:00\nqsub: waiting for job 308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov to start\nqsub: job 308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov ready\n\nCurrently Loaded Modules:\n  1) nvidia/24.11        5) cray-pmi/6.1.15      9) darshan/3.4.4            13) craype-network-ofi\n  2) craype/2.7.34       6) cray-pals/1.6.1     10) xalt/3.1.4-202508192222  14) perftools-base/25.03.0\n  3) cray-dsmml/0.3.1    7) cray-libpals/1.6.1  11) PrgEnv-nvidia/8.6.0\n  4) cray-mpich/8.1.32   8) craype-x86-milan    12) libfabric/1.22.0\n\njkwack@x3008c0s13b1n0:~/BabelStream/build_polaris_debug&gt; nvcc -g -G -c ../src/cuda/CUDAStream.cu  -I ../src/\n\njkwack@x3008c0s13b1n0:~/BabelStream/build_polaris_debug&gt; nvcc -g -G -c ../src/main.cpp -DCUDA -I ../src/cuda/ -I ../src/\n\njkwack@x3008c0s13b1n0:~/BabelStream/build_polaris_debug&gt; nvcc -g -G main.o CUDAStream.o -o cuda-stream-debug\n\njkwack@x3008c0s13b1n0:~/BabelStream/build_polaris_debug&gt; ./cuda-stream-debug\nBabelStream\nVersion: 4.0\nImplementation: CUDA\nRunning kernels 100 times\nPrecision: double\nArray size: 268.4 MB (=0.3 GB)\nTotal size: 805.3 MB (=0.8 GB)\nUsing CUDA device NVIDIA A100-SXM4-40GB\nDriver: 11040\nFunction    MBytes/sec  Min (sec)   Max         Average\nCopy        1313940.694 0.00041     0.00047     0.00047\nMul         1302000.791 0.00041     0.00048     0.00047\nAdd         1296217.720 0.00062     0.00070     0.00069\nTriad       1296027.887 0.00062     0.00070     0.00069\nDot         823405.227  0.00065     0.00076     0.00075\n\njkwack@x3008c0s13b1n0:~/BabelStream/build_polaris_debug&gt; cuda-gdb ./cuda-stream-debug\nNVIDIA (R) CUDA Debugger\n11.4 release\nPortions Copyright (C) 2007-2021 NVIDIA Corporation\nGNU gdb (GDB) 10.1\nCopyright (C) 2020 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\nType \"show copying\" and \"show warranty\" for details.\nThis GDB was configured as \"x86_64-pc-linux-gnu\".\nType \"show configuration\" for configuration details.\nFor bug reporting instructions, please see:\n&lt;https://www.gnu.org/software/gdb/bugs/&gt;.\nFind the GDB manual and other documentation resources online at:\n    &lt;http://www.gnu.org/software/gdb/documentation/&gt;.\n\nFor help, type \"help\".\nType \"apropos word\" to search for commands related to \"word\"...\nReading symbols from ./cuda-stream-debug...\n(cuda-gdb) b CUDAStream.cu:203\nBreakpoint 1 at 0x412598: CUDAStream.cu:203. (2 locations)\n(cuda-gdb) r\nStarting program: /home/jkwack/BabelStream/build_polaris_debug/cuda-stream-debug\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib64/libthread_db.so.1\".\nBabelStream\nVersion: 4.0\nImplementation: CUDA\nRunning kernels 100 times\nPrecision: double\nArray size: 268.4 MB (=0.3 GB)\nTotal size: 805.3 MB (=0.8 GB)\n[Detaching after fork from child process 58459]\n[New Thread 0x15554c6bb000 (LWP 58475)]\nUsing CUDA device NVIDIA A100-SXM4-40GB\nDriver: 11040\n[New Thread 0x15554c4ba000 (LWP 58476)]\n[Switching focus to CUDA kernel 0, grid 5, block (0,0,0), thread (0,0,0), device 0, sm 0, warp 3, lane 0]\n\nThread 1 \"cuda-stream-deb\" hit Breakpoint 1, triad_kernel&lt;double&gt;&lt;&lt;&lt;(32768,1,1),(1024,1,1)&gt;&gt;&gt; (a=0x155506000000, b=0x1554f6000000, c=0x1554e6000000)\n    at ../src/cuda/CUDAStream.cu:203\n203   a[i] = b[i] + scalar * c[i];\n(cuda-gdb) c\nContinuing.\n[Switching focus to CUDA kernel 0, grid 5, block (1,0,0), thread (0,0,0), device 0, sm 0, warp 32, lane 0]\n\nThread 1 \"cuda-stream-deb\" hit Breakpoint 1, triad_kernel&lt;double&gt;&lt;&lt;&lt;(32768,1,1),(1024,1,1)&gt;&gt;&gt; (a=0x155506000000, b=0x1554f6000000, c=0x1554e6000000)\n    at ../src/cuda/CUDAStream.cu:203\n203   a[i] = b[i] + scalar * c[i];\n(cuda-gdb) info locals\ni = 1024\n(cuda-gdb) p b[i]\n$1 = 0.040000000000000008\n(cuda-gdb) p scalar\n$2 = 0.40000000000000002\n(cuda-gdb) p c[i]\n$3 = 0.14000000000000001\n(cuda-gdb) d 1\n(cuda-gdb) c\nContinuing.\nFunction    MBytes/sec  Min (sec)   Max         Average\nCopy        1314941.553 0.00041     0.00041     0.00041\nMul         1301022.680 0.00041     0.00042     0.00041\nAdd         1293858.147 0.00062     0.00063     0.00063\nTriad       1297681.929 0.00062     0.00063     0.00062\nDot         828446.963  0.00065     0.00066     0.00065\n[Thread 0x15554c4ba000 (LWP 58476) exited]\n[Thread 0x15554c6bb000 (LWP 58475) exited]\n[Inferior 1 (process 58454) exited normally]\n(cuda-gdb) q\n\njkwack@x3008c0s13b1n0:~/BabelStream/build_polaris_debug&gt;\n</code></pre>"},{"location":"polaris/performance-tools/NVIDIA-Nsight/","title":"NVIDIA Nsight tools","text":""},{"location":"polaris/performance-tools/NVIDIA-Nsight/#references","title":"References","text":"<ul> <li>NVIDIA Nsight Systems Documentation</li> <li>NVIDIA Nsight Compute Documentation</li> </ul>"},{"location":"polaris/performance-tools/NVIDIA-Nsight/#introduction","title":"Introduction","text":"<p>NVIDIA\u00ae Nsight\u2122 Systems provides developers a system-wide visualization of an applications performance. Developers can optimize bottlenecks to scale efficiently across any number or size of CPUs and GPUs on Polaris. For further optimizations to compute kernels developers should use Nsight Compute.</p> <p>The NVIDIA Nsight Compute is an interactive kernel profiler for CUDA applications. It provides detailed performance metrics and API debugging via a user interface and command line tool.</p> <p>In addition, the baseline feature of this tool allows users to compare results within the tool. NVIDIA Nsight Compute provides a customizable and data-driven user interface,  metric collection, and can be extended with analysis scripts for post-processing results.</p>"},{"location":"polaris/performance-tools/NVIDIA-Nsight/#step-by-step-guide","title":"Step-by-step guide","text":""},{"location":"polaris/performance-tools/NVIDIA-Nsight/#common-part-on-polaris","title":"Common part on Polaris","text":"<p>Build your application for Polaris, and then submit your job script to Polaris or start an interactive job mode on Polaris as follows: <pre><code>$ qsub -I -l select=1 -l walltime=1:00:00 -l filesystems=home:eagle -q debug -A &lt;project-name&gt;\n\n$ module li\n\nCurrently Loaded Modules:\n  1) nvidia/24.11        5) cray-pmi/6.1.15      9) darshan/3.4.4            13) craype-network-ofi\n  2) craype/2.7.34       6) cray-pals/1.6.1     10) xalt/3.1.4-202508192222  14) perftools-base/25.03.0\n  3) cray-dsmml/0.3.1    7) cray-libpals/1.6.1  11) PrgEnv-nvidia/8.6.0\n  4) cray-mpich/8.1.32   8) craype-x86-milan    12) libfabric/1.22.0\n\n$ nsys --version\nNVIDIA Nsight Systems version 2024.6.1.90-246134905481v0\n\n$ ncu --version\nNVIDIA (R) Nsight Compute Command Line Profiler\nCopyright (c) 2018-2024 NVIDIA Corporation\nVersion 2024.3.2.0 (build 34861637) (public-release)\n</code></pre></p>"},{"location":"polaris/performance-tools/NVIDIA-Nsight/#nsight-systems","title":"Nsight Systems","text":"<p>Run your application with Nsight Systems as follows: <pre><code>$ nsys profile -o {output_filename} --stats=true ./{your_application}\n</code></pre></p> <p>Run your application on multiple nodes (e.g., 2 nodes) with Nsight Systems as follows: <pre><code>$ mpirun -n 8 --ppn 4 --env TMPDIR=/home/{user ID}/ nsys profile -o {output_filename}_%q{PMI_RANK} --stats=true ./{your_application}\n</code></pre></p>"},{"location":"polaris/performance-tools/NVIDIA-Nsight/#nsight-compute","title":"Nsight Compute","text":"<p>Run your application with Nsight Compute. <pre><code>$ ncu --set detailed -k {kernel_name} -o {output_filename} ./{your_application}\n</code></pre></p> <p>Remark: Without -o option, Nsight Compute provides performance data as a standard output</p>"},{"location":"polaris/performance-tools/NVIDIA-Nsight/#post-processing-the-profiled-data","title":"Post-processing the profiled data","text":""},{"location":"polaris/performance-tools/NVIDIA-Nsight/#post-processing-via-cli","title":"Post-processing via CLI","text":"<pre><code>$ nsys stats {output_filename}.qdrep\n$ ncu -i {output_filename}.ncu-rep\n</code></pre>"},{"location":"polaris/performance-tools/NVIDIA-Nsight/#post-processing-on-your-local-system-via-gui","title":"Post-processing on your local system via GUI","text":"<ul> <li>Install NVIDIA Nsight Systems and NVIDIA Nsight Compute after downloading both of them from the  NVIDIA Developer Zone. Remark: Local client version should be the same as or newer than NVIDIA Nsight tools on Polaris.</li> <li>Download nsys output files (i.e., ending with .qdrep and . sqlite) to your local system, and then open them with NVIDIA Nsight Systems on your local system.</li> <li>Download ncu output files (i.e., ending with .ncu-rep) to your local system, and then open them with NVIDIA Nsight Compute on your local system.</li> </ul>"},{"location":"polaris/performance-tools/NVIDIA-Nsight/#more-options-for-performance-analysis-with-nsight-systems-and-nsight-compute","title":"More options for performance analysis with Nsight Systems and Nsight Compute","text":"<pre><code>$ nsys --help\n$ ncu --help\n</code></pre>"},{"location":"polaris/performance-tools/NVIDIA-Nsight/#a-quick-example","title":"A quick example","text":""},{"location":"polaris/performance-tools/NVIDIA-Nsight/#nsight-systems_1","title":"Nsight Systems","text":""},{"location":"polaris/performance-tools/NVIDIA-Nsight/#running-a-stream-benchmark-with-nsight-systems","title":"Running a stream benchmark with Nsight Systems","text":"<pre><code>jkwack@x3008c0s13b1n0:~/BabelStream/build_polaris&gt; nsys profile -o JKreport-nsys-BableStream --stats=true ./cuda-stream\nWarning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\nCollecting data...\nBabelStream\nVersion: 4.0\nImplementation: CUDA\nRunning kernels 100 times\nPrecision: double\nArray size: 268.4 MB (=0.3 GB)\nTotal size: 805.3 MB (=0.8 GB)\nUsing CUDA device NVIDIA A100-SXM4-40GB\nDriver: 11040\nFunction    MBytes/sec  Min (sec)   Max         Average\nCopy        1368294.603 0.00039     0.00044     0.00039\nMul         1334324.779 0.00040     0.00051     0.00041\nAdd         1358476.737 0.00059     0.00060     0.00059\nTriad       1366095.332 0.00059     0.00059     0.00059\nDot         1190200.569 0.00045     0.00047     0.00046\nProcessing events...\nSaving temporary \"/var/tmp/pbs.308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/nsys-report-f594-c524-6b4c-300a.qdstrm\" file to disk...\n\nCreating final output files...\nProcessing [===============================================================100%]\nSaved report file to \"/var/tmp/pbs.308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/nsys-report-f594-c524-6b4c-300a.qdrep\"\nExporting 7675 events: [===================================================100%]\n\nExported successfully to\n/var/tmp/pbs.308834.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/nsys-report-f594-c524-6b4c-300a.sqlite\n\n\nCUDA API Statistics:\n\n Time(%)  Total Time (ns)  Num Calls  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)           Name\n -------  ---------------  ---------  ------------  ------------  ------------  ------------  ---------------------\n    41.5      197,225,738        401     491,834.8       386,695       592,751      96,647.5  cudaDeviceSynchronize\n    35.4      168,294,004          4  42,073,501.0       144,211   167,547,885  83,649,622.0  cudaMalloc\n    22.5      106,822,589        103   1,037,112.5       446,617    20,588,840   3,380,727.4  cudaMemcpy\n     0.4        1,823,597        501       3,639.9         3,166        24,125       1,228.9  cudaLaunchKernel\n     0.2        1,166,186          4     291,546.5       130,595       431,599     123,479.8  cudaFree\n\n\n\nCUDA Kernel Statistics:\n\n Time(%)  Total Time (ns)  Instances  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)                             Name\n -------  ---------------  ---------  ------------  ------------  ------------  -----------  ----------------------------------------------------------\n    24.5       58,415,138        100     584,151.4       582,522       585,817        543.0  void add_kernel&lt;double&gt;(const T1 *, const T1 *, T1 *)\n    24.4       58,080,329        100     580,803.3       579,802       582,586        520.5  void triad_kernel&lt;double&gt;(T1 *, const T1 *, const T1 *)\n    18.3       43,602,345        100     436,023.5       430,555       445,979      2,619.5  void dot_kernel&lt;double&gt;(const T1 *, const T1 *, T1 *, int)\n    16.5       39,402,677        100     394,026.8       392,444       395,708        611.5  void mul_kernel&lt;double&gt;(T1 *, const T1 *)\n    16.1       38,393,119        100     383,931.2       382,556       396,892      1,434.1  void copy_kernel&lt;double&gt;(const T1 *, T1 *)\n     0.2          523,355          1     523,355.0       523,355       523,355          0.0  void init_kernel&lt;double&gt;(T1 *, T1 *, T1 *, T1, T1, T1)\n\n\n\nCUDA Memory Operation Statistics (by time):\n\n Time(%)  Total Time (ns)  Count  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)      Operation\n -------  ---------------  -----  ------------  ------------  ------------  -----------  ------------------\n   100.0       61,323,171    103     595,370.6         2,399    20,470,146  3,439,982.0  [CUDA memcpy DtoH]\n\n\n\nCUDA Memory Operation Statistics (by size):\n\n Total (MB)  Count  Average (MB)  Minimum (MB)  Maximum (MB)  StdDev (MB)      Operation\n ----------  -----  ------------  ------------  ------------  -----------  ------------------\n    805.511    103         7.820         0.002       268.435       45.361  [CUDA memcpy DtoH]\n\n\n\nOperating System Runtime API Statistics:\n\n Time(%)  Total Time (ns)  Num Calls  Average (ns)  Minimum (ns)  Maximum (ns)  StdDev (ns)        Name\n -------  ---------------  ---------  ------------  ------------  ------------  ------------  --------------\n    85.9      600,896,697         20  30,044,834.9         3,477   100,141,768  42,475,064.1  poll\n    13.5       94,610,402      1,201      78,776.4         1,002    11,348,375     402,562.6  ioctl\n     0.2        1,374,312         79      17,396.4         3,486       434,715      48,015.2  mmap64\n     0.1          877,705         51      17,209.9         1,031       748,723     104,491.6  fopen\n     0.1          741,969         12      61,830.8        17,272       256,852      64,706.5  sem_timedwait\n     0.1          529,563        120       4,413.0         1,292        20,579       2,134.3  open64\n     0.0          251,602          4      62,900.5        57,337        72,126       6,412.6  pthread_create\n     0.0           93,461         18       5,192.3         1,011        19,386       4,401.0  mmap\n     0.0           37,621         11       3,420.1         1,302        11,672       2,867.6  munmap\n     0.0           35,735          9       3,970.6         1,723         6,251       1,477.2  fgetc\n     0.0           33,533          1      33,533.0        33,533        33,533           0.0  fgets\n     0.0           26,832         13       2,064.0         1,452         3,366         542.6  write\n     0.0           21,341          5       4,268.2         1,213         9,738       3,378.3  putc\n     0.0           20,838          6       3,473.0         1,763         6,853       1,801.1  open\n     0.0           17,016         10       1,701.6         1,523         1,834          96.9  read\n     0.0           11,430          8       1,428.8         1,082         1,583         151.9  fclose\n     0.0            6,202          1       6,202.0         6,202         6,202           0.0  pipe2\n     0.0            5,961          2       2,980.5         2,254         3,707       1,027.4  socket\n     0.0            5,670          2       2,835.0         2,795         2,875          56.6  fwrite\n     0.0            5,481          1       5,481.0         5,481         5,481           0.0  connect\n     0.0            5,279          2       2,639.5         1,743         3,536       1,267.8  fread\n     0.0            1,082          1       1,082.0         1,082         1,082           0.0  bind\n\nReport file moved to \"/home/jkwack/BabelStream/build_polaris/JKreport-nsys-BableStream.qdrep\"\nReport file moved to \"/home/jkwack/BabelStream/build_polaris/JKreport-nsys-BableStream.sqlite\"\n</code></pre>"},{"location":"polaris/performance-tools/NVIDIA-Nsight/#reviewing-the-nsight-systems-data-via-gui","title":"Reviewing the Nsight Systems data via GUI","text":""},{"location":"polaris/performance-tools/NVIDIA-Nsight/#nsight-compute_1","title":"Nsight Compute","text":""},{"location":"polaris/performance-tools/NVIDIA-Nsight/#running-a-stream-benchmark-with-nsight-compute-for-triad_kernel","title":"Running a stream benchmark with Nsight Compute for triad_kernel","text":"<pre><code>jkwack@x3008c0s13b1n0:~/BabelStream/build_polaris&gt; ncu --set detailed -k triad_kernel -o JKreport-ncu_detailed-triad_kernel-BableStream ./cuda-stream\nBabelStream\nVersion: 4.0\nImplementation: CUDA\nRunning kernels 100 times\nPrecision: double\nArray size: 268.4 MB (=0.3 GB)\nTotal size: 805.3 MB (=0.8 GB)\n==PROF== Connected to process 56600 (/home/jkwack/BabelStream/build_polaris/cuda-stream)\nUsing CUDA device NVIDIA A100-SXM4-40GB\nDriver: 11040\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\n==PROF== Profiling \"triad_kernel\": 0%....50%....100% - 18 passes\nFunction    MBytes/sec  Min (sec)   Max         Average\nCopy        1331076.105 0.00040     0.00042     0.00041\nMul         1304696.608 0.00041     0.00043     0.00042\nAdd         1322600.587 0.00061     0.00062     0.00061\nTriad       1327.700    0.60654     0.62352     0.61106\nDot         850376.762  0.00063     0.00070     0.00065\n==PROF== Disconnected from process 56600\n==PROF== Report: /home/jkwack/BabelStream/build_polaris/JKreport-ncu_detailed-triad_kernel-BableStream.ncu-rep\n</code></pre>"},{"location":"polaris/performance-tools/NVIDIA-Nsight/#reviewing-the-nsight-compute-data-via-gui","title":"Reviewing the Nsight Compute data via GUI","text":""},{"location":"polaris/programming-models/julia/","title":"Julia","text":"<p>Experimental support</p> <p>Support for the Julia programming language on Polaris is currently experimental. This guide provides a set of best practices, but you may encounter unexpected issues.</p>"},{"location":"polaris/programming-models/julia/#introduction","title":"Introduction","text":"<p>Julia is a high-level, high-performance programming language designed for technical and scientific computing. It combines the ease of use of dynamic languages with the performance of compiled languages, making it well-suited for large-scale simulations and data analysis.</p> <p>This guide details how to install, configure, and run Julia on the Polaris supercomputer, focusing on leveraging the system's key architectural features for large-scale parallel and GPU-accelerated computing.</p> <p>!!! example \"Contributing*</p> <pre><code>This guide is a first draft of the Julia documentation for Polaris. If you have suggestions or find errors, please open a pull request or contact us by [opening a ticket](../../support/ticket.md) at the [ALCF Helpdesk](mailto:support@alcf.anl.gov).\n</code></pre> <p>All the source files used in this documentation are located at https://github.com/anlsys/julia_alcf. Feel free to open PRs!</p>"},{"location":"polaris/programming-models/julia/#julia-installation","title":"Julia Installation","text":"<p>We recommend installing Julia in a project directory <code>$PROJECT</code> on Eagle or Flare for faster file access and to avoid your home directory.</p> <ol> <li>Clone the configuration files     <pre><code>git clone https://github.com/anlsys/julia_alcf\n</code></pre></li> <li>Run setup script     <pre><code>cd julia_alcf/polaris\n./setup.sh\n</code></pre>     This script contains steps that eventually will be executed by an admin<ul> <li>Install Julia in <code>$JULIA_DEPOT_PATH</code> (e.g., <code>/eagle/$PROJECT/path/to/julia_depot</code>)</li> <li>Configure Julia options through a global <code>LocalPreferences.toml</code> file</li> <li>Set up module files</li> </ul> </li> <li> <p>Add <code>$JULIA_DEPOT_PATH</code> that you entered during setup to your shell configuration file (e.g., <code>~/.bashrc</code> or <code>~/.bash_profile</code>) and load the module path.</p> <pre><code>export JULIA_DEPOT_PATH=/eagle/$PROJECT/.../julia_depot\nmodule use $JULIA_DEPOT_PATH/modulefiles\n</code></pre> </li> </ol>"},{"location":"polaris/programming-models/julia/#loading-julia","title":"Loading Julia","text":"<p>Load the Julia module: <pre><code>module load julia\n</code></pre></p>"},{"location":"polaris/programming-models/julia/#configuring-the-programming-environment","title":"Configuring the Programming Environment","text":"<p>To leverage Polaris's architecture, you must configure Julia to use the system's optimized libraries for <code>MPI.jl</code>, <code>CUDA.jl</code>, and <code>HDF5.jl</code>. For a modern, interactive development experience, we recommend using Visual Studio Code with the official Julia and Remote - SSH extensions.</p> <p>Installing all required packages can be done in a Julia REPL with the following commands: <pre><code>using Pkg\nPkg.add([\"MPI\", \"MPIPreferences\", \"CUDA\", \"HDF5\"])\n</code></pre> The packages will be loaded with the options specified in the <code>LocalPreferences.toml</code> file created during the setup process in <code>$JULIA_DEPOT_PATH/environments/v1.12</code>.</p> <pre><code>## Verify Configuration on a Compute Node\n\nThe Polaris login nodes do not have GPU access. You must request an interactive job to test your GPU configuration.\n\n```bash\n# Request an interactive node\nqsub -I -l select=1,walltime=1:00:00,filesystems=home:eagle -A [PROJECT] -q debug\n\n# Once on the node, run the verification\njulia --project -e \"using CUDA; CUDA.versioninfo()\"\n\n# Expected Output Snippet\n# CUDA runtime 12.2, local installation\n# ...\n# Preferences:\n# - CUDA_Runtime_jll.local: true\n# ...\n# 4 devices:\n#   0: NVIDIA A100-SXM4-40GB ...\n</code></pre>"},{"location":"polaris/programming-models/julia/#example-julia-code-for-approximating-pi","title":"Example Julia Code for Approximating Pi","text":"pi.jl<pre><code>using CUDA\nusing HDF5\nusing MPI\nusing Printf\nusing Random\n\n# GPU kernel to check if points fall within a circle\nfunction pi_kernel(x, y, d, n)\n    idx = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n    if idx &lt;= n\n        d[idx] = (x[idx] - 0.5)^2 + (y[idx] - 0.5)^2 &lt;= 0.25 ? 1 : 0\n    end\n    return nothing\nend\n\n# Function to run the computation on a single GPU\nfunction approximate_pi_gpu(n::Integer)\n    x = CUDA.rand(Float64, n)\n    y = CUDA.rand(Float64, n)\n    d = CUDA.zeros(Float64, n)\n\n    nblocks = ceil(Int64, n / 32)\n    @cuda threads=32 blocks=nblocks pi_kernel(x, y, d, n)\n\n    return sum(d)\nend\n\nfunction main()\n    n = 100_000  # Number of points per MPI rank\n\n    # Use a fixed random seed for reproducibility\n    Random.seed!(1234 + MPI.Comm_rank(MPI.COMM_WORLD))\n\n    # Each rank computes its sum on the GPU, then we reduce across all ranks\n    local_sum = approximate_pi_gpu(n)\n    total_sum = MPI.Allreduce(local_sum, MPI.SUM, MPI.COMM_WORLD)\n\n    # Calculate final approximation\n    comm_size = MPI.Comm_size(MPI.COMM_WORLD)\n    pi_approx = (4 * total_sum) / (n * comm_size)\n\n    if MPI.Comm_rank(MPI.COMM_WORLD) == 0\n        @printf \"Approximation of \u03c0: %.10f\\n\" pi_approx\n        @printf \"Error:              %.10f\\n\" abs(pi_approx - \u03c0)\n    end\n    return pi_approx\nend\n\n# --- Main Execution ---\nMPI.Init()\n\n# Ensure the script doesn't run in an interactive Julia session without MPI\nif !isinteractive()\n    pi_approx = main()\n\n    # Rank 0 writes the result to an HDF5 file\n    if MPI.Comm_rank(MPI.COMM_WORLD) == 0\n        h5open(\"pi_approximation.h5\", \"w\") do file\n            write(file, \"pi\", pi_approx)\n        end\n    end\n    MPI.Finalize()\nend\n</code></pre>"},{"location":"polaris/programming-models/julia/#job-submission-script","title":"Job Submission Script","text":"<p>This PBS script requests resources and launches the Julia application using <code>mpiexec</code>. submit.sh<pre><code>#!/bin/bash -l\n#PBS -l select=1:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:10:00\n#PBS -l filesystems=home:eagle\n#PBS -q debug\n#PBS -A YOUR_PROJECT_ID\n\ncd ${PBS_O_WORKDIR}\nmodule load julia\n\n# --- Job Settings ---\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=4\nNDEPTH=8 # For CPU binding\nNTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))\n\necho \"Nodes: ${NNODES}, Total Ranks: ${NTOTRANKS}, Ranks/Node: ${NRANKS_PER_NODE}\"\n\n# --- Execution ---\n# Path to the Julia executable\nJULIA_EXE_PATH=$(which julia)\n\n# mpiexec arguments\nMPI_ARGS=\"-n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth\"\n\necho \"Running Julia from: ${JULIA_EXE_PATH}\"\nmpiexec ${MPI_ARGS} ${JULIA_EXE_PATH} --project pi.jl\n</code></pre></p>"},{"location":"polaris/programming-models/kokkos-polaris/","title":"Kokkos","text":""},{"location":"polaris/programming-models/kokkos-polaris/#kokkos_1","title":"Kokkos","text":"<p>Kokkos Core implements a programming model in C++ for writing performance-portable applications targeting all major HPC platforms. For that purpose, it provides abstractions for both parallel execution of code and data management. Kokkos is designed to target complex node architectures with N-level memory hierarchies and multiple types of execution resources. It currently can use Serial and OpenMP (threads) for CPU execution spaces (\"backends\") and CUDA, HIP, SYCL, and OpenMPTarget for GPU execution spaces. By convention, Kokkos only allows one GPU backend at a time.</p>"},{"location":"polaris/programming-models/kokkos-polaris/#kokkos-documentation","title":"Kokkos Documentation","text":"<ul> <li>Kokkos-core Wiki</li> <li>Kokkos GitHub</li> </ul>"},{"location":"polaris/programming-models/kokkos-polaris/#kokkos-on-polaris","title":"Kokkos on Polaris","text":"<p>Following the Polaris upgrade to HPCM 1.10, the module setup to use the prebuilt Kokkos changed.</p> <p>The prebuilt Kokkos on Polaris includes three backends: Serial and OpenMP for CPU execution and CUDA for GPU execution. To use it, run:</p> <pre><code>module load craype-x86-milan\nmodule load craype-accel-nvidia80\nmodule swap PrgEnv-nvidia PrgEnv-gnu\nmodule use /soft/modulefiles\nmodule load cuda-PrgEnv-nvidia/12.2.91\nmodule load kokkos\n</code></pre> <p>This sets the following environment variables, some of which are used by <code>cmake</code>:</p> <ul> <li><code>KOKKOS_HOME</code> - path to the <code>lib64/</code>, <code>include/</code> files installed</li> <li><code>LIBRARY_PATH</code> - prepends <code>$KOKKOS_HOME/lib64</code> to this variable used by <code>cmake</code></li> <li><code>CPATH</code> - prepends <code>$KOKKOS_HOME/include</code> to this variable used by <code>cmake</code></li> <li><code>LD_LIBRARY_PATH</code> - prepends <code>$KOKKOS_HOME/lib64</code> to this variable</li> </ul>"},{"location":"polaris/programming-models/kokkos-polaris/#building-a-kokkos-application-using-cmake","title":"Building a Kokkos Application Using <code>cmake</code>","text":"<p>Add these lines to <code>CMakeLists.txt</code>:</p> <pre><code>find_package(Kokkos REQUIRED)\ntarget_link_libraries(myTarget Kokkos::kokkoscore)\n</code></pre> <p>Here is a simple example <code>CMakeLists.txt</code> to compile an example program:</p> <pre><code>cmake_minimum_required(VERSION 3.22)\nproject(buildExample)\nfind_package(Kokkos REQUIRED)\n\nset(buildExample_SOURCE_DIR \".\")\n\nset(top_SRCS\n  ${buildExample_SOURCE_DIR}/example1.cpp)\n\nset(SOURCE_FILES ${top_SRCS})\n\nadd_executable(example1_sycl_aot ${SOURCE_FILES})\ntarget_link_libraries(example1_sycl_aot Kokkos::kokkoscore)\ntarget_include_directories(example1_sycl_aot PUBLIC ${buildExample_SOURCE_DIR})\n</code></pre> <p>Configure and build it like this:</p> <pre><code>mkdir build\ncd build\ncmake -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc ..\nmake\n</code></pre>"},{"location":"polaris/programming-models/kokkos-polaris/#building-a-kokkos-application-using-make","title":"Building a Kokkos Application Using <code>make</code>","text":"<p>Here's an example <code>Makefile</code>:</p> <pre><code># KOKKOS_HOME set via:\n#   module load kokkos\n\n# You can look at the first lines of $KOKKOS_HOME/KokkosConfigCommon.cmake to\n# see the flags used in cmake configuration of the kokkos library build. The\n# default Kokkos module on Polaris was built with PrgEnv-nvidia and includes\n# Serial, OpenMP (threads), and CUDA backends. So you should have that\n# environment module loaded and include compiler flags for CUDA and OpenMP:\n\n# Cray MPI wrapper for C++ and C compilers:\nCXX=CC\nCC=cc\n\nCPPFLAGS=-cuda -fopenmp\nLDFLAGS=\n\nLDFLAGS=$(CPPFLAGS) $(LDFLAGS)\nLDLIBS=-L$(KOKKOS_HOME)/lib64 -lkokkoscore -lkokkossimd -lpthread\n\nSRCS=example1.cpp\nOBJS=$(subst .cpp,.o,$(SRCS))\n\nall: example1_polaris\n\nexample1_polaris: $(OBJS)\n        $(CXX) $(LDFLAGS) -o example1_polaris $(OBJS) $(LDLIBS)\n\nexample1.o: example1.cpp\n\nclean:\n        rm -f $(OBJS)\n\ndistclean: clean\n        rm -f example1_polaris\n</code></pre>"},{"location":"polaris/programming-models/kokkos-polaris/#configuring-your-own-kokkos-build-on-polaris","title":"Configuring Your Own Kokkos Build on Polaris","text":"<p>Here are recommended environment settings and configuration to build your own Kokkos libraries on Polaris:</p>"},{"location":"polaris/programming-models/kokkos-polaris/#environment","title":"Environment","text":"<p>To match what was done in the centrally-built Kokkos associated with the modules discussed above, use the programming environment <code>PrgEnv-gnu</code>, and use the Cray wrapper <code>CC</code> as the C++ compiler. You'll also need to explicitly load the CUDA toolkit version 12.2.91 as shown:</p> <pre><code>module restore\nmodule load craype-x86-milan\nmodule load craype-accel-nvidia80\nmodule swap PrgEnv-nvidia PrgEnv-gnu\nmodule use /soft/modulefiles\nmodule load cuda-PrgEnv-nvidia/12.2.91\nmodule load spack-pe-base cmake\n</code></pre>"},{"location":"polaris/programming-models/kokkos-polaris/#cmake-configuration","title":"CMake Configuration","text":"<p>This example builds three backends: OpenMP, Serial, and CUDA.</p> <pre><code>git clone git@github.com:kokkos/kokkos.git\ncd kokkos\nmkdir build\ncd build\n\ncmake\\\n -DCMAKE_BUILD_TYPE=RelWithDebInfo\\\n -DCMAKE_INSTALL_PREFIX=\"./install\"\\\n -DCMAKE_CXX_COMPILER=CC\\\n -DKokkos_ENABLE_OPENMP=ON\\\n -DKokkos_ENABLE_SERIAL=ON\\\n -DKokkos_ARCH_ZEN3=ON\\\n -DKokkos_ARCH_AMPERE80=ON\\\n -DKokkos_ENABLE_CUDA=ON\\\n -DKokkos_ENABLE_AGGRESSIVE_VECTORIZATION=ON\\\n -DKokkos_ENABLE_TESTS=OFF\\\n -DBUILD_TESTING=OFF\\\n -DKokkos_ENABLE_CUDA_LAMBDA=ON\\\n -DKokkos_ENABLE_IMPL_DESUL_ATOMICS=OFF\\\n -DCMAKE_CXX_STANDARD=17\\\n -DCMAKE_EXE_LINKER_FLAGS=-no-gcc-rpath\\\n ..\n\nmake -j8 install\n</code></pre>"},{"location":"polaris/programming-models/openmp-polaris/","title":"OpenMP","text":""},{"location":"polaris/programming-models/openmp-polaris/#overview","title":"Overview","text":"<p>The OpenMP API is an open standard for parallel programming. The specification document can be found here: OpenMP Specification. The specification describes directives, runtime routines, and environment variables that allow an application developer to express parallelism (e.g., shared memory multiprocessing and device offloading). Many compiler vendors provide implementations of the OpenMP specification (OpenMP Specifications).</p>"},{"location":"polaris/programming-models/openmp-polaris/#setting-the-environment-to-use-openmp-on-polaris","title":"Setting the environment to use OpenMP on Polaris","text":"<p>Many of the programming environments available on Polaris have OpenMP support.</p> Module OpenMP CPU Support? OpenMP GPU Support? PrgEnv-nvidia Yes Yes llvm Yes Yes PrgEnv-gnu Yes No PrgEnv-cray Yes Yes* <p>*Currently, <code>PrgEnv-cray</code> is not recommended for OpenMP offload.</p> <p>By default, the <code>PrgEnv-nvidia</code> module is loaded. To switch to other modules, you can use <code>module switch</code>.</p>"},{"location":"polaris/programming-models/openmp-polaris/#using-prgenv-nvidia","title":"Using <code>PrgEnv-nvidia</code>","text":"<p>This is loaded by default, so there's no need to load additional modules. You can confirm that it is loaded by running <code>module list</code> to check that <code>PrgEnv-nvidia</code> is in the list.</p>"},{"location":"polaris/programming-models/openmp-polaris/#using-llvm","title":"Using LLVM","text":"<p>To use the LLVM module, load the following:</p> <pre><code>module use /soft/modulefiles\nmodule load mpiwrappers/cray-mpich-llvm\nmodule load cudatoolkit-standalone\n</code></pre> <p>See the LLVM compiling page here for more information.</p>"},{"location":"polaris/programming-models/openmp-polaris/#using-prgenv-gnu","title":"Using PrgEnv-gnu","text":"<p>To switch from <code>PrgEnv-nvidia</code> to <code>PrgEnv-gnu</code>, you can run:</p> <pre><code>module switch PrgEnv-nvidia PrgEnv-gnu\n</code></pre> <p>The gcc/gfortran on Polaris was not built with GPU support.</p>"},{"location":"polaris/programming-models/openmp-polaris/#using-prgenv-cray","title":"Using <code>PrgEnv-cray</code>","text":"<p>To switch from <code>PrgEnv-nvidia</code> to <code>PrgEnv-cray</code>, you can run:</p> <pre><code>module switch PrgEnv-nvidia PrgEnv-cray\n</code></pre> <p>To use OpenMP on the GPU, load <code>cudatoolkit-standalone</code>, although this is not recommended at the moment.</p> <pre><code>module load cudatoolkit-standalone\n</code></pre>"},{"location":"polaris/programming-models/openmp-polaris/#building-on-polaris","title":"Building on Polaris","text":"<p>The following table shows what compiler and flags to use with which PrgEnv:</p> Module Compiler Flags PrgEnv-nvidia cc/CC/ftn (nvc/nvc++/nvfortran) -mp=gpu -gpu=cc80 llvm mpicc/mpicxx (clang/clang++) -fopenmp --offload-arch=sm_80 PrgEnv-gnu cc/CC/ftn (gcc/g++/gfortran) -fopenmp PrgEnv-cray cc/CC/ftn -fopenmp <p>For example, to compile a simple code hello.cpp:</p>"},{"location":"polaris/programming-models/openmp-polaris/#for-prgenv-nvidia-after-loading-the-modules-as-discussed-above-we-would-use","title":"For <code>PrgEnv-nvidia</code>, after loading the modules as discussed above, we would use:","text":"<pre><code>CC -mp=gpu -gpu=cc80 hello.cpp\nftn -mp=gpu -gpu=cc80 hello.F90\n</code></pre>"},{"location":"polaris/programming-models/openmp-polaris/#for-llvm-after-loading-the-modules-as-discussed-above","title":"For LLVM, after loading the modules as discussed above:","text":"<pre><code>mpicxx -fopenmp --offload-arch=sm_80 hello.cpp \n</code></pre> <p>Note that if you want to force the code to error out if it cannot run on the GPU (instead of falling back to run on the host, which is the default), you can additionally compile with <code>-fopenmp-offload-mandatory</code>.</p>"},{"location":"polaris/programming-models/openmp-polaris/#for-prgenv-gnu-after-loading-the-modules-as-discussed-above-we-would-use","title":"For PrgEnv-gnu, after loading the modules as discussed above, we would use:","text":"<pre><code>CC -fopenmp hello.cpp\nftn -fopenmp hello.F90\n</code></pre>"},{"location":"polaris/programming-models/openmp-polaris/#for-prgenv-cray-after-loading-the-modules-as-discussed-above-we-would-use","title":"For PrgEnv-cray, after loading the modules as discussed above, we would use:","text":"<pre><code>CC -fopenmp hello.cpp\nftn -fopenmp hello.F90\n</code></pre>"},{"location":"polaris/programming-models/openmp-polaris/#running-on-polaris","title":"Running on Polaris","text":"<p>To run, you can execute the produced executable or use mpiexec in a job script, and then submit the script to the Polaris queue, like:</p> <pre><code>$ cat submit.sh\n#!/bin/sh\n#PBS -l select=1:system=polaris\n#PBS -l walltime=0:30:00\n#PBS -q debug \n#PBS -A Catalyst\n#PBS -l filesystems=home:eagle\n\ncd ${PBS_O_WORKDIR}\nmpiexec -n 1 ./executable\n$ # submit to the queue:\n$ qsub -l select=1:system=polaris -l walltime=0:30:00 -l filesystems=home:eagle -q debug -A Catalyst ./submit.sh\n</code></pre> <p>In the above, having the PBS options in the script and on the command line is redundant, but we put it there to show both ways of launching. This submits the script to one node in the debug queue on Polaris, requesting 30 minutes and the eagle and home filesystems. It will charge project Catalyst for the time.</p> <p>More details for setting up the job script are in the Job Scheduling and Execution section.</p>"},{"location":"polaris/programming-models/openmp-polaris/#example","title":"Example","text":"<pre><code>$ cat hello.cpp\n#include &lt;stdio.h&gt;\n#include &lt;omp.h&gt;\n\nint main(int argc, char** argv) {\n\n  printf(\"Number of devices: %d\\n\", omp_get_num_devices());\n\n  #pragma omp target\n  {\n    if (!omp_is_initial_device())\n      printf(\"Hello world from accelerator.\\n\");\n    else\n      printf(\"Hello world from host.\\n\");\n  }\n  return 0;\n}\n\n$ cat hello.F90\nprogram main\n  use omp_lib\n  implicit none\n  integer flag\n\n  write(*,*) \"Number of devices:\", omp_get_num_devices()\n\n  !$omp target map(from:flag)\n    if (.not. omp_is_initial_device()) then\n      flag = 1\n    else\n      flag = 0\n    endif\n  !$omp end target\n\n  if (flag == 1) then\n    print *, \"Hello world from accelerator\"\n  else\n    print *, \"Hello world from host\"\n  endif\n\nend program main\n\n$ # To compile\n$ CC -mp=gpu -gpu=cc80 hello.cpp -o c_test\n$ ftn -mp=gpu -gpu=cc80 hello.F90 -o f_test\n\n$ # To run \n$ mpiexec -n 1 ./c_test\nNumber of devices: 4\nHello world from accelerator.\n$ mpiexec -n 1 ./f_test\n Number of devices:            4\n Hello world from accelerator\n</code></pre>"},{"location":"polaris/programming-models/sycl-polaris/","title":"SYCL","text":"<p>SYCL (pronounced \u2018sickle\u2019) is a royalty-free, cross-platform abstraction layer that enables code for heterogeneous processors to be written using standard ISO C++ with the host and kernel code for an application contained in the same source file.</p> <ul> <li>Specification: https://www.khronos.org/sycl/</li> <li>Source code of the compiler: https://github.com/intel/llvm</li> <li>ALCF Tutorial: https://github.com/argonne-lcf/sycltrain</li> </ul> <pre><code>module load oneapi/upstream\n</code></pre> <p>Note</p> <p>This module (compilers, libraries) is built periodically from the latest open-source rather than releases. For more details on the release version of the compiler, please find the details here. As such, these compilers will get new features and updates quickly that may break on occasion. Please submit any issues at the respective GitHub repositories for the compilers and libraries.</p>"},{"location":"polaris/programming-models/sycl-polaris/#components","title":"Components","text":"<ul> <li>These are the components associated with this module:</li> </ul> User Application Component Compilers DPC++ oneMath Interface oneMath oneDPL oneDPL SYCLomatic/DPCT dpct"},{"location":"polaris/programming-models/sycl-polaris/#dependencies","title":"Dependencies","text":"<ul> <li>The SYCL programming model is supported through <code>oneapi</code> compilers that were built from source code.</li> <li>Loading this module switches the default programming environment to GNU with the following dependencies:</li> <li>PrgEnv-gnu</li> <li>cuda-PrgEnv-nvidia</li> <li>An environment variable is set when loading the module: <code>ONEAPI_DEVICE_SELECTOR=cuda:gpu</code></li> </ul>"},{"location":"polaris/programming-models/sycl-polaris/#example-how-to-use-sycl-with-mpi-and-openmp","title":"Example: How to use SYCL with MPI and OpenMP","text":"Toggle for SYCL example with OpenMP &amp; MPI for CPU-side <pre><code>#include &lt;stdlib.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;iostream&gt;\n#include &lt;iomanip&gt;\n#include &lt;string.h&gt;\n#include &lt;mpi.h&gt;\n#include &lt;sched.h&gt;\n#include &lt;sycl/sycl.hpp&gt;\n#include &lt;omp.h&gt;\n\n// SYCL port of https://code.ornl.gov/olcf/hello_jobstep\n// To compile: mpicxx -fsycl -fopenmp -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 hello_jobstep.cpp -o hello_jobstep.out\n\nint main(int argc, char *argv[]){\n\n  MPI_Init(&amp;argc, &amp;argv);\n\n  int size;\n  MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n\n  char name[MPI_MAX_PROCESSOR_NAME];\n  int resultlength;\n  MPI_Get_processor_name(name, &amp;resultlength);\n\n  // If CUDA_VISIBLE_DEVICES is set, capture visible GPUs\n  const char* gpu_id_list;\n  const char* cuda_visible_devices = getenv(\"CUDA_VISIBLE_DEVICES\");\n  if(cuda_visible_devices == NULL){\n    gpu_id_list = \"N/A\";\n  }\n  else{\n    gpu_id_list = cuda_visible_devices;\n  }\n\n  // Find how many GPUs L0 runtime says are available\n  int num_devices = 0;\n  std::vector&lt;sycl::device&gt; sycl_all_devs = sycl::device::get_devices(sycl::info::device_type::gpu);\n  num_devices = sycl_all_devs.size();\n\n  int hwthread;\n  int thread_id = 0;\n\n  if(num_devices == 0){\n#pragma omp parallel default(shared) private(hwthread, thread_id)\n    {\n      thread_id = omp_get_thread_num();\n      hwthread = sched_getcpu();\n\n      printf(\"MPI %03d - OMP %03d - HWT %03d - Node %s\\n\",\n             rank, thread_id, hwthread, name);\n\n    }\n  }\n  else{\n\n    std::string busid = \"\";\n\n    std::string busid_list = \"\";\n    std::string rt_gpu_id_list = \"\";\n\n    // Loop over the GPUs available to each MPI rank\n    for(int i=0; i&lt;num_devices; i++){\n\n      // // Get the PCIBusId for each GPU and use it to query for UUID\n      busid = sycl_all_devs[i].get_info&lt;sycl::ext::intel::info::device::pci_address&gt;();\n      busid_list.append(busid);\n\n      // Concatenate per-MPIrank GPU info into strings for print\n      if(i &gt; 0) rt_gpu_id_list.append(\",\");\n      rt_gpu_id_list.append(std::to_string(i));\n    }\n\n#pragma omp parallel default(shared) private(hwthread, thread_id)\n    {\n#pragma omp critical\n      {\n        thread_id = omp_get_thread_num();\n        hwthread = sched_getcpu();\n\n        printf(\"MPI %03d - OMP %03d - HWT %03d - Node %s - RT_GPU_ID %s - GPU_ID %s - Bus_ID %s\\n\",\n               rank, thread_id, hwthread, name, rt_gpu_id_list.c_str(), gpu_id_list, busid_list.c_str());\n      }\n    }\n  }\n\n  MPI_Finalize();\n\n  return 0;\n}\n</code></pre> <p>Compile and Run <pre><code>$ mpiexec -n 4 --ppn 4 --env OMP_NUM_THREADS=1 ./set_affinity_gpu_polaris.sh ./hello_jobstep.out\n\nMPI 000 - OMP 000 - HWT 000 - Node x3200c0s37b0n0 - RT_GPU_ID 0 - GPU_ID 3 - Bus_ID 0000:C7:00.0\nMPI 001 - OMP 000 - HWT 001 - Node x3200c0s37b0n0 - RT_GPU_ID 0 - GPU_ID 2 - Bus_ID 0000:85:00.0\nMPI 003 - OMP 000 - HWT 003 - Node x3200c0s37b0n0 - RT_GPU_ID 0 - GPU_ID 0 - Bus_ID 0000:07:00.0\nMPI 002 - OMP 000 - HWT 002 - Node x3200c0s37b0n0 - RT_GPU_ID 0 - GPU_ID 1 - Bus_ID 0000:46:00.0\n$ ./a.out\n</code></pre></p>"},{"location":"polaris/programming-models/sycl-polaris/#example-using-gpu-aware-mpi","title":"Example (using GPU-aware MPI)","text":"<pre><code>#include &lt;stdlib.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;mpi.h&gt;\n\n#include &lt;sycl/sycl.hpp&gt;\n\n// Modified from NERSC website:\n// https://docs.nersc.gov/development/programming-models/mpi\nint main(int argc, char *argv[]) {\n\n    int myrank, num_ranks;\n    double *val_device;\n    double *val_host;\n    char machine_name[MPI_MAX_PROCESSOR_NAME];\n    int name_len=0;\n\n    MPI_Init(&amp;argc, &amp;argv);\n    MPI_Comm_rank(MPI_COMM_WORLD, &amp;myrank);\n    MPI_Comm_size(MPI_COMM_WORLD, &amp;num_ranks);\n    MPI_Get_processor_name(machine_name, &amp;name_len);\n\n    sycl::queue q{sycl::gpu_selector_v};\n\n    std::cout &lt;&lt; \"Rank #\" &lt;&lt; myrank &lt;&lt; \" runs on: \" &lt;&lt; machine_name\n              &lt;&lt; \", uses device: \"\n              &lt;&lt; q.get_device().get_info&lt;sycl::info::device::name&gt;() &lt;&lt; \"\\n\";\n\n    MPI_Barrier(MPI_COMM_WORLD);\n    int one=1;\n    val_host = (double *)malloc(one*sizeof(double));\n    val_device = sycl::malloc_device&lt;double&gt;(one,q);\n\n    const size_t size_of_double = sizeof(double);\n    *val_host = -1.0;\n    if (myrank != 0) {\n        std::cout &lt;&lt; \"I am rank \" &lt;&lt; myrank\n                  &lt;&lt; \" and my initial value is: \" &lt;&lt; *val_host &lt;&lt; \"\\n\";\n    }\n\n    if (myrank == 0) {\n        *val_host = 42.0;\n        q.memcpy(val_device,val_host,size_of_double).wait();\n        std::cout &lt;&lt; \"I am rank \" &lt;&lt; myrank\n                  &lt;&lt; \" and will broadcast value: \" &lt;&lt; *val_host &lt;&lt; \"\\n\";\n    }\n\n    MPI_Bcast(val_device, 1, MPI_DOUBLE, 0, MPI_COMM_WORLD);\n\n    double check = 42.0;\n    if (myrank != 0) {\n        //Device to Host\n        q.memcpy(val_host,val_device,size_of_double).wait();\n        assert(*val_host == check);\n        std::cout &lt;&lt; \"I am rank \" &lt;&lt; myrank\n                  &lt;&lt; \" and received broadcast value: \" &lt;&lt; *val_host &lt;&lt; \"\\n\";\n    }\n\n    sycl::free(val_device,q);\n    free(val_host);\n\n    MPI_Finalize();\n\n    return 0;\n}\n</code></pre> <p>Load Modules</p> <pre><code>module load oneapi/upstream\nmodule load mpiwrappers/cray-mpich-oneapi-upstream\nmodule load craype-accel-nvidia80\nexport MPICH_GPU_SUPPORT_ENABLED=1\n</code></pre> <p>Compile and Run</p> <p><pre><code>$ mpicxx -L/opt/cray/pe/mpich/8.1.28/gtl/lib -lmpi_gtl_cuda -std=c++17 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 main.cpp\n$ mpiexec -n 2 --ppn 2 --depth=1 --cpu-bind depth ./set_affinity_gpu_polaris.sh ./a.out\n</code></pre> For further details regarding the arguments passed to the <code>mpiexec</code> command shown above, please visit the Job Scheduling and Execution section. A simple example describing the details and execution of the <code>set_affinity_gpu_polaris.sh</code> file can be found here.</p> <p>Note: By default, there is no GPU-aware MPI library linking support. The example above shows how the user can enable the linking by specifying the path to the GTL (GPU Transport Layer) library (<code>libmpi_gtl_cuda</code>) to the link line.</p>"},{"location":"polaris/programming-models/sycl-polaris/#oneapi-math-library-onemath","title":"oneAPI Math Library (oneMath)","text":"<p>oneMath is an open-source implementation of the oneMath interface according to the oneMath specification. It works with multiple devices (backends) using device-specific libraries underneath.</p> <p>oneMath is part of oneAPI. Various backends supported are shown below. More information here.</p> User Application Third-Party Library cuBLAS oneMath interface cuSOLVER cuRAND"},{"location":"polaris/programming-models/sycl-polaris/#example-using-mathgemm","title":"Example (using math::gemm)","text":"<p>The following snippet shows how to compile and run a SYCL code with the oneMath library. For instance, a GPU-based GEMM is performed using the <code>math::gemm</code> API and the results are compared to a CPU-based GEMM performed using the traditional BLAS (e.g., AOCL-BLIS) library. <pre><code>#include &lt;limits&gt;\n#include &lt;random&gt;\n\n#include &lt;sycl/sycl.hpp&gt;\n\n#include &lt;oneapi/math.hpp&gt;  // ONEMATH GPU header\n#include &lt;cblas.h&gt;         // BLIS   CPU header\n\n// Matrix size constants\n#define SIZE 4800 // Must be a multiple of 8.\n#define M SIZE / 8\n#define N SIZE / 4\n#define P SIZE / 2\n\n//////////////////////////////////////////////////////////////////////////////////////////\n\nbool ValueSame(double a, double b) { return std::fabs(a - b) &lt; 1.0e-08; }\nint VerifyResult(double *c_A, double *c_B) {\n  bool MismatchFound = false;\n\n  for (size_t i = 0; i &lt; M; i++) {\n    for (size_t j = 0; j &lt; P; j++) {\n      if (!ValueSame(c_A[i * P + j], c_B[i * P + j])) {\n        std::cout &lt;&lt; \"fail - The result is incorrect for element: [\" &lt;&lt; i &lt;&lt; \", \" &lt;&lt; j\n                  &lt;&lt; \"], expected: \" &lt;&lt; c_A[i * P + j] &lt;&lt; \" , but got: \" &lt;&lt; c_B[i * P + j]\n                  &lt;&lt; std::endl;\n        MismatchFound = true;\n      }\n    }\n  }\n\n  if (!MismatchFound) {\n    std::cout &lt;&lt; \"SUCCESS - The results are correct!\" &lt;&lt; std::endl;\n    return 0;\n  } else {\n    std::cout &lt;&lt; \"FAIL - The results mis-match!\" &lt;&lt; std::endl;\n    return -1;\n  }\n}\n\n//////////////////////////////////////////////////////////////////////////////////////////\n\nint main() {\n  std::random_device rd;  // Will be used to obtain a seed for the random number engine\n  std::mt19937 gen(rd()); // Standard mersenne_twister_engine seeded with rd()\n  std::uniform_real_distribution&lt;&gt; dis(1.0, 2.0);\n\n  // C = alpha * op(A) * op(B)  + beta * C\n  oneapi::math::transpose transA = oneapi::math::transpose::nontrans;\n  oneapi::math::transpose transB = oneapi::math::transpose::nontrans;\n\n  // matrix data sizes\n  int m = M;\n  int n = P;\n  int k = N;\n\n  // leading dimensions of data\n  int ldA = k;\n  int ldB = n;\n  int ldC = n;\n\n  // set scalar fp values\n  double alpha = 1.0;\n  double beta = 0.0;\n\n  // 1D arrays on host side\n  double *A;\n  double *B;\n  double *C_host_onemath, *C_cblas;\n\n  A = new double[M * N]{};\n  B = new double[N * P]{};\n  C_cblas = new double[M * P]{};\n  C_host_onemath = new double[M * P]{};\n\n  // prepare matrix data with ROW-major style\n  // A(M, N)\n  for (size_t i = 0; i &lt; M; i++)\n    for (size_t j = 0; j &lt; N; j++)\n      A[i * N + j] = dis(gen);\n  // B(N, P)\n  for (size_t i = 0; i &lt; N; i++)\n    for (size_t j = 0; j &lt; P; j++)\n      B[i * P + j] = dis(gen);\n\n  std::cout &lt;&lt; \"Problem size: c(\" &lt;&lt; M &lt;&lt; \",\" &lt;&lt; P &lt;&lt; \") = a(\" &lt;&lt; M &lt;&lt; \",\" &lt;&lt; N &lt;&lt; \") * b(\" &lt;&lt; N\n            &lt;&lt; \",\" &lt;&lt; P &lt;&lt; \")\" &lt;&lt; std::endl;\n\n  // Resultant matrix: C_cblas\n  cblas_dgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, m, n, k, alpha, A, ldA, B, ldB, beta,\n              C_cblas, ldC);\n\n  // Resultant matrix: C_onemath\n  sycl::queue q(sycl::property_list{sycl::property::queue::in_order{}});\n  std::cout &lt;&lt; \"Device: \" &lt;&lt; q.get_device().get_info&lt;sycl::info::device::name&gt;() &lt;&lt; std::endl &lt;&lt; std::endl;\n\n  double* A_dev        = sycl::malloc_device&lt;double&gt;(M*N, q);\n  double* B_dev        = sycl::malloc_device&lt;double&gt;(N*P, q);\n  double* C_dev_onemath = sycl::malloc_device&lt;double&gt;(M*P, q);\n\n  q.memcpy(A_dev, A, (M*N) * sizeof(double));\n  q.memcpy(B_dev, B, (N*P) * sizeof(double));\n\n  auto gemm_event = oneapi::math::blas::column_major::gemm(q, transB, transA, n, m, k, alpha, B_dev, ldB, A_dev, ldA, beta, C_dev_onemath, ldC);\n\n  q.memcpy(C_host_onemath, C_dev_onemath, (M*P) * sizeof(double));\n\n  q.wait();\n  std::cout &lt;&lt; \"Verify results between Onemath &amp; CBLAS: \";\n  int result_cblas = VerifyResult(C_cblas, C_host_onemath);\n\n  delete[] A;\n  delete[] B;\n  delete[] C_cblas;\n  delete[] C_host_onemath;\n  sycl::free(A_dev, q);\n  sycl::free(B_dev, q);\n  sycl::free(C_dev_onemath, q);\n  return result_cblas;\n}\n</code></pre></p> <p>Compile and Run</p> <p>The user would need to provide paths to the math libraries as shown below. Also, please provide the AOCL library for CPU GEMM by <code>module load aocl</code>. Environment variables <code>MKLROOT</code> is defined with the <code>oneapi</code> module &amp; <code>AOCL_ROOT</code> is defined with the <code>aocl</code> module. Note: Please pay attention to the linker options for AOCL &amp; oneMath libraries. <pre><code>$ clang++ -std=c++17 -sycl-std=2020 -O3 -fsycl -fsycl-targets=nvptx64-nvidia-cuda -Xsycl-target-backend --cuda-gpu-arch=sm_80 -L$AOCL_ROOT/lib -lblis -L$MKLROOT/lib -lonemath sycl_onemath_gemm.cpp -o sycl_onemath_gemm.out\n</code></pre></p>"},{"location":"polaris/programming-models/sycl-polaris/#further-documentation","title":"Further documentation","text":"<p>There is additional documentation on how to get good performance available on the Codeplay Developer website.</p>"},{"location":"polaris/running-jobs/","title":"Running Jobs on Polaris","text":""},{"location":"polaris/running-jobs/#queues","title":"Queues","text":"<p>There are five production queues you can target in your qsub (<code>-q &lt;queue name&gt;</code>):</p> Queue Name Node Min Node Max Time Min Time Max Notes debug 1 2 5 min 1 hr max 24 nodes in use by this queue at any given time; Only 8 nodes are exclusive (see Note below) debug-scaling 1 10 5 min 1 hr max 1 job running/accruing/queued per-user prod 10 496 5 min 24 hrs Routing queue; See below preemptable 1 10 5 min 72 hrs Please be aware that jobs in the preemptable queue can be killed at any time if jobs are submitted to the demand queue. Max 20 jobs running/accruing/queued per-project; see Note below demand 1 56 5 min 1 hr By request only; max 100 jobs running/accruing/queued per-project <p>Note: Please be aware that jobs in the preemptable queue can be killed at any time if jobs are submitted to the demand queue. Jobs in the demand queue take priority over jobs in the preemptable queue. This means jobs in the preemptable queue may be preempted (killed without any warning) if there are jobs in the demand queue. Unfortunately, there's always an inherent risk of jobs being killed when using the preemptable queue.  Please use the following command to view details of a queue: <code>qstat -Qf &lt;queuename&gt;</code></p> <p>To make your job rerunnable, add the following PBS directive: <code>#PBS -r y</code>. This will ensure your job will restart once the demand job is complete. </p> <p>Note: The debug queue has 8 exclusively dedicated nodes. If there are free nodes in production, then debug jobs can take another 16 nodes for a total of 24.</p> <p><code>prod</code> is a routing queue and routes your job to one of the following six execution queues:</p> Queue Name Node Min Node Max Time Min Time Max Notes small 10 24 5 min 3 hrs medium 25 99 5 min 6 hrs large 100 496 5 min 24 hrs backfill-small 10 24 5 min 3 hrs low priority, negative project balance backfill-medium 25 99 5 min 6 hrs low priority, negative project balance backfill-large 100 496 5 min 24 hrs low priority, negative project balance <ul> <li>Note 1: You cannot submit to these queues directly; you can only submit to the routing queue \"<code>prod</code>\".</li> <li>Note 2: All of these queues have a limit of ten (10) jobs running/accruing per-project.</li> <li>Note 3: All of these queues have a limit of one hundred (100) jobs queued (not accruing score) per-project.</li> <li>Note 4: As of January 2023, it is recommended to submit jobs with a maximum node count of 476-486 nodes given current rates of downed nodes (larger jobs may sit in the queue indefinitely).</li> </ul>"},{"location":"polaris/running-jobs/#interactive-jobs-on-compute-nodes","title":"Interactive Jobs on Compute Nodes","text":"<p>Here is how to submit an interactive job to, for example, edit/build/test an application on Polaris compute nodes: <pre><code>qsub -I -l select=1 -l filesystems=home:eagle -l walltime=1:00:00 -q debug -A &lt;project_name&gt;\n</code></pre></p> <p>This command requests 1 node for a period of 1 hour in the debug queue, requiring access to the <code>/home</code> and <code>/eagle</code> filesystems. After waiting in the queue for a node to become available, a shell prompt on a compute node will appear. You may then start building applications and testing GPU affinity scripts on the compute node.</p> <p>Info</p> <p>If you want to <code>ssh</code> or <code>scp</code> to one of your assigned compute nodes, you will need to make sure your <code>$HOME</code> directory and your <code>$HOME/.ssh</code> directory permissions are both set to <code>700</code>.</p>"},{"location":"polaris/running-jobs/#running-mpiopenmp-applications","title":"Running MPI+OpenMP Applications","text":"<p>Once a submitted job is running, calculations can be launched on the compute nodes using <code>mpiexec</code> to start an MPI application. Documentation is accessible via <code>man mpiexec</code>, and some helpful options follow.</p> <ul> <li><code>-n</code> total number of MPI ranks</li> <li><code>-ppn</code> number of MPI ranks per node</li> <li><code>--cpu-bind</code> CPU binding for application</li> <li><code>--depth</code> number of CPUs per rank (useful with <code>--cpu-bind</code>)</li> <li><code>--env</code> set environment variables (<code>--env OMP_NUM_THREADS=2</code>)</li> <li><code>--hostfile</code> indicate file with hostnames (the default is <code>--hostfile $PBS_NODEFILE</code>)</li> </ul> <p>A sample submission script with directives is below for a 4-node job with 8 MPI ranks on each node and 8 OpenMP threads per rank. Each hardware thread runs a single OpenMP thread since there are 64 hardware threads on the CPU (2 per core). You can download and compile <code>hello_affinity</code> from this link.</p> <pre><code>#!/bin/bash -l\n#PBS -N AFFINITY\n#PBS -l select=4:ncpus=256\n#PBS -l walltime=0:10:00\n#PBS -q debug-scaling\n#PBS -A Catalyst  # Replace with your project\n\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS=8 # Number of MPI ranks to spawn per node\nNDEPTH=8 # Number of hardware threads per rank (i.e. spacing between MPI ranks)\nNTHREADS=8 # Number of software threads per rank to launch (i.e. OMP_NUM_THREADS)\n\nNTOTRANKS=$(( NNODES * NRANKS ))\n\necho \"NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS} THREADS_PER_RANK= ${NTHREADS}\"\n\n# Change the directory to work directory, which is the directory you submit the job.\ncd $PBS_O_WORKDIR\nmpiexec --np ${NTOTRANKS} -ppn ${NRANKS} -d ${NDEPTH} --cpu-bind depth -env OMP_NUM_THREADS=${NTHREADS} ./hello_affinity\n</code></pre>"},{"location":"polaris/running-jobs/#compute-node-access-to-the-internet","title":"Compute Node Access to the Internet","text":"<p>Currently, the only access to the internet is via a proxy. Here are the proxy environment variables for Polaris:</p> <pre><code>export http_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport https_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport ftp_proxy=\"http://proxy.alcf.anl.gov:3128\"\n</code></pre> <p>In the future, though we don't have a timeline on this because it depends on future features in Slingshot and internal software development, we intend to have public IP addresses be a schedulable resource. For instance, if only your head node needed public access, your select statement might look something like: <code>-l select=1:pubnet=True+63</code>.</p>"},{"location":"polaris/running-jobs/#controlling-where-your-job-runs","title":"Controlling Where Your Job Runs","text":"<p>If you wish to have your job run on specific nodes, form your select like this: <code>-l select=1:vnode=&lt;node name1&gt;+1:vnode=&lt;node name2&gt;...</code>. Obviously, that gets tedious for large jobs.</p> <p>If you want to control the location of a few nodes, for example, 2 out of 64, but the rest don't matter, you can do something like this: <code>-l select=1:vnode=&lt;node name1&gt;+1:vnode=&lt;node name2&gt;+62:system=foo</code>.</p> <p>Every node has a PBS resource called <code>tier0</code> with a rack identifier and <code>tier1</code> with a dragonfly group identifier. If you want all your nodes grouped in a rack, you can add the group specifier <code>-l select=8:system=foo,place=scatter:group=tier0</code>. If you wanted everything in the same dragonfly group, replace <code>tier0</code> with <code>tier1</code>. Note that you have to also explicitly specify the place when you use group. If you wanted a specific rack or dragonfly group instead of any of them, you are back to the select: <code>-l select 10:tier0=x3001-g0</code>.</p>"},{"location":"polaris/running-jobs/#network-rack-and-dragonfly-group-mappings","title":"Network: Rack and Dragonfly Group Mappings","text":"<ul> <li>Racks contain (7) 6U chassis; each chassis has 2 nodes for 14 nodes per rack</li> <li>The hostnames are of the form xRRPPc0sUUb[0|1]n0 where:<ul> <li>RR is the row {30, 31, 32}</li> <li>PP is the position in the row {30 goes 1-16, 31 and 32 go 1-12}</li> <li>c is chassis and is always 0</li> <li>s stands for slot, but in this case is the RU in the rack and values are {1,7,13,19,25,31,37}</li> <li>b is BMC controller and is 0 or 1 (each node has its own BMC)</li> <li>n is node, but is always 0 since there is only one node per BMC</li> </ul> </li> <li>So, 16+12+12 = 40 racks * 14 nodes per rack = 560 nodes.</li> <li>Note that in production group 9 (the last 4 racks) will be the designated on-demand racks</li> <li>The management racks are x3000 and X3100 and are dragonfly group 10</li> <li>The TDS rack is x3200 and is dragonfly group 11</li> <li>Each compute node will have a PBS resource named <code>tier0</code> which will be equal to the values in the table below. This allows you to group your jobs within a rack if you wish. There is also a resource called <code>tier1</code> which will be equal to the column headings. This allows you to group your jobs within a dragonfly group if you wish.</li> </ul> g0 g1 g2 g3 g4 g5 g6 g7 g8 g9 x3001-g0 x3005-g1 x3009-g2 x3013-g3 x3101-g4 x3105-g5 x3109-g6 x3201-g7 x3205-g8 x3209-g9 x3002-g0 x3006-g1 x3010-g2 x3014-g3 x3102-g4 x3106-g5 x3110-g6 x3202-g7 x3206-g8 x3210-g9 x3003-g0 x3007-g1 x3011-g2 x3015-g3 x3103-g4 x3107-g5 x3111-g6 x3203-g7 x3207-g8 x3211-g9 x3004-g0 x3008-g1 x3012-g2 x3016-g3 x3104-g4 x3108-g5 x3112-g6 x3204-g7 x3208-g8 x3212-g9"},{"location":"polaris/running-jobs/using-gpus/","title":"Using GPUs on Polaris Compute Nodes","text":"<p>Polaris compute nodes each have 4 NVIDIA A100 GPUs; more details are in Machine Overview.</p>"},{"location":"polaris/running-jobs/using-gpus/#discovering-gpus","title":"Discovering GPUs","text":"<p>When on a compute node (for example in an Interactive Job), you can discover information about the available GPUs, and processes running on them, with the command <code>nvidia-smi</code>.</p>"},{"location":"polaris/running-jobs/using-gpus/#running-gpu-enabled-applications","title":"Running GPU-enabled Applications","text":"<p>GPU-enabled applications will run on the compute nodes using PBS submission scripts like the ones in Running Jobs.</p> <p>Some GPU specific considerations:</p> <ul> <li>The environment variable <code>MPICH_GPU_SUPPORT_ENABLED=1</code> needs to be set if your application requires GPU-aware MPI support whereby the MPI library sends and receives data directly from GPU buffers. In this case, it will be important to have the <code>craype-accel-nvidia80</code> module loaded both when compiling your application and during runtime to correctly link against a GPU Transport Layer (GTL) MPI library. Otherwise, you'll likely see <code>GPU_SUPPORT_ENABLED is requested, but GTL library is not linked</code> errors during runtime.</li> <li>If running on a specific GPU or subset of GPUs is desired, then the <code>CUDA_VISIBLE_DEVICES</code> environment variable can be used. For example, if one only wanted an application to access the first two GPUs on a node, then setting <code>CUDA_VISIBLE_DEVICES=0,1</code> could be used.</li> </ul>"},{"location":"polaris/running-jobs/using-gpus/#binding-mpi-ranks-to-gpus","title":"Binding MPI ranks to GPUs","text":"<p>The Cray MPI on Polaris does not currently support binding MPI ranks to GPUs. For applications that need this support, this instead can be handled by use of a small helper script that will appropriately set <code>CUDA_VISIBLE_DEVICES</code> for each MPI rank. One example is available here where each MPI rank is similarly bound to a single GPU with round-robin assignment.</p> <p>An example <code>set_affinity_gpu_polaris.sh</code> script follows where GPUs are assigned round-robin to MPI ranks.</p> <p>set_affinity_gpu_polaris.sh<pre><code>#!/bin/bash -l\nnum_gpus=4\n# need to assign GPUs in reverse order due to topology\n# See Polaris Device Affinity Information:\n# https://www.alcf.anl.gov/support/user-guides/polaris/hardware-overview/machine-overview/index.html\ngpu=$((${num_gpus} - 1 - ${PMI_LOCAL_RANK} % ${num_gpus}))\nexport CUDA_VISIBLE_DEVICES=$gpu\necho \"RANK= ${PMI_RANK} LOCAL_RANK= ${PMI_LOCAL_RANK} gpu= ${gpu}\"\nexec \"$@\"\n</code></pre> This script can be placed just before the executable in the <code>mpiexec</code> command like so: <pre><code>mpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth ./set_affinity_gpu_polaris.sh ./hello_affinity\n</code></pre> Users with different needs, such as assigning multiple GPUs per MPI rank, can modify the above script to suit their needs.</p>"},{"location":"polaris/running-jobs/using-gpus/#running-multiple-mpi-applications-on-a-node","title":"Running Multiple MPI Applications on a Node","text":"<p>Multiple applications can be run simultaneously on a node by launching several <code>mpiexec</code> commands and backgrounding them. For performance, it will likely be necessary to ensure that each application runs on a distinct set of CPU resources and/or targets specific GPUs. One can provide a list of CPUs using the <code>--cpu-bind</code> option, which when combined with <code>CUDA_VISIBLE_DEVICES</code> provides a user with specifying exactly which CPU and GPU resources to run each application on. In the example below, four instances of the application are simultaneously running on a single node. In the first instance, the application is spawning MPI ranks 0-7 on CPUs 24-31 and using GPU 0. This mapping is based on output from the <code>nvidia-smi topo -m</code> command and pairs CPUs with the closest GPU.</p> <pre><code>export CUDA_VISIBLE_DEVICES=0\nmpiexec -n 8 --ppn 8 --cpu-bind list:24:25:26:27:28:29:30:31 ./hello_affinity &amp;\n\nexport CUDA_VISIBLE_DEVICES=1\nmpiexec -n 8 --ppn 8 --cpu-bind list:16:17:18:19:20:21:22:23 ./hello_affinity &amp;\n\nexport CUDA_VISIBLE_DEVICES=2\nmpiexec -n 8 --ppn 8 --cpu-bind list:8:9:10:11:12:13:14:15 ./hello_affinity &amp;\n\nexport CUDA_VISIBLE_DEVICES=3\nmpiexec -n 8 --ppn 8 --cpu-bind list:0:1:2:3:4:5:6:7 ./hello_affinity &amp;\n\nwait\n</code></pre>"},{"location":"polaris/running-jobs/using-gpus/#running-multiple-processes-per-gpu","title":"Running Multiple Processes per GPU","text":"<p>There are 2 approaches to launching multiple concurrent processes on a single Nvidia GPU: using the Multi-Process Service (MPS) which will run multiple logical threads per device and using MIG Mode which physically partitions the GPU for thread execution.</p>"},{"location":"polaris/running-jobs/using-gpus/#using-mps-on-the-gpus","title":"Using MPS on the GPUs","text":"<p>Documentation for the NVIDIA Multi-Process Service (MPS) can be found here</p> <p>In the script below, note that if you are going to run this as a multi-node job you will need to do this on every compute node, and you will need to ensure that the paths you specify for <code>CUDA_MPS_PIPE_DIRECTORY</code> and <code>CUDA_MPS_LOG_DIRECTORY</code> do not \"collide\" and end up with all the nodes writing to the same place.</p> <p>An example is available in the Getting Started Repo and discussed below. The local SSDs or <code>/dev/shm</code> or incorporation of the node name into the path would all be possible ways of dealing with that issue.</p> <pre><code>#!/bin/bash -l\nexport CUDA_MPS_PIPE_DIRECTORY=&lt;/path/writeable/by/you&gt;\nexport CUDA_MPS_LOG_DIRECTORY=&lt;/path/writeable/by/you&gt;\nCUDA_VISIBLE_DEVICES=0,1,2,3 nvidia-cuda-mps-control -d\necho \"start_server -uid $( id -u )\" | nvidia-cuda-mps-control\n</code></pre> <p>To verify the control service is running:</p> <pre><code>nvidia-smi | grep -B1 -A15 Processes\n</code></pre> <p>And the output should look similar to this:</p> <pre><code>+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|    0   N/A  N/A     58874      C   nvidia-cuda-mps-server             27MiB |\n|    1   N/A  N/A     58874      C   nvidia-cuda-mps-server             27MiB |\n|    2   N/A  N/A     58874      C   nvidia-cuda-mps-server             27MiB |\n|    3   N/A  N/A     58874      C   nvidia-cuda-mps-server             27MiB |\n+-----------------------------------------------------------------------------+\n</code></pre> <p>To shut down the service:</p> <p><code>echo \"quit\" | nvidia-cuda-mps-control</code></p> <p>To verify the service shut down properly:</p> <p><code>nvidia-smi | grep -B1 -A15 Processes</code></p> <p>And the output should look like this:</p> <pre><code>+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n</code></pre> <p>In some instances, users may find it useful to set the environment variable <code>CUDA_MPS_ACTIVE_THREAD_PERCENTAGE</code> which limits the fraction of the GPU available to a MPS process.  Over provisioning of the GPU is permitted, i.e. the sum across all MPS processes may exceed 100 per cent.</p>"},{"location":"polaris/running-jobs/using-gpus/#using-mps-in-multi-node-jobs","title":"Using MPS in Multi-node Jobs","text":"<p>As stated earlier, it is important to start the MPS control service on each node in a job that requires it. An example is available in the Getting Started Repo. The helper script <code>enable_mps_polaris.sh</code> can be used to start the MPS on a node.</p> <pre><code>#!/bin/bash -l\n\nexport CUDA_MPS_PIPE_DIRECTORY=/tmp/nvidia-mps\nexport CUDA_MPS_LOG_DIRECTORY=/tmp/nvidia-log\nCUDA_VISIBLE_DEVICES=0,1,2,3 nvidia-cuda-mps-control -d\necho \"start_server -uid $( id -u )\" | nvidia-cuda-mps-control\n</code></pre> <p>The helper script <code>disable_mps_polaris.sh</code> can be used to disable MPS at appropriate points during a job script, if needed.</p> <pre><code>#!/bin/bash -l\n\necho quit | nvidia-cuda-mps-control\n</code></pre> <p>In the example job script <code>submit.sh</code> below, MPS is first enabled on all nodes in the job using <code>mpiexec -n ${NNODES} --ppn 1</code> to launch the enablement script using a single MPI rank on each compute node. The application is then run as normally. If desired, a similar one-rank-per-node <code>mpiexec</code> command can be used to disable MPS on all the nodes in a job.</p> <pre><code>#!/bin/bash -l\n#PBS -l select=1:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -q debug\n#PBS -A Catalyst\n#PBS -l filesystems=home:eagle\n\ncd ${PBS_O_WORKDIR}\n\n# MPI example w/ 8 MPI ranks per node spread evenly across cores\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=8\nNDEPTH=8\nNTHREADS=1\n\nNTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))\necho \"NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}\"\n\n# Enable MPS on each node allocated to job\nmpiexec -n ${NNODES} --ppn 1 ./enable_mps_polaris.sh\n\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth ./hello_affinity\n\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth ./set_affinity_gpu_polaris.sh ./hello_affinity\n\n# Disable MPS on each node allocated to job\nmpiexec -n ${NNODES} --ppn 1 ./disable_mps_polaris.sh\n</code></pre>"},{"location":"polaris/running-jobs/using-gpus/#multi-instance-gpu-mig-mode","title":"Multi-Instance GPU (MIG) mode","text":"<p>MIG mode can be enabled and configured on Polaris by passing a valid configuration file to <code>qsub</code>: <pre><code>qsub ... -l mig_config=/home/ME/path/to/mig_config.json ...\n</code></pre></p> <p>You can find a concise explanation of MIG concepts and terms at NVIDIA MIG User Guide.</p>"},{"location":"polaris/running-jobs/using-gpus/#configuration","title":"Configuration","text":"<p>Please study the following example of a valid configuration file:</p> <pre><code>{\n  \"group1\": {\n    \"gpus\": [0,1],\n    \"mig_enabled\": true,\n    \"instances\": {\"7g.40gb\": [\"4c.7g.40gb\", \"3c.7g.40gb\"] }\n  },\n  \"group2\": {\n    \"gpus\": [2,3],\n    \"mig_enabled\": true,\n    \"instances\": {\"3g.20gb\": [\"2c.3g.20gb\", \"1c.3g.20gb\"], \"2g.10gb\": [\"2g.10gb\"], \"1g.5gb\": [\"1g.5gb\"]}\n  }\n}\n</code></pre>"},{"location":"polaris/running-jobs/using-gpus/#notes","title":"Notes","text":"<ul> <li>Group names are arbitrary but must be unique.</li> <li><code>\"gpus\"</code> must be an array of integers. If only one physical GPU is being configured in a group, it must still be contained within an array (e.g., <code>\"gpus\": [0],</code>).</li> <li>Only groups with <code>mig_enabled</code> set to <code>true</code> will be configured.</li> <li><code>instances</code> denote the MIG GPU instances and the nested compute instances you wish to be configured.</li> <li>Syntax is <code>{\"gpu instance 1\": [\"cpu instance 1\", \"cpu instance 2\"], ...}</code>.</li> <li>Valid GPU instances are <code>1g.5gb</code>, <code>1g.10gb</code>, <code>2g.10gb</code>, <code>3g.20gb</code>, <code>4g.20gb</code>, and <code>7g.40gb</code>. The first number denotes the number of slots used out of 7 total, and the second number denotes memory in GB.</li> <li>The default CPU instance for any GPU instance has the same identifier as the GPU instance (in which case it will be the only one configurable).</li> <li>Other CPU instances can be configured with the identifier syntax <code>Xc.Y</code>, where <code>X</code> is the number of slots available in that GPU instance, and <code>Y</code> is the GPU instance identifier string.</li> <li>Some GPU instances cannot be configured adjacently, despite there being sufficient slots/memory remaining (e.g., <code>3g.20gb</code> and <code>4g.20gb</code>). Please see NVIDIA MIG documentation for further details.</li> <li>Currently, MIG configuration is only available in the debug, debug-scaling, and preemptable queues. Submissions to other queues will result in any MIG config files passed being silently ignored.</li> <li>Files that do not match the above syntax will be silently rejected, and any invalid configurations in properly formatted files will be silently ignored. Please test any changes to your configuration in an interactive job session before use.</li> <li>A basic validator script is available at <code>/soft/pbs/mig_conf_validate.sh</code>. It will check for simple errors in your config and print the expected configuration. For example:</li> </ul> <pre><code>ascovel@polaris-login-02:~&gt; /soft/pbs/mig_conf_validate.sh -h\nusage: mig_conf_validate.sh -c CONFIG_FILE\nascovel@polaris-login-02:~&gt; /soft/pbs/mig_conf_validate.sh -c ./polaris-mig/mig_config.json\nexpected MIG configuration:\nGPU     GPU_INST   COMPUTE_INST\n-------------------------------\n0       7g.40gb    4c.7g.40gb\n0       7g.40gb    3c.7g.40gb\n1       7g.40gb    4c.7g.40gb\n1       7g.40gb    3c.7g.40gb\n2       2g.10gb    2g.10gb\n2       4g.20gb    2c.4g.20gb\n2       4g.20gb    2c.4g.20gb\n3       2g.10gb    2g.10gb\n3       4g.20gb    2c.4g.20gb\n3       4g.20gb    2c.4g.20gb\nascovel@polaris-login-02:~&gt;\n</code></pre>"},{"location":"polaris/running-jobs/using-gpus/#example-use-of-mig-compute-instances","title":"Example use of MIG compute instances","text":"<p>The following example demonstrates the use of MIG compute instances via the <code>CUDA_VISIBLE_DEVICES</code> environment variable:</p> <pre><code>ascovel@polaris-login-02:~/polaris-mig&gt; qsub -l mig_config=/home/ascovel/polaris-mig/mig_config.json -l select=1 -l walltime=60:00 -l filesystems=home:eagle -A Operations -q R639752 -k doe -I\nqsub: waiting for job 640002.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov to start\nqsub: job 640002.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov ready\n\nascovel@x3209c0s19b0n0:~&gt; cat ./polaris-mig/mig_config.json\n{\n  \"group1\": {\n    \"gpus\": [0,1],\n    \"mig_enabled\": true,\n    \"instances\": {\"7g.40gb\": [\"4c.7g.40gb\", \"3c.7g.40gb\"] }\n  },\n  \"group2\": {\n    \"gpus\": [2,3],\n    \"mig_enabled\": true,\n    \"instances\": {\"4g.20gb\": [\"2c.4g.20gb\", \"2c.4g.20gb\"], \"2g.10gb\": [\"2g.10gb\"] }\n  }\n}\nascovel@x3209c0s19b0n0:~&gt; nvidia-smi -L | grep -Po -e \"MIG[0-9a-f\\-]+\"\nMIG-63aa1884-acb8-5880-a586-173f6506966c\nMIG-b86283ae-9953-514f-81df-99be7e0553a5\nMIG-79065f64-bdbb-53ff-89e3-9d35f270b208\nMIG-6dd56a9d-e362-567e-95b1-108afbcfc674\nMIG-76459138-79df-5d00-a11f-b0a2a747bd9e\nMIG-4d5c9fb3-b0e3-50e8-a60c-233104222611\nMIG-bdfeeb2d-7a50-5e39-b3c5-767838a0b7a3\nMIG-87a2c2f3-d008-51be-b64b-6adb56deb679\nMIG-3d4cdd8c-fc36-5ce9-9676-a6e46d4a6c86\nMIG-773e8e18-f62a-5250-af1e-9343c9286ce1\nascovel@x3209c0s19b0n0:~&gt; for mig in $( nvidia-smi -L | grep -Po -e \"MIG[0-9a-f\\-]+\" ) ; do CUDA_VISIBLE_DEVICES=${mig} ./saxpy &amp; done 2&gt;/dev/null\nascovel@x3209c0s19b0n0:~&gt; nvidia-smi | tail -n 16\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|    0    0    0      17480      C   ./saxpy                          8413MiB |\n|    0    0    1      17481      C   ./saxpy                          8363MiB |\n|    1    0    0      17482      C   ./saxpy                          8413MiB |\n|    1    0    1      17483      C   ./saxpy                          8363MiB |\n|    2    1    0      17484      C   ./saxpy                          8313MiB |\n|    2    1    1      17485      C   ./saxpy                          8313MiB |\n|    2    5    0      17486      C   ./saxpy                          8313MiB |\n|    3    1    0      17487      C   ./saxpy                          8313MiB |\n|    3    1    1      17488      C   ./saxpy                          8313MiB |\n|    3    5    0      17489      C   ./saxpy                          8313MiB |\n+-----------------------------------------------------------------------------+\nascovel@x3209c0s19b0n0:~&gt;\n</code></pre>"},{"location":"polaris/visualization/","title":"Visualization on Polaris","text":"<p>Starting in January 2024, Polaris will serve as the primary production resource for visualization and analysis.</p> <p>Below is a list of the available visualization tools along with links to their corresponding documentation.</p> <p>ParaView: ParaView is an open-source visualization engine that seamlessly integrates with your existing tools and workflows. It allows you to construct visualization pipelines for quick data analysis. Whether interactively exploring large datasets in 3D or performing batch processing programmatically, ParaView provides versatile capabilities. For additional information, visit the Kitware website.</p> <p>VisIt: VisIt is an open-source, interactive, and scalable visualization, animation, and analysis tool. Users can rapidly generate visualizations, animate them over time, apply various operators and mathematical expressions, and save resulting images and animations for presentations. VisIt supports a diverse range of visualization features, enabling users to view data, including scalar and vector fields, on 2D and 3D structured, adaptive, and unstructured meshes. Thanks to its customizable plugin design, VisIt can visualize data from over 120 different scientific data formats. For more information, check the VisIt project GitHub page.</p> <p>FFmpeg: FFmpeg is a complete solution to record, convert, and stream audio and video. For more information, visit the FFmpeg webpage.</p> <p>ImageMagick: ImageMagick is a free, open-source software suite used for editing and manipulating digital images. It can be used to create, edit, compose, or convert bitmap images, and supports a wide range of file formats, including JPEG, PNG, GIF, TIFF, and PDF. More information is available on the ImageMagick webpage.</p>"},{"location":"polaris/visualization/ffmpeg/","title":"FFmpeg on Polaris","text":""},{"location":"polaris/visualization/ffmpeg/#note-the-ffmpeg-module-is-currently-missing-on-polaris-after-a-recent-upgrade-a-spack-build-of-ffmpeg-will-be-available-soon","title":"NOTE: The FFmpeg module is currently missing on Polaris after a recent upgrade. A Spack build of FFmpeg will be available soon.","text":"<p>To use FFmpeg on Polaris, first load the corresponding module:</p> <pre><code>module load ffmpeg\n</code></pre> <p>This is a typical command line to create a movie from a series of snapshots in PNG format:</p> <pre><code>ffmpeg -r 15 -i frames.%03d.png -r 25 -pix_fmt yuv420p movie.mp4\n</code></pre> <p>where:</p> <ul> <li><code>-r 15</code> is the input frame rate. Experiment with values smaller than the output frame rate for longer movies.</li> <li><code>-r 25</code> is the output frame rate (use this value for standard 25 frames per second).</li> <li><code>-i frames.%03d.png</code> reads the input frames in sequence.</li> <li><code>-pix_fmt yuv420p</code> is needed for movies to play in browsers.</li> <li><code>movie.mp4</code> is the resulting movie.</li> </ul>"},{"location":"polaris/visualization/imagemagick/","title":"ImageMagick on Polaris","text":"<p>To use ImageMagick on Polaris, first load the corresponding module:</p> <pre><code>module use /soft/modulefiles\nmodule load spack-pe-base imagemagick\n</code></pre>"},{"location":"polaris/visualization/paraview-manual-launch/","title":"Manually launching a ParaView server on Polaris","text":"<p>Sometimes it is convenient to manually launch an instance of the ParaView server. In this section, we will explain an alternative method to run the ParaView server on Polaris using an interactive job, where the user can launch the ParaView server from the command line interface.</p> <p>Note: this method is better suited for experienced users. If you are just starting with ParaView, we recommend the client/server mode as your primary method for using this tool.</p>"},{"location":"polaris/visualization/paraview-manual-launch/#setting-up-paraview","title":"Setting up ParaView","text":"<p>From your local client, select Connect, either from the File menu or by clicking on the icon circled below:</p> <p> </p> <p>A new window will open where you can configure a server. Click on Add Server:</p> <p></p> <p>Give your server a name, select Client/Server, localhost, and a TCP port (8000 in this example).</p> <p></p> <p>Click \"Configure\". In the next window, there is an option to set up how the ParaView server will be launched, and the default is \"Manual\". Leave it on \"Manual\" and click \"Save\".</p> <p>You will use these settings when establishing the connection.</p>"},{"location":"polaris/visualization/paraview-manual-launch/#launching-the-paraview-server-on-polaris","title":"Launching the ParaView server on Polaris","text":"<p>You can launch an interactive session on Polaris compute nodes with the following command (adjust parameters as needed to match your allocation, desired number of nodes, queue, walltime, and filesystems):</p> <pre><code>qsub -l walltime=01:00:00 -l select=2 -A yourallocation -q debug -I -l filesystems=home:eagle\n</code></pre> <p>When the job starts, you will receive a prompt on your head node like this:</p> <pre><code>username@x3005c0s7b0n0:~&gt;\n</code></pre> <p>Make a note of the node hostname (<code>x3005c0s7b0n0</code> in the example above). You can also get this information from <code>qstat -fx jobID</code>.</p> <p>Now load the ParaView module:</p> <pre><code>username@x3005c0s7b0n0:~&gt; module use /soft/modulefiles \nusername@x3005c0s7b0n0:~&gt; module load visualization/paraview/paraview-5.12.0-EGL\n</code></pre> <p>and launch the ParaView server with:</p> <pre><code>username@x3005c0s7b0n0:~&gt; mpirun -n 8 pvserver --server-port=8000\nWaiting for client...\nConnection URL: cs://x3005c0s7b0n0:8000\nAccepting connection(s): x3005c0s7b0n0:8000\n</code></pre> <p>In this case, <code>pvserver</code> will be listening on TCP port 8000 of your head node. You can change this port if you want.</p>"},{"location":"polaris/visualization/paraview-manual-launch/#creating-a-tunnel-over-ssh","title":"Creating a tunnel over ssh","text":"<p>We need to establish an ssh tunnel to connect the client to the server. On your local machine, open a new terminal and type:</p> <pre><code>ssh -v -N -L 8000:x3005c0s7b0n0:8000 polaris.alcf.anl.gov\n</code></pre> <p>where 8000 is a TCP port and <code>x3005c0s7b0n0</code> is the name of your head node. Adjust these values accordingly.</p> <p>Among multiple lines with debug information, you should see something like:</p> <pre><code>debug1: Local connections to LOCALHOST:8000 forwarded to remote address x3005c0s7b0n0:8000\n</code></pre> <p>Keep this terminal open for the duration of your session to keep the ssh tunnel active.</p> <p>Now you are ready to launch your ParaView client locally. Keep in mind that client and server versions must match. The ParaView version currently deployed on Polaris is 5.12.0.</p>"},{"location":"polaris/visualization/paraview-manual-launch/#connecting-to-paraview-server","title":"Connecting to ParaView server","text":"<p>Connect your ParaView client to the server configuration you created above. You can select Connect, either from the File menu or the icon circled in the figure:</p> <p> </p> <p>and select the configuration you created in a previous step.</p> <p>The connection should point to:</p> <pre><code>localhost:8000\n</code></pre> <p>In the terminal where you launched the server, you will see now that the connection is established. Note that ParaView may take a few seconds to connect. This is normal behavior.</p> <pre><code>username@x3005c0s7b0n0:~&gt; mpirun -n 8 pvserver --server-port=8000\nWaiting for client...\nConnection URL: cs://x3005c0s7b0n0:8000\nAccepting connection(s): x3005c0s7b0n0:8000\nClient connected.\n</code></pre> <p>At this point, you can use ParaView normally.</p>"},{"location":"polaris/visualization/paraview-tutorial/","title":"ParaView Tutorial","text":""},{"location":"polaris/visualization/paraview-tutorial/#overview","title":"Overview","text":"<p>This tutorial is intended to be a hands-on resource for users interested in learning the basic concepts of ParaView. The examples can easily be run on a laptop, using the example data set provided.</p> <ul> <li>Tour of ParaView</li> <li>Show range of visualization methods</li> <li>Walk through various visualization techniques, hopefully illustrating how these can apply to your own data</li> <li>Feel for ParaView \"way\"</li> <li>Terminology and step-by-step process peculiar to ParaView, which may differ from other packages, e.g., VisIt</li> </ul> <p> </p> Bloodflow Visualization by Joe Insley, ALCF"},{"location":"polaris/visualization/paraview-tutorial/#data","title":"Data","text":"<p>The data used for this tutorial is:</p> <ul> <li>Blood flow simulation data</li> <li>Multiple data types</li> <li>Continuum data field (unstructured mesh, tetrahedral): fluid field, plasma</li> <li>Particle data (unstructured points): individual particles moving in the flow</li> <li>Red Blood Cells (RBC, unstructured mesh, triangle): mesh of the surface of an RBC<ul> <li>Healthy</li> <li>Diseased</li> </ul> </li> <li>Generated using an integrated Nektar/LAMMPS simulation code</li> <li>Courtesy of George Karniadakis and Leopold Grinberg of Brown University</li> </ul> <p>The data is available for download here (~27MB compressed, ~39MB uncompressed): Data set for ParaView Red Blood Cell Tutorial</p>"},{"location":"polaris/visualization/paraview-tutorial/#1-load-multi-component-dataset","title":"1. Load Multi-component Dataset","text":"<ul> <li>From the File menu, (you can also click the file folder icon, shown above) open each of the following data sets (select then click \"OK\").</li> <li>The files will then appear in the Pipeline Browser.</li> <li>Click Apply in the Object Inspector.</li> <li>You will need to do this one at a time:</li> <li>continuum...vtu</li> <li>particles...vtu</li> <li>rbc_...vtu</li> <li>bad_rbc...vtu</li> </ul> <p>Note: The \"...\" in the name, and the arrow in the file browser, indicates that there are multiple time steps for each of these files.</p> <p> </p> With all of the default settings, you should see something like this"},{"location":"polaris/visualization/paraview-tutorial/#2-select-which-data-to-view","title":"2. Select which data to view","text":"<p>Let's start by looking at the continuum.000* data. This is an unstructured mesh that has velocity and count (density) values.</p> <ul> <li>Hide other data sets using the Eyeball icon next to their names in the Pipeline Browser.</li> <li>Black = visible, Grey = hidden</li> <li>Select continuum.000* (name is highlighted) in the Pipeline Browser.</li> <li>Click on the name to highlight it.</li> <li>When manipulating appearance or applying filters, these always affect the selected data set.</li> <li>Switch to the Display tab in the Object Inspector.</li> <li>Under Color by, select Velocity from the dropdown.</li> <li>There is also a shortcut to Color by in the menu bar near the top of the GUI.</li> </ul> <p> </p> Select which data to view"},{"location":"polaris/visualization/paraview-tutorial/#3-manipulating-the-color-map","title":"3. Manipulating the Color Map","text":"<p>To change the colors used to represent the Velocity:</p> <ul> <li>Under Color by, click the Edit Color Map... button.</li> <li>On the Color Scale Editor window, click the Choose Preset button.</li> <li>On the Preset Color Scales window, select: Blue to Red Rainbow, and click OK. Then click Close on the Color Scale Editor window.</li> <li>You can also create and save your own color maps.</li> </ul> <p> </p> Manipulating the Color Map"},{"location":"polaris/visualization/paraview-tutorial/#4-data-representation","title":"4. Data Representation","text":"<p>In order to be able to see the particles and red blood cells inside the cylinder, we need to be able to see through it. If we scroll down a bit in the Object Inspector view:</p> <ul> <li>Group of controls labeled Style</li> <li>In the Representation dropdown, select Wireframe</li> </ul> <p> </p> Data Representation"},{"location":"polaris/visualization/paraview-tutorial/#5-generate-streamlines","title":"5. Generate Streamlines","text":"<ul> <li>ParaView enables the generation of different types of data from existing data sets in the Pipeline.</li> <li>Streamlines: Generated from vectors of the flow field. These curves show the direction a fluid element will travel in at any point in time.</li> <li>Make sure that the continuum.000* data is selected in the Pipeline Browser.</li> <li>From the main menu select: Filters-&gt;Alphabetical-&gt;Stream Tracer, or click on the Stream Tracer icon from the menu bar.</li> <li>In the Object Inspector make sure the Properties tab is selected.</li> <li>Scroll down to seeds, and change Seed Type to Line Source.</li> <li>Click the Y Axis button to set the seed line to run along the Y axis.</li> <li>The default Resolution is set to 100. This will make things a bit cluttered, especially when we start adding in the other data, so let's reduce this to 25.</li> <li>Click the Apply button.</li> </ul> Generate Streamlines"},{"location":"polaris/visualization/paraview-tutorial/#6-streamlines-as-tubes","title":"6. Streamlines as Tubes","text":"<p>The streamlines are just that, lines. We can use the Tubes filter to represent them as 3D objects, rather than just lines.</p> <ul> <li>With StreamTracer1 selected in the Pipeline Browser, from the main menu select: Filters-&gt;Alphabetical-&gt;Tube.</li> <li>In the Object Inspector make sure the Properties tab is selected.</li> <li>The default value for the Radius is a bit too large for this data, let's set that value to 0.</li> <li>Click the Apply button.</li> <li>Notice that the StreamLine1 object has automatically been hidden.</li> <li>There are many different ways to color these tubes.</li> <li>With Tubes1 selected, switch to the Display tab in the Object Inspector.</li> <li>The Color by dropdown lets you choose from a handful of different variables.</li> </ul> <p> </p> Streamlines as Tubes"},{"location":"polaris/visualization/paraview-tutorial/#7-cutting-planes-slices","title":"7. Cutting Planes (Slices)","text":"<p>Now let's add some cutting planes, or slices, to see what the cross-section of the continuum data looks like.</p> <ul> <li>Again, be sure that the <code>continuum.000* data</code> is selected in the Pipeline Browser.</li> <li>Filters-&gt;Alphabetical-&gt;Slice or Click on the Slice icon from the menu bar.</li> <li>In the Object Inspector make sure the Properties tab is selected.</li> <li>At the bottom of the Object Inspector is a section titled Slice Offset Values. Here we can generate values for multiple slices to be made.</li> <li>First click the Delete All button to remove initial values.</li> <li>Next, click the New Range button. This will bring up an Add Range dialog box.</li> <li>Set the number of Steps to 7. Click OK.</li> <li>Click the Apply button.</li> <li>With Slice1 selected in the Object Inspector, switch to the Display tab.</li> <li>Set Color by value to Velocity.</li> </ul> <p> </p> Cutting Planes (Slices)"},{"location":"polaris/visualization/paraview-tutorial/#8-data-representation-opacity","title":"8. Data Representation: Opacity","text":"<p>Even with the continuum data represented as wireframe, there is still considerable occlusion of the interior structures. In order to further reduce this occlusion by the wireframe, we can make it more transparent.</p> <ul> <li>Again, be sure that the <code>continuum.000* data</code> is selected in the Pipeline Browser.</li> <li>In the Object Inspector make sure the Display tab is selected.</li> <li>In the Object Inspector there is a section titled Style.</li> <li>Set Opacity to 0.2.</li> </ul> <p> </p> Data Representation: Opacity"},{"location":"polaris/visualization/paraview-tutorial/#9-animating-simulation-data","title":"9. Animating Simulation Data","text":"<p>Since our data has multiple time steps, we can easily animate through them to see how the data changes over time.</p> <ul> <li>Simply click the Play button on the animation bar at the top of the GUI.</li> <li>Pause to make it stop.</li> <li>Loop: With this button toggled on, animation will repeat until stopped.</li> </ul> <p> </p> Animating Simulation Data"},{"location":"polaris/visualization/paraview-tutorial/#10-animations","title":"10. Animations","text":"<p>Animations can be saved to disk as a movie file, to be played back later.</p> <ul> <li>From the main menu: File-&gt;Save Animation.</li> <li>Animation Settings Dialog: Save Animation.</li> <li>Files of type: AVI files (*.avi).</li> <li>Enter a name in File name:</li> <li>Click OK.</li> <li>Movie can be played back with standard media players (Windows Media Player, QuickTime, VLC, etc.).</li> </ul> <p> </p> Animations"},{"location":"polaris/visualization/paraview-tutorial/#11-particles-as-glyphs","title":"11. Particles as Glyphs","text":"<p>Glyphs are another way of visually representing data where the attributes of a graphical element are dictated by attributes of the data.</p> <p>All of the particles are displayed as red points in the graphics window. There are ~39K particles in this particular data set, which makes the display a bit cluttered. In order to both filter some of these out, and create 3D representations for them, let's apply a glyph filter to this data.</p> <p>Now let's add some of our other data back into the scene. Let's start with the particle data.</p> <p>All of the particles are displayed as red points in the graphics window. There are ~39K particles in this particular data set, which makes the display rather cluttered. In order to both filter some of these out, and create 3D representations for them, we will apply the glyph filter to this data.</p> <p>Note: that the particles.000* is still visible.</p> <ul> <li>Unhide the <code>particles.000* data</code>: click Eye icon.</li> <li>Select <code>particles.000* data</code>: click on name.</li> <li>Filters-&gt;Alphabetical-&gt;Glyph or click on the Glyph icon from the menu bar.</li> <li>Glyph Type: Sphere.</li> <li>Radius: 0.15.</li> <li>Orient: Unchecked.</li> <li>Scale Mode: off.</li> <li>Set Scale Factor: 1 - Edit: Checked.</li> <li>Maximum Number of Points: 3000.</li> <li>Mask Points: Checked.</li> <li>Random Mode: Unchecked.</li> <li>Click the Apply button.</li> <li>Since our goal was to unclutter the display, let's hide the particles.000* by toggling them off, by clicking on the Eye icon next to it in the Pipeline Browser.</li> <li>Let's also switch to the Display tab in the Object Inspector, with Glyph1 selected, and change the Color by value to GlyphVector. Since the GlyphVector value is based on the velocity, we can Edit Color Map... and choose the same Blue to Red Rainbow preset that we previously chose for velocity.</li> </ul> <p> </p> Particles as Glyphs"},{"location":"polaris/visualization/paraview-tutorial/#12-enter-red-blood-cells","title":"12. Enter: Red Blood Cells","text":"<p>Now let's add in both of the other data sets, which are polygonal meshes that make up Red Blood Cells (RBCs).</p> <p>These two data sets are essentially the same kind of data, so we can apply the same filters and make the same types of representation changes to each of them. However, some of the RBCs are marked by the simulation that generated them as healthy (rbc.000) and some of them are marked as diseased (bad_rbc.000).</p> <ul> <li>Unhide the rbc.000 and bad_rbc.000 data sets by clicking the Eye icon next to each of them to make them visible.</li> </ul> <p> </p> Enter: Red Blood Cells"},{"location":"polaris/visualization/paraview-tutorial/#13-using-color-to-differentiate-data","title":"13. Using Color to Differentiate Data","text":"<p>To enable us to distinguish these two types of data from one another, we can vary their representations.</p> <p>One way to do this is by setting the color of the two data sets to different colors. Repeat this process for each of rbc.000 and bad_rbc.000, picking different colors.</p> <ul> <li>Select one of the rbc data sets in the Pipeline Browser.</li> <li>Go to the Display tab in the Object Inspector.</li> <li>In the Color by: dropdown select Solid Color.</li> <li>Click on the Set Solid Color... button.</li> <li>Select a color from the Select Color dialog that appears.</li> <li>Repeat for the other RBC data set, choosing a different color.</li> </ul> <p> </p> Using Color to Differentiate Data"},{"location":"polaris/visualization/paraview-tutorial/#14-further-exploration-highlight-the-mesh","title":"14. Further Exploration: Highlight the Mesh","text":"<p>Change the representation of one of the RBC data sets.</p> <p>In this example, the continuum.000* data is also hidden to reduce confusion with showing multiple overlapping meshes.</p> <ul> <li>Select one of the RBC data sets.</li> <li>Go to the Display tab in the Object Inspector.</li> <li>For the Representation select Surface With Edges.</li> <li>In the Edge Style section click on the Set Edge Color... button to select a different color from the Select Color dialog.</li> </ul> <p> </p> Further Exploration: Highlight the Mesh"},{"location":"polaris/visualization/paraview-tutorial/#15-further-exploration-highlight-the-vertices","title":"15. Further Exploration: Highlight the Vertices","text":"<p>Add glyphs to illustrate the position of the vertices of one of the RBC data sets.</p> <ul> <li>Select one of the RBC data sets.</li> <li>Select the Glyph filter.</li> <li>Since this filter was used recently, it can also be found under: Filters-&gt;Recent-&gt;Glyph.</li> <li>As in the earlier example, set the various configuration options for the glyph attributes.</li> <li>Note: that this time, we want to show all of the vertices of the RBC, so we should uncheck the Mask Points option.</li> </ul> <p> </p> Further Exploration: Highlight the Vertices"},{"location":"polaris/visualization/paraview-tutorial/#16-further-exploration-color-by-variable","title":"16. Further Exploration: Color by Variable","text":"<p>Try playing around with the viewing options and representations of the other data objects.</p> <p>Change the:</p> <ul> <li>Color by values</li> <li>Opacity</li> <li>Representation</li> <li>Etc.</li> </ul> <p> </p> Further Exploration: Color by Variable"},{"location":"polaris/visualization/paraview-tutorial/#17-background-color","title":"17. Background Color","text":"<ul> <li>Background color is an important part of final visualization.</li> <li>From the main menu choose: Edit-&gt;View Settings...</li> <li>Under General in the View Settings dialog box, select Choose Color.</li> <li>Select Color: OK.</li> <li>Apply, then OK.</li> </ul> Background Color <p>This tutorial was developed with support from National Science Foundation Grant OCI-0904190, and from the Argonne Leadership Computing Facility at Argonne National Laboratory, which is supported by the Office of Science of the U.S. Department of Energy under contract DE-AC02-06CH11357.</p>"},{"location":"polaris/visualization/paraview/","title":"ParaView on Polaris","text":"<p>The recommended way of running ParaView on Polaris is in client/server mode. This consists of running the ParaView client on your local resource and the ParaView server on the Polaris compute nodes. The ParaView client needs to first be installed on your local resource and must match the version that you run on Polaris.</p> <p>There are multiple versions of ParaView installed on Polaris. To find the versions of ParaView currently available on Polaris, run the following command on a login node:  <pre><code>module use /soft/modulefiles\nmodule avail paraview\n</code></pre></p> <p>Binary and source packages of the ParaView client for Linux, macOS, and Windows are available from the ParaView Download Page. </p>"},{"location":"polaris/visualization/paraview/#connecting-to-the-paraview-server-on-polaris","title":"Connecting to the ParaView server on Polaris","text":"<p>This section describes how to launch the ParaView server on Polaris from a local ParaView client.</p>"},{"location":"polaris/visualization/paraview/#start-paraview-client","title":"Start ParaView Client","text":"<p>First, launch the ParaView client on your local resource. You will need to configure some server settings in the client. This initial setup should only need to be done once and can be reused each time you want to run ParaView on Polaris.</p>"},{"location":"polaris/visualization/paraview/#server-configuration","title":"Server Configuration","text":""},{"location":"polaris/visualization/paraview/#1-select-connect","title":"1. Select Connect","text":"<p>From the ParaView client, choose to connect to a server by either clicking on the \"Connect\" icon in the menu bar</p> <p> </p> <p>or selecting File-&gt;Connect from the main menu.</p> <p></p>"},{"location":"polaris/visualization/paraview/#2-set-up-servers-first-time-only","title":"2. Set Up Servers (first time only)","text":"<p>The first time you want to run a server on Polaris and have it connect to your local ParaView client, you will need to set up a server. Once this server is set up, you can reuse it each time you run the ParaView client with the ParaView server on Polaris.</p> <p>Kitware, the developers of ParaView, maintain a database of server configurations that you can retrieve through the ParaView client. In the File-&gt;Connect menu, press the button named \"Fetch Servers\" and select POLARIS@ANL. Windows users should select \"windows to POLARIS@ANL\". Press \"Import Selected\".</p> <p></p>"},{"location":"polaris/visualization/paraview/#3-use-paraview","title":"3. Use ParaView","text":"<p>After the previous step, you can now select POLARIS@ANL in the File-&gt;Connect menu and press Connect.</p> <p></p> <p>At this point, a new window will pop up.</p> <p></p> <p>There are a number of parameters that you must enter manually here:</p> <p>Xterm executable: the path of a terminal on your system. The figure shows the case of a Mac with XQuartz. You may need to change these values for Windows or Linux.</p> <p>SSH executable: the name of your SSH command. It may be different on Windows depending on the SSH client installed (e.g., PuTTY).</p> <p>Remote machine: leave this value at polaris.alcf.anl.gov.</p> <p>Username: your ALCF username.</p> <p>ParaView version: the version of ParaView that you want to use. Verify first that this version is installed on the system (as described at the top of this document). You will also need to add a <code>-EGL</code> suffix.</p> <p>Example: <pre><code>5.12.0-EGL\n</code></pre></p> <p>Client port: it is safe to use the default value.</p> <p>Server port: it is safe to use the default value.</p> <p>Number of nodes to reserve: enter the number of Polaris compute nodes you want to use for your job.</p> <p>Number of ranks per node: enter the number of ranks per node.</p> <p>Number of minutes to reserve: the duration of your job in minutes.</p> <p>Account: enter here the name of your ALCF allocation.</p> <p>Queue: the name of the Polaris queue you would like to use (e.g., <code>debug</code> for small, quick jobs, <code>prod</code>, <code>preemptable</code>).</p> <p>File Systems: enter here the file systems you need for your job, separated with colons, no spaces. Keep in mind that your job may not run if one of these file systems is not available at that time, so enter these values carefully.</p> <p>Job name: safe to use the default value. The PBS scheduler will assign this name to your job.</p> <p>Now you can press OK to establish the connection with a ParaView server on Polaris.</p> <p>An SSH connection will be established with a Polaris login node, and a password will be requested in a terminal, similar to the process you normally use to connect and work on the system.</p> <p>After you enter your password, a job will be queued, and you will see a window like this:</p> <p></p> <p>When the job is launched on the compute nodes, the previous window will go away, and ParaView will show it is connected to Polaris in its Pipeline Browser:</p> <p></p> <p>At this point, you can open datasets stored on the ALCF file systems and use ParaView normally.</p>"},{"location":"polaris/visualization/paraview/#additional-information","title":"Additional Information","text":"<ul> <li>ParaView Documentation</li> <li>ParaView Community Support</li> </ul>"},{"location":"polaris/visualization/visit/","title":"VisIt on Polaris","text":""},{"location":"polaris/visualization/visit/#getting-started","title":"Getting Started","text":"<p>The latest VisIt versions installed on Polaris are 3.3.3 and 3.4.0.</p> <p>Please note that at the time of this writing, VisIt version 3.4.0 does not yet have a client for Mac available.</p> <p>Follow these steps to install VisIt on your local machine:</p> <ul> <li>Download and install VisIt for your local platform (macOS, Windows, Linux). The version you download must match the server version installed on Polaris. Use this page</li> <li>Download the Polaris host profile for VisIt (you may need to right-click and choose \"Save link as...\" or \"Save target as...\")</li> <li>Copy this file to a file called <code>~/.visit/hosts/host_anl_polaris.xml</code> on Mac or Linux. For Windows, specify the equivalent path.</li> </ul> <p>Note: VisIt allows the user to download host profiles for ANL, but all these settings are outdated. We are working with the VisIt developers to update the ANL host list.</p> <p>Additional information for using VisIt in client/server mode is available here.</p>"},{"location":"polaris/visualization/visit/#running-visit","title":"Running VisIt","text":"<ul> <li>Start up VisIt on your local machine.</li> <li>Click File -&gt; Open File and choose \"ANL Polaris\" from the \"Host\" dropdown.</li> </ul> <ul> <li>You'll be prompted for your password; enter your ALCF authenticator app response.</li> <li>When you open a selected file, it will launch a job on Polaris.</li> <li>You will need to specify the \"Bank\" (Project) to use when VisIt submits jobs to the queue on Polaris. Specify a project in the Options box.</li> <li>If your environment doesn't get sourced correctly with non-interactive SSH, you can set the default project to use under Options -&gt; Host profiles.</li> </ul> <ul> <li>Note: Don't change the contents of the \"Machine file\" field (it should be <code>$PBS_NODEFILE</code>).</li> <li>Note: The default Launch Profile is set to serial. We recommend leaving this setting in its default value, but using the parallel method to launch jobs on Polaris.</li> <li>Note: Don't change the contents of \"launchMethod\". It must be <code>qsub/aprun</code> even though Polaris does not use <code>aprun</code>.</li> <li>If you'd like to change other job parameters (like the number of processes, nodes, and walltime), you can do so. Please enter time in the format required by the PBS scheduler (i.e., 1:00:00 for one hour).</li> <li>If you'd like these changes to be used as your default, be sure to save them using Save Settings under the Options menu.</li> </ul>"},{"location":"polaris/visualization/visit/#additional-information","title":"Additional Information","text":"<ul> <li>VisIt user manual</li> <li>VisIt wiki</li> </ul>"},{"location":"polaris/visualization/vnc/","title":"VNC on Polaris","text":""},{"location":"polaris/visualization/vnc/#overview","title":"Overview","text":"<p>VNC (Virtual Network Computing) is available on Polaris to run graphics applications. To avoid slowing down login nodes, please run VNC on compute nodes.</p>"},{"location":"polaris/visualization/vnc/#password-for-vnc","title":"Password for VNC","text":"<p>Create a unique password for VNC and store it in a secure directory.</p> <p>Setting the password:</p> <pre><code>vncpasswd [file]\n</code></pre> <p>Omitting <code>[file]</code> will save the password to <code>~/.vnc/passwd</code>.</p>"},{"location":"polaris/visualization/vnc/#vnc-launch-script","title":"VNC Launch Script","text":"<p>Create a script for your preferred shell (e.g., Bash) with the following commands:</p> <pre><code>#!/bin/bash\n\nXvnc -PasswordFile ~/.vnc/passwd -geometry 1920x1080 :0 &amp;\nsleep 2\nicewm --display=:0 &amp;\nxterm -display :0 &amp;\n</code></pre>"},{"location":"polaris/visualization/vnc/#launching-the-script","title":"Launching the Script","text":"<ol> <li>Start an interactive session using <code>qsub</code> with the <code>-I</code> option.</li> <li>Run the VNC launch script on the compute node.</li> </ol>"},{"location":"polaris/visualization/vnc/#establishing-an-ssh-tunnel","title":"Establishing an SSH Tunnel","text":"<p>On another terminal, type:</p> <pre><code>ssh -v -N -L 5900:x3005c0s7b0n0:5900 yourusername@polaris.alcf.anl.gov\n</code></pre> <p>where <code>x3005c0s7b0n0</code> is the name of your Polaris compute node. The default TCP port for VNC is 5900. Edit as needed.</p>"},{"location":"polaris/visualization/vnc/#connecting-to-your-vnc-server","title":"Connecting to Your VNC Server","text":"<ol> <li>Install a VNC client on your local computer.</li> <li>Run the client and connect to <code>localhost:5900</code>.</li> <li>Enter your VNC password.</li> <li>Launch your graphics application from the xterm.</li> </ol>"},{"location":"polaris/visualization/vnc/#tips","title":"Tips","text":"<ul> <li>Keep the SSH tunnel terminal open during your session.</li> <li>Adjust the SSH tunnel command as needed for your setup.</li> <li>If for any reason you need to restart the VNC server and get error messages, try:</li> </ul> <pre><code>killall Xvnc icewm xterm\n</code></pre>"},{"location":"polaris/workflows/balsam/","title":"Balsam","text":"<p>Balsam is a Python-based workflow manager that helps users execute large numbers of jobs, potentially with inter-job dependencies, track job outcomes, and manage post-processing analysis. A Balsam Site runs on a node with access to the job scheduler, where it can submit and monitor jobs. Overall job state is aggregated on the Balsam Server, making job data from all Sites accessible from any individual site (or the user's laptop) via the command-line interface or the Python API. To get information on how to use the command-line tool, you can type <code>balsam --help</code> in your shell.</p> <p>Full documentation for Balsam is available online.</p> <p>Balsam requires Python 3.7+. To install Balsam on Polaris, first set up a virtual Python environment:</p> <pre><code>module use /soft/modulefiles\nmodule load conda\nconda activate base\npython -m venv env\nsource env/bin/activate\npip install --upgrade pip\npip install --pre balsam\n</code></pre> <p>To use Balsam, users need an account on the Balsam server. Users can get an account by contacting the ALCF Help Desk. Once a user has an account, they can log in and create a new site. A Balsam site is a project space for your workflow. You will be prompted to select which machine (Polaris) you are working on when creating a new site:</p> <pre><code>balsam login\nbalsam site init -n new-site new-site\ncd new-site\nbalsam site start\n</code></pre> <p>See the Balsam documentation for full details.</p>"},{"location":"polaris/workflows/dragon/","title":"Dragon","text":"<p>DragonHPC is a composable distributed runtime for managing processes, memory, and data at scale through high-performance communication.  Dragon is an open source project developed by HPE.</p> <p>Dragon has a Python API and a C/c++ API.  The Python API is an extension of Python's <code>multiprocessing</code> API, and therefore DragonHPC can be used to scale Python <code>multiprocessing</code> code across multi-node jobs.  It can be installed with pip in conda or Python virtual environments.</p> <p>DragonHPC allows parallel process launching, including PMI enabled processes for MPI applications, with fine-grained control of CPU/GPU affinity.  DragonHPC also has a distributed data layer or distributed dictionary that allows for in-memory data sharing between processes on different nodes.</p> <p>Please see DragonHPC's Introduction in their documenation for examples of how to use <code>dragon</code>.</p>"},{"location":"polaris/workflows/dragon/#installation","title":"Installation","text":"<p>To install in a Python virtual environment on Polaris:</p> <pre><code>module use /soft/modulefiles\nmodule load conda\nconda activate base\npython -m venv _env\nsource _env/bin/activate\npip install dragonhpc\ndragon-config add --ofi-runtime-lib=/opt/cray/libfabric/1.22.0/lib64\n</code></pre> <p>The last installation step that calls <code>dragon-config</code> is necessary to enable <code>dragon</code> to use high-speed RDMA transfers across Polaris's Slingshot network.  Skipping this step will result in <code>dragon</code> using slower TCP transfers for cross node communication and data transfer.</p>"},{"location":"polaris/workflows/dragon/#execution-of-dragon-driver-scripts","title":"Execution of Dragon Driver Scripts","text":"<p>Dragon driver scripts written with the Python API should be executed with the <code>dragon</code> application:</p> <pre><code>dragon my_dragon_script.py\n</code></pre> <p>Alternatively, it can be launched with the python binary but the <code>-m</code> flag should be set to <code>dragon</code>:</p> <pre><code>python -m dragon my_dragon_script.py\n</code></pre> <p>Dragon needs access to the PBS <code>qstat</code> command in order to run (this is used to determine the nodes have been allocated by PBS as opposed to SLURM or LSF and determines how dragon will discover nodes and launch the runtime).  In some interactive jobs on Polaris, you may need to modify the <code>PATH</code> to ensure <code>qstat</code> is visible to <code>dragon</code>:</p> <pre><code>export PATH=/opt/pbs/bin:$PATH\n</code></pre> <p>Currently, we also recommend unloading the <code>xalt</code> module on Polaris when running Dragon:</p> <pre><code>module unload xalt\n</code></pre>"},{"location":"polaris/workflows/dragon/#policies-for-polaris-nodes","title":"Policies for Polaris Nodes","text":"<p>The <code>dragon</code> object that sets CPU, GPU and node affinities for processes is the Dragon <code>Policy</code>.</p> <p>A common <code>Policy</code> setting on Polaris is to run one process per GPU (four per node).  </p> <p>Dragon's Native Pool can use policies to run a pool of processes that bind each process to specific GPUs and CPUs on specific nodes. (Note that the <code>multiprocessing</code> Pool with <code>dragon</code> selected as the start method can only distribute processes across multiple nodes; it cannot set explicit GPU and CPU binding affinities).  Here is an example of how to run a pool across nodes on Polaris binding 1 pool process per GPU with the Native Dragon Pool:</p> <pre><code>import dragon\nfrom dragon.infrastructure.policy import Policy\nfrom dragon.native.machine import System, Node\nfrom dragon.native.pool import Pool\n\n# List of optimal bindings for GPUs to CPUs on a Polaris node\ngpu_affinities = [[3],[2],[1],[0]]\ncpu_affinities = [list(range(c, c+8)) for c in range(0, 32, 8)]\nnum_gpus_per_node = 4\n\n# A simple function to demonstrate task execution\ndef hello_world(message):\n    # do some work on the gpu here...                        \n    return f\"Hello {message}\"\n\nif __name__ == '__main__':\n\n    # Get list of nodes in the runtime       \n    alloc = System()\n    nodelist = alloc.nodes\n\n    # Create a policy for every GPU in the runtime              \n    polaris_policies_for_gpus = []\n    for node in nodelist:\n        node_name = Node(node).hostname\n        for i in range(num_gpus_per_node):\n            pol = Policy(host_name=node_name,\n                        cpu_affinity=cpu_affinities[i],\n                        gpu_affinity=gpu_affinities[i],\n                        placement=Policy.Placement.HOST_NAME,)\n            polaris_policies_for_gpus.append(pol)\n\n    messages = [f'pool_task_{i}' for i in range(32)]\n    dragon_pool = Pool(policy=polaris_policies_for_gpus, processes_per_policy=1)\n    async_results = dragon_pool.map_async(hello_world, messages)\n    results = async_results.get()\n    for res in results:\n        print(res, flush=True)\n    dragon_pool.close()\n    dragon_pool.join()\n</code></pre> <p>Here is an example of how to do a similar thing with a <code>ProcessGroup</code>:</p> <pre><code>import os\nimport dragon\nfrom dragon.infrastructure.policy import Policy\nfrom dragon.native.machine import System, Node\nfrom dragon.native.process_group import ProcessGroup\nfrom dragon.native.process import ProcessTemplate\n\n# List of optimal bindings for GPUs to CPUs on a Polaris node\ngpu_affinities = [[3],[2],[1],[0]]\ncpu_affinities = [list(range(c, c+8)) for c in range(0, 32, 8)]\nnum_gpus_per_node = 4\n\n# A simple function to demonstrate task execution and GPU affinity\ndef hello_world(message):\n    # do some work on the gpu here...\n    return f\"Hello {message}\"\n\nif __name__ == '__main__':\n\n    # Get list of nodes in the runtime\n    alloc = System()\n    nodelist = alloc.nodes\n\n    # Create a policy for every GPU in the runtime\n    polaris_policies_for_gpus = []\n    for node in nodelist:\n        node_name = Node(node).hostname\n        for i in range(num_gpus_per_node):\n            pol = Policy(host_name=node_name,\n                        cpu_affinity=cpu_affinities[i],\n                        gpu_affinity=gpu_affinities[i],\n                        placement=Policy.Placement.HOST_NAME,)\n            polaris_policies_for_gpus.append(pol)\n\n    pg = ProcessGroup()\n    for pol in polaris_policies_for_gpus:\n        pg.add_process(nproc=1, \n                       template=ProcessTemplate(target=hello_world,\n                                                args=('hello',),\n                                                cwd=os.getcwd(),\n                                                policy=pol,))\n    pg.init()\n    pg.start()\n    pg.join()\n    pg.close()\n</code></pre>"},{"location":"polaris/workflows/dragon/#distributed-dictionaries","title":"Distributed Dictionaries","text":"<p>Dragon offers a distributed data layer called a Dragon Dictionary.  The Dragon Dictionary or <code>DDict</code> can span all nodes or a subset of nodes in your runtime and can also use Policies for optimal node placement.  Regardless of whether a <code>DDict</code> spans all nodes or a subset, any process in the runtime on any node can access the dictionary.</p> <p>To create a <code>DDict</code> that spans all nodes in the runtime:</p> <p><pre><code>from dragon.native.machine import System\nfrom dragon.data.ddict import DDict\n\nalloc = System()\nnum_nodes = int(alloc.nnodes)\ndict_mem_per_node = 1 * 1024**3 # ask for 1 GB per node, expressed in units of bytes\n# Note that the total_mem is the total memory across all the nodes\ndist_dict = DDict(managers_per_node=1, n_nodes=num_nodes, total_mem=num_nodes*dict_mem_per_node)\n</code></pre> For more details on how to use Dragon Dictionaries, see the DragonHPC documentation.</p>"},{"location":"polaris/workflows/dragon/#running-mpi-applications","title":"Running MPI applications","text":"<p>MPI applications can be run with the Dragon <code>ProcessGroup</code>.  To enable message passing between processes in a Dragon ProcessGroup on Polais set the <code>pmi</code> flag when creating the process group like this:</p> <p><pre><code>from dragon.native.process_group import ProcessGroup\nfrom dragon.infrastructure.facts import PMIBackend\n\npg = ProcessGroup(pmi=PMIBackend.CRAY) \n</code></pre> Processes can be added to the <code>ProcessGroup</code> according to your application needs.  See the DragonHPC documentation on orchestrating MPI applications.</p>"},{"location":"polaris/workflows/libensemble/","title":"libEnsemble","text":"<p>libEnsemble is a Python toolkit for running dynamic ensembles of calculations.</p> <p>Users provide generator and simulator functions to express their ensembles, where the generator can steer the ensemble based on previous results. These functions can portably submit external executables at any scale. System details are detected, and dynamic resource management is provided. This includes automatically detecting, assigning, and reassigning GPUs for ensemble members. libEnsemble can be used in a consistent manner on laptops, clusters, and supercomputers with minimal required dependencies.</p>"},{"location":"polaris/workflows/libensemble/#getting-libensemble-on-polaris","title":"Getting libEnsemble on Polaris","text":"<p>libEnsemble is provided on Polaris in the conda module:</p> <pre><code>module use /soft/modulefiles\nmodule load conda\nconda activate base\n</code></pre> <p>See the docs for more details on using Python on Polaris</p> Creating a virtual environment and updating <code>libEnsemble</code> <p>E.g., to create a virtual environment that allows installation of further packages with pip:</p> <pre><code>python -m venv /path/to-venv --system-site-packages\n. /path/to-venv/bin/activate\n</code></pre> <p>Where <code>/path/to-venv</code> can be anywhere you have write access. For future uses, just load the conda module and run the activate line.</p> <p>You can also ensure you are using the latest version of libEnsemble:</p> <pre><code>pip install libensemble\n</code></pre>"},{"location":"polaris/workflows/libensemble/#libensemble-examples","title":"libEnsemble examples","text":"<p>For a very simple example of using libEnsemble, see the Simple Introduction tutorial.</p> <p>For an example that runs a small ensemble using a C application (offloading work to the GPU), see the GPU app tutorial. The required files for this tutorial can be found in this directory. A video demo is also available.</p>"},{"location":"polaris/workflows/libensemble/#job-submission","title":"Job Submission","text":"<p>libEnsemble runs on the compute nodes on Polaris using either Python's <code>multiprocessing</code> or <code>mpi4py</code>. The user can set the number of workers for maximum concurrency. libEnsemble will detect the nodes available from the PBS environment and use these for running simulations. Polaris supports running multiple concurrent simulations on each node if desired.</p> <p>A simple example batch script for a libEnsemble use case that runs five workers on one node:</p> submit_libe.sh<pre><code>#!/bin/bash -l\n#PBS -l select=1:system=polaris\n#PBS -l walltime=00:15:00\n#PBS -l filesystems=home:eagle\n#PBS -q debug\n#PBS -A &lt;myproject&gt;\n\nexport MPICH_GPU_SUPPORT_ENABLED=1\ncd $PBS_O_WORKDIR\npython run_libe_forces.py --comms local --nworkers 5\n</code></pre> <p>The script can be run with: <pre><code>qsub submit_libe.sh\n</code></pre></p> <p>Or you can run an interactive session with: <pre><code>qsub -A &lt;myproject&gt; -l select=1 -l walltime=15:00 -lfilesystems=home:eagle -qdebug -I\n</code></pre></p>"},{"location":"polaris/workflows/libensemble/#further-links","title":"Further links","text":"<ul> <li>libEnsemble Documentation</li> <li>libEnsemble GitHub repo</li> </ul>"},{"location":"polaris/workflows/parsl/","title":"Parsl on Polaris","text":"<p>Parsl is a flexible and scalable parallel programming library for Python.</p> <p>-- Parsl Documentation</p> <p>For many applications, managing an ensemble of jobs into a workflow is a critical step that can easily become a performance bottleneck. Many tools exist to address this, of which <code>parsl</code> is just one. On this page, we'll highlight some of the key pieces of information about <code>parsl</code> that are relevant to Polaris. <code>Parsl</code> is also extensively documented, has a dedicated Slack channel, and a large community of users and developers beyond ALCF. We encourage you to engage with the <code>parsl</code> community for support with <code>parsl</code>-specific questions, and for Polaris-specific questions or problems, please contact support@alcf.anl.gov.</p>"},{"location":"polaris/workflows/parsl/#getting-parsl-on-polaris","title":"Getting Parsl on Polaris","text":"<p>You can install parsl by building off of the <code>conda</code> modules. You have some flexibility in how you want to extend the <code>conda</code> module to include parsl, but here is an example way to do it:</p> <pre><code># Load the Conda Module (needed every time you use parsl)\nmodule use /soft/modulefiles\nmodule load conda\nconda activate\n\n# Create a virtual env that uses the conda env as the system packages.\n# Only do the next line on initial setup:\npython -m venv --system-site-packages /path/to/your/virtualenv\n\n# Load the virtual env (every time):\nsource /path/to/your/virtualenv/bin/activate\n\n# Install parsl (only once)\npip install parsl\n</code></pre>"},{"location":"polaris/workflows/parsl/#using-parsl-on-polaris","title":"Using Parsl on Polaris","text":"<p>Parsl has a variety of possible configuration settings. As an example, we provide the configuration below that will run one task per GPU:</p> <pre><code>from parsl.config import Config\n\n# PBSPro is the right provider for Polaris:\nfrom parsl.providers import PBSProProvider\n# The high throughput executor is for scaling to HPC systems:\nfrom parsl.executors import HighThroughputExecutor\n# Use the MPI launcher to create one worker per GPU\nfrom parsl.launchers import MpiExecLauncher\n# For checkpointing:\nfrom parsl.utils import get_all_checkpoints\n\n# Adjust your user-specific options here:\nrun_dir=\"/lus/eagle/projects/yourproject/yourrundir/\"\n\nuser_opts = {\n    \"worker_init\":      f\"source /path/to/your/virtualenv/bin/activate; cd {run_dir}\", # load the environment where parsl is installed\n    \"scheduler_options\":\"#PBS -l filesystems=home:eagle\" , # specify any PBS options here, like filesystems\n    \"account\":          \"YOURPROJECT\",\n    \"queue\":            \"debug-scaling\",\n    \"walltime\":         \"1:00:00\",\n    \"nodes_per_block\":  3, # think of a block as one job on polaris, so to run on the main queues, set this &gt;= 10\n    \"cpus_per_node\":    32, # Up to 64 with multithreading\n    \"available_accelerators\": 4, # Each Polaris node has 4 GPUs, setting this ensures one worker per GPU\n}\n\ncheckpoints = get_all_checkpoints(run_dir)\nprint(\"Found the following checkpoints: \", checkpoints)\n\nconfig = Config(\n        executors=[\n            HighThroughputExecutor(\n                label=\"htex\",\n                heartbeat_period=15,\n                heartbeat_threshold=120,\n                worker_debug=True,\n                available_accelerators=user_opts[\"available_accelerators\"],\n                max_workers_per_node=user_opts[\"available_accelerators\"],\n                # This give optimal binding of threads to GPUs on a Polaris node\n                cpu_affinity=\"list:24-31,56-63:16-23,48-55:8-15,40-47:0-7,32-39\",\n                prefetch_capacity=0,\n                provider=PBSProProvider(\n                    launcher=MpiExecLauncher(bind_cmd=\"--cpu-bind\", overrides=\"--depth=64 --ppn 1\"),\n                    account=user_opts[\"account\"],\n                    queue=user_opts[\"queue\"],\n                    select_options=\"ngpus=4\",\n                    # PBS directives (header lines)\n                    scheduler_options=user_opts[\"scheduler_options\"],\n                    # Command to be run before starting a worker, such as:\n                    worker_init=user_opts[\"worker_init\"],\n                    # number of compute nodes allocated for each block\n                    nodes_per_block=user_opts[\"nodes_per_block\"],\n                    init_blocks=1,\n                    min_blocks=0,\n                    max_blocks=1, # Can increase more to have more parallel jobs\n                    cpus_per_node=user_opts[\"cpus_per_node\"],\n                    walltime=user_opts[\"walltime\"]\n                ),\n            ),\n        ],\n        checkpoint_files = checkpoints,\n        run_dir=run_dir,\n        checkpoint_mode = 'task_exit',\n        retries=2,\n        app_cache=True,\n)\n</code></pre>"},{"location":"polaris/workflows/parsl/#known-issues","title":"Known Issues","text":"<p>Warning</p> <p>Starting in September 2025, users testing parsl in single node jobs may encounter an error that makes reference to <code>OSError: AF_UNIX path too long</code>.  To fix this, include in the <code>worker_init</code> for cases using the <code>PBSProProvider</code> or in the job script for cases using the <code>LocalProvider</code> this environment variable setting: <code>export TMPDIR=/tmp</code></p>"},{"location":"polaris/workflows/smartsim/","title":"SmartSim and SmartRedis","text":"<p>SmartSim is an open-source tool developed by Hewlett Packard Enterprise (HPE) designed to facilitate the integration of traditional HPC simulation applications with machine learning workflows. There are two core components to SmartSim:</p> <ul> <li>Infrastructure library (IL)</li> <li>Provides an API to start, stop, and monitor HPC applications from Python</li> <li>Interfaces with the scheduler to launch jobs (PBSPro on Polaris and Cobalt on Theta/ThetaGPU)</li> <li>Deploys a distributed in-memory database called the Orchestrator</li> <li>SmartRedis client library</li> <li>Provides clients that connect to the Orchestrator from Fortran, C, C++, and Python code</li> <li>The client API library enables data transfer to/from the database and the ability to load and run JIT-traced Python and ML runtimes acting on stored data</li> </ul> <p>For more resources on SmartSim, follow the links below:</p> <ul> <li>Source code</li> <li>Documentation</li> <li>Zoo of examples</li> <li>Fall 2023 ALCF User Hands-On Workshop</li> <li>NekRS-ML</li> </ul>"},{"location":"polaris/workflows/smartsim/#installation-with-pytorch-gpu-backend","title":"Installation with PyTorch GPU Backend","text":"<p>SmartSim on Polaris can be installed by creating a virtual environment based on the ML conda module. From a compute node, execute: <pre><code>module use /soft/modulefiles\nmodule load conda/2024-04-29\nconda activate base\npython -m venv --clear /path/to/_ssim_env --system-site-packages\nsource /path/to/_ssim_env/bin/activate\n</code></pre> Note that <code>/path/to/</code> can either be a user's home or project directory.</p> <p>Then set up the environment variables: <pre><code>export CC=cc\nexport CXX=CC\nexport CUDNN_BASE=/soft/libraries/cudnn/cudnn-12-linux-x64-v9.1.0.70\nexport CUDNN_LIBRARY=$CUDNN_BASE/lib/\nexport CUDNN_INCLUDE_DIR=$CUDNN_BASE/include/\nexport LD_LIBRARY_PATH=$CUDNN_LIBRARY:$LD_LIBRARY_PATH\nexport TORCH_CMAKE_PATH=$( python -c 'import torch;print(torch.utils.cmake_prefix_path)' )\nexport TORCH_PATH=$( python -c 'import torch; print(torch.__path__[0])' )\nexport LD_LIBRARY_PATH=$TORCH_PATH/lib:$LD_LIBRARY_PATH\n</code></pre></p> <p>Now, install SmartSim and the PyTorch GPU backend: <pre><code>git clone https://github.com/rickybalin/SmartSim.git\ncd SmartSim\npip install -e .\nsmart build -v --device gpu --torch_dir $TORCH_CMAKE_PATH --no_tf\ncd ..\n</code></pre></p> <p>and validate the build with: <pre><code>smart validate\n</code></pre></p> <p>Finally, install the SmartRedis library: <pre><code>git clone https://github.com/rickybalin/SmartRedis.git\ncd SmartRedis\nmake lib DEP_CC=cc DEP_CXX=CC\npip install -e .\ncd ..\n</code></pre></p> <p>To use SmartSim in the future, simply source the following environment. Note that the Torch libraries need to be prepended to <code>LD_LIBRARY_PATH</code>: <pre><code>module use /soft/modulefiles\nmodule load conda/2024-04-29\nconda activate base\nsource /path/to/_ssim_env/bin/activate\nexport TORCH_PATH=$( python -c 'import torch; print(torch.__path__[0])' )\nexport LD_LIBRARY_PATH=$TORCH_PATH/lib:$LD_LIBRARY_PATH\n</code></pre></p>"},{"location":"polaris/workflows/smartsim/#installation-with-tensorflow-gpu-backend","title":"Installation with TensorFlow GPU Backend","text":"<p>To use the TensorFlow backend with the SmartSim Orchestrator, the installation steps are very similar but require downgrading the TensorFlow version to 2.13.1. Follow the same instructions outlined above for the PyTorch backend, with the following exceptions:</p> <ul> <li>After creating and sourcing the Python virtual environment, downgrade TensorFlow with <code>pip install tensorflow==2.13.1</code>. Note that this will also downgrade typing-extensions, which will cause compatibility issues with PyTorch in the conda module.</li> <li>No need to export <code>TORCH_CMAKE_PATH</code> and <code>TORCH_PATH</code>, or modify <code>LD_LIBRARY_PATH</code>.</li> <li>Build the SmartSim backend with <code>smart build -v --device gpu --no_pt</code>.</li> </ul>"},{"location":"polaris/workflows/smartsim/#examples","title":"Examples","text":"<p>You can find examples of in situ training and inference of ML models from an ongoing CFD simulation at the NekRS-ML repository. The <code>smartredis</code> branch has instructions on how to build and run the examples on Polaris.</p> <p>The Fall 2023 ALCF User Hands-On Workshop repository also contains information on how to use SmartSim and NekRS-ML on Polaris, but note that some of the instructions are specific to the Fall of 2023.</p>"},{"location":"polaris/workflows/smartsim/#notes","title":"Notes","text":"<ul> <li>SmartSim workflows, such as online training, often require launching multiple MPI applications on the same set of nodes. On Polaris, the <code>MPICH_OFI_CXI_PID_BASE=0</code> must be exported before the first call to <code>mpiexec</code>, and then incremented by 1 and re-exported before each successive call. This is done with the SmartSim API by adding <code>env_vars={'MPICH_OFI_CXI_PID_BASE':str(0)}</code> to the <code>PalsMpiexecSettings()</code> API.</li> </ul>"},{"location":"policies/","title":"ALCF Facility Policies","text":"<p>Be sure to familiarize yourself with the various policies and procedures for ALCF users, categorized below.</p>"},{"location":"policies/#accounts","title":"Accounts","text":"<p>All holders of user accounts must comply with ALCF and Argonne National Laboratory computing usage policies, including meeting certain security requirements and executing specific science- or engineering-related computing jobs:</p> <ul> <li>Accounts Policy</li> <li>Account Sponsorship and Retention Policy</li> <li>User Authentication Policy</li> </ul>"},{"location":"policies/#alcf-acknowledgement-policy","title":"ALCF Acknowledgement Policy","text":"<p>As a U.S. Department of Energy Office of Science User Facility dedicated to the advancement of scientific discovery, the ALCF requests that its users acknowledge and promote the work of others and the resources with which this work was accomplished.</p> <ul> <li>ALCF Acknowledgement Policy</li> </ul>"},{"location":"policies/#data-and-allocation","title":"Data and Allocation","text":"<p>These policies detail data and software usage, as well as pullback and refunds of computing hours:</p> <ul> <li>Pullback Policy</li> <li>Refund Policy</li> <li>Data Policy</li> <li>Software Policy</li> </ul>"},{"location":"policies/#quarterly-reports","title":"Quarterly Reports","text":"<p>The ALCF is required to report the progress and accomplishments of its allocation projects. Policies are detailed by award type.</p> <ul> <li>Quarterly Report Policy</li> </ul>"},{"location":"policies/#queue-and-scheduling-policies","title":"Queue and Scheduling Policies","text":"<ul> <li>General Policies</li> </ul>"},{"location":"policies/alcf-acknowledgement-policy/","title":"ALCF Acknowledgement Policy","text":"<p>As a U.S. Department of Energy user facility dedicated to the advancement of scientific discoveries, the Argonne Leadership Computing Facility (ALCF) provides unique computing resources and expertise to a user community that is bound by certain policies designed to acknowledge and promote the work of others as well as the resources used to accomplish this work.</p> <p>The ALCF requests your continued compliance with the terms of your program or discretionary award, specifically with regard to acknowledgments in publications and presentations based on work done with ALCF resources. Also, please forward your accepted publication citations to pubs@alcf.anl.gov.</p>"},{"location":"policies/alcf-acknowledgement-policy/#ai-testbeds-publication-guidance","title":"AI Testbeds Publication Guidance","text":"<p>To publish technical reports and research papers using the ALCF AI testbeds, we request you to provide us with a draft of your paper prior to submission by emailing a copy to us at support@alcf.anl.gov. We will work closely with the AI testbed vendors to provide feedback in a timely manner. We strongly recommend you engage us and the vendors early and often in this process to help us facilitate your research objectives.</p> <p>For guidance on acknowledgements, please see the following sample policies:</p>"},{"location":"policies/alcf-acknowledgement-policy/#alcf-only-acknowledgement","title":"ALCF Only Acknowledgement","text":"<p>Users, and ALCF staff scientists without direct project funding, should acknowledge the ALCF in all publications and presentations that speak to work performed on ALCF resources.</p> <p>This research used resources of the Argonne Leadership Computing Facility, a U.S. Department of Energy (DOE) Office of Science user facility at Argonne National Laboratory and is based on research supported by the U.S. DOE Office of Science-Advanced Scientific Computing Research Program, under Contract No. DE-AC02-06CH11357.</p>"},{"location":"policies/alcf-acknowledgement-policy/#incitealcf-acknowledgement","title":"INCITE/ALCF Acknowledgement","text":"<p>Users should acknowledge the ALCF in all publications and presentations that speak to INCITE work performed on ALCF resources.</p> <p>An award for computer time was provided by the U.S. Department of Energy\u2019s (DOE) Innovative and Novel Computational Impact on Theory and Experiment (INCITE) Program. This research used resources from the Argonne Leadership Computing Facility, a U.S. DOE Office of Science user facility at Argonne National Laboratory, which is supported by the Office of Science of the U.S. DOE under Contract No. DE-AC02-06CH11357.</p>"},{"location":"policies/alcf-acknowledgement-policy/#incitealcfolcf-acknowledgement","title":"INCITE/ALCF/OLCF Acknowledgement","text":"<p>Users should acknowledge the ALCF and OLCF in all publications and presentations that speak to INCITE work performed on ALCF and OLCF resources.</p> <p>An award for computer time was provided by the U.S. Department of Energy\u2019s (DOE) Innovative and Novel Computational Impact on Theory and Experiment (INCITE) Program. This research used supporting resources at the Argonne and the Oak Ridge Leadership Computing Facilities. The Argonne Leadership Computing Facility at Argonne National Laboratory is supported by the Office of Science of the U.S. DOE under Contract No. DE-AC02-06CH11357. The Oak Ridge Leadership Computing Facility at the Oak Ridge National Laboratory is supported by the Office of Science of the U.S. DOE under Contract No. DE-AC05-00OR22725.</p>"},{"location":"policies/accounts/","title":"Accounts Policy","text":"<p>All holders of user accounts must abide by all appropriate Argonne Leadership Computing Facility and Argonne National Laboratory computing usage policies. The policy details are outlined in the following documents:</p> <ul> <li>ANL's Information Technology Access Agreement</li> <li>Addendum to ANL's Information Technology Access Agreement</li> </ul> <p>These are described at the time of the account request and include requirements such as using a sufficiently strong password, appropriate use of the system, and so on. Any user not following these requirements will have their account disabled.</p> <p>Furthermore, ALCF resources are intended to be used as a computing resource for specific computational science or engineering work, not as a general-purpose computing system.</p> <p>If someone is using the system extensively but not carrying out any computational activities, their account could be disabled.</p>"},{"location":"policies/accounts/account-sponsorship-retention-policy/","title":"Account Sponsorship &amp; Retention Policy","text":"<p>This page is designed to help you understand the different types of accounts that you will encounter at the ALCF. The policy outlined reviews the responsibilities of an account holder, an account sponsor, and those of a foreign national.</p>"},{"location":"policies/accounts/account-sponsorship-retention-policy/#alcf-account-types","title":"ALCF Account Types","text":"<p>Annual: This account applies to users who are not ALCF Regular Employees. The default renewal date (account deactivation date) for the account is a year from the day the account was requested. These accounts are renewed annually and must be approved by an ALCF Staff member or a Project PI (also known as the \u201capprover\u201d). Users are required to update their account information and agree to the Terms of Use each year. Users need to be a part of an active project for their account to be renewed.</p> <p>Permanent: This account applies to individuals who are Regular Employees within the ALCF and CPS Divisions. If you hold this type of account, periodic renewal is not necessary.</p> <p>Note: Foreign Nationals have a second date (apart from their account deactivation date) that controls their account access. Accounts held by foreign nationals require paperwork referred to as an ANL-593 (or just 593 for shorthand). This paperwork is also required for any on-site access and also applies to computer accounts. DOE requirements state that the ALCF is to disable any account with expired 593 paperwork.</p> <p>A notification system has been established that issues a warning notice to users when expiration approaches and requests action to ensure that accounts are not needlessly turned off. An approval from the project PI is required to renew ANL 593 for project members that are foreign nationals.</p>"},{"location":"policies/accounts/account-sponsorship-retention-policy/#your-responsibilities-as-an-account-approver","title":"Your responsibilities as an account approver","text":"<p>If you approve any accounts, please take note of the following roles and responsibilities:</p> <p>By approving someone for an account at the ALCF, you are accepting responsibility for the account applicant and confirming that this individual is who they claim to be and is thus entitled to work on our computers. Do not simply \"rubber stamp\" any account application that claims you as an account approver/project PI.</p> <p>You are also responsible for approving account renewal requests. When an account is about to expire, we send a warning notification to the account holder. Among other things, the account holder is asked to contact the approver (the PI of any of the active projects the account holder is associated with) if they wish to renew their account. We cannot and will not extend someone's account without an approval. An important aspect of this process to note is that inaction will result in the account becoming deactivated on the expiration date.</p> <p>You are also responsible for approving ANL 593 renewal requests. When an account\u2019s 593 is about to expire, we send a warning notification to the account holder. Among other things, the account holder is asked to contact the approver (the PI of any of the active projects the account holder is associated with) if they wish to renew their 593. We cannot and will not extend someone's 593 without an approval. An important aspect of this process to note is that inaction will result in the account becoming deactivated at the expiration date.</p>"},{"location":"policies/accounts/account-sponsorship-retention-policy/#account-retention-policy","title":"Account Retention Policy","text":"<p>Accounts can exist in one of three states:</p> <ul> <li>Active: The active state is normal for an account.</li> <li>Inactive: The inactive state occurs when an account expires, and the ability to use ALCF resources is removed by changing the active status of the account to inactive. All files continue to exist in the user's home directory. An account will remain in the inactive state for at least 90 days before moving to the next state.</li> <li>Deleted: After 90 days, an inactive account will be deleted. This removes all references to the account from the system (except the accounts database), including any files and home directories.</li> </ul> <p>Users with inactive or deleted accounts can request a reactivation by visiting https://my.alcf.anl.gov/accounts/#/accountReactivate and clicking on the \u201cReactivate An Account\u201d link.</p>"},{"location":"policies/accounts/user-authentication-policy/","title":"User Authentication Policy","text":"<p>Users of the ALCF systems are required to use a one-time passcode (OTP) generated by a physical token or MobilePASS+ mobile token. This document explains the policies users must follow regarding your access token for accessing the ALCF systems.</p>"},{"location":"policies/accounts/user-authentication-policy/#multi-factor-authentication","title":"Multi-factor authentication","text":"<p>By the NIST guidelines for identification and authentication (NIST 800-53, Revision 3, Control IA-2), ALCF aims for a Moderate level of security controls. All production systems in ALCF require multi-factor authentication for users. The two factors are your token PIN and the OTP generated by the token.</p>"},{"location":"policies/accounts/user-authentication-policy/#mobile-and-physical-tokens","title":"Mobile and physical tokens","text":"<p>ALCF provides every user of the production resources a physical or mobile token. An account can only be associated with a single token (physical or mobile). See Using Passcode Tokens for more information.</p> <p>At the end of your account or project lifecycle, the physical token must be returned to ALCF Support:</p> <p>Mailing Address</p> <p>ALCF Service Desk Argonne National Laboratory 9700 South Cass Avenue Building 240, Room 2129 Lemont, IL 60439</p>"},{"location":"policies/accounts/user-authentication-policy/#protecting-your-passcode-token","title":"Protecting Your Passcode Token","text":"<p>Your passcode token should be protected by you as carefully as your credit cards or house keys. If your token is lost, stolen, or damaged, please contact us immediately so that we can deactivate the token and prevent unauthorized access. Sharing of tokens is strictly forbidden. Please do not mark on the token or alter it in any way.</p>"},{"location":"policies/data-and-software-policies/data-policy/","title":"Data Policy","text":""},{"location":"policies/data-and-software-policies/data-policy/#alcf-data-confidentiality","title":"ALCF Data Confidentiality","text":"<p>The Argonne Leadership Computing Facility (ALCF) network is an open-research network. Because our resources and networks are open to many users and cannot be protected at a partitioned level, we cannot guarantee complete security for any data that resides here. It is up to users to provide the security they need.</p> <p>Data is not encrypted at rest. Data transferred via SSH (i.e., scp) is encrypted in transmission using SSH\u2019s mechanisms (e.g., AES256, etc.). Data transferred via Globus (GridFTP) isn't normally fully encrypted. The GridFTP control channel is encrypted, but the data channel by default is not (though the authentication processes for both channels are encrypted). If you need full encryption of the data stream, you need to explicitly select \"encrypt transfer\" in the \"Transfer &amp; Timer Options\" in the Globus UI or use equivalent options in the CLI or transfer API if you're using those. More information here: https://docs.globus.org/faq/security.</p> <p>The basic level of protection provided is UNIX file level permissions; it is the user's responsibility to ensure that file permissions and umasks are set to match their needs.</p> <p>Warning</p> <p>The default permissions and umasks are group and world readable. For help determining or setting file permissions or umasks, or creating a UNIX group, contact support@alcf.anl.gov.</p>"},{"location":"policies/data-and-software-policies/data-policy/#alcf-staff-with-root-privileges","title":"ALCF Staff with Root Privileges","text":"<p>ALCF resource administrators with root privileges are not constrained by the file permissions, and they have the capability to open and/or copy all files on the system. They can also assume a user\u2019s identity on the system. There is no audit trail for access, touching, or moving data; however, ALCF staff does not view or modify project data unless directed by a PI or project member to help debug a problem. Data may be touched or accessed by the filesystem itself if data needs to be repaired or verified for integrity after a filesystem event (e.g., a fsck).</p> <p>The ALCF resources are Federal resources and are the property of the United States Government. Any or all uses of this system and all files on this system may be intercepted, monitored, recorded, copied, audited, inspected, and disclosed to authorized site, Department of Energy, and law enforcement personnel, as well as authorized officials of other agencies, both domestic and foreign.</p> <p>Administrators use elevated privileges for maintenance and system management. Following are instances where ALCF staff might look at your files:</p> <ul> <li>We maintain copies of all job submission error, output, and log files and may review them to determine if a job failure was due to user error or a system failure.</li> <li>If you request our assistance via any mechanism (for example, support ticket, direct personal email, in-person, etc.), be aware we may need to view your files using elevated privileges to aid us in resolving your issue.</li> </ul>"},{"location":"policies/data-and-software-policies/data-policy/#use-of-proprietarylicensed-software","title":"Use of Proprietary/Licensed Software","text":"<p>All software used on ALCF computers must be appropriately acquired and used according to the appropriate licensing. Possession or use of illegally copied software is prohibited. Likewise, users shall not copy copyrighted software, except as permitted by the owner of the copyright. Currently, the use of export-controlled codes is prohibited.</p>"},{"location":"policies/data-and-software-policies/data-policy/#prohibited-data","title":"Prohibited Data","text":"<p>The ALCF computer systems are operated as research systems and contain only data related to scientific research. Use of ALCF resources to store, manipulate, or remotely access any sensitive or national security information is prohibited unless documented and approved by the PI and ALCF leadership.</p> <p>This includes, but is not limited to, personally identifiable information (data that falls under the Privacy Act of 1974, 5 U.S.C. 552a), controlled unclassified information (CUI) to include unclassified controlled nuclear information (UCNI), naval nuclear propulsion information (NNPI), International Traffic in Arms Relations (ITAR), the design or development of nuclear, biological, or chemical weapons, or any weapons of mass destruction. The use of ALCF resources for personal or non-work-related activities is also prohibited.</p>"},{"location":"policies/data-and-software-policies/data-policy/#export-control","title":"Export Control","text":"<p>All principal investigators using ALCF resources and ALCF staff members working with project teams are responsible for knowing whether their project generates any of these prohibited data types or information that falls under Export Control. For questions, contact ALCF Support at support@alcf.anl.gov.</p>"},{"location":"policies/data-and-software-policies/data-policy/#data-storage-systems","title":"Data Storage Systems","text":"<p>Data stored for any length of time on ALCF resources should only be data directly related to work done on any of the ALCF leadership computing systems. Specific policies apply to the three types of data storage systems maintained at ALCF. Read these policies carefully and plan accordingly in terms of space, usage, and data protection.</p>"},{"location":"policies/data-and-software-policies/data-policy/#home-file-system-space-agile-home-gecko-home","title":"Home File System Space (agile-home, gecko-home)","text":"<p>The home file system (/home) is intended to hold your executable files, configuration files, etc. It is NOT meant to hold the output from your application runs (use the data/parallel file system for that purpose). The home file system space is generally moderate in size and is the best protected. Because of its size, backups are practical to accomplish. The system performs tape backups, enabling the recovery of files more than seven days old or recovery from a catastrophic disk failure. Users should email support@alcf.anl.gov if they need assistance. The table below indicates the capabilities and characteristics of each file system.</p> <p>AI Testbed home</p> <p><code>/home/</code> shared across the ALCF AI testbed systems, including the AI testbed's login and compute nodes, is different from mira-home. Default user quota on the AI testbed's home is 1 TB storage and 1,000,000 files. This space is backed up.</p>"},{"location":"policies/data-and-software-policies/data-policy/#team-project-or-campaign-file-system-eagle-flare","title":"Team Project or Campaign File System (Eagle, Flare)","text":"<p>The team project/campaign file system is intended primarily for results output from your computational runs on the ALCF computing systems. This space is accessible to the team members of your project that have an ALCF account. Default storage quota is 1 TB and the default period is 1 year. Consider this space intermediate-term storage. Once any active production and/or analysis is complete and you no longer need regular access to the data, archive it within the ALCF (explained below) or transfer it to your home institution or move it to Eagle to share it with the broader community (explained below).</p> <p>This space has redundancy in the servers and storage but is so large that replication, snapshots, and backups are not practical. Eagle is a Lustre global parallel file system. All new projects will be given storage allocations on Eagle. More information on Lustre File Striping Basics: Lustre File Striping Basics.</p> <p>Pullback Policy: Projects that do not use a minimum of 50% of their allocated space after 6 months will be subject to a quota limit reduction.</p> <p>AI Testbed projects file system</p> <p>The team project/campaign file system /projects mounted on AI Testbed's login and compute nodes is intended to facilitate project collaboration and is accessible to the team members of your project that have an ALCF account. Default group storage quota is 2 TB and 2,000,000 files. Please note that this space isn't backed up. Our policy is that data will be purged from disk 6 months after project completion.</p>"},{"location":"policies/data-and-software-policies/data-policy/#shared-community-project-or-campaign-file-system-eagle-flare","title":"Shared Community Project or Campaign File System (Eagle, Flare)","text":"<p>These Lustre global parallel file systems have community sharing abilities and are useful for sharing the project/campaign data with the broader research community via Globus. This space does not have redundancy in the servers or storage and is so large that replication, snapshots, and backups are not practical. The table below indicates the capabilities and characteristics of each file system. Default storage quota is 1 TB and the default period is 2 years. More information on Lustre file striping can be found in this presentation.</p> <p>Data Pullback Policy:  Projects that do not use a minimum of 50% of their allocated space after 6 months will be subject to a quota limit reduction.</p> <p>Access Termination Policy:  Project endpoints that have exhibited no activity* for a period of 6 months after the project ends will be disabled and the storage space will be reclaimed. Notification will be sent to the PI and project members 30 days prior to and the day of the action.</p> <p>Activity is defined as, but not limited to:</p> <ul> <li>Creation of the Globus endpoint</li> <li>Globus transfers to and from the endpoint</li> <li>atime audits of data files indicating access</li> <li>Other factors may include DOIs and citations referring to the project</li> </ul>"},{"location":"policies/data-and-software-policies/data-policy/#archive-space","title":"Archive Space","text":"<p>The archive space is intended for offline storage of results you wish to retain but either have no immediate need to access or no room in your parallel file system space. Archiving capabilities are available via HPSS. The primary HPSS access is via HSI. HTAR is available, but its path length and file size limitations often cause it to fail. Globus Online and GridFTP are clients that can also be used with HPSS.  Due to the possibility of data corruption, users can request 2 copies for particularly critical data. Such requests will be handled on a case-by-case basis.</p>"},{"location":"policies/data-and-software-policies/data-policy/#data-storage-policies","title":"Data Storage Policies","text":""},{"location":"policies/data-and-software-policies/data-policy/#disk-capacity-and-retention-policies","title":"Disk Capacity and Retention Policies","text":"---- /home lus/eagle/projects, /eagle, /grand, lus/flare/projects or /flare Default Quota <sup>1</sup> 50 GB 1 TB / 1 million files Quota Enforcement <sup>2</sup> hard/soft hard/soft Disk Redundancy <sup>3</sup> dual parity dual parity File Server Snapshots <sup>6</sup> (frequency/retained) none none File Server Metadata Redundancy yes yes File Server Metadata Replication <sup>4</sup> yes yes File Server Data Replication <sup>5</sup> yes no Data Purged from Disk n/a After 6 months of inactivity once project ends (see Access termination policy listed in the section above) <sup>8</sup>"},{"location":"policies/data-and-software-policies/data-policy/#tape-capacity-and-retention-policies","title":"Tape Capacity and Retention Policies","text":"---- /home lus/eagle/projects, /eagle, /grand, lus/flare/projects or /flare Automatic Backup to Tape? <sup>6</sup> yes no Archived to Tape Before Deleted from Disk? <sup>8</sup> yes no <ol> <li>While quotas are subject to negotiation on a case-by-case basis, disk space is a finite resource and projects must exercise good data management practices for their own sake and the sake of other users of the facility. With Lustre, it has become necessary to enforce file quotas as well, which are also negotiable.</li> <li>\u201cHard quota enforcement\u201d means a job will fail when writing output if you exceed the hard quota limit. \"Soft quota enforcement\" means you may exceed the soft quota limit (but never the higher hard quota value) for up to seven days. If you do not drop back below the soft quota limit within seven days, writes will begin to fail.</li> <li>Hard drives are in redundancy groups of 10 disks (8 data + 2 parity). In other words, three out of 10 drives would have to fail before data loss occurred.</li> <li>Metadata (i.e., information listing which blocks are part of which files) is written twice to two different storage arrays. Thus, even if an entire array were lost, the metadata would be preserved.</li> <li>Refers to the fact that data (user output) is written twice with each block on two different storage arrays, so that even if an entire array were lost, the data would be preserved.</li> <li>\u201cYes\u201d denotes that ALCF does regular backups without intervention from the user. Currently gecko-home is unable to be backed up.  </li> <li>The project directory is available on disk for the stipulated period but project quotas are reduced immediately following project end date. Access to the directory will be removed after 180 days. Requests to restore/extend access or reset the quota are reviewed on a case-by-case basis. </li> <li>Users who wish to retain data must archive or transfer their data elsewhere at the end of the project. Users need an active ALCF account to access archived data on HPSS. See Account Retention Policy for more information. The user is responsible for archiving the data to HPSS or copying it to another facility as desired. Data will be retained on tape for 2 years, at which time it is eligible for removal (subject to change). </li> </ol>"},{"location":"policies/data-and-software-policies/software-policy/","title":"ALCF Resource Software Use","text":"<p>All software used on ALCF computers must be appropriately acquired and used according to the appropriate licensing. Possession or use of illegally copied software is prohibited. Likewise, users shall not copy copyrighted software, except as permitted by the owner of the copyright. Currently, the use of export-controlled codes is prohibited.</p>"},{"location":"policies/data-and-software-policies/software-policy/#community-software-policy","title":"Community Software Policy","text":"<p>ALCF supports the deployment of community software from active projects on production systems.  User deployments are system-specific, and their maintenance is the sole responsibility of the project deploying it. There shall be no expectation of additional support from ALCF, other than for the provisioning of space and integration with the module system. Projects will be provided with an initial module file from a template, with the expectation that they will update and maintain the module, providing paths and instructions so that user communities can access the software.</p>"},{"location":"policies/queue-scheduling/","title":"Queue and Scheduling Policy","text":""},{"location":"policies/queue-scheduling/#general-policy","title":"General Policy","text":"<p>We ask that all users follow good etiquette and be excellent to one another.</p>"},{"location":"policies/queue-scheduling/#priority","title":"Priority","text":"<p>As with all Argonne Leadership Computing Facility production systems, job priority in the queue is based on several criteria:</p> <ul> <li>Positive balance of your project</li> <li>Size (in nodes) of the job; larger jobs receive higher priority</li> <li>The type of project (e.g., INCITE, ALCC, or discretionary)</li> <li>Job duration - shorter duration jobs will accumulate priority more quickly, so it is best to specify the job run time as accurately as possible</li> </ul>"},{"location":"policies/queue-scheduling/#reservations-and-scheduling-policy","title":"Reservations and Scheduling Policy","text":"<p>Some work will require use of Polaris that necessitates deviation from regular policy. On such occasions, normal reservation policy applies. Please send the regular form no fewer than five (5) business days in advance.</p>"},{"location":"policies/queue-scheduling/#big-run-mondays","title":"Big Run Mondays","text":"<p>As part of our regular maintenance procedures on Mondays, we will promote to the highest priority any jobs in the queued state requesting 802 nodes or more. Promotion is subject to operational discretion.</p> <p>We may also, at our discretion, take the opportunity to promote the priority of capability jobs (20% of the machine) if the system has been drained of jobs for any other reason.</p>"},{"location":"policies/queue-scheduling/#monday-maintenance","title":"Monday Maintenance","text":"<p>On Mondays when the ALCF is on a regular business schedule, the system may be expected to undergo maintenance from 9:00 am until 5:00 pm US Central Time. The <code>showres</code> command may be used to view pending and active maintenance reservations.</p>"},{"location":"policies/queue-scheduling/#incitealcc-overburn-policy","title":"INCITE/ALCC Overburn Policy","text":"<p>If an INCITE or ALCC project has exhausted its allocation in the first 11 months of its allocation year, it is eligible for overburn running. At this point, capability jobs (20% of the machine) submitted by INCITE and ALCC projects will run in the default queue (instead of backfill) for the first 11 months of the allocation year until 125% of the project allocation has been consumed.</p> <p>INCITE and ALCC projects needing additional overburn hours should email support@alcf.anl.gov with a short description of what they plan to do with the additional hours, highlighting specific goals or milestones and the time expected to accomplish them. This will be reviewed by the scheduling committee, allocations committee, and ALCF management. Requests should be submitted 15 days before the start of the next quarter of the allocation year for full consideration. Non-capability jobs (less than 20% of the machine) from projects that have exhausted their allocation will continue to run in backfill.</p> <p>To be clear, this policy does not constitute a guarantee of extra time, and we reserve the right to prioritize the scheduling of jobs submitted by projects that have not yet used 100% of their allocations, so the earlier that an INCITE or ALCC project exhausts its allocation, the more likely it is to be able to take full advantage of this policy.</p>"},{"location":"policies/queue-scheduling/pullback-policy/","title":"Pullback Policy","text":"<p>In an effort to ensure that valuable ALCF computing resources are used judiciously, a pullback policy has been instituted. Projects granted allocations under the INCITE and ALCC programs that have not used a significant amount of their allocation will be evaluated and adjusted during the year following the policies outlined on this page.</p> <p>The figures outlined below represent the maximum amount that will be pulled back from projects after specific dates during the allocation period. The decision to reduce allocations will be made on a case-by-case basis in discussion with the project's primary investigators (PIs).</p>"},{"location":"policies/queue-scheduling/pullback-policy/#incite-pullback-policy","title":"INCITE Pullback Policy","text":"<p>On May 1 of the current INCITE calendar year: - If usage is less than 15%, remove up to 15% of the unused balance. - If usage is less than 10%, remove up to 30% of the unused balance.</p> <p>On September 1 of the current INCITE calendar year: - If usage is less than 50%, remove up to 33% of the unused balance. - If usage is less than 33%, remove up to 50% of the unused balance. - If usage is less than 10%, remove up to 75% of the unused balance.</p>"},{"location":"policies/queue-scheduling/pullback-policy/#alcc-pullback-policy","title":"ALCC Pullback Policy","text":"<p>ALCC projects must use 50% of their allocation within the first seven months of the allocation cycle. Any unused time in excess of 50% will be deducted from the project allocation at the end of the seven-month period.</p>"},{"location":"policies/queue-scheduling/refund-policy/","title":"Refund Policy","text":"<p>If a system problem affects your run, ALCF will consider a refund of node hours. The ALCF expects all applications to regularly checkpoint, so refunds are typically capped at four hours of runtime for the affected job, unless the problem in question prevented checkpoints.</p> <p>ALCF strongly advises against symlinking between filesystems or hard-coding paths to a different filesystem.</p> <p>To request a refund, send the following information to support@alcf.anl.gov: - Job ID - Machine - Reason for refund request</p> <p>For more information, contact support@alcf.anl.gov.</p>"},{"location":"running-jobs/","title":"Running Jobs using PBS","text":""},{"location":"running-jobs/#additional-resources-documentation","title":"Additional Resources / Documentation","text":"<p>The following PBS information is general and applies to obtaining and managing compute resources for all systems at ALCF.</p> <ul> <li>ALCF Status:<ul> <li>Live at https://status.alcf.anl.gov</li> </ul> </li> <li>Obtaining and managing compute resources at ALCF:<ul> <li>Quick Start</li> <li>Definitions and Notes</li> <li>Using Fakeroot with Singularity</li> </ul> </li> <li>Working with PBS:<ul> <li>Users Guide</li> <li>Big Book   This is really excellent. We highly suggest you download it and search   through it when you have questions.</li> <li>Reference Guide   It shows every option and gives you details on how to format various elements on the command line.</li> <li>Shell Commands:<ul> <li>qsub: Submit a job to run</li> <li>qstat: Query the status of jobs/queues</li> <li>qalter: Alter a queued job</li> <li>qdel: Delete a queued or running job</li> <li>qmove: Move a job to a different queue</li> <li>qhold,qrls: Place/release a hold on a job in a queue</li> <li>qselect: Utility to select JobIDs that meet criteria</li> <li>qmsg: Write a message into a job's output file</li> <li>qsig: Send a signal to a job</li> <li>pbsnodes: Get information about the current state of nodes</li> <li> <p>pbs-tui</p> <pre><code>uv run --with pbs-tui pbs-tui\n</code></pre> </li> </ul> </li> </ul> </li> </ul>"},{"location":"running-jobs/#introduction","title":"Introduction","text":"<p>At a high level, getting computational tasks run on an HPC system is a two-step process:</p> <ol> <li>You request and get allocated resources (we allocate at the node level, but    some facilities you request number of cores and RAM, etc.) on one or more of    the systems.    This is accomplished by interacting with the job scheduler / workload    manager.    In the ALCF, we use PBS Professional.</li> <li>You execute your tasks on those resources.    This is accomplished in your job script by interacting with various system    services (MPI, OpenMP, the HPE PALS task launch system, etc.)</li> </ol> <p>Our documentation is organized in two sections aligned with the two steps described above.</p>"},{"location":"running-jobs/#obtaining-and-managing-compute-resources-at-alcf","title":"Obtaining and managing compute resources at ALCF","text":""},{"location":"running-jobs/#definitions-and-notes","title":"Definitions and Notes","text":"<p><code>chunk</code> :    A set of resources allocated as a unit to a job. Specified inside a selection directive. All parts of a chunk come from the same host. In a typical MPI (Message-Passing Interface) job, there is one chunk per MPI process.</p> <p><code>vnode</code> :   A virtual node, or vnode, is an abstract object representing a host or a set of resources which form a usable part of an execution host. This could be an entire host, or a nodeboard or a blade. A single host can be made up of multiple vnodes. Each vnode can be managed and scheduled independently. Each vnode in a complex must have a unique name. Vnodes on a host can share resources, such as node-locked licenses. PBS operates on vnodes. A vnode can, and in ALCF often will, represent an entire host, but it doesn't have to. For instance, there is a mode on Polaris where we could have each physical host look like four vnodes, each with 16 threads, 1/4 of the RAM and one A100.</p> <p><code>ncpus</code> :   Number of resources available to execute a program. In ALCF, given the way we configure PBS, this equates to a hardware thread. For example, a single socket node with a 32 core CPU, each with two hardware threads would report that as ncpus=64.</p> <p><code>ngpus</code> :   The number of allocable GPUs on the vnode. For an NVIDIA A100, this could be one, however, if we enable Multi Instance GPU (MIG) mode and use cgroups it could be as high as 7.</p> <p><code>job</code> :   A job equates to a qsub. A set of resources allocated to you for a period of time. You will execute one or more <code>tasks</code> on those resources during your job.</p> <p><code>task</code> :   A single execution on the resources of your job, often an <code>mpiexec</code> invocation launched by PALS or PMIx. You may run one task or many tasks during your job. You may run tasks sequentially or divide your resources up and run several tasks concurrently. Also sometimes referred to as job steps.</p>"},{"location":"running-jobs/#quick-start","title":"Quick Start","text":"<p>Here are the \"Big Four\" commands you will use:</p> <ol> <li><code>qsub</code>: request resources (generally compute nodes) to run your job and start your script/executable on the head node. Here is the minimal qsub allowed at the ALCF:<ul> <li><code>qsub -A &lt;project&gt; -l select=&lt;# of nodes&gt;,walltime=HH:MM:SS,filesystems=fs1:fs2 &lt;your job script&gt;</code></li> <li>The <code>-A</code>, <code>walltime</code>, and <code>filesystems</code> are mandatory. You will receive errors if they are not specified.</li> <li>We automatically add <code>-k doe</code> for you. This streams your output back rather than spooling it and copying it back at the end of the job. It probably isn't a bad idea to specify it in your script, but we enforce that option, so if you try and change it, you will get an error.</li> <li>It is highly likely you will also want to add <code>-l place=scatter</code> so that each of your chunks (<code>&lt;# of nodes&gt;</code>) gets its own vnode.</li> <li>If you want to run an executable rather than a script replace <code>&lt;your jobs script&gt;</code> in the example above with <code>-- &lt;your executable&gt;</code> (that is dash dash)</li> <li>PBS Documentation: Users Guide, Chapter 2, page UG-11 and Reference Guide Chapter 2, section 2.57, page RG-216</li> </ul> </li> <li><code>qstat</code>: check on the status of your jobs or queues<ul> <li>Try these variations and see which you like best: <code>qstat</code>, <code>qstat -was</code>, <code>qstat -was1</code>, <code>qstat -wan</code>, <code>qstat -wan1</code>. Add <code>-x</code> to see jobs that have completed. We keep two weeks of history.</li> <li><code>qstat -Q</code> will list all the queues in case you forget.</li> <li>PBS Documentation: Users Guide Sec. 10.2, page UG-175; Reference Guide Sec. 2.55, page RG-200</li> </ul> </li> <li><code>qalter</code>: update your request for resources<ul> <li>Just like qsub, just add a jobid at the end. Only works before the job starts;</li> <li>If you want to change the walltime to 30 minutes: <code>qalter -l walltime=30:00:00 &lt;jobid&gt;</code></li> <li>PBS Documentation: Users Guide Sec. 9.2, page UG-168; Reference Guide Sec. 2.40, page RG-130</li> </ul> </li> <li><code>qdel</code>: cancel a job that you don't need. This will also kill a running job<ul> <li><code>qdel &lt;jobid&gt;</code></li> <li>Occasionally, the job will still show up in <code>qstat</code> after you try and <code>qdel</code> it. When this happens you can try <code>qdel -W force &lt;jobid&gt;</code>. If it still won't go away, please send mail to support@alcf.anl.gov and one of the administrators can remove it for you. DO NOT just default to using <code>-W force</code>. The force does not do all of the clean up and can cause problems of its own.</li> <li>PBS Documentation: Users Guide Sec. 9.3, page UG-170; Reference Guide Sec. 2.41, page RG-143</li> </ul> </li> </ol> <p>Note</p> <p>The page numbers in the PBS guides are unique. If you search for the specified page number it will take you directly to the relevant page.</p>"},{"location":"running-jobs/#qsub-submit-a-job-to-run","title":"<code>qsub</code>: submit a job to run","text":"<p>Users Guide, Chapter 2, page UG-11 and Reference Guide Chapter 2, section 2.57, page RG-216</p> <p>At the ALCF, your qsub will likely use the following parameters:</p> <pre><code>qsub -A &lt;project&gt; -k doe -l select=&lt;#&gt;:system=&lt;name&gt;, walltime=HH:MM:SS, filesystems=fs1:fs2, place=scatter &lt;your job script&gt;\n</code></pre> <p>Where:</p> <ul> <li>project is the project name associated with your allocation. What you check the balance of with the <code>sbank</code> command. This is a mandatory option at the ALCF. If you don't include it you will get <code>qsub: Account_Name is required to be set.</code></li> <li><code>-k doe</code> is telling PBS to stream your output rather than buffer it on the compute nodes and then <code>scp</code> it at the end of the job. Note we will automatically add this if you don't specify it. We enforce this option, so if you try and specify any other output handling you will get an error.</li> <li># of chunks (typically nodes). Each of our systems has a PBS \"resource\" called <code>system</code> defined and set to the system name (<code>polaris</code>, <code>aurora</code>, etc)</li> <li><code>walltime=HH:MM:SS</code> specifying a wall time is mandatory at the ALCF. Valid wall times depend on the queue you are using. There is a table with the queues for each machine at the end of this section and in the machine specific documentation.</li> <li><code>filesystems=fs1:fs2:...</code> Specifying which filesystems your application uses is mandatory at ALCF. The reason for this is if a filesystem goes down, we have a way of making PBS aware of that and it won't run jobs that need that filesystem. If you don't specify filesystems you will receive the following error: <code>qsub: Resource: filesystems is required to be set.</code></li> <li><code>place=scatter</code> is telling PBS you want each of your chunks on a separate   vnode.</li> </ul> <p>By default, PBS will pack your chunks to get maximum utilization.   If you requested <code>ncpus=1</code> and <code>chunks=64</code> without <code>place=scatter</code> on a   system with <code>ncpus=64</code>, all your chunks would end up on one node.</p> <ul> <li>Your job script:</li> </ul> <p>See Example Job Scripts for more information   about how to build your job script.   For options that won't change, you do have the option of taking things off   the command line and putting them in your job script.   For instance the above command line could be simplified to   <code>qsub -l select=&lt;#&gt; &lt;your job script&gt;</code> if you added the following to the top   (the PBS directives have to be before any executable line) of your job script.</p> <pre><code>```bash linenums=\"1\"\n#PBS -A &lt;project&gt;\n#PBS -k doe\n#PBS -l walltime=HH:MM:SS\n#PBS -l filesystems=fs1:fs2\n```\n</code></pre> <p>Also note that if you want to run an executable directly rather than a script you use two dashes and the executable name in place of your script name like this: <code>-- /usr/bin/sleep 600</code></p>"},{"location":"running-jobs/#resource-selection-and-job-placement","title":"Resource Selection and Job Placement","text":"<p>Section 2.57.2.6 RG-219 Requesting Resources and Placing jobs in the Reference Guide.</p> <p>Resources come in two flavors:</p> <ul> <li>Job Wide: Walltime is the most common example of a job wide resource. You use the <code>-l</code> option to specify job wide resources, i.e. <code>-l walltime=06:00:00</code>. All the resources in the job have the same walltime.</li> <li><code>-l &lt;resource name&gt;=&lt;value&gt;[,&lt;resource name&gt;=&lt;value&gt; ...]</code></li> <li>Chunks: (see the definition above) This is how you describe what your needs are to run your job. You do this with the <code>-l select=</code> syntax. In the ALCF, we do whole node scheduling and every node has a resource called <code>system</code> which is set to the system name it belongs to (Polaris, Aurora, etc). This means you can typically get away with the very simple <code>-l select=128:system=foo</code> which will give you 128 complete nodes on system foo.</li> <li><code>-l select=[&lt;N&gt;:]&lt;chunk&gt;[+[&lt;N&gt;:]&lt;chunk&gt; ...]</code> where N specifies how many of that chunk and a chunk is of the form:</li> <li><code>&lt;resource name&gt;=&lt;value&gt;[:&lt;resource name&gt;=&lt;value&gt; ...]</code></li> <li>Here is a hypothetical example that would select resources with A100s and other resources with A40 GPUs. PBS takes care of co-scheduling the nodes on the two systems for you transparently. Note that in this case since we did not specify <code>system=</code> if there were multiple systems that could satisfy a chunk you wouldn't know ahead of time which system you would get.</li> </ul> <p><code>-l select=128:ncpus=64:ngpus=4:gputype=A100+32:ncpus=64:ngpus=2:gputype=A40</code></p> <p>You also have to tell PBS how you want the chunks distributed across the physical hardware. You do that via the <code>-l place</code> option:</p> <ul> <li><code>-l place=[&lt;arrangement&gt;][: &lt;sharing&gt; ][: &lt;grouping&gt;]</code> where</li> <li>arrangement is one of <code>free | pack | scatter | vscatter</code><ul> <li>unless you have a specific reason to do otherwise, you probably want to set this to <code>scatter</code>, otherwise you may not get what you expect. For instance on a host with ncpus=64, if you requested <code>-l select=8:ncpus=8</code> you could end up with all of our chunks on one node.</li> <li><code>free</code> means PBS can distribute them as it sees fit</li> <li><code>pack</code> means all chunks from one host. Note that this is not the minimum number of hosts, it is one host. If the chunks can't fit on one host, the qsub will fail.</li> <li><code>scatter</code> means take only one chunk from any given host.</li> <li><code>vscatter</code> means take only one chunk from any given vnode. If a host has multiple vnodes, you could end up with more than one chunk on the host.</li> </ul> </li> <li>sharing is one of <code>excl | shared | exclhost</code> where<ul> <li>NOTE: Node configuration can override your requested sharing mode. For instance, in most cases ALCF sets the nodes to <code>force_exclhost</code>, so normally you don't have to specify this.</li> <li><code>excl</code> means this job gets the entire vnode</li> <li><code>shared</code> means the vnode could be shared with another job from another user.</li> <li><code>exclhost</code> means this job gets the entire host, even if it has multiple vnodes.</li> </ul> </li> <li>group=<code>&lt;resource name&gt;</code><ul> <li>As an example, for machines that use a dragonfly network topology, we provide a PBS resource named <code>tier1</code> indicating which dragonfly group a node is in. If you wanted to ensure that all the chunks came from a single dragonfly group, you could specify <code>place=group=tier1</code> as part of your qsub. <code>tier0</code> is rack granularity, so <code>group=tier0</code> would ensure your nodes all came from one rack. Note that if you requested more nodes than were available in a rack your job would never run and you would see something like <code>Not Running: Insufficient amount of resource: tier0</code>.</li> </ul> </li> </ul> <p>We have defined placement sets for the tier0 and tier1 resources. As a result, if you don't specify a grouping PBS will preferentially group your nodes in a placement set, but it won't drain or delay your job start to do so. For example, if you request 10 nodes and don't specify a grouping, if 10 nodes are available in the same rack, all your nodes will be in one rack. If not, but there are 10 nodes in a single dragonfly group, all your nodes will be in one dragonfly group. If you wish to specify a specific rack or dragonfly group, that is accomplished via the select syntax. For instance, <code>qsub ... -l select=10:tier1=g0</code> would force your 10 nodes to be in dragonfly group 0.</p> <p>Here is a heavily commented sample PBS submission script that shows some more of the options, but remember that the PBS manuals referenced at the top of this page are the ultimate resource.</p> <pre><code>#!/bin/bash -l\n# UG Section 2.5, page UG-24 Job Submission Options\n# Add another # at the beginning of the line to comment out a line\n# NOTE: adding a switch to the command line will override values in this file.\n\n# These options are MANDATORY at ALCF; Your qsub will fail if you don't provide them.\n#PBS -A &lt;short project name&gt;\n#PBS -l walltime=HH:MM:SS\n#file systems used by the job\n#PBS -l filesystems=home:eagle\n\n\n# Highly recommended\n# The first 15 characters of the job name are displayed in the qstat output:\n#PBS -N &lt;name&gt;\n\n# If you need a queue other than the default, which is prod (uncomment to use)\n##PBS -q &lt;queue name&gt;\n\n# Controlling the output of your application\n# UG Sec 3.3 page UG-42 Managing Output and Error Files\n# By default, PBS spools your output on the compute node and then uses scp to move it the\n# destination directory after the job finishes.  Since we have globally mounted file systems\n# it is highly recommended that you use the -k option to write directly to the destination\n# the doe stands for direct, output, error\n#PBS -k doe\n#PBS -o &lt;path for stdout&gt;\n#PBS -e &lt;path for stderr&gt;\n\n# If you want to merge stdout and stderr, use the -j option\n# oe=merge stdout/stderr to stdout, eo=merge stderr/stdout to stderr, n=don't merge\n#PBS -j n\n\n# Controlling email notifications\n# UG Sec 2.5.1, page UG-25 Specifying Email Notification\n# When to send email b=job begin, e=job end, a=job abort, j=subjobs (job arrays), n=no mail\n#PBS -m be\n# Be default, mail goes to the submitter, use this option to add others (uncomment to use)\n#PBS -M &lt;email addresses&gt;\n\n# Setting job dependencies\n# UG Section 6.2, page UG-109 Using Job Dependencies\n# There are many options for how to set up dependencies;\n# afterok will give behavior similar to Cobalt (uncomment to use)\n##PBS depend=afterok:&lt;jobid&gt;:&lt;jobid&gt;\n\n# Environment variables (uncomment to use)\n# UG Section 6.12, page UG-126 Using Environment Variables\n# RG Sect 2.57.7, page RG-233 Environment variables PBS puts in the job environment\n##PBS -v &lt;variable list&gt;\n## -v a=10, \"var2='A,B'\", c=20, HOME=/home/zzz\n##PBS -V exports all the environment variables in your environment to the compute node\n\n\n# The rest is an example of how an MPI job might be set up\necho Working directory is $PBS_O_WORKDIR\ncd $PBS_O_WORKDIR\n\necho Jobid: $PBS_JOBID\necho Running on host `hostname`\necho Running on nodes `cat $PBS_NODEFILE`\n\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS=1           # Number of MPI ranks per node\nNDEPTH=1           # Number of hardware threads per rank, spacing between MPI ranks on a node\nNTHREADS=1         # Number of OMP threads per rank, given to OMP_NUM_THREADS\n\nNTOTRANKS=$(( NNODES * NRANKS ))\n\necho \"NUM_OF_NODES=${NNODES}  TOTAL_NUM_RANKS=${NTOTRANKS}  RANKS_PER_NODE=${NRANKS}  THREADS_PER_RANK=${NTHREADS}\"\n\nmpiexec --np ${NTOTRANKS} -ppn ${NRANKS} -d ${NDEPTH} -env OMP_NUM_THREADS=${NTHREADS} ./hello_mpi\n</code></pre>"},{"location":"running-jobs/#email-notifications","title":"Email Notifications","text":"<p>Users should add <code>-M &lt;email address&gt;</code> if they want notifications as a best practice.</p> <p>Note: For users with '@alcf.anl.gov' email addresses, PBS will send out an email once the job has ended by default. If you do not want to receive these notifications, you will need to add <code>#PBS -m n</code> to your script."},{"location":"running-jobs/#specifying-filesystems","title":"Specifying Filesystems","text":"<p>Note: The <code>filesystems</code> attribute is mandatory. If you do not specify a filesystem(s) you will receive the following error message upon submission:</p> <p><code>qsub: Resource: filesystems is required to be set.</code></p> <p>Valid filesystems are <code>home</code> and <code>eagle</code>. For example, to request the home and Eagle filesystems for your job you would add <code>-l filesystems=home:eagle</code> to your <code>qsub</code> command.</p> <p>If a job is submitted while a filesystem it requested is marked down, the job will be queued but will not run, with a message in the comment field of the job as to why it is not running. Run <code>qstat -f &lt;jobid&gt;</code> to see the comment field. For example, if the job requested for eagle and if Eagle is unavailable, the comment field will have <code>Can Never Run: Insufficient amount of server resource: eagle_fs (True != False)</code>). Once the affected filesystem has been returned to normal operation, and the filesystem is marked as being available, the job will then be scheduled normally. The job cannot run until all filesystems requested by the job are available.</p> <p>If a job requesting a filesystem that is marked down is already in the queue, the job will be not run until all of its requested filesystems are available.</p> <p>An example of a job requesting filesystems:</p> <p><code>qsub -l select=10:ncpus=64,walltime=30:00,filesystems=eagle:home -A ProjectX -q prod my_job.sh</code></p> <p>To update the filesystems list for your job, use <code>qalter</code>.</p>"},{"location":"running-jobs/#qsub-examples","title":"qsub examples","text":"<ul> <li><code>qsub -A my_allocation -l select=4:system=polaris -l filesystems=home:eagle -l walltime=30:00 -q debug-scaling -- a.out</code></li> <li>run a.out on 4 chunks on polaris with a walltime of 30 minutes in debug-scaling queue; charge my_allocation;</li> <li>Since we allocate full nodes on Polaris, 4 chunks will be 4 nodes. If we shared nodes, that would be 4 threads.</li> <li>use the -- (dash dash) syntax when directly running an executable.</li> <li><code>qsub -A my_allocation -l place=scatter  -l filesystems=home:eagle -l select=32:ncpus=32 -q prod -l walltime=30:00 mpi_mm_64.sh</code></li> <li>32 chunks on any system that meets the requirements. Each chunk must have 32 HW threads; <code>place=scatter</code> means use a different vnode for each chunk, even if you could fit more than one on a vnode. Use the queue named <code>prod</code>.</li> </ul>"},{"location":"running-jobs/#qstat-query-the-status-of-jobsqueues","title":"<code>qstat</code>: Query the status of jobs/queues","text":"<p>Users Guide Sec. 10.2, page UG-175; Reference Guide Sec. 2.55, page RG-200</p>"},{"location":"running-jobs/#jobs","title":"Jobs","text":"<p>At its most basic, you just type <code>qstat</code> and it will list all the jobs currently running, queued, or held on the system. If you are interested in a specific job or jobs, you can provide a space-separated list on the command line: <code>qstat job1 job2...</code>.</p> <pre><code>Job id            Name             User              Time Use S Queue\n----------------  ---------------- ----------------  -------- - -----\n349726.polaris-p* PDE2             user1                    0 Q prod\n336987.polaris-p* inf_clDB         user2                    0 H large\n353205.polaris-p* 3d-2.sub         user3             2044:14* R large\n</code></pre> <p>One of the annoying things about <code>qstat</code> is that the output fields are fixed width and it will truncate the output. This is indicated by an asterisk as the last character. You can add <code>-w</code> for wide. It doesn't prevent truncation, but makes it less likely. A useful variant is <code>qstat -was1</code>. It shows the number of nodes, tasks, the requested walltime, and the comment, all on one line. <code>qstat -wan</code> will give you the node list you ran on, just remember that can be long. If you want an estimate of when the job will start, add the <code>-T</code> option. Note that start time is not available for all jobs, just the next N jobs that are expected to run. If you want to know everything there is to know about the job, add the <code>-f</code> flag.</p> <pre><code>                                                            Req'd  Req'd   Elap\nJob ID          Username Queue    Jobname    SessID NDS TSK Memory Time  S Time\n--------------- -------- -------- ---------- ------ --- --- ------ ----- - -----\n353201.polaris* user1    large    3d-1.sub    34449  60 38*    --  24:00 R 08:25    Job run at Tue Nov 15 at 16:44 on (x3006c0s13b1n0:ngpus=4:ncpus=64)+(x...\n353289.polaris* user2    medium   run_mae_l*    --   32 20*    --  12:00 Q   --     Not Running: Job would conflict with reservation or top job\n353411.polaris* user3    large    1310W60       --   64  64    --  06:00 Q   --     Not Running: Not enough free nodes available\n336990.polaris* user4    large    inf_clDB      --  464 29*    --  01:00 H   --     Job held by user4 on Mon Oct  3 20:16:26 2022\n</code></pre> <p>The <code>comment</code> field is your friend. Wondering why your job isn't running? Check the comment. Wondering about the fate of a finished job? Add the <code>-x</code> option to see finished jobs (our history retention is currently set at two weeks) and check the comment. This cannot be stressed enough. Often, when a user ticket comes in about PBS, we answer it by looking at the comment.</p> <p>If you are familiar with <code>jq</code> or some other command line JSON tool, the <code>-F JSON</code> option can be quite handy. <code>grep</code> is great, but when you grep the <code>-f</code> output for something, you probably want to know which node the found lines belong to. With the JSON output that is trivial.</p> <pre><code>allcock@polaris-login-02:~/.ssh&gt;  qstat -fF JSON | jq '.Jobs | map_values(select(.job_state == \"R\") | {Job_Name, Account_Name, qtime, stime})'\n{\n  \"349710.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\": {\n    \"Job_Name\": \"P38\",\n    \"Account_Name\": \"CompBioAffin\",\n    \"qtime\": \"Fri Nov  4 11:04:12 2022\",\n    \"stime\": \"Fri Nov 11 07:52:12 2022\"\n  },\n  \"352220.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\": {\n    \"Job_Name\": \"mdsim_10000_run1.pbs\",\n    \"Account_Name\": \"RL-fold\",\n    \"qtime\": \"Thu Nov 10 22:41:55 2022\",\n    \"stime\": \"Fri Nov 11 09:00:12 2022\"\n  },\n</code></pre>"},{"location":"running-jobs/#queues","title":"Queues","text":"<p><code>qstat -Q</code> Will show you the names of all the queues and tell you their status. If they are enabled (Ena column), you can queue jobs into them. If they are started (Str column) then the scheduler will try and run jobs from it. There is a <code>-f</code> (full) option but that is mostly for admins, though you can find the min and max node count <code>(resources_[min|max].nodect)</code> and min and max walltime <code>(resources_[min|max]walltime)</code> from the output. Those values are also available in this documentation.</p>"},{"location":"running-jobs/#qalter-alter-a-queued-job","title":"<code>qalter</code>: Alter a queued job","text":"<p>Users Guide Sec. 9.2, page UG-168; Reference Guide Sec. 2.40, page RG-130</p> <p>Basically takes the same options as <code>qsub</code>; Say you typoed and set the walltime to 300 minutes instead of 30 minutes. You could fix it (if the job had not started running) by doing <code>qalter -l walltime=30:00 &lt;jobid&gt; [&lt;jobid&gt; &lt;jobid&gt;...]</code> The new value overwrites any previous value.</p>"},{"location":"running-jobs/#qdel-delete-a-queued-or-running-job","title":"<code>qdel</code>: Delete a queued or running job","text":"<p>Users Guide Sec. 9.3, page UG-170; Reference Guide Sec. 2.41, page RG-143</p> <p><code>qdel &lt;jobid&gt; [&lt;jobid&gt; &lt;jobid&gt;...]</code></p> <p>Occasionally, the job will still show up in <code>qstat</code> after you try and <code>qdel</code> it. When this happens you can try <code>qdel -W force &lt;jobid&gt;</code>. If it still won't go away, please send mail to support@alcf.anl.gov and one of the administrators can remove it for you. DO NOT just default to using <code>-W force</code>. The force does not do all of the clean up and can cause problems of its own.</p>"},{"location":"running-jobs/#qmove-move-a-job-to-a-different-queue","title":"<code>qmove</code>: Move a job to a different queue","text":"<p>Users Guide Sec. 9.7, page UG-173; Reference Guide Sec. 2.46, page RG-175</p> <ul> <li><code>qmove &lt;new queue&gt; &lt;jobid&gt; [&lt;jobid&gt; &lt;jobid&gt;...]</code></li> <li>Only works before a job starts running</li> </ul>"},{"location":"running-jobs/#qholdqrls-place-release-a-user-hold-on-a-job","title":"<code>qhold,qrls</code>: Place / release a user hold on a job","text":"<p>Reference Guide Sec 2.44, page RG-150 and Sec 2.50, page RG-183</p> <ul> <li><code>[qhold | qrls] &lt;jobid&gt; [&lt;jobid&gt; &lt;jobid&gt;...]</code></li> </ul>"},{"location":"running-jobs/#qselect-query-jobids-for-use-in-commands","title":"<code>qselect</code>: Query jobids for use in commands","text":"<p>Users Guide Sec. 10.1, page UG-175; Reference Guide Sec. 2.52, page RG-189</p> <ul> <li><code>qdel qselect -N test1</code> will delete all the jobs that had the job name set to <code>test1</code>.</li> </ul>"},{"location":"running-jobs/#qmsg-write-a-message-into-a-jobs-output-file","title":"<code>qmsg</code> Write a message into a job's output file","text":"<p>Users Guide Sec. 9.4, page UG-171; Reference Guide Sec. 2.47, page RG-177</p> <ul> <li><code>qmsg -E -O \"This is the message\" &lt;jobid&gt; [&lt;jobid&gt; &lt;jobid&gt;...]</code></li> <li><code>-E</code> writes it to standard error, <code>-O</code> writes it to standard out</li> </ul>"},{"location":"running-jobs/#qsig-send-a-signal-to-a-job","title":"<code>qsig</code> Send a signal to a job","text":"<p>Users Guide Sec. 9.5, page UG-172; Reference Guide Sec. 2.53, page RG-195</p> <ul> <li><code>qsig -s &lt;signal&gt; &lt;jobid&gt; [&lt;jobid&gt; &lt;jobid&gt;...]</code></li> <li>If you don't specify a signal, <code>SIGTERM</code> is sent.</li> </ul>"},{"location":"running-jobs/#pbsnodes-get-information-about-the-current-state-of-nodes","title":"<code>pbsnodes</code> Get information about the current state of nodes","text":"<p>Reference Guide Sec 2.7 page RG-36</p> <p>This is more for admins, but it can tell you what nodes are free (state), how many \"CPUs\" which is actually the number of threads (ncpus), how many GPUs (ngpus) which with some GPUs like NVIDIA A100s can change depending on the MIG mode, and if the node is shared or not (sharing).</p> <p><code>pbsnodes &lt;node name&gt;</code>: Everything there is to know about a node</p> <pre><code>&gt; pbsnodes x3002c0s7b1n0\nx3002c0s7b1n0\n     Mom = x3002c0s7b1n0.hsn.cm.polaris.alcf.anl.gov\n     Port = 15002\n     pbs_version = 2022.1.1.20220926110806\n     ntype = PBS\n     state = free\n     pcpus = 64\n     resources_available.arch = linux\n     resources_available.demand = False\n     resources_available.gputype = A100\n     resources_available.host = x3002c0s7b1n0\n     resources_available.mem = 527672492kb\n     resources_available.ncpus = 64\n     resources_available.ngpus = 4\n     resources_available.system = polaris\n     resources_available.tier0 = x3002-g0\n     resources_available.tier1 = g0\n     resources_available.vnode = x3002c0s7b1n0\n     resources_assigned.accelerator_memory = 0kb\n     resources_assigned.hbmem = 0kb\n     resources_assigned.mem = 0kb\n     resources_assigned.naccelerators = 0\n     resources_assigned.ncpus = 0\n     resources_assigned.ngpus = 0\n     resources_assigned.vmem = 0kb\n     resv_enable = True\n     sharing = force_exclhost\n     license = l\n     last_state_change_time = Tue Nov 15 19:26:39 2022\n     last_used_time = Tue Nov 15 19:26:39 2022\n     server_instance_id = polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov:15001\n</code></pre> <p><code>pbsnodes -avSj</code>: A nice table to see what is free and in use</p> <pre><code>&gt; pbsnodes -avSj\n                                                        mem       ncpus   nmics   ngpus\nvnode           state           njobs   run   susp      f/t        f/t     f/t     f/t   jobs\n--------------- --------------- ------ ----- ------ ------------ ------- ------- ------- -------\nx3014c0s19b0n0  job-exclusive        1     1      0  503gb/503gb   63/64     0/0     4/4 353394\nx3014c0s19b1n0  resv-exclusive       0     0      0  503gb/503gb    0/64     0/0     4/4 --\nx3014c0s1b0n0   offline              0     0      0  503gb/503gb   64/64     0/0     4/4 --\n</code></pre> <p><code>pbsnodes -avSj | grep free | wc -l</code>: A quick way to see how many nodes are free</p> <pre><code>[20220217-21:09:30]&gt; pbsnodes -avSj | grep free | wc -l\n38\n</code></pre> <p><code>pbsnodes -avSj | grep free | awk '{print $1}'</code>: Lists the free nodes</p> <pre><code>[20220217-21:09:30]&gt; pbsnodes -avSj | grep free | awk '{print $1}'\nx3201c0s25b0n0\nx3209c0s13b0n0\nx3209c0s19b0n0\nx3209c0s1b1n0\n</code></pre> <p><code>pbsnodes -l</code>: (lowercase l) see which nodes are down. The comment often indicates why it is down</p> <pre><code>[20220217-21:10:31]&gt; pbsnodes -l\nx3014c0s19b0n0       offline,resv-exclusive Xid 74 -- GPUs need reseat\nx3014c0s25b0n0       offline,resv-exclusive Checking on ConnectX-5 firmware\n</code></pre>"},{"location":"running-jobs/#job-priority","title":"Job Priority","text":"<p>In PBS it is not easy to see a priority order for which jobs will run next. The best way is to use the <code>-T</code> option on qsub and look at the estimated start times. ALCF runs a custom scheduler algorithm, but in general, the job priority in the queue is based on several criteria:</p> <ol> <li>positive balance of your project</li> <li>size (in nodes) of the job, larger jobs receive higher priority</li> <li>the type of project (e.g. INCITE, ALCC, or discretionary)</li> <li>job duration: shorter duration jobs will accumulate priority more quickly, so it is best to specify the job run time as accurately as possible</li> </ol>"},{"location":"running-jobs/#troubleshooting-common-errors","title":"Troubleshooting / Common Errors","text":"<p>If you receive a <code>qsub: Job rejected by all possible destinations</code> error, then check your submission parameters. The issue is most likely that your walltime or node count do not fall within the ranges listed above for the production execution queues. Please see the table above for limits on production queue job sizes.</p> <p>Job missing from queue</p> <p>If you receive a job ID but you cannot find your job with <code>qstat</code>, then this may be a submission parameter issue. This can happen for batch submission because the job is being accepted into the routing (<code>prod</code>) queue. The routing/<code>prod</code> queue's parameters are more broad since it needs to accommodate for all three production queues (<code>small</code>, <code>medium</code>, &amp; <code>large</code>). The prod routing queue accepts the job, generating a job ID. Depending on what is going on with the system, the routing may or may not occur before the <code>qsub</code> returns (i.e., if the queues are backed-up the routing queue can't route the job before the <code>qsub</code> returns). If the routing is delayed then a job ID is returned, and routing is completed later. Since the <code>qsub</code> has ended then there isn't a way to inform the user that this has been rejected by all routing destinations. If you run a <code>qstat</code> on the <code>jobid</code>, it will return <code>qstat: Unknown Job Id &lt;jobid&gt;</code>.</p>"},{"location":"running-jobs/#using-fakeroot-with-singularity","title":"Using Fakeroot with Singularity","text":"<p>The fakeroot feature (commonly referred to as rootless mode) allows an unprivileged user to run a container as a \u201cfake root\u201d user by leveraging user namespace UID/GID mapping. To request this feature be enabled on your job add the following to your <code>qsub</code> command line:</p> <p><code>-l singularity_fakeroot=true</code></p>"},{"location":"running-jobs/example-job-scripts/","title":"Example Job Scripts","text":"<p>This page contains a small collection of example job scripts users may find useful for submitting their jobs on Polaris. Additional information on PBS and how to submit these job scripts is available here.</p> <p>A simple example using a similar script on Polaris is available in the Getting Started Repo.</p> <p>Comments in PBS scripts</p> <p>Since <code>#</code> is required prior to each PBS directive, comments should be added after the directives have been listed in your submission script. If you try to add comments within the directive list, you could experience submission issues due to PBS attempting to read your comment as an additional directive. This includes adding comments on the same line as a directive (i.e., <code>#PBS -q &lt;queue_name&gt;  #comment</code>).</p>"},{"location":"running-jobs/example-job-scripts/#cpu-mpi-openmp-examples","title":"CPU MPI-OpenMP Examples","text":"<p>The following <code>submit.sh</code> example submits a 1-node job to Polaris with 16 MPI ranks per node and 2 OpenMP threads per rank. See Queues for details on practical limits to node counts and job times for different sizes of jobs.</p> <p>The <code>hello_affinity</code> program is a compiled C++ code, which is built via <code>make -f Makefile.nvhpc</code> in the linked directory after cloning the Getting Started repository.</p> submit.sh<pre><code>#!/bin/bash -l\n#PBS -l select=1:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -l filesystems=home:eagle\n#PBS -q debug\n#PBS -A Catalyst\n\n# Change to working directory\ncd ${PBS_O_WORKDIR}  # (1)!\n\n# MPI and OpenMP settings\nNNODES=`wc -l &lt; $PBS_NODEFILE` # (2)!\nNRANKS_PER_NODE=16 # (3)!\nNDEPTH=2 # (4)!\nNTHREADS=2 # (5)!\n\nNTOTRANKS=$(( NNODES * NRANKS_PER_NODE )) # (6)!\necho \"NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}\"\n\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth --env OMP_NUM_THREADS=${NTHREADS} -env OMP_PLACES=threads ./hello_affinity\n</code></pre> <ol> <li><code>cd ${PBS_O_WORKDIR}</code>: change into the working directory from where <code>qsub</code> was executed.</li> <li><code>NNODES= `wc -l &lt; $PBS_NODEFILE`</code>: one method for determining the total number of nodes allocated to a job.</li> <li><code>NRANKS_PER_NODE=16</code>: This is a helper variable to set the number of MPI ranks for each node to 16.</li> <li><code>NDEPTH=2</code>: This is a helper variable to space MPI ranks 2 \"slots\" from each other. In this example, individual threads correspond to a slot. This will be used together with the <code>--cpu-bind</code> option from <code>mpiexec</code> and additional binding options are available (e.g. <code>numa</code>, <code>socket</code>, <code>core</code>, etc.).</li> <li><code>NTHREADS=2</code>: This is a helper variable to set the number of OpenMP threads per MPI rank.</li> <li><code>NTOTRANKS=$(( NNODES * NRANKS_PER_NODE))</code>: This is a helper variable calculating the total number of MPI ranks spanning all nodes in the job.</li> </ol> <p>The following function in the <code>hello_affinity</code> source code is essential for uniquely identifying the CUDA device even when Multi-Instance GPU (MIG) is enabled, as each physical device will be partitioned into multiple virtual devices, each with unique UUIDs differentiated by the last few characters:</p> Identifying physical or virtual GPU by UUID <pre><code>//https://stackoverflow.com/questions/68823023/set-cuda-device-by-uuid\nvoid uuid_print(cudaUUID_t a){\n  std::cout &lt;&lt; \"GPU\";\n  std::vector&lt;std::tuple&lt;int, int&gt; &gt; r = {{0,4}, {4,6}, {6,8}, {8,10}, {10,16}};\n  for (auto t : r){\n    std::cout &lt;&lt; \"-\";\n    for (int i = std::get&lt;0&gt;(t); i &lt; std::get&lt;1&gt;(t); i++)\n      std::cout &lt;&lt; std::hex &lt;&lt; std::setfill('0') &lt;&lt; std::setw(2) &lt;&lt; (unsigned)(unsigned char)a.bytes[i];\n  }\n  std::cout &lt;&lt; std::endl;\n}\n</code></pre> <p>Zsh users</p> <p>If you are a <code>zsh</code> user, you will need to ensure all PBS job submission and shell scripts include the <code>-l</code> flag following <code>#!/bin/bash</code> as seen in the example above to ensure your environment is being instantiated properly. <code>zsh</code> is not officially supported by HPE and support from ALCF will be best effort only.</p> <p>Each Polaris compute node has 1 Milan CPU with a total of 32 physical cores, with each core supporting 2 hardware threads (for a total of 64 logical cores).</p> <p>The process affinity in this example is set up to map each MPI rank to 2 physical cores. Each MPI rank spawns 2 OpenMP threads, so 1 thread per physical core. The OpenMP settings bind each OpenMP thread to a single hardware thread within a core, such that all 32 physical cores are utilized. CPU core IDs <code>32</code> to <code>63</code> are not mapped to any MPI rank, since they correspond to simultaneous multithreaded (SMT) sibling hardware threads that share the execution resources of the core ids <code>0</code> to <code>31</code>, respectively.</p> <ul> <li><code>cd ${PBS_O_WORKDIR}</code>: change into the working directory from where <code>qsub</code> was executed.</li> <li><code>NNODES= `wc -l &lt; $PBS_NODEFILE`</code>: one method for determining the total number of nodes allocated to a job.</li> <li><code>NRANKS_PER_NODE=16</code>: This is a helper variable to set the number of MPI ranks for each node to 16.</li> <li><code>NDEPTH=2</code>: This is a helper variable to space MPI ranks 2 \"slots\" from each other. In this example, individual threads correspond to a slot. This will be used together with the <code>--cpu-bind</code> option from <code>mpiexec</code> and additional binding options are available (e.g. <code>numa</code>, <code>socket</code>, <code>core</code>, etc.).</li> <li><code>NTHREADS=2</code>: This is a helper variable to set the number of OpenMP threads per MPI rank.</li> <li><code>NTOTRANKS=$(( NNODES * NRANKS_PER_NODE))</code>: This is a helper variable calculating the total number of MPI ranks spanning all nodes in the job.</li> </ul> <p>Information on the use of <code>mpiexec</code> is available via <code>man mpiexec</code>. Some notes on the specific options used in the above example follow.</p> <ul> <li><code>-n ${NTOTRANKS}</code>: This is specifying the total number of MPI ranks to start.</li> <li><code>--ppn ${NRANKS_PER_NODE}</code>: This is specifying the number of MPI ranks to start on each node.</li> <li><code>--depth=${NDEPTH}</code>: This is specifying how many cores/threads to space MPI ranks apart on each node.</li> <li><code>--cpu-bind depth</code>: This is indicating the number of cores/threads will be bound to MPI ranks based on the <code>depth</code> argument.</li> <li><code>--env OMP_NUM_THREADS=${NTHREADS}</code>: This is setting the environment variable <code>OMP_NUM_THREADS</code> to determine the number of OpenMP threads per MPI rank.</li> <li><code>--env OMP_PLACES=threads</code>: This is indicating how OpenMP should distribute threads across the resource, in this case across hardware threads.</li> </ul>"},{"location":"running-jobs/example-job-scripts/#hardware-threads","title":"Hardware threads","text":"<p>This example is similar to the previous, but it exhausts all 64 logical cores available on each compute node CPU. We double the number of MPI ranks to 32, one per each physical core. Using <code>--cpu-bind=core</code>, the <code>--depth</code> flag value becomes interpreted by Cray MPICH as spacing in number of physical cores, so <code>NDEPTH=1</code> ensures that rank 0 is bound to CPU core IDs <code>(0,32)</code>, the 2 SMT sibling hardware threads that share the first physical core.</p> submit_hw_threads.sh<pre><code>#!/bin/bash -l\n#PBS -l select=1:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -l filesystems=home:eagle\n#PBS -q debug\n#PBS -A Catalyst\n\n# Change to working directory\ncd ${PBS_O_WORKDIR}\n\n# MPI and OpenMP settings\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=32\nNDEPTH=1\nNTHREADS=2\n\nNTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))\necho \"NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}\"\n\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind core --env OMP_NUM_THREADS=${NTHREADS} -env OMP_PLACES=threads ./hello_affinity\n</code></pre> <p>Many HPC applications do not benefit from utilizing the CPU's SMT2 capabilities, and such software may achieve better performance by using the previous script such that each of the 32 physical cores only runs a single OpenMP thread.</p>"},{"location":"running-jobs/example-job-scripts/#gpu-mpi-examples","title":"GPU MPI Examples","text":"<p>Using the CPU job submission examples above as a baseline, there are not many additional changes needed to enable an application to make use of the 4 NVIDIA A100 GPUs on each Polaris node. In the following 2-node example (because <code>#PBS -l select=2</code> indicates the number of nodes requested), 4 MPI ranks will be started on each node assigning 1 MPI rank to each GPU in a round-robin fashion. A simple example using a similar job submission script on Polaris is available in the Getting Started Repo.</p> submit_gpu.sh<pre><code>#!/bin/bash -l\n#PBS -l select=2:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -l filesystems=home:eagle\n#PBS -j oe\n#PBS -q debug\n#PBS -A Catalyst\n\n# Enable GPU-MPI (if supported by application)\nexport MPICH_GPU_SUPPORT_ENABLED=1\n\n# Change to working directory\ncd ${PBS_O_WORKDIR}\n\n# MPI and OpenMP settings\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=$(nvidia-smi -L | wc -l)\nNDEPTH=8\nNTHREADS=1\n\nNTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))\necho \"NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}\"\n\n# For applications that internally handle binding MPI/OpenMP processes to GPUs\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth --env OMP_NUM_THREADS=${NTHREADS} -env OMP_PLACES=threads ./hello_affinity\n\n# For applications that need mpiexec to bind MPI ranks to GPUs\n#mpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth --env OMP_NUM_THREADS=${NTHREADS} -env OMP_PLACES=threads ./set_affinity_gpu_polaris.sh ./hello_affinity\n</code></pre> <p>The affinity options <code>NDEPTH=8;</code> and <code>--cpu-bind depth</code> or <code>core</code> are set to ensure that each MPI rank is bound to a separate NUMA node. If OpenMP threading is desired, set <code>NTHREADS=8</code> for each MPI rank to spawn 1 thread per physical core (all in the same NUMA domain that the rank is bound to). The OpenMP-related options are not needed if your application does not use OpenMP. Nothing additional is required on the <code>mpiexec</code> command for applications that internally manage GPU devices and handle the binding of MPI/OpenMP processes to GPUs. A small helper script is available for those with applications that rely on MPI to handle the binding of MPI ranks to GPUs. Some notes on this helper script and other key differences with the early CPU example follow.</p> <p><code>export MPICH_GPU_SUPPORT_ENABLED=1</code></p> <p>For applications that support GPU-aware MPI (i.e. use MPI to communicate data directly between GPUs), this environment variable is required to enable GPU support in Cray's MPICH. Omitting this will result in a segfault. Support for this also requires that the application was linked against the GPU Transport Layer library (e.g. -lmpi_gtl_cuda), which is automatically included for users by the <code>craype-accel-nvidia80</code> module in the default environment on Polaris. If this gtl library is not properly linked, then users will see an error message indicating that upon executing the first MPI command that uses a device pointer.</p> <p><code>./set_affinity_gpu_polaris.sh</code></p> <p>This script is useful for those applications that rely on MPI to bind MPI ranks to GPUs on each node. Such a script is not necessary when the application handles process-gpu binding. This script simply sets the environment variable <code>CUDA_VISIBLE_DEVICES</code> to a restricted set of GPUs (e.g. each MPI rank sees only one GPU). Otherwise, users would find that all MPI ranks on a node will target the first GPU likely having a negative impact on performance. An example for this script is available in the Getting Started repo and copied below.</p>"},{"location":"running-jobs/example-job-scripts/#hardware-threads_1","title":"Hardware threads","text":"submit_gpu_hw_threads.sh<pre><code>#!/bin/bash -l\n#PBS -l select=2:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -l filesystems=home:eagle\n#PBS -q debug\n#PBS -A Catalyst\n\n# Enable GPU-MPI (if supported by application)\nexport MPICH_GPU_SUPPORT_ENABLED=1\n\n# Change to working directory\ncd ${PBS_O_WORKDIR}\n\n# MPI and OpenMP settings\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=$(nvidia-smi -L | wc -l)\nNDEPTH=16\nNTHREADS=16\n\nNTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))\necho \"NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}\"\n\n# For applications that internally handle binding MPI/OpenMP processes to GPUs\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind numa --env OMP_NUM_THREADS=${NTHREADS} -env OMP_PLACES=threads ./hello_affinity\n\n# For applications that need mpiexec to bind MPI ranks to GPUs\n#mpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind numa --env OMP_NUM_THREADS=${NTHREADS} -env OMP_PLACES=threads ./set_affinity_gpu_polaris.sh ./hello_affinity\n</code></pre> <p>As in the previous hardware threads example, the MPI ranks are spaced apart assuming the user wants to utilize all 64 logical cores (achieved by setting <code>NTHREADS=$NDEPTH=16</code> and <code>--cpu-bind numa</code> here).</p> <p>In this script, we have added <code>-j oe</code> to the list of PBS options; <code>-j oe</code> combines stdout and stderr to the same file and uses the stdout filename provided (if provided). <code>-j eo</code> would do the same but use the stderr filename provided. Without these options, separate files containing stdout and stderr of the job are produced.</p> <p>Here we compare two bare-bones PBS submission scripts for a CUDA example with and without MPI:</p> No MPIWith MPI <pre><code>#!/bin/bash\n#PBS -l select=1\n#PBS -l walltime=00:10:00\n#PBS -q debug\n#PBS -l filesystems=home\n#PBS -A &lt;project-name&gt;\n#PBS -o logs/\n#PBS -e logs/\n\n\n\n$HOME/ALCFBeginnersGuide/polaris/examples/01_example_cu\n</code></pre> <pre><code>#!/bin/bash\n#PBS -l select=2\n#PBS -l walltime=00:10:00\n#PBS -q debug\n#PBS -l filesystems=home\n#PBS -A &lt;project-name&gt;\n#PBS -o logs/\n#PBS -e logs/\n\n# Count number of nodes assigned\nNNODES=`wc -l &lt; $PBS_NODEFILE`\n# set 1 MPI rank per GPU\nNRANKS_PER_NODE=4\n# calculate total ranks\nNTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))\necho NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE}\n\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} $HOME/ALCFBeginnersGuide/polaris/examples/01_example_mpi\n</code></pre>"},{"location":"running-jobs/example-job-scripts/#setting-gpu-affinity-for-each-mpi-rank","title":"Setting GPU affinity for each MPI rank","text":"<p>The <code>CUDA_VISIBLE_DEVICES</code> environment variable is provided for users to set which GPUs on a node are accessible to an application or MPI ranks started on a node.</p> <p>A copy of the small helper script provided in the Getting Started repo is provided below for reference:</p> set_affinity_gpu_polaris.sh<pre><code>#!/bin/bash -l\nnum_gpus=4\n# need to assign GPUs in reverse order due to topology\n# See Polaris Device Affinity Information https://www.alcf.anl.gov/support/user-guides/polaris/hardware-overview/machine-overview/index.html\ngpu=$((${num_gpus} - 1 - ${PMI_LOCAL_RANK} % ${num_gpus}))\nexport CUDA_VISIBLE_DEVICES=$gpu\necho \u201cRANK= ${PMI_RANK} LOCAL_RANK= ${PMI_LOCAL_RANK} gpu= ${gpu}\u201d\nexec \"$@\"\n</code></pre> <p>Note</p> <p>The <code>echo</code> command prints a helpful message for the user to confirm the desired mapping is achieved. Users are encouraged to edit this file as necessary for their particular needs.</p> <p>Warning</p> <p>If planning large-scale runs with many thousands of MPI ranks, it is advised to comment out the <code>echo</code> command above so as not to have thousands of lines of output written to <code>stdout</code>.</p>"},{"location":"running-jobs/example-job-scripts/#single-node-ensemble-calculations-example","title":"Single-node Ensemble Calculations Example","text":"<p>In the script below, a set of four applications are launched simultaneously on a single node. Each application runs on 8 MPI ranks and targets a specific GPU using the <code>CUDA_VISIBLE_DEVICES</code> environment variable. In the first instance, MPI ranks 0-7 will spawn on CPUs 24-31, and GPU 0 is used. This pairing of CPUs and GPU is based on output of the <code>nvidia-smi topo-m</code> command showing which CPUs share a NUMA domain with each GPU. It is important to background processes using <code>&amp;</code> and to <code>wait</code> for all runs to complete before exiting the script or continuing on with additional work. Note, multiple applications can run on the same set of CPU resources, but it may not be optimal depending on the workload. An example is available in the Getting Started Repo.</p> <pre><code>#!/bin/bash -l\n#PBS -l select=1:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -q debug\n#PBS -A Catalyst\n#PBS -l filesystems=home:eagle\n\n#cd ${PBS_O_WORKDIR}\n\n# MPI example w/ 8 MPI ranks per node spread evenly across cores\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=8\nNTHREADS=1\n\nnvidia-smi topo -m\n\nNTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))\necho \"NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}\"\n\nexport CUDA_VISIBLE_DEVICES=0\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --cpu-bind list:24:25:26:27:28:29:30:31 ./hello_affinity &amp;\n\nexport CUDA_VISIBLE_DEVICES=1\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --cpu-bind list:16:17:18:19:20:21:22:23 ./hello_affinity &amp;\n\nexport CUDA_VISIBLE_DEVICES=2\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --cpu-bind list:8:9:10:11:12:13:14:15 ./hello_affinity &amp;\n\nexport CUDA_VISIBLE_DEVICES=3\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --cpu-bind list:0:1:2:3:4:5:6:7 ./hello_affinity &amp;\n\nwait\n</code></pre>"},{"location":"running-jobs/example-job-scripts/#multi-node-ensemble-calculations-example","title":"Multi-node Ensemble Calculations Example","text":"<p>To run multiple concurrent applications on distinct sets of nodes, one simply needs to provide appropriate hostfiles to the <code>mpiexec</code> command. The <code>split</code> unix command is one convenient way to create several unique hostfiles, each containing a subset of nodes available to the job. In the 8-node example below, a total of four applications will be launched on separate sets of nodes. The <code>$PBS_NODEFILE</code> file will be split into several hostfiles, each containing two lines (nodes). These smaller hostfiles are then used as the argument to the <code>--hostfile</code> argument of <code>mpiexec</code> to the launch applications. It is important to background processes using <code>&amp;</code> and to <code>wait</code> for applications to finish running before leaving the script or continuing on with additional work. Note, multiple applications can run on the same set of CPU resources, but it may not be optimal depending on the workload. An example is available in the Getting Started Repo.</p> <pre><code>#!/bin/bash -l\n#PBS -l select=8:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:30:00\n#PBS -q debug-scaling\n#PBS -A Catalyst\n#PBS -l filesystems=home:eagle\n\ncd ${PBS_O_WORKDIR}\n\n# MPI example w/ multiple runs per batch job\nNNODES=`wc -l &lt; $PBS_NODEFILE`\n\n# Settings for each run: 2 nodes, 4 MPI ranks per node spread evenly across cores\n# User must ensure there are enough nodes in job to support all concurrent runs\nNUM_NODES_PER_MPI=2\nNRANKS_PER_NODE=4\nNDEPTH=8\nNTHREADS=1\n\nNTOTRANKS=$(( NUM_NODES_PER_MPI * NRANKS_PER_NODE ))\necho \"NUM_OF_NODES= ${NNODES} NUM_NODES_PER_MPI= ${NUM_NODES_PER_MPI} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}\"\n\n# Increase value of suffix-length if more than 99 jobs\nsplit --lines=${NUM_NODES_PER_MPI} --numeric-suffixes=1 --suffix-length=2 $PBS_NODEFILE local_hostfile\n\nfor lh in local_hostfile*\ndo\n  echo \"Launching mpiexec w/ ${lh}\"\n  mpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --hostfile ${lh} --depth=${NDEPTH} --cpu-bind depth ./hello_affinity &amp;\n  sleep 1s\ndone\n\nwait\n</code></pre>"},{"location":"running-jobs/example-job-scripts/#job-array-example","title":"Job array example","text":"<p>In situations where you wish to repeat a job multiple times with a small change each time, such as in a parameter space study, a job array may be an option. Unlike the multi-node ensemble case above, each subjob in a job array is its own job and will have its own initialization and tear-down by PBS. Also, a job array will not block all nodes for the length of the longest running task, as is the case for an ensemble job. Jobs on Polaris cannot share nodes with other jobs, so job arrays on Polaris cannot be used to distribute work to different CPU cores or GPUs on a node. In that case, an ensemble job or using <code>mpiexec</code> as a parallel launcher can accomplish that goal.</p> <p>Both ensemble jobs and job arrays become unwieldy and inefficient for very large numbers of tasks. They either have limits to the number of tasks that can be created at once (job arrays) or are unable to refill idle nodes when tasks complete (ensemble jobs). In such cases, a workflow management tool that can manage the running of tasks is recommended.</p>"},{"location":"running-jobs/example-job-scripts/#job-array-submission-scripts","title":"Job array submission scripts","text":"<p>An example job array submission script:</p> submit_array.sh<pre><code>#!/bin/bash -l\n#PBS -l select=1:system=polaris\n#PBS -l place=scatter\n#PBS -l walltime=0:10:00\n#PBS -q preemptable\n#PBS -A datascience\n#PBS -l filesystems=home:eagle\n#PBS -j oe\n#PBS -r y\n#PBS -J 0-7:2\n\ncd ${PBS_O_WORKDIR}\n\n# Create a unique subdirectory for subjob with PBS_ARRAY_INDEX\nSUBDIRECTORY=\"${PBS_ARRAY_INDEX}\"\nmkdir -p ${SUBDIRECTORY}\ncd ${SUBDIRECTORY}\n\n# File name where stdout and stderr of application will be directed in subjob subdirectory\nOUT_FILE=\"subjob_${PBS_ARRAY_INDEX}.out\"\n\necho \"Running subjob ${SUBDIRECTORY}\"\necho \"Directing application output to ${SUBDIRECTORY}/${OUT_FILE}\"\n\n# MPI example w/ 16 MPI ranks per node spread evenly across cores\nNNODES=`wc -l &lt; $PBS_NODEFILE`\nNRANKS_PER_NODE=16\nNDEPTH=4\nNTHREADS=1\n\nNTOTRANKS=$(( NNODES * NRANKS_PER_NODE ))\necho \"NUM_OF_NODES= ${NNODES} TOTAL_NUM_RANKS= ${NTOTRANKS} RANKS_PER_NODE= ${NRANKS_PER_NODE} THREADS_PER_RANK= ${NTHREADS}\"\n\nAPP_PATH=${PBS_O_WORKDIR}/hello_affinity\n\nmpiexec -n ${NTOTRANKS} --ppn ${NRANKS_PER_NODE} --depth=${NDEPTH} --cpu-bind depth ${APP_PATH} &amp;&gt; ${OUT_FILE}\n</code></pre> <p>There are two required options for job arrays in PBS: <code>-r</code> and <code>-J</code>.</p> <p>The <code>-r</code> option must be set like this: <pre><code>#PBS -r y\n</code></pre></p> <p>The <code>-J</code> option sets the number of subjobs in the array and the value of their array indices. The example script above will run 4 subjobs and space their array indices in increments of 2, so the array indices will be 0, 2, 4, and 6.</p> <p>The form the <code>-J</code> option takes is <pre><code>#PBS -J &lt;start_index&gt;-&lt;end_index&gt;:&lt;skip_index&gt;%&lt;num_concurrent&gt;\n</code></pre> * <code>&lt;start_index&gt;</code> is the index of the first job in the array * <code>&lt;end_index&gt;</code> is the index of the last job in the array * <code>&lt;skip_index&gt;</code> is the number of index integers to skip between subjobs * <code>&lt;num_concurrent&gt;</code> is the maximum number of subjobs that will run concurrently at one time</p> <p>Within a subjob, the environment variable <code>PBS_ARRAY_INDEX</code> will contain the index of the subjob in the array. It can be used in the job script to set the value or paths of inputs or outputs.</p>"},{"location":"running-jobs/example-job-scripts/#interacting-with-job-arrays","title":"Interacting with job arrays","text":"<p>The status of job arrays can be queried with the command: <pre><code>qstat -t\n</code></pre></p> <p>When interacting with a job array with commands like <code>qdel</code> or <code>qalter</code>, include the brackets with the jobid, e.g.: <pre><code>qdel 1991684[]\n</code></pre></p>"},{"location":"running-jobs/example-job-scripts/#limits-on-job-arrays","title":"Limits on job arrays","text":"<p>The number of subjobs in a job array is limited by the number of jobs that can be submitted to the queue.</p> <p>On Polaris, for the debug queue, that is 1, for preemptable, that is 20, and for prod that is 10.</p> <p>The limit for prod on Polaris is 10 because 10 is the maximum number of jobs that can be routed by prod to one of the execution queues (small, medium, or large). One note, PBS will allow job array submissions of up to 100 subjobs in prod, however, these job arrays will not run because they will not route to an execution queue. This is a known issue on Polaris.</p>"},{"location":"running-jobs/machine-reservations/","title":"Machine Reservations","text":"<p>To get a reservation, you must first demonstrate a need to run outside of the normal queueing policies. Reservations are available only to projects with a positive allocation.</p> <p>A 5-business-day lead time is recommended to ensure timely approval. Scheduling is contingent on machine availability.</p> <p>Disclaimer</p> <p>Approval for reservation requests is subject to their appropriateness and machine availability. Not all requests will be approved. It is particularly difficult to accommodate reservation requests during busy times of the year, e.g., Supercomputing, end of the ALCC and INCITE allocation cycles.</p> <p>Kindness Policy</p> <p>We do monitor reservation utilization. The Scheduling Committee reserves the right to cancel reservations without notice if we decide a reservation is underutilized, not being properly utilized, or otherwise wasting resources. For instance, requesting a 12-hour reservation for interactive work, but then going to lunch leaving the reservation empty with no work.</p> <p>Early Completion Policy</p> <p>If you have finished running your jobs before your reservation has ended, please reach out to the support team (support@alcf.anl.gov) to release it for other users. At this time, there is no way for a user to release a reservation early.</p>"},{"location":"running-jobs/machine-reservations/#relevant-terms","title":"Relevant terms","text":"Reservation A number of nodes on a system set aside from the general pool of resources for a limited time. Only certain users or projects can submit to the queues assigned to the reservation. Score boost A job with a boosted score helps it move ahead in the queue, but it still allows the scheduler to more efficiently fill the machine."},{"location":"running-jobs/machine-reservations/#-fill-out-the-form-","title":"-&gt; Fill out the Form &lt;-","text":""},{"location":"running-jobs/machine-reservations/#querying-reservations-via-command-line","title":"Querying Reservations via Command Line","text":"<p>You can see reservations using the <code>pbs_rstat</code> command:</p>"},{"location":"running-jobs/machine-reservations/#submitting-to-a-reservation","title":"Submitting to a reservation","text":"<p>Use the <code>pbs_rstat</code> command on the login node to view the list of all reservations.</p> <pre><code>&gt; pbs_rstat\nResv ID      Queue     User     State               Start / Duration / End             \n---------------------------------------------------------------------------\nA123456.po   A123456   smith@   CO       Mon Aug 18 09:00 / 43200 / Tue Aug 19 11:00\n</code></pre> <p>For recurring reservations, the <code>reserve_start</code> and <code>reserve_end</code> are always the first instance. <code>reserve_index</code> and <code>reserve_count</code> tell you where you are in the recurrence.</p>"},{"location":"running-jobs/machine-reservations/#using-a-reservation","title":"Using a Reservation","text":"<p>Once the reservation is set up, jobs can be submitted to the reservation queue prior to the reservation start time. In the example above, the queue name is shown in the <code>Queue</code> column.</p> <pre><code>qsub -q A123456 walltime=60:00 -l select=1024:system=polaris -l filesystems=eagle myprog.exe\n</code></pre> <p>For jobs using 33 percent or more of a system, place your job in the queue at least 12 hours prior to the start of the reservation or your reservation may be canceled. The machine will start to drain for your reservation, and it is important that your job is ready to run.</p> <p>You can also move jobs from the regular queue to the reservation queue at any time using the <code>qmove</code> command. Keep in mind that a job won't start unless enough time is left in the reservation.</p> <p>Danger</p> <p>There is absolutely no time padding at the end of the reservation. When the reservation ends, all jobs are terminated, deleted, and the reservation queue is deleted. If a routing queue is used for the reservation, then jobs may be preserved, but any running job(s) are still terminated.</p>"},{"location":"running-jobs/not_in_nav/pbs-qsub-options-table/","title":"PBS Pro <code>qsub</code> Options","text":"<p>Version 1.2 2021-04-28 </p> <p><code>-l select</code> and similar options use a lowercase \"L\", <code>-I</code> for interactive is an uppercase \"I\".</p> Cobalt CLI PBS CLI PBS Directive Function and Page Reference <code>-A &lt;account_string&gt;</code> <code>-A &lt;account_string&gt;</code> <code>#PBS Account_Name=&lt;accounting string&gt;</code> \"Specifying Accounting String\u201d UG-29 <code>-n NODES</code><code>--nodecount NODES</code> <code>-l select=NODES:system=&lt;hostname&gt;</code> One or more <code>#PBS -l &lt;resource name&gt;=&lt;value&gt;</code> directives \"Requesting Resources\u201d UG-51 <code>-t</code> <code>--walltime</code> <code>-l walltime=H:MM:SS</code> One or more <code>#PBS -l &lt;resource name&gt;=&lt;value&gt;</code> directives \"Requesting Resources\u201d UG-51 <code>--attrs</code> <code>filesystems=&lt;resource&gt;</code> <code>-l filesystems=&lt;resource&gt;</code> One or more <code>#PBS -l &lt;resource name&gt;=&lt;value&gt;</code> directives \"Requesting Resources\u201d UG-51 <code>-q</code> <code>-q &lt;destination&gt;</code> <code>#PBS -q &lt;queue name&gt;</code> <code>#PBS -q @&lt;server name&gt;</code> <code>#PBS -q &lt;queue name&gt;@&lt;server name&gt;</code> \"Specifying Server and/or Queue\u201d UG-29 <code>--env</code> <code>-v &lt;variable list&gt;</code> \"Exporting Specific Environment Variables\u201d UG-126 <code>--env</code> <code>-V</code> <code>#PBS -V</code> \"Exporting All Environment Variables\u201d UG-126 <code>--attrs</code> Done via custom resources and select statements \"Setting Job Attributes\u201d UG-16 <code>--dependencies=&lt;list&gt;</code> <code>-W depend=afterok:&lt;list&gt;</code> <code>#PBS depend=...</code> \"Using Job Dependencies\u201d UG-107 <code>-I</code><code>--interactive</code> <code>-I</code> Deprecated for use in a script \"Running Your Job Interactively\u201d UG-121 <code>--jobname</code> <code>-N &lt;name&gt;</code> <code>#PBS -N &lt;job name&gt;</code> <code>#PBS -WJob_Name=&lt;job name&gt;</code> \"Specifying Job Name\u201d UG-27 <code>-e</code><code>--error=</code> <code>-e &lt;path&gt;</code> <code>#PBS -e &lt;path&gt;</code><code>#PBS Error_Path=&lt;path&gt;</code> \"Paths for Output and Error Files\u201d UG-42 <code>-o</code>--output= <code>-o &lt;path&gt;</code> <code>#PBS -o &lt;path&gt;</code><code>#PBS Output_Path=&lt;path&gt;</code> \"Paths for Output and Error Files\u201d UG-42 <code>-M</code>--notify see note #1 <code>-M &lt;user list&gt;</code> <code>-m &lt;mail options&gt;</code> (<code>-m be</code> is suggested) <code>#PBS -M &lt;mail recipients&gt;</code> <code>#PBS -WMail_Users=&lt;mail recipients&gt;</code> <code>#PBS -m &lt;mail points&gt;</code> <code>#PBS -WMail_Points=&lt;mail points&gt;</code> \"Setting Email Recipient List\u201d UG-26 <code>-u</code><code>--umask</code> <code>-W umask=&lt;value&gt;</code> <code>#PBS umask=&lt;value&gt;</code> \"Changing Linux Job umask\u201d UG-45 <code>-h</code> <code>-h</code> <code>#PBS -h</code> \"Holding and Releasing Jobs\u201d UG-115 <code>--proccount</code> See Note #2 <code>-l mpiprocs</code>Not needed to get equivalent Cobalt functionality One or more <code>#PBS -l &lt;resource name&gt;=&lt;value&gt;</code> directives \"Requesting Resources\u201d UG-51"},{"location":"running-jobs/not_in_nav/pbs-qsub-options-table/#pbs-options-that-provide-functionality-above-and-beyond-cobalt","title":"PBS options that provide functionality above and beyond Cobalt","text":"<p>Depending on policy decisions, not all of these options may be available.</p> Cobalt CLI PBS CLI PBS Directive Function and Page Reference N/A <code>-a &lt;date_time&gt;</code> <code>#PBS -a</code> \"Deferring Execution\u201d UG-119 N/A <code>-C &lt;directive prefix&gt;</code> \"Changing the Directive Prefix\u201d UG-16 N/A <code>-c &lt;interval&gt;</code> <code>#PBS -c</code> \"Using Checkpointing\u201d UG-113 N/A <code>-G</code> \"Submitting Interactive GUI Jobs on Windows\u201d UG-125 N/A <code>-J X-Y[:Z]</code> <code>#PBS -J</code> \"Submitting a Job Array\u201d UG-150 N/A <code>-j &lt;join&gt;</code> <code>#PBS Join_Path=&lt;joining option&gt;</code> \"Merging Output and Error Files\u201d UG-43 N/A <code>-k &lt;keep&gt;</code> <code>#PBS Keep_Files=&lt;keep option&gt;</code> \"Keeping Output and Error Files on Execution Host\u201d UG-44 N/A <code>-p &lt;priority&gt;</code> <code>#PBS -p</code> \"Setting Priority for Your Job\u201d UG-120 N/A <code>-P &lt;project&gt;</code> <code>#PBS project=&lt;project name&gt;</code> \"Specifying a Project for a Job\u201d UG-27 N/A <code>-r &lt;value&gt;</code> <code>#PBS -r</code> \"Allowing Your Job to be Re-run\u201d UG-118 N/A <code>-R &lt;remove options&gt;</code> \"Avoiding Creation of stdout and/or stderr\u201d UG-43 N/A <code>-S &lt;path list&gt;</code> \"Specifying the Top Shell for Your Job\u201d UG-19 N/A See Note #3 <code>-u &lt;user list&gt;</code> <code>#PBS User_List=&lt;username list&gt;</code> \"Specifying Job Username\u201d UG-28 N/A <code>-W block=true</code> <code>#PBS block=true</code> \"Making qsub Wait Until Job Ends\u201d UG-120 N/A <code>-W group_list=&lt;list&gt;</code> <code>#PBS group_list=&lt;group list&gt;</code> \"Specifying Job Group ID\u201d UG-28 N/A <code>-W release_nodes_on_stageout=&lt;value&gt;</code> \"Releasing Unneeded Vnodes from Your Job\u201d UG-127 N/A <code>-W run_count=&lt;value&gt;</code> \"Controlling Number of Times Job is Re-run\u201d UG-119 N/A <code>-W sandbox=&lt;value&gt;</code> \"Staging and Execution Directory: User Home vs. Job-specific\u201d UG-31 N/A <code>-W stagein=&lt;list&gt;</code> <code>#PBS -W stagein=&lt;execution path&gt;@&lt;input file storage host&gt;:&lt;input file storage path&gt;[,...]</code> \"Input/Output File Staging\u201d UG-31 N/A <code>-W stageout=&lt;list&gt;</code> <code>#PBS -W stageout=&lt;execution path&gt;@&lt;output file storage host&gt;:&lt;output file storage path&gt;[,...]</code> \"Input/Output File Staging\u201d UG-31 N/A <code>-X</code> \"Receiving X Output from Interactive Linux Jobs\u201d UG-124 N/A <code>-z</code> <code>#PBS -z</code> \"Suppressing Printing Job Identifier to stdout\u201d UG-30"},{"location":"running-jobs/not_in_nav/pbs-qsub-options-table/#notes","title":"Notes","text":"<ol> <li>To get the equivalent mail notifications from PBS, it requires two parameters: the <code>-M</code> just like Cobalt, but also <code>-m be</code> (the <code>be</code> stands for \"beginning\" and \"end\") to specify when the mails should go out. This will give you the same behavior as Cobalt.</li> <li><code>--proccount</code>, while available, only changed behavior on the Blue Gene machines. To get equivalent functionality, just drop it from the CLI. In PBS, it does influence the <code>PBS_NODES</code> file. See Section 5.1.3 in the PBS Users Guide page UG-78.</li> <li>The following Cobalt options have no equivalent in PBS:<ul> <li><code>--cwd</code>: use a script and <code>cd</code> to the directory you want to run from.</li> <li><code>--user_list</code>: There is no way to do this. We will work on adding this functionality.</li> <li><code>--debuglog</code>: Are we going to try and generate the equivalent of a <code>.cobalt</code> file?</li> </ul> </li> <li>The following Cobalt options were Blue Gene specific and no longer apply:<ul> <li><code>--kernel</code></li> <li><code>-K KERNELOPTIONS</code></li> <li><code>--ion_kernel</code></li> <li><code>--ion_kerneloption</code></li> <li><code>--mode</code>: see notes on running scripts, Python, and other executables</li> <li><code>--geometry</code></li> <li><code>--disable_preboot</code></li> </ul> </li> </ol>"},{"location":"services/","title":"ALCF Services","text":"<p>Below is a list of some of the services ALCF offers.</p> <ul> <li>Inference Endpoints: API endpoints for running LLM inference against models hosted on ALCF systems.</li> <li>JupyterHub: An interactive computing environment for Python and other languages.</li> <li>Continuous Integration: Automated processes to help build, test, package, and deploy on ALCF systems.</li> </ul>"},{"location":"services/continuous-integration/","title":"Continuous Integration","text":""},{"location":"services/continuous-integration/#continuous-integration_1","title":"Continuous Integration","text":"<p>Continuous Integration (CI) in software development is the practice of committing code changes regularly to a version control system and having automated processes perform build, test, package, and deploy activities.</p> <p>The key concepts of CI include high frequency, repeatability, and automation in order to realize increased quality and ease of delivery. The main goal CI aims to achieve is the elimination of build and deployment issues, which in turn improves development cycles, provides a timely feedback loop with developers, and results in higher quality deliverables with reduced development time.</p> <p>CI usually describes the work that is done by a deployment or operations team to build and deploy code throughout an environment and make it available to the different interested teams involved in the SDLC. The steps that make up this process are referred to as a workflow or pipeline, which, when combined with automation, provides the mechanism for Continuous Integration.</p> <p>Today it is a common practice to use a CI tool for defining pipelines and executing the tasks required to take code from a source stored in a version control system to compiled and packaged artifacts executing in production. Two excellent examples of CI tools are Jenkins and GitLab.</p>"},{"location":"services/continuous-integration/#ci-tools-at-alcf","title":"CI Tools at ALCF","text":""},{"location":"services/continuous-integration/#gitlab-ci","title":"GitLab-CI","text":"<p>GitLab is an application that offers combined functionality as a git repository, issue tracker, and CI/CD platform. The ALCF implementation of the GitLab-CI environment leverages upstream GitLab runners combined with the ECP's Jacamar custom executor. As CI/CD is built directly into GitLab, it can allow for tighter DevOps processes. GitLab-CI is meant to provide CI/CD services for projects using GitLab-CI to store their git repositories. ALCF does not allow users to join their own private runners to our existing GitLab CI environment and provides runners on our supported systems.</p>"},{"location":"services/gitlab-ci/","title":"Continuous Integration via GitLab-CI","text":""},{"location":"services/gitlab-ci/#gitlab-ci","title":"GitLab-CI","text":"<p>GitLab is an application that offers combined functionality as a git repository, issue tracker, and CI/CD platform. The ALCF implementation of the GitLab-CI environment leverages upstream GitLab runners combined with the ECP's Jacamar custom executor. As CI/CD is built directly into GitLab, it can allow for tighter DevOps processes.</p> <p>GitLab-CI is meant to provide CI/CD services for projects using GitLab-CI to store your git repositories and execute code on our HPC clusters. ALCF does not allow users to join their own private runners to our existing GitLab CI/CD environment and provides dedicated runners for our supported systems.</p> <p>Additional information, technical and user documentation, and community support can be found on GitLab's Runner website.</p> <p>Also see GitLab's CI/CD YAML syntax reference for the full list of keywords supported by GitLab CI.</p> <p>ALCF's GitLab-CI environment can be accessed by logging into the ALCF GitLab-CI web portal using your ALCF credentials (ALCF username and cryptocard token password).</p>"},{"location":"services/gitlab-ci/#quickstart","title":"Quickstart","text":"<ul> <li>A user emails ALCF Support requesting access for their ALCF Project for gitlab-ci.alcf.anl.gov.</li> <li>ALCF Support will add the ALCF Project to the appropriate system(s) via the Account and Project management system.</li> <li>ALCF will create a <code>GitLab Group/SubGroup</code> for the ALCF Project and map it to the appropriate LDAP group that maps to the ALCF Project.</li> <li>ALCF Support will reply back to the user and inform them that the project is created.</li> <li>User(s) will need to log in to gitlab-ci.alcf.anl.gov and configure their initial GitLab profile. Users will add an SSH key so they can pull/push code to the GitLab server.</li> <li>User will then need to create a <code>GitLab Project</code> in their assigned <code>GitLab Group/SubGroup</code>.</li> <li>CI/CD needs to be enabled for the GitLab Project.</li> <li>When ready to run CI/CD jobs, users will add a <code>.gitlab-ci.yml</code> file to their git repositories.</li> <li>They will need to set any ALCF specific variable(s).</li> </ul> <p>Example: <code>.gitlab-ci.yml</code> file for Aurora <pre><code># this include allows us to reference defaults in anl/ci-resource/defaults\ninclude:\n  - project: 'anl/ci-resources/defaults'\n    ref: main\n    file:\n      - '/runners.yml'\n\nstages:\n  - my_batch # stages may have any name\n\n# the below submits a batch job to the scheduler\nsubmit_batch: # CI jobs may have any name\n  stage: my_batch  # from the stages list above\n  extends: .aurora-batch-runner # this includes the defaults provided in the 'anl/ci-resources/defaults' project\n  variables:  # scheduler parameters must be included, adjust the below to match your values\n    ANL_AURORA_SCHEDULER_PARAMETERS: \"-A ProjectName -l select=1,walltime=10:00,filesystems=home -q myQueue\"\n  script:\n    - id\n    - hostname\n    - echo \"Running on $(hostname) with setuid shell runner\"\n</code></pre></p> <p>To run a stage on a different system, change the <code>extends</code> key and the scheduler parameters. The list of ALCF provided <code>extends</code> is in the <code>include</code>ed runners.yml file. For Crux, proxy variables are provided through the same file.</p> <p>For a more complete example, see the .gitlab-ci.yml file in the large-example project.</p>"},{"location":"services/gitlab-ci/#glossary","title":"Glossary","text":"<ul> <li>Group - A collection of projects. Certain settings can be applied at the <code>Group</code> level and apply down to all child <code>SubGroups</code> and/or <code>Projects</code>. When an ALCF Project is allocated resources on the GitLab-CI environment, we will create a GitLab <code>Group</code> that will map to your ALCF Project allocation.</li> <li>Jacamar-CI - A Custom Executor we use that runs jobs as a given user on the shell and is capable of submitting jobs to schedulers like Cobalt and PBS.</li> <li>Job - An individual set of commands that are run. This is the lowest unit of GitLab-CI abstraction.</li> <li>Pipeline - GitLab organizes your jobs for each run into a <code>pipeline</code>.</li> <li>Project - GitLab Projects can be thought of as an individual git repository plus all services and features GitLab layers on top. This term is unrelated to the ALCF Project concept. ALCF Projects often map to LDAP groups and/or quotas and allocations.</li> <li>Stage - A collection of jobs in a pipeline. Jobs in the next stage will not start until the jobs in the current stage complete. If a job fails, the pipeline will not run the following stages by default.</li> <li>Triggering User - The user whose actions cause a CI/CD job to run and who the Jacamar-CI executor will run the jobs as. Examples include pushing commits up to the server, creating a merge request, and/or merging one branch into another branch.</li> </ul>"},{"location":"services/gitlab-ci/#projects-using-cicd","title":"Projects Using CI/CD","text":"<p>Any project with a git repository on the GitLab-CI environment has access to the CI/CD environment by default. In order to launch a shell job on a system, you must already have access to that system.</p>"},{"location":"services/gitlab-ci/#on-boarding-with-cicd","title":"On-Boarding with CI/CD","text":"<p>To gain access to the GitLab-CI environment, send an email to support@alcf.anl.gov requesting access for your project(s). Include with the request:</p> <ul> <li>That you are requesting access to the GitLab-CI environment at https://gitlab-ci.alcf.anl.gov</li> <li>The ALCF Project shortname</li> <li>The PI\u2019s name </li> </ul> <p>GitLab-CI jobs run as the triggering user on relevant systems. The triggering user's home directory will be used by Jacamar-CI to copy the git repository and cache files into <code>~/.jacamar-ci</code>. This job will run out of their home directory and consume filesystem quota. If you need more space, you should try to reference files in any ALCF Project allocations you have on shared filesystems. Unfortunately, the initial git clone must run out of <code>~/.jacamar-ci</code> in your home directory.</p> <p>The triggering user is defined as the user account who caused the CI/CD pipeline to execute, via scheduling a re-occurring job, pushing commits up to the server, creating a merge request, and/or merging a branch. When the CI/CD jobs run, they will run as that user on the relevant systems. For a job to succeed, the <code>triggering user</code> must have appropriate permissions and access to all relevant systems and files.</p>"},{"location":"services/gitlab-ci/#initial-login-and-profile-setup-of-gitlab-ci","title":"Initial Login and Profile Setup of GitLab-CI","text":"<ul> <li>Log in to gitlab-ci.alcf.anl.gov using your username and Cryptocard token.</li> <li>Once logged in, add your public key you already have or created earlier so that it can be associated with your account.</li> <li>Click the Profile icon on the upper right-hand corner, then click \"Edit Profile\"      GitLab Profile Dropdown screenshot </li> <li>Click \"SSH Keys\" on the left-hand menu.      GitLab Profile Add SSH Key screenshot </li> <li>Copy/Paste your SSH public key into the large text box under the word Key.<ul> <li>On Linux, Unix, and OSX-based systems using OpenSSH, your SSH public key is commonly found at <code>~/.ssh/id_rsa.pub</code>. If using Windows, you will need to consult your application's documentation on the location of your public key.</li> <li>Give it a descriptive title such as where the key resides; by default, it will extract the name from the end of the public key if possible.</li> </ul> </li> <li>Click the <code>Add Key</code> button. The button is disabled until you paste a key.</li> </ul>"},{"location":"services/gitlab-ci/#gitlab-projects-repositories","title":"GitLab Projects (repositories)","text":"<p>GitLab takes a git repository, adds additional functionality, and calls it a <code>GitLab Project</code>. This is the most common level you will be interacting with GitLab at. Please do not confuse ALCF Projects with <code>GitLab Projects</code> as they are two separate things. ALCF Projects more closely map to the <code>GitLab Group/SubGroup</code> concept, which we explain in the next section.  Once you are assigned access to a <code>GitLab Group/SubGroup</code>, you will be able to create arbitrary <code>GitLab Projects</code> underneath, configuring CI/CD jobs for each independently.</p> <p>To create a new <code>GitLab Project</code>:</p> <ul> <li>In the left pane, click \"Groups\", and then click the \"Explore groups\" link on the right.</li> </ul> <p> </p> GitLab Your Groups Page screenshot <ul> <li>From the list in the \"Explore groups\" page, click the group you were informed corresponds to your <code>ALCF Project</code>.</li> </ul> <p> </p> GitLab Explore Groups Page screenshot <ul> <li>Click the <code>New project</code> button near the upper right. If this is the first project you are creating, you will have two large square buttons near the middle of the screen to create <code>GitLab SubGroups</code> or <code>GitLab Projects</code>.</li> </ul> <p> </p> GitLab Empty Group Page screenshot <ul> <li>On the <code>Create new project</code> page, click <code>Create blank project</code>.</li> </ul> <p> </p> GitLab Create New Project screenshot <ul> <li>Fill in the <code>Project Name</code> field. The <code>Project slug</code> field will auto-populate based on the <code>Project Name</code>; do not change it. If you are pushing an existing repository, you MUST uncheck the default <code>Initialize repository with a README</code> option. Failure to uncheck this option will result in a merge conflict that you will need to resolve manually between your existing \"local\" git repository and the one you just created on the server.</li> </ul> <p> </p> GitLab Create New Project screenshot <ul> <li>Click the <code>Create project</code> button near the bottom.</li> <li>After creating the project, navigate to \"Settings\" &gt; \"General\", expand the \"Visibility, project features, permissions\" section, and enable the \"CI/CD\" toggle.</li> </ul>"},{"location":"services/gitlab-ci/#gitlab-groupssubgroups-folders","title":"GitLab Groups/SubGroups (Folders)","text":"<p>GitLab organizes <code>GitLab Projects</code> into \"folders\" called <code>Groups</code> or <code>SubGroups</code>. When an ALCF Project is granted access to GitLab-CI, a GitLab <code>Group</code> will be created with access for all members of that ALCF Project. Users will then be able to create arbitrary GitLab <code>Projects</code>. </p> <p>Each ALCF Project will have a top-level <code>Group</code> or <code>SubGroup</code> created with the ALCF Project\u2019s name. It is used for organization in the multi-project environment and is required for implementing the needed level of security. The <code>Group</code> folder is where all of your <code>GitLab Projects</code> are to be stored. You can additionally create new <code>SubGroups</code>, <code>Projects</code>, group variables, etc., within your designated <code>Group</code>, <code>SubGroups</code>, and/or <code>Projects</code>.</p> <p>To create a new <code>GitLab SubGroup</code>:</p> <ul> <li>In the left pane, click \"Groups\", and then click the \"Explore groups\" link on the right.</li> </ul> <p> </p> GitLab Your Groups Page screenshot <ul> <li>From the list in the \"Explore groups\" page, click the group you were informed corresponds to your <code>ALCF Project</code>.</li> </ul> <p> </p> GitLab Explore Groups Page screenshot <ul> <li>Click the <code>New subgroup</code> button near the upper right. If this is the first project you are creating, you will have two large square buttons near the middle of the screen to create <code>GitLab SubGroups</code> or <code>GitLab Projects</code>.</li> </ul> <p> </p> GitLab Empty Group Page screenshot <ul> <li>On the <code>Create subgroup</code> page, enter the <code>Subgroup name</code>. <code>Subgroup slug</code> will auto-populate; do not change it.</li> </ul> <p> </p> GitLab Create New SubGroup screenshot <ul> <li>Click the <code>Create subgroup</code> button near the bottom.</li> </ul>"},{"location":"services/gitlab-ci/#gitlab-runner-nodes","title":"GitLab Runner Nodes","text":"<p>Each system is assigned one or more GitLab runner node(s) that are shared by all users in GitLab-CI. Each runner is only capable of running one user's pipeline at a time, while multiple jobs in that pipeline may run in parallel.</p> <p>Each node will have two runners available, <code>shell</code> and <code>batch</code>. <code>shell</code> will run shell jobs directly on the runner node as the user. <code>batch</code> will submit the job to the HPC cluster's scheduler that is paired to that node. You will need to select the appropriate runner in your <code>.gitlab-ci.yml</code> file for the job to be executed properly. For more details on the <code>.gitlab-ci.yml</code> file, please see upstream docs.</p>"},{"location":"services/gitlab-ci/#gitlab-ciyml-configuration-sections","title":"<code>.gitlab-ci.yml</code> Configuration Sections","text":"<p>GitLab uses a per repository <code>.gitlab-ci.yml</code> file. On any commit, merge request, or merge, GitLab will attempt to trigger a CI/CD pipeline based on the contents of this file. Within the <code>.gitlab-ci.yml</code> file, you can limit jobs to only run under certain conditions. A common workflow is to have linting and validation happen on every commit to a non-master/non-main branch. Larger, more complex tasks are then performed when that branch is merged back into master/main. All jobs launched on a given event are organized into a <code>Pipeline</code>. You can watch the progress of your pipeline via the CI/CD pipeline page for your <code>Project</code>.</p> <p> </p> GitLab Group and Projects screenshot <p> </p> GitLab Group and Projects screenshot"},{"location":"services/gitlab-ci/#tags","title":"Tags","text":"<p>Tags are used to select which runner a job will be sent to. Improper tags can prevent your job from running and result in a failed job. Tags should be added by extending the defaults in the 'anl/ci-resources/defaults' runner.yml file. ALCF specific tags are described here in case overrides are needed.</p>"},{"location":"services/gitlab-ci/#alcf-specific-tags","title":"ALCF Specific tags","text":"<p>Two tags are necessary to run on our systems. One tag will select which cluster the jobs are sent to. The other will determine if the job is to be run locally on the GitLab runner host, or if it is to be submitted to a job scheduler on an HPC cluster.</p> <p>Cluster Tag(s)</p> Cluster tag Description Polaris polaris This tag will send jobs to the Polaris HPC runners Aurora aurora This tag will send jobs to the Aurora HPC runners Crux crux This tag will send jobs to the Crux HPC runners <p>Job Type Tag(s)</p> tag Description shell This tag will execute the job locally on the GitLab runner host. batch This tag will submit the job to the HPC cluster's job scheduler."},{"location":"services/gitlab-ci/#variables","title":"Variables","text":"<p>Variables can be stored two ways: inline in the <code>.gitlab-ci.yml</code> file or as a setting in the GitLab <code>Group</code> or <code>Project</code> itself. Variables are exported as environment variables by gitlab-runner for each job and can be used inside the <code>.gitlab-ci.yml</code> file.</p> <p>GitLab also has a list of predefined variables available in every GitLab CI/CD pipeline.</p> <p>To set a variable directly in the <code>.gitlab-ci.yml</code> file, declare a <code>variables:</code> section with each <code>VariableName: \"VariableValue\"</code> being on its own line. <code>variables:</code> can be declared globally or in individual jobs.</p> <p>Example: Declaring variables <pre><code>variables:\n  GlobalVariable1: \"Global Value 1\"\n  GlobalVariable2: \"Global Value 2\"\n\njob:\n  variables:\n    LocalVariable: 'This is a local variable'\n  script:\n    - 'echo $LocalVariable'\n</code></pre></p> <p>To store variables in the <code>Group</code> or <code>Project</code> settings, in the left side menu, click <code>Settings&gt;CI/CD</code>. Expand the Variables option on the right side frame. You can then add variables by clicking <code>Add variable</code>.</p> <p>For more details, please see the upstream docs.</p> <p> </p> GitLab Group and Projects screenshot <p> </p> GitLab Group and Projects screenshot"},{"location":"services/gitlab-ci/#alcf-specific-variables","title":"ALCF Specific Variables","text":"<p>If you are planning to submit jobs to a scheduler, then you will need to specify a per system variable <code>ANL_${CLUSTER}_SCHEDULER_PARAMETERS</code>; where <code>${CLUSTER}</code> is the name of the cluster. This variable will contain any command line flags you would need to submit jobs as if you were on the command line/scripting. Please consult the below table for more info.</p> Cluster Scheduler Variable Name Support docs Polaris PBS ANL_POLARIS_SCHEDULER_PARAMETERS Polaris Getting Started Aurora PBS ANL_AURORA_SCHEDULER_PARAMETERS Aurora Getting Started Crux PBS ANL_CRUX_SCHEDULER_PARAMETERS Crux Getting Started <p>Example: Running a batch job <pre><code>include:\n  - project: 'anl/ci-resources/defaults'\n    ref: main\n    file:\n      - '/runners.yml'\n\nbatch_test:\n  extends: .polaris-batch-runner\n  variables:\n    ANL_POLARIS_SCHEDULER_PARAMETERS: \"-A ProjectName -l select=1,walltime=10:00,filesystems=home -q myQueue\"\n  script:\n    - echo \"Job start\"\n    - aprun -n 1 id\n    - aprun -n 1 hostname\n    - aprun -n 1 echo \"Running with setuid batch runner\"\n    - echo \"Job end\"\n</code></pre></p>"},{"location":"services/gitlab-ci/#stages","title":"Stages","text":"<p>Jobs can be organized into <code>stages</code>. Jobs in the next stage will not start until all dependencies in the previous stage have completed. This is often used if there are building and testing steps required before code may be run or packaged. These stages are assembled in a <code>Pipeline</code>, a directed graph of <code>stages</code>. By default, GitLab includes the following stages executed in the below order: <pre><code>.pre\nbuild\ntest\ndeploy\n.post\n</code></pre></p> <p>You may declare your own stages by first declaring a <code>stages:</code> array near the top of your <code>.gitlab-ci.yml</code> file. Stages will be processed in the order given in the array.</p> <p>Example: Declaring Stages <pre><code>stages:\n  - stage1\n  - stage2\n  - stage3\n</code></pre></p> <p>Example: Pipeline with custom stages <pre><code># this include allows us to reference defaults in anl/ci-resource/defaults\ninclude:\n  - project: 'anl/ci-resources/defaults'\n    ref: main\n    file:\n      - '/runners.yml'\n\nvariables:\n  ANL_POLARIS_SCHEDULER_PARAMETERS: \"-A ProjectName -l select=1,walltime=10:00,filesystems=home -q myQueue\"\nstages:\n  - stage1\n  - stage2\ntest1:\n  stage: stage1\n  extends: .polaris-shell-runner\n  script:\n    - export\n    - id\n    - hostname\n    - echo \"Running with setuid shell runner\" \n    - echo test &gt; test.txt\ntest2:\n  stage: stage2\n  extends: .polaris-batch-runner\n  script:\n    - echo \"Job 2 start\"\n    - aprun -n 1 id\n    - aprun -n 1 hostname\n    - aprun -n 1 echo \"Running with setuid batch runner\"\n    - echo \"Job 2 end\"\n</code></pre></p>"},{"location":"services/gitlab-ci/#rules","title":"Rules","text":"<p>GitLab allows for CI/CD jobs to be launched only if certain conditions are met. GitLab sets a series of variables in addition to any the user explicitly sets when a job launches. A job can check these variables and choose to run or not based on the results. This is often used to ensure certain jobs only run on commits, merge requests, and/or merges. By default, if any rule matches, it will run. You can override this behavior with commands like <code>when: never</code> when a conditional matches.</p> <p>For more details, please see the upstream docs.</p> <p>Rules can use the following conditional checks: <pre><code>if\nchanges\nexists\nallow_failure\nvariables\nwhen\n</code></pre></p> <p>Example: GitLab job designed to only run on merge requests <pre><code>test1:\n  rules:\n    - if: $CI_COMMIT_TAG                    # Do not execute jobs for tag context\n      when: never\n    - if: $CI_COMMIT_BRANCH == \"master\"     # Do not run on master, since will run on the merge request just prior\n      when: never\n    - if: $CI_MERGE_REQUEST_IID             # CI_MERGE_REQUEST_IID exists, so run job\n  stage: stage1\n  extends: .polaris-shell-runner\n  script:\n    - echo \"Run test 1\"\n</code></pre></p>"},{"location":"services/gitlab-ci/#job-scheduling","title":"Job Scheduling","text":"<p>GitLab provides pipeline scheduling functionality to support recurring pipelines, specified using a Cron-like syntax. Pipeline scheduling is available in the project sidebar under \"Build\" &gt; \"Pipeline schedules\". For more details, see the upstream documentation.</p>"},{"location":"services/gitlab-ci/#template-jobs","title":"Template Jobs","text":"<p>GitLab allows you to create <code>template jobs</code>, these are pieces of job specifications which can be included in jobs. Each <code>template job</code> name must begin with a period (.) and follow the same syntax as normal jobs. To instantiate a job based on the <code>template job</code>, use the keyword <code>extends</code>. If your specific job declares a key/value already in the template, the specific job will overwrite it.</p> <p>Example: Use a job template so two tests will only run on merge requests <pre><code>.MR_rules:\n  rules:\n    - if: $CI_COMMIT_TAG                    # Do not execute jobs for tag context\n      when: never\n    - if: $CI_COMMIT_BRANCH == \"master\"     # Do not run on master, otherwise runs everything from scratch on merge\n      when: never\n    - if: $CI_MERGE_REQUEST_IID\n    - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"'    \n\ntest1:\n  extends: .MR_rules\n  stage: stage1\n  extends: .polaris-shell-runner\n  script:\n    - echo \"Run test 1\"\ntest2:\n  extends: .MR_rules\n  stage: stage2\n  extends: .polaris-shell-runner\n  script:\n    - echo \"Run test 2\"\n</code></pre></p>"},{"location":"services/gitlab-ci/#console-output","title":"Console Output","text":"<p>To see the output of a job, click on it in the GUI, and it will show the STDOUT and STDERR from the job run. If the job did not launch successfully, it will have error messages from gitlab-runner or Jacamar-CI or both. Please be aware of any sensitive data you do not want exported or saved to the output console, such as passwords. Please do not output large amounts of data from your jobs to the stdout. If your CI/CD job outputs large amounts of text to STDOUT or STDERR, consider redirecting it into a job log.</p> <p> </p> GitLab Group Job Console"},{"location":"services/gitlab-ci/#storage-use-and-policy","title":"Storage Use and Policy","text":""},{"location":"services/gitlab-ci/#gitlab-project-quota","title":"GitLab Project Quota","text":"<p>Each repository has a default quota of 1GB. Quota increases may be requested by emailing Support. This quota is separate from the storage quotas allocated to ALCF Projects and ALCF Users on the HPC clusters and shared filesystems.</p>"},{"location":"services/gitlab-ci/#cicd-filesystem-usage","title":"CI/CD Filesystem Usage","text":"<p>CI/CD jobs will run out of your home directory by default. Each job will begin by cloning the repository into a path under <code>~/.jacamar-ci</code> and will continue to write there unless you reference other destinations in your CI/CD job. You will need to ensure that you have the minimum amount of space for this runner operation. If you do not, the job will fail to run. Each GitLab runner will create a new subdirectory under <code>~/.jacamar-ci</code> for itself; however, it will reuse space for subsequent pipelines launched for that project on that runner.</p> <p>It is recommended that if you need more space than your home directory can provide, you leverage any ALCF Project space you may have been allocated on a shared filesystem.</p>"},{"location":"services/gitlab-ci/#gitlab-ci-access-termination-policy","title":"GitLab-CI Access Termination Policy","text":"<p>Projects that have been inactive for at least 6 months will have their access disabled and their repositories deleted. Notification will be sent to the PI 30 days prior to the day of the action. </p> <p>Inactivity is defined as, but not limited to:</p> <ul> <li>No new projects created</li> <li>No new commits to an existing project</li> <li>Prolonged period of continuously failing CI/CD jobs (In the case of re-occurring scheduled jobs)</li> </ul>"},{"location":"services/gitlab-ci/#gitlab-rest-api","title":"GitLab REST API","text":"<p>The GitLab REST API provides programmatic access to read and modify GitLab resources by using standard HTTP methods and JSON data formats.<sup>1</sup> The examples below demonstrate how to fetch the logs and artifacts from a GitLab pipeline in a GitLab project.</p> <p>In order to use the REST API,  a personal access token is required. Please follow the instructions at GitLab Personal Access Token documentation to create one. This token is used to authenticate the user and must be kept secure and not shared with others. Next, we need to find the project id for the GitLab project. In order to find the project ID, navigate to the project homepage in the GitLab web interface and click the button with three vertical dots in the upper right corner of the page and then click <code>Copy project ID</code> (see the figure below).</p> <p></p> <p>GitLab Project ID screenshot</p> <p>We use the <code>curl</code> command to interact with the GitLab REST API. First, lets get all the pipeline IDs for the given project ID. Each of the GitLab CI run (or a pipeline) has an unique ID.</p> <pre><code>source ./secrets.data\n\n# GitLab project ID\nPROJ_ID=\"18\"\n# Gitlab project URL\nPROJ_URL=\"https://gitlab-ci.alcf.anl.gov/api/v4/projects/${PROJ_ID}/\"\n\n# GitLab API endpoint to list pipelines.\nPIPELINE_URL=\"${PROJ_URL}/pipelines\"\n\n# Make the request to list pipelines.\nresponse=$(curl --silent --header \\\n  \"PRIVATE-TOKEN: ${SECRET_ACCESS_TOKEN}\" \\\n  \"${PIPELINE_URL}\")\n\n# Extract pipeline IDs\npipeline_ids=$(echo \"$response\" | jq -r '.[].id')\n\n# Print pipeline IDs\necho \"Pipeline IDs:\"\nfor id in $pipeline_ids; do\n  echo \"$id\"\ndone\n</code></pre> <p>The file <code>secret.data</code> contains the <code>SECRET_ACCESS_TOKEN</code> variable which stores the personal access token for the user. The <code>jq</code> command is used to parse the JSON response from the GitLab REST API and extract the pipeline IDs (you can read more about the <code>jq</code> command at jq Manual). Note that you may want to change the <code>PROJ_URL</code> based on the root endpoint of your GitLab instance (i.e., appropriately replace <code>gitlab-ci.alcf.anl.gov</code> with your GitLab instance URL). Once the pipeline IDs are obtained, we can fetch the logs and artifacts for a specific pipeline as shown below.</p> <pre><code>source ./secrets.data\n\n# GitLab pipeline ID\nPIPELINE_ID=\"2040\"\n# Directory to save the logs\nLOG_DIR=\"pipeline_logs\"\n\n# Create the log directory if it doesn't exist\nmkdir -p \"$LOG_DIR\"\n\n# Function to get all jobs in a given pipeline\nget_pipeline_jobs() {\n  curl --header \"PRIVATE-TOKEN: ${SECRET_ACCESS_TOKEN}\" \\\n       \"${PROJ_URL}/pipelines/${PIPELINE_ID}/jobs\"\n}\n\n# Function to download the log of a given job\ndownload_job_log() {\n  local job_id=$1\n  local job_name=$2\n  curl --header \"PRIVATE-TOKEN: ${SECRET_ACCESS_TOKEN}\" \\\n    \"${PROJ_URL}/jobs/${job_id}/trace\" \\\n    -o \"${LOG_DIR}/${job_id}_${job_name}.txt\"\n  echo \"Downloaded log for job ${job_name} (ID: ${job_id})\"\n}\n\n# Function to download job artifacts\ndownload_job_artifacts() {\n  local job_id=$1\n  local job_name=$2\n  curl --header \"PRIVATE-TOKEN: ${SECRET_ACCESS_TOKEN}\" \\\n    \"${PROJ_URL}/jobs/${job_id}/artifacts\" \\\n    -o \"${LOG_DIR}/${job_id}_${job_name}.zip\"\n  echo \"Downloaded artifacts for job ${job_name} (ID: ${job_id})\"\n}\n\n# Get the list of jobs in the pipeline\njobs=$(get_pipeline_jobs)\n\n# Extract job IDs and names from the jobs list and download their logs\necho \"$jobs\" | jq -c '.[]' | while read -r job; do\n  job_id=$(echo \"${job}\" | jq -r '.id')\n  job_name=$(echo \"${job}\" | jq -r '.name')\n  download_job_log \"${job_id}\" \"${job_name}\"\n  download_job_artifacts \"${job_id}\" \"${job_name}\"\ndone\n</code></pre> <p>Note that the <code>gitlab-ci.alcf.anl.gov</code> doesn't require a proxy or to be connected to Argonne network. If you run into issue, please contact ALCF Support.</p> <ol> <li> <p>GitLab REST API \u21a9</p> </li> </ol>"},{"location":"services/inference-endpoints/","title":"ALCF Inference Endpoints","text":"<p>Unlock Powerful AI Inference at Argonne Leadership Computing Facility (ALCF). This service provides API access to a variety of state-of-the-art open-source models running on dedicated ALCF hardware. Join our mailing list to receive updates and maintenance notifications.</p>"},{"location":"services/inference-endpoints/#quick-start","title":"Quick Start","text":"<p>This guide will walk you through the fastest ways to start using the ALCF Inference Endpoints.</p>"},{"location":"services/inference-endpoints/#web-ui","title":"Web UI","text":"<p>The easiest way to get started is through the web interface, accessible at https://inference.alcf.anl.gov/</p> <p>The UI is based on the popular Open WebUI platform. After logging in with your ANL or ALCF credentials, you can:</p> <ol> <li>Select a model from the dropdown menu at the top of the screen.</li> <li>Start a conversation directly in the chat interface.</li> </ol> <p>In the model selection dropdown, you can see the status of each model:</p> <p></p> <ul> <li>Live: These models are \"hot\" and ready for immediate use.</li> <li>Starting: A node has been acquired and the model is being loaded into memory.</li> <li>Queued: The model is in a queue waiting for resources to become available.</li> <li>Offline: The model is available but not currently loaded. It will be queued for loading when a user sends a request.</li> <li>All: Lists all available models regardless of their status.</li> </ul> <p>For Advanced UI Features</p> <p>For a full guide on advanced features like RAG (Retrieval-Augmented Generation), function calling, and more, please refer to the official Open WebUI documentation.</p>"},{"location":"services/inference-endpoints/#api-access","title":"API Access","text":"<p>For programmatic access, you can use the API endpoints directly.</p>"},{"location":"services/inference-endpoints/#1-setup-your-environment","title":"1. Setup Your Environment","text":"<p>You can run the following setup from anywhere (your local machine, or an ALCF machine).</p> <pre><code># Create a new Conda environment\nconda create -n globus_env python==3.11.9 --y\nconda activate globus_env\n\n# Install necessary packages\npip install openai globus_sdk\n</code></pre>"},{"location":"services/inference-endpoints/#2-authenticate","title":"2. Authenticate","text":"<p>To access the endpoints, you need an authentication token.</p> <pre><code># Download the authentication helper script\nwget https://raw.githubusercontent.com/argonne-lcf/inference-endpoints/refs/heads/main/inference_auth_token.py\n\n# Authenticate with your Globus account\npython inference_auth_token.py authenticate\n</code></pre> <p>This will generate and store access and refresh tokens in your home directory. To see how much time you have left before your access token expires, type the following command (<code>units</code> can be seconds, minutes, or hours):</p> <pre><code>python inference_auth_token.py get_time_until_token_expiration --units seconds\n</code></pre> <p>Token Validity</p> <ul> <li>Access tokens are valid for 48 hours. The <code>get_access_token</code> command will automatically refresh your token if it has expired.</li> <li>An internal policy requires re-authentication every 7 days. If you encounter permission errors, logout from Globus at app.globus.org/logout and re-run <code>python inference_auth_token.py authenticate --force</code>.</li> </ul>"},{"location":"services/inference-endpoints/#3-make-a-test-call","title":"3. Make a Test Call","text":"<p>Once authenticated, you can make a test call using cURL or Python.</p> cURLPython (OpenAI SDK) <pre><code>#!/bin/bash\n\n# Get your access token\naccess_token=$(python inference_auth_token.py get_access_token)\n\ncurl -X POST \"https://inference-api.alcf.anl.gov/resource_server/metis/api/v1/chat/completions\" \\\n     -H \"Authorization: Bearer ${access_token}\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n            \"model\": \"Meta-Llama-3.1-8B-Instruct\",\n            \"messages\":[{\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms.\"}]\n         }'\n</code></pre> <pre><code>from openai import OpenAI\nfrom inference_auth_token import get_access_token\n\n# Get your access token\naccess_token = get_access_token()\n\nclient = OpenAI(\n    api_key=access_token,\n    base_url=\"https://inference-api.alcf.anl.gov/resource_server/metis/api/v1\"\n)\n\nresponse = client.chat.completions.create(\n    model=\"Meta-Llama-3.1-8B-Instruct\",\n    messages=[{\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms.\"}]\n)\n\nprint(response.choices[0].message.content)\n</code></pre>"},{"location":"services/inference-endpoints/#system-details","title":"System Details","text":""},{"location":"services/inference-endpoints/#available-clusters","title":"Available Clusters","text":"<p>Two clusters are currently active, with additional systems coming soon:</p> Cluster Status Framework Base URL Supported Endpoints Sophia Active vLLM <code>/resource_server/sophia/vllm/v1</code> <code>/chat/completions</code><code>/completions</code><code>/embeddings</code><code>/batches</code> SambaNova SN40L (Metis) Active SambaNova API <code>/resource_server/metis/api/v1</code> <code>/chat/completions</code> Cerebras CS-3 Coming Soon - - - GH200 Nvidia Coming Soon - - - <p>Cluster Differences</p> <ul> <li>Sophia uses vLLM and supports the full range of OpenAI-compatible endpoints including chat, completions, embeddings, and batch processing.</li> <li>Metis uses SambaNova's inference API and currently supports only chat completions.</li> </ul> <p>Discovering Available Models</p> <p>You can programmatically query all available models and endpoints: <pre><code>access_token=$(python inference_auth_token.py get_access_token)\ncurl -X GET \"https://inference-api.alcf.anl.gov/resource_server/list-endpoints\" \\\n     -H \"Authorization: Bearer ${access_token}\"\n</code></pre></p>"},{"location":"services/inference-endpoints/#api-usage-examples","title":"API Usage Examples","text":""},{"location":"services/inference-endpoints/#querying-endpoint-status","title":"Querying Endpoint Status","text":"Querying Endpoint Status <p>You can check the status of models on the cluster and list all available endpoints programmatically.</p> Check Job/Model StatusList All Available Endpoints <p>This endpoint provides information about what is currently live or queued. <pre><code>#!/bin/bash\n\n# Get your access token\naccess_token=$(python inference_auth_token.py get_access_token)\n\n# Check Sophia cluster status\ncurl -X GET \"https://inference-api.alcf.anl.gov/resource_server/sophia/jobs\" \\\n -H \"Authorization: Bearer ${access_token}\"\n\n# Check Metis cluster status (replace 'sophia' with 'metis')\ncurl -X GET \"https://inference-api.alcf.anl.gov/resource_server/metis/jobs\" \\\n -H \"Authorization: Bearer ${access_token}\"\n</code></pre></p> <p>Switching Between Clusters</p> <p>Replace <code>/sophia/</code> with <code>/metis/</code> in the URL to query the Metis cluster instead.</p> <p>This provides a list of all available endpoints. <pre><code>#!/bin/bash\n\n# Get your access token\naccess_token=$(python inference_auth_token.py get_access_token)\n\ncurl -X GET \"https://inference-api.alcf.anl.gov/resource_server/list-endpoints\" \\\n -H \"Authorization: Bearer ${access_token}\"\n</code></pre></p>"},{"location":"services/inference-endpoints/#chat-completions","title":"Chat Completions","text":"Chat Completions <p>This endpoint is used for conversational AI.</p> cURLPython (OpenAI SDK) <pre><code>#!/bin/bash\naccess_token=$(python inference_auth_token.py get_access_token)\n\n# Sophia cluster example\ncurl -X POST \"https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/chat/completions\" \\\n     -H \"Authorization: Bearer ${access_token}\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n            \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n            \"temperature\": 0.2,\n            \"max_tokens\": 150,\n            \"messages\":[{\"role\": \"user\", \"content\": \"What are the symptoms of diabetes?\"}]\n         }'\n\n# Metis cluster example (replace '/sophia/vllm' with '/metis/api')\ncurl -X POST \"https://inference-api.alcf.anl.gov/resource_server/metis/api/v1/chat/completions\" \\\n     -H \"Authorization: Bearer ${access_token}\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n            \"model\": \"Meta-Llama-3.1-8B-Instruct\",\n            \"temperature\": 0.2,\n            \"max_tokens\": 150,\n            \"messages\":[{\"role\": \"user\", \"content\": \"What are the symptoms of diabetes?\"}]\n         }'\n</code></pre> <pre><code>from openai import OpenAI\nfrom inference_auth_token import get_access_token\n\naccess_token = get_access_token()\n\n# Sophia cluster\nclient = OpenAI(\n    api_key=access_token,\n    base_url=\"https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1\"\n)\n\nresponse = client.chat.completions.create(\n    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n    messages=[{\"role\": \"user\", \"content\": \"What are the symptoms of diabetes?\"}]\n)\nprint(response.choices[0].message.content)\n\n# Metis cluster (replace '/sophia/vllm' with '/metis/api')\nclient_metis = OpenAI(\n    api_key=access_token,\n    base_url=\"https://inference-api.alcf.anl.gov/resource_server/metis/api/v1\"\n)\n\nresponse = client_metis.chat.completions.create(\n    model=\"Meta-Llama-3.1-8B-Instruct\",\n    messages=[{\"role\": \"user\", \"content\": \"What are the symptoms of diabetes?\"}]\n)\nprint(response.choices[0].message.content)\n</code></pre> <p>Switching Between Clusters</p> <p>To target a different cluster, simply replace the cluster/framework portion of the URL:</p> <ul> <li>Sophia: <code>/resource_server/sophia/vllm/v1</code></li> <li>Metis: <code>/resource_server/metis/api/v1</code></li> </ul>"},{"location":"services/inference-endpoints/#vision-language-models","title":"Vision Language Models","text":"Vision Language Models <p>Use this endpoint to analyze images with text prompts.</p> Python (OpenAI SDK) <pre><code>from openai import OpenAI\nimport base64\nfrom inference_auth_token import get_access_token\n\naccess_token = get_access_token()\nclient = OpenAI(\n    api_key=access_token,\n    base_url=\"https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1\"\n)\n\ndef encode_image(image_path):\n    with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode('utf-8')\n\nimage_path = \"scientific_diagram.png\" # Replace with your image\nbase64_image = encode_image(image_path)\n\nresponse = client.chat.completions.create(\n    model=\"Qwen/Qwen2-VL-72B-Instruct\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": \"Describe the key components in this scientific diagram\"},\n                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n            ]\n        }\n    ],\n    max_tokens=300\n)\nprint(response.choices[0].message.content)\n</code></pre>"},{"location":"services/inference-endpoints/#embeddings","title":"Embeddings","text":"Embeddings <p>This endpoint generates vector embeddings from text, currently supported by the <code>infinity</code> framework.</p> Python (OpenAI SDK) <pre><code>from openai import OpenAI\nfrom inference_auth_token import get_access_token\n\naccess_token = get_access_token()\nclient = OpenAI(\n    api_key=access_token,\n    base_url=\"https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1\"\n)\n\nresponse = client.embeddings.create(\n  model=\"mistralai/Mistral-7B-Instruct-v0.3-embed\",\n  input=\"The food was delicious and the waiter...\",\n  encoding_format=\"float\"\n)\nprint(response.data[0].embedding)\n</code></pre> <p>For more examples, please see the inference-endpoints GitHub repository.</p>"},{"location":"services/inference-endpoints/#available-models","title":"Available Models","text":"<p>Models are organized by cluster and marked with the following capabilities:</p> <ul> <li>B - Batch Processing Enabled</li> <li>T - Tool Calling Enabled</li> <li>R - Reasoning Enabled</li> <li>H - Always Hot Model</li> </ul>"},{"location":"services/inference-endpoints/#sophia-cluster-vllm","title":"Sophia Cluster (vLLM)","text":"Chat Language Models <p>Qwen Family</p> <ul> <li>Qwen/Qwen2.5-7B-Instruct<sup>B</sup><sup>T</sup></li> <li>Qwen/Qwen2.5-14B-Instruct<sup>B</sup><sup>T</sup></li> <li>Qwen/QwQ-32B<sup>B</sup><sup>R</sup><sup>T</sup></li> <li>Qwen/Qwen3-32B<sup>B</sup><sup>R</sup><sup>T</sup><sup>H</sup></li> <li>Qwen/Qwen3-235B-A22B<sup>T</sup></li> <li>Qwen/Qwen3-Next-80B-A3B-Instruct<sup>T</sup></li> <li>Qwen/Qwen3-Next-80B-A3B-Thinking<sup>R</sup><sup>T</sup></li> </ul> <p>Meta Llama Family</p> <ul> <li>meta-llama/Meta-Llama-3.1-8B-Instruct<sup>B</sup><sup>T</sup><sup>H</sup></li> <li>meta-llama/Meta-Llama-3.1-70B-Instruct<sup>B</sup><sup>T</sup><sup>H</sup></li> <li>meta-llama/Meta-Llama-3.1-405B-Instruct<sup>B</sup><sup>T</sup></li> <li>meta-llama/Llama-3.3-70B-Instruct<sup>B</sup><sup>T</sup></li> <li>meta-llama/Llama-4-Scout-17B-16E-Instruct<sup>B</sup><sup>T</sup><sup>H</sup></li> <li>meta-llama/Llama-4-Maverick-17B-128E-Instruct<sup>T</sup></li> </ul> <p>Mistral Family</p> <ul> <li>mistralai/Mistral-Large-Instruct-2407</li> <li>mistralai/Mixtral-8x22B-Instruct-v0.1</li> </ul> <p>OpenAI Family</p> <ul> <li>openai/gpt-oss-20b<sup>B</sup><sup>R</sup><sup>T</sup><sup>H</sup></li> <li>openai/gpt-oss-120b<sup>B</sup><sup>R</sup><sup>T</sup><sup>H</sup></li> </ul> <p>Aurora GPT Family</p> <ul> <li>argonne/AuroraGPT-IT-v4-0125<sup>B</sup></li> <li>argonne/AuroraGPT-Tulu3-SFT-0125<sup>B</sup></li> <li>argonne/AuroraGPT-DPO-UFB-0225<sup>B</sup></li> <li>argonne/AuroraGPT-KTO-UFB-0325<sup>B</sup></li> </ul> <p>Other Models</p> <ul> <li>allenai/Llama-3.1-Tulu-3-405B</li> <li>google/gemma-3-27b-it<sup>B</sup><sup>T</sup><sup>H</sup></li> <li>mgoin/Nemotron-4-340B-Instruct-hf</li> <li>zai-org/GLM-4.5-Air<sup>T</sup></li> </ul> Vision Language Models <ul> <li>Qwen/Qwen2-VL-72B-Instruct<sup>T</sup></li> <li>Qwen/Qwen2.5-VL-72B-Instruct<sup>T</sup></li> <li>meta-llama/Llama-3.2-90B-Vision-Instruct</li> </ul> Embedding Models <ul> <li>mistralai/Mistral-7B-Instruct-v0.3-embed</li> <li>Qwen/Qwen3-Embedding-8B</li> <li>Salesforce/SFR-Embedding-Mistral</li> </ul>"},{"location":"services/inference-endpoints/#metis-cluster-sambanova","title":"Metis Cluster (SambaNova)","text":"Chat Language Models <ul> <li>DeepSeek-R1<sup>R</sup><sup>H</sup></li> <li>Meta-Llama-3.1-8B-Instruct<sup>H</sup></li> <li>Meta-Llama-3.3-70B-Instruct<sup>H</sup></li> <li>Qwen2.5-Coder-0.5B-Instruct<sup>H</sup></li> </ul> <p>Metis Limitations</p> <ul> <li>Batch processing and Tool Calling is not currently supported on the Metis cluster</li> <li>Only chat completions endpoint is available</li> </ul> <p>Want to add a model?</p> <p>To request a new model, please contact ALCF Support.</p>"},{"location":"services/inference-endpoints/#batch-processing","title":"Batch Processing","text":"<p>For large-scale inference, the batch processing service allows you to submit a file with up to 150,000 requests.</p> <p>Batch Processing Requirements</p> <ul> <li>You must have an active ALCF allocation.</li> <li>Input files and output folders must be located within the <code>/eagle/argonne_tpc</code> project space or a world-readable directory.</li> <li>Each line in the input file must be a complete JSON request object (JSON Lines format).</li> <li>Only models marked with B support batch processing.</li> </ul>"},{"location":"services/inference-endpoints/#batch-api-endpoints","title":"Batch API Endpoints","text":""},{"location":"services/inference-endpoints/#create-batch","title":"Create Batch","text":"Create Batch Request cURLPython <pre><code>#!/bin/bash\n\n# Get your access token\naccess_token=$(python inference_auth_token.py get_access_token)\n\n# Define the base URL\nbase_url=\"https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/batches\"\n\n# Submit batch request\ncurl -X POST \"$base_url\" \\\n     -H \"Authorization: Bearer ${access_token}\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n          \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n          \"input_file\": \"/eagle/argonne_tpc/path/to/your/input.jsonl\"\n        }'\n\n# Submit batch request with custom output folder\ncurl -X POST \"$base_url\" \\\n     -H \"Authorization: Bearer ${access_token}\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n          \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n          \"input_file\": \"/eagle/argonne_tpc/path/to/your/input.jsonl\",\n          \"output_folder_path\": \"/eagle/argonne_tpc/path/to/your/output/folder/\"\n        }'\n</code></pre> <pre><code>import requests\nimport json\nfrom inference_auth_token import get_access_token\n\n# Get your access token\naccess_token = get_access_token()\n\n# Define headers and URL\nheaders = {\n    'Authorization': f'Bearer {access_token}',\n    'Content-Type': 'application/json'\n}\nurl = \"https://inference-api.alcf.anl.gov/resource_server/sophia/vllm/v1/batches\"\n\n# Submit batch request\ndata = {\n    \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n    \"input_file\": \"/eagle/argonne_tpc/path/to/your/input.jsonl\",\n    \"output_folder_path\": \"/eagle/argonne_tpc/path/to/your/output/folder/\"\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nprint(response.json())\n</code></pre>"},{"location":"services/inference-endpoints/#retrieve-batch","title":"Retrieve Batch","text":"Retrieve Batch Metrics cURLPython <pre><code>#!/bin/bash\n\n# Get your access token\naccess_token=$(python inference_auth_token.py get_access_token)\n\n# Get results of specific batch\nbatch_id=\"your-batch-id\"\ncurl -X GET \"https://inference-api.alcf.anl.gov/resource_server/v1/batches/${batch_id}/result\" \\\n     -H \"Authorization: Bearer ${access_token}\"\n</code></pre> <pre><code>import requests\nfrom inference_auth_token import get_access_token\n\n# Get your access token\naccess_token = get_access_token()\n\n# Define headers and URL\nheaders = {\n    'Authorization': f'Bearer {access_token}'\n}\nbatch_id = \"your-batch-id\"\nurl = f\"https://inference-api.alcf.anl.gov/resource_server/v1/batches/{batch_id}/result\"\n\n# Get batch results\nresponse = requests.get(url, headers=headers)\nprint(response.json())\n</code></pre> <p>Sample Output: <pre><code>{\n    \"results_file\": \"/eagle/argonne_tpc/path/to/your/output/folder/&lt;input-file-name&gt;_&lt;model&gt;_&lt;batch-id&gt;/&lt;input-file-name&gt;_&lt;timestamp&gt;.results.jsonl\",\n    \"progress_file\": \"/eagle/argonne_tpc/path/to/your/output/folder/&lt;input-file-name&gt;_&lt;model&gt;_&lt;batch-id&gt;/&lt;input-file-name&gt;_&lt;timestamp&gt;.progress.json\",\n    \"metrics\": {\n        \"response_time\": 27837.440138816833,\n        \"throughput_tokens_per_second\": 3899.833442250346,\n        \"total_tokens\": 108561380,\n        \"num_responses\": 99985,\n        \"lines_processed\": 100000\n    }\n}\n</code></pre></p>"},{"location":"services/inference-endpoints/#list-batch","title":"List Batch","text":"List All Batches cURLPython <pre><code>#!/bin/bash\n\n# Get your access token\naccess_token=$(python inference_auth_token.py get_access_token)\n\n# List all batches\ncurl -X GET \"https://inference-api.alcf.anl.gov/resource_server/v1/batches\" \\\n     -H \"Authorization: Bearer ${access_token}\"\n\n# Optionally filter by status (pending, running, completed, or failed)\ncurl -X GET \"https://inference-api.alcf.anl.gov/resource_server/v1/batches?status=completed\" \\\n     -H \"Authorization: Bearer ${access_token}\"\n</code></pre> <pre><code>import requests\nfrom inference_auth_token import get_access_token\n\n# Get your access token\naccess_token = get_access_token()\n\n# Define headers and URL\nheaders = {\n    'Authorization': f'Bearer {access_token}'\n}\nurl = \"https://inference-api.alcf.anl.gov/resource_server/v1/batches\"\n\n# List all batches\nresponse = requests.get(url, headers=headers)\nprint(response.json())\n\n# Optionally filter by status (pending, running, completed, or failed)\nparams = {'status': 'completed'}\nresponse = requests.get(url, headers=headers, params=params)\nprint(response.json())\n</code></pre> <p>Sample Output: <pre><code>[\n  {\n    \"batch_id\": \"f8fa8efd-1111-476d-a0a0-111111111111\",\n    \"cluster\": \"sophia\",\n    \"created_at\": \"2025-02-20 18:39:58.049584+00:00\",\n    \"framework\": \"vllm\",\n    \"input_file\": \"/eagle/argonne_tpc/path/to/your/output/folder/chunk_a.jsonl\",\n    \"status\": \"pending\"\n  },\n  {\n    \"batch_id\": \"4b8a31b8-2222-479f-8c8c-222222222222\",\n    \"cluster\": \"sophia\",\n    \"created_at\": \"2025-02-20 18:40:30.882414+00:00\",\n    \"framework\": \"vllm\",\n    \"input_file\": \"/eagle/argonne_tpc/path/to/your/output/folder/chunk_b.jsonl\",\n    \"status\": \"pending\"\n  }\n]\n</code></pre></p>"},{"location":"services/inference-endpoints/#batch-status","title":"Batch Status","text":"Get Batch Status cURLPython <pre><code>#!/bin/bash\n\n# Get your access token\naccess_token=$(python inference_auth_token.py get_access_token)\n\n# Get status of specific batch\nbatch_id=\"your-batch-id\"\ncurl -X GET \"https://inference-api.alcf.anl.gov/resource_server/v1/batches/${batch_id}\" \\\n     -H \"Authorization: Bearer ${access_token}\"\n</code></pre> <pre><code>import requests\nfrom inference_auth_token import get_access_token\n\n# Get your access token\naccess_token = get_access_token()\n\n# Define headers and URL\nheaders = {\n    'Authorization': f'Bearer {access_token}'\n}\nbatch_id = \"your-batch-id\"\nurl = f\"https://inference-api.alcf.anl.gov/resource_server/v1/batches/{batch_id}\"\n\n# Get batch status\nresponse = requests.get(url, headers=headers)\nprint(response.json())\n</code></pre> <p>Batch Status Codes: - pending: The request was submitted, but the job has not started yet. - running: The job is currently running on a compute node. - failed: An error occurred; the error message will be displayed when querying the result. - completed: :tada:</p>"},{"location":"services/inference-endpoints/#cancel-batch","title":"Cancel Batch","text":"Cancel Submitted Batch <p>The inference team is currently developing a mechanism for users to cancel submitted batches. In the meantime, please contact us with your <code>batch_id</code> if you have a batch to cancel.</p>"},{"location":"services/inference-endpoints/#performance-and-wait-times","title":"Performance and Wait Times","text":"<ul> <li>Cold Starts: The first query to an inactive model on Sophia may take 10-15 minutes to load.</li> <li>Queueing: During high demand, your request may be queued until resources are available.</li> <li>Payload Limits: Payloads are limited to 10MB per request and is further limited by the model's context window.</li> </ul> <p>On Sophia, from the 10 nodes reserved for inference, 5 nodes are dedicated to serving popular models \"hot\" for immediate access. The remaining 5 nodes rotate through other models based on user requests. These dynamically loaded models will remain active for up to 24 hours and will be unloaded if not used for 2 hours.</p>"},{"location":"services/inference-endpoints/#important-notes","title":"Important Notes","text":"<ul> <li>If you\u2019re interested in extended model runtimes, reservations, or private model deployments, please contact ALCF Support.</li> </ul>"},{"location":"services/inference-endpoints/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Connection Timeout: The model you are requesting may be queued as the cluster has too many pending jobs. You can check model status by querying the <code>/jobs</code> endpoint. See Querying Endpoint Status for an example.</li> <li>Permission Denied: Your token may have expired. Logout from Globus at app.globus.org/logout and re-authenticate using the <code>--force</code> flag.</li> <li>Batch Permission Error: Ensure your input/output paths are in a readable location like <code>/eagle/argonne_tpc</code>. It is currently internal only to ALCF and will be made public in the future.</li> <li>IdentityMismatchError: Detected a change in identity: This happens when trying to get an access token using a Globus identity that is not linked to the one you previously used to generate your access tokens. Locate your tokens file (typically at <code>~/.globus/app/58fdd3bc-e1c3-4ce5-80ea-8d6b87cfb944/inference_app/tokens.json</code>), delete it, and restart the authentication process.</li> </ul>"},{"location":"services/inference-endpoints/#notifications","title":"Notifications","text":"<p>To receive notifications regarding new model support, maintenances, and policy updates, please join our mailing list.</p>"},{"location":"services/inference-endpoints/#contact-us","title":"Contact Us","text":"<p>For questions or support, please contact ALCF Support.</p>"},{"location":"services/jupyter-hub/","title":"JupyterHub","text":"<p>JupyterHub is an open-source service application that enables users to launch separate Jupyter instances on a remote server.</p> <p>ALCF JupyterHub provides access to Polaris with the same authentication protocol that is used to access these systems, but through a web interface rather than a terminal.</p> <p>On the ALCF JupyterHub home page, users can choose their desired system.</p> <p>Upon selection, they'll be directed to the sign-in page to enter their ALCF username and  passcode token.</p> <p></p> <p>ALCF JupyterHub home page and sign-in screen</p> <p>We describe below how to use JupyterHub on Polaris in more detail.</p>"},{"location":"services/jupyter-hub/#polaris","title":"Polaris","text":"<p>The Polaris JupyterHub server runs on a Polaris login node and launches individual users' environments on the compute nodes through the PBS job scheduler.</p> <p>After the authentication step, the user will be presented with the menu of the available job options to start the Jupyter instance.</p> <ul> <li>Select a job profile: This field lists the available profiles, which is   limited to \"Polaris Compute Node\" at this time.</li> <li>Queue Name: This field provides a list of available queues on the system.</li> <li>Project List: This field displays the active projects associated with the   user on Polaris.</li> <li>Number of Nodes: This field allows the user to select the number of compute   nodes to be allocated.</li> <li>Runtime (minutes:seconds): This field allows the user to set the runtime of   the job in minutes and seconds. The user should refer to the   Polaris queue scheduling policy   for minimum and maximum runtime allowed for the selected queue.</li> <li>File Systems: This field allows the user to select the file systems to be   mounted.   By default, all the file systems are selected.</li> </ul> <p></p> <p>Polaris Job options</p> <p>Once the appropriate information is provided, the user will click the \"Start\" button and wait for the job to spawn.</p> <p>If there's an extended wait time due to a lengthy job queue, the interface might time out, leading to the job's removal from the queue.</p> <p>If not, the job kicks off and it begins to use up the user's allocation based on the chosen job options.</p> <p>It's crucial for users to shut down the server when resources are no longer required.</p> <p>Failing to do so will result in continued consumption of the allocated time until the predetermined runtime concludes.</p> <p></p> <p>Job queued</p> <p>Warning</p> <p>If you would like to change your selection about where to run the Jupyter instance after the Notebook has started, you need to stop the server to be able to see the drop-down menu again.</p>"},{"location":"services/jupyter-hub/#known-issues","title":"Known Issues","text":""},{"location":"services/jupyter-hub/#spawn-failed-timeout","title":"Spawn Failed: Timeout","text":"<p>This happens when the queue is backed up. Since Jupyter is interactive, it expects an immediate connection. Therefore, it waits 5 minutes for your job to begin before throwing this error. You can monitor the queue usage with Gronk and submit when there isn't a wait.</p>"},{"location":"services/jupyter-hub/#additional-notes","title":"Additional Notes","text":""},{"location":"services/jupyter-hub/#custom-ipython-kernels","title":"Custom IPython Kernels","text":"<p>ALCF JupyterHub provides a set of pre-configured IPython kernels for the users to select.</p> <p>However, users may need custom kernels with additional packages installed.</p> <p>This can be achieved by first creating custom Python environments either through venv or conda.</p> <p>More information on creating custom Python environments can be found in our documentation for Polaris.</p> <p>After activating the custom environment, the <code>ipykernel</code> package needs to be installed with the following command:</p> <pre><code>pip install ipykernel\n</code></pre> <p>Once <code>ipykernel</code> is installed, the custom kernel can be added to the list of available kernels with the following command:</p> <pre><code>python -m ipykernel install --user --name custom_kernel_name\n</code></pre> <p>where <code>custom_kernel_name</code> is the name of the kernel that will appear in the kernel list.</p> <p>This name does not have to match the name of the environment, but should not contain spaces.</p> <p>If you want more flexibility in naming, you can add the <code>--display-name</code> argument as shown below.</p> <pre><code>python -m ipykernel install --user --name custom_kernel_name --display-name \"Polaris Python 3.11 Tensorflow 2.4.1\"\n</code></pre> <p>Note that you still need to provide <code>--name</code> with a simple name that does not contain spaces.</p> <p>Additionally, you can also set environment variables for the kernel with the <code>--env</code> argument, i.e:</p> <pre><code>python -m ipykernel install --user --name custom_kernel_name --env http_proxy http://proxy.alcf.anl.gov:3128 --env https_proxy http://proxy.alcf.anl.gov:3128\n</code></pre> <p>You can see the list of available kernels with the following command:</p> <pre><code>jupyter kernelspec list\n</code></pre> <p>By default, the kernels are installed in the user's home directory under <code>~/.local/share/jupyter/kernels/</code>.</p> <p>All the configuration is specified in the <code>kernel.json</code> file under the kernel directory.</p> <p>For the example above, the path for the json file will be <code>~/.local/share/jupyter/kernels/custom_kernel_name/kernel.json</code>.</p> <p>You can edit this file to add additional environment variables or change the display name.</p> <p>Once you've followed the steps above, your new kernel will be visible on JupyterHub.</p> <p>It's recommended to perform these steps in a terminal, ideally on the login node of the system you're using.</p> <p>After setting up a custom kernel, you can easily add more packages directly within JupyterHub.</p> <p>Simply create a new notebook using your custom kernel and use the <code>%pip</code> or <code>%conda</code> magic commands to install packages.</p> <p>If you're on a compute node, remember to enable internet access by configuring the <code>http_proxy</code> and <code>https_proxy</code> environment variables as previously mentioned.</p>"},{"location":"services/jupyter-hub/#accessing-project-folders","title":"Accessing Project Folders","text":"<p>The Jupyter file browser limits the user to view files and directories within their home directory.</p> <p>To access directories located outside of the user home directory, a symbolic link to the directory must be created within the user home directory.</p> <p>An example of this is:</p> <pre><code>ln -s /project/ABC ~/ABC_project_link\n</code></pre> <p>Please note that one can run any shell command directly on a Jupyter notebook by simply adding an exclamation mark, <code>!</code>, to the beginning of the command.</p> <p>For example, the above command can be run from a notebook cell as follows:</p> <pre><code>!ln -s /project/ABC ~/ABC_project_link\n</code></pre>"},{"location":"services/jupyter-hub/#ending-a-jupyter-notebook-running-on-a-compute-node","title":"Ending a Jupyter Notebook running on a compute node","text":"<p>Failing to correctly end a running Jupyter Notebook will continue to consume the selected project's allocation on the resource in question.</p> <p>When a user has completed their task in Jupyter, the user should stop the Jupyter instance running on the compute node before logging out.</p> <p>To stop the Notebook, click the \"Control Panel\" button in the top right, then click \"Stop My Server\".</p> <p></p> <p>Stop panel</p> <p></p> <p>Stop server</p>"},{"location":"services/jupyter-hub/#resources","title":"Resources","text":"<ul> <li>Jupyter Lab documentation.</li> <li>ALCF Hands-on HPC Workshop presentation on Python and Jupyter on Polaris:<ul> <li>slides</li> <li>video</li> </ul> </li> <li>ALCF webinar on JupyterHub:<ul> <li>slides</li> <li>video</li> </ul> </li> </ul>"},{"location":"sophia/","title":"Sophia Machine Overview","text":"<p>Sophia is comprised of 24 NVIDIA DGX A100 nodes. Each DGX A100 node comprises eight NVIDIA A100 Tensor Core GPUs and two AMD Rome CPUs that provide 22 nodes with 320 GB of GPU memory and two nodes with 640 GB of GPU memory (8,320 GB in total) for training artificial intelligence (AI) datasets, while also enabling GPU-specific and -enhanced high-performance computing (HPC) applications for modeling and simulation.</p> <p>A 15-terabyte solid-state drive offers up to 25 gigabits per second in bandwidth. The dedicated compute fabric comprises 20 Mellanox QM9700 HDR200 40-port switches wired in a fat-tree topology.</p> <p>Table 1 summarizes the capabilities of a Sophia compute node:</p> COMPONENT COUNT PER NODE AGGREGATE AMD Rome 64-core CPU 2 48 DDR4 Memory 1 TB on 320 GB nodes &amp; 2 TB on 640 GB nodes 26 TB NVIDIA A100 GPU 8 192 GPU Memory 22 nodes w/ 320 GB &amp; 2 nodes w/ 640 GB 8,320 GB HDR200 Compute Ports 8 192 HDR200 Storage Ports 2 48 100GbE Ports 2 48 3.84 TB Gen4 NVME drives 4 96"},{"location":"sophia/getting-started/","title":"Getting Started on Sophia","text":""},{"location":"sophia/getting-started/#logging-into-sophia","title":"Logging Into Sophia","text":"<p>To log into Sophia: <pre><code>ssh &lt;username&gt;@sophia.alcf.anl.gov\n</code></pre> Then, type in the password from your CRYPTOCard/MobilePASS+ token. Once logged in, you land on one of the Sophia login nodes (sophia-login-01, sophia-login-02).</p>"},{"location":"sophia/getting-started/#hardware-overview","title":"Hardware Overview","text":"<p>An overview of the Sophia system, including details on the compute node architecture, is available on the Machine Overview page.</p>"},{"location":"sophia/getting-started/#compiling-applications","title":"Compiling Applications","text":"<p>For all code building and development, please use Sophia compute nodes. Please read through the Compiling and Linking Overview page and corresponding pages depending on the target compiler and programming model.</p>"},{"location":"sophia/getting-started/#accessing-additional-software","title":"Accessing Additional Software","text":"<p>ALCF installs additional software in <code>/soft</code>, which can be accessed via module commands by altering your <code>$MODULEPATH</code>: <pre><code>module use /soft/modulefiles\n</code></pre> The available software can then be queried with <code>module avail</code>.</p>"},{"location":"sophia/getting-started/#submitting-and-running-jobs","title":"Submitting and Running Jobs","text":"<p>Please read through the Running Jobs with PBS at the ALCF page for information on using the PBS scheduler and preparing job submission scripts.</p> <p>For more information on Sophia queues and job submission, visit: Running Jobs on Sophia.</p>"},{"location":"sophia/getting-started/#lustre-file-striping","title":"Lustre File Striping","text":"<p>In addition to the content above, here is a document on Lustre File Striping Basics.</p> <ul> <li>Lustre File Striping Basics</li> </ul>"},{"location":"sophia/getting-started/#proxy","title":"Proxy","text":"<p>If the node you are on doesn\u2019t have outbound network connectivity, add the following to your <code>~/.bash_profile</code> file to access the proxy host:</p> <pre><code># proxy settings\nexport HTTP_PROXY=\"http://proxy.alcf.anl.gov:3128\"\nexport HTTPS_PROXY=\"http://proxy.alcf.anl.gov:3128\"\nexport http_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport https_proxy=\"http://proxy.alcf.anl.gov:3128\"\nexport ftp_proxy=\"http://proxy.alcf.anl.gov:3128\"\n</code></pre>"},{"location":"sophia/getting-started/#getting-assistance","title":"Getting Assistance","text":"<p>Please direct all questions, requests, and feedback to support@alcf.anl.gov.</p>"},{"location":"sophia/compiling-and-linking/compiling-and-linking-overview/","title":"Compiling and Linking on Sophia","text":""},{"location":"sophia/compiling-and-linking/compiling-and-linking-overview/#overview","title":"Overview","text":"<p>Sophia has AMD processors on the login nodes (<code>sophia-login-01,02</code>) and AMD processors and NVIDIA A100 GPUs on the compute nodes (see Machine Overview page). The login nodes can be used to create containers and launch jobs.</p> <p>Must compile on a compute node</p> <p>Until the cross-compiling environment is set up or dedicated build nodes are added, the compute nodes will have to be used for compiling. Do not compile codes on the login nodes. To launch an interactive job and acquire a compute node for compiling, use:</p> <pre><code>qsub -I -l select=1 -l walltime=HH:MM:SS -q by-gpu -A &lt;myProjectName&gt; -l filesystems=home:eagle\n</code></pre> <p>The default programming environment on the Sophia compute nodes is the GNU compiler tools coupled with NVIDIA\u2019s CUDA toolkit.</p> <p>For non-GPU codes:</p> <ul> <li><code>gcc</code></li> <li><code>g++</code></li> <li><code>gfortran</code></li> </ul> <p>For CUDA codes, please note that there is a new driver (v470) and default CUDA toolkit (v12.4):</p> <ul> <li><code>nvcc</code></li> </ul> <p>The default Nvidia installed software will be in your PATH on compute nodes (not on login nodes).</p> <pre><code>which nvcc\n</code></pre> <p>NEEDS UPDATING: everything from here down:</p> <p>For MPI, the latest MPI is in <code>/usr/mpi/gcc/openmpi-4.1.5a1</code>:</p> <ul> <li><code>mpicc</code></li> <li><code>mpicxx</code>/<code>mpic++</code>/<code>mpiCC</code></li> <li><code>mpifort</code>/<code>mpif77</code>/<code>mpif90</code></li> </ul> <p>On the login nodes, GNU compilers are available.</p>"},{"location":"sophia/compiling-and-linking/compiling-and-linking-overview/#modules-on-sophia","title":"Modules on Sophia","text":"<p>Available modules can be listed via the command:</p> <pre><code>module avail\n</code></pre> <p>Loaded modules in your environment can be listed via the command:</p> <pre><code>module list\n</code></pre> <p>To load new modules, use:</p> <pre><code>module load &lt;module_name&gt;\n</code></pre> <p>Usage: csh and zsh users do not have to do anything special to their environments. Bash users, however, will need to add the following to any job scripts:</p> <pre><code>#!/bin/bash\n. /etc/profile\n</code></pre> <p>Bash users are also encouraged to modify their <code>~/.bashrc</code> to ensure the Ubuntu system <code>/etc/bash.bashrc</code> file is sourced properly:</p> <pre><code># Source global definitions\nif [ -f /etc/bashrc ]\nthen\n    . /etc/bashrc\nelif [ -f /etc/bash.bashrc ]\nthen\n    . /etc/bash.bashrc\nfi\n</code></pre>"},{"location":"sophia/containers/containers/","title":"Containers on Sophia","text":"<p>Sophia, powered by NVIDIA A100 GPUs, benefits from container-based workloads for seamless compatibility across NVIDIA systems. This guide details the use of containers on Sophia, including custom container creation, large-scale execution, and common pitfalls.</p>"},{"location":"sophia/containers/containers/#apptainer-setup","title":"Apptainer Setup","text":"<p>Sophia employs Apptainer (formerly known as Singularity) for container management. To set up Apptainer, run:</p> <pre><code>module use /soft/spack/base/0.7.1/install/modulefiles/Core/\nmodule load apptainer\napptainer version #1.3.3\n</code></pre> <p>The Apptainer version on Sophia is 1.3.3. Detailed user documentation is available here.</p>"},{"location":"sophia/containers/containers/#building-from-docker-or-argonne-github-container-registry","title":"Building from Docker or Argonne GitHub Container Registry","text":"<p>Containers on Sophia can be built by writing Dockerfiles on a local machine and then publishing the container to DockerHub, or by directly building them on an ALCF compute node by writing an Apptainer recipe file. If you prefer to use existing containers, you can pull them from various registries like DockerHub and run them on Sophia.</p> <p>Since Docker requires root privileges, which users do not have on Sophia, existing Docker containers must be converted to Apptainer. To build a Docker-based container on Sophia, use the following as an example:</p> <pre><code>qsub -I -A &lt;Project&gt; -l select=1:ngpus=8:ncpus=256 -l walltime=01:00:00 -l filesystems=home:eagle -l singularity_fakeroot=True -q by-node -k doe\nexport HTTP_PROXY=http://proxy.alcf.anl.gov:3128\nexport HTTPS_PROXY=http://proxy.alcf.anl.gov:3128\nexport http_proxy=http://proxy.alcf.anl.gov:3128\nexport https_proxy=http://proxy.alcf.anl.gov:3128\nmodule use /soft/spack/base/0.7.1/install/modulefiles/Core/\nmodule load apptainer\napptainer build --fakeroot pytorch:22.06-py3.sing docker://nvcr.io/nvidia/pytorch:22.06-py3\n</code></pre> <p>You can find the latest prebuilt NVIDIA PyTorch containers here. The TensorFlow containers are here (though note that LCF doesn't typically prebuild the TF-1 containers). You can search the full container registry here. For custom containers tailored for Sophia, visit ALCF's GitHub container registry.</p> <p>Note: Currently, container build and executions are only supported on the Sophia compute nodes.</p>"},{"location":"sophia/data-science/dask/","title":"Dask","text":"<p>Dask is a Python library for parallel and distributed computing. A Dask cluster is composed of one scheduler that coordinates the job of many workers, which can have access to CPU or GPU resources. </p> <p>RAPIDS is a suite of software libraries by NVIDIA for \"building end-to-end data science and analytics pipelines on GPUs\".  For example, RAPIDS' <code>cuDF</code>, <code>cuPY</code>, <code>cuML</code> libraries implement common Pandas, Numpy and Scikit-learn APIs, respectively, allowing to run them at scale on a GPU cluster, using Dask.</p> <p>Here we show how to install RAPIDS and Dask in a conda environment on Sophia and how to start a cluster with GPU workers.</p>"},{"location":"sophia/data-science/dask/#install-rapids-and-dask","title":"Install RAPIDS and Dask","text":"<ol> <li> <p>Login to Sophia    <pre><code>ssh &lt;username&gt;@sophia.alcf.anl.gov\n</code></pre></p> </li> <li> <p>Start an interactive session. Follow the instructions specified here to start an interactive job on Sophia.  In the example command below we request 2 GPUs:    <pre><code>qsub -I -l select=2 -l walltime=HH:MM:SS -q by-gpu -A &lt;myProjectName&gt; -l filesystems=home:eagle\n</code></pre></p> </li> <li> <p>Load modules    <pre><code>module load compilers/openmpi\nmodule load conda  \n</code></pre></p> </li> <li> <p>Follow the installation instructions on the RAPIDS Docs, select the appropriate CUDA Version (you can find it in the output of <code>nvidia-smi</code>), and copy the installation command, which should be similar to the one below (replace <code>/path/to/env/rapids-25.06_sophia</code> with your preferred path and name for the environment):    <pre><code>conda create -y -p /path/to/env/rapids-25.06_sophia -c rapidsai -c conda-forge -c nvidia rapids=25.06 python=3.11 'cuda-version&gt;=12.0,&lt;=12.8'\n# activate the environment\nconda activate /path/to/env/rapids-25.06_sophia\n</code></pre></p> </li> <li> <p>Optional: Install <code>jupyterlab</code> and create a <code>ipykernel</code> <pre><code>conda install -y ipykernel jupyterlab-nvdashboard dask-labextension\nenv=$(basename `echo $CONDA_PREFIX`) &amp;&amp; \\\npython -m ipykernel install --prefix=${CONDA_PREFIX} --name \"$env\" --display-name \"Python [\"$env\"]\"\n</code></pre></p> </li> </ol>"},{"location":"sophia/data-science/dask/#start-a-dask-cluster","title":"Start a Dask cluster","text":"<p>The following script, <code>dask_start.sh</code>, starts a Dask cluster:</p> dask_start.sh<pre><code>#!/bin/bash\n# $1 : number of ranks per node (dafault: 8)\n\nTMP_EXE=dask_start_worker.sh\ncat &gt; ${TMP_EXE} &lt;&lt; EOF\n#!/bin/bash\nCUDA_VISIBLE_DEVICES=\\${OMPI_COMM_WORLD_LOCAL_RANK} dask cuda worker \\\n  --device-memory-limit 40GB \\\n  --scheduler-file ~/scheduler.json \\\n  --protocol tcp \\\n  &gt;/tmp/dask_worker_\\${OMPI_COMM_WORLD_RANK}_\\${OMPI_COMM_WORLD_LOCAL_RANK}_\\${HOSTNAME}.log 2&gt;&amp;1\nEOF\nchmod 755 ${TMP_EXE}\n\n# start the scheduler\nrm -f ~/scheduler.json\necho \"starting the scheduler\"\nnohup dask scheduler --scheduler-file ~/scheduler.json  &gt;/tmp/dask_scheduler.log 2&gt;&amp;1 &amp;\nsleep 10\n\n# start the workers\nNUM_NODES=$(cat $PBS_NODEFILE | wc -l)\nNRANKS_PER_NODE=${1:-8}\necho \"starting\" ${NRANKS_PER_NODE} \"workers per node on\" ${NUM_NODES} \"nodes\"\nmpiexec  -np $((NRANKS_PER_NODE*NUM_NODES)) ./${TMP_EXE}\n\nrm ./${TMP_EXE}\n</code></pre> <ol> <li> <p>Copy the script to Sophia and make it executable: <code>chmod a+x ./dask_start.sh</code></p> </li> <li> <p>On a compute node, load modules and activate the Dask conda environment created in Install RAPIDS and Dask <pre><code>module load compilers/openmpi\nmodule load conda  \nconda activate /path/to/env/rapids-25.06_sophia\n</code></pre></p> </li> <li> <p>Start the Dask cluster    <pre><code>./dask_start.sh &lt;num_gpus&gt; &amp;\n</code></pre>    where <code>&lt;num_gpus&gt;</code> is the number of GPUs per node requested (the default is 8).</p> </li> </ol>"},{"location":"sophia/data-science/dask/#connect-to-the-dask-cluster-from-python","title":"Connect to the Dask cluster from python","text":"<p>The following python script, <code>dask_example.py</code>, shows how to connect to a running Dask cluster, print the GPU uuid of each worker, and shut down the cluster:</p> dask_example.py<pre><code>from dask.distributed import Client\nfrom pathlib import Path\nclient = Client(scheduler_file=f'{Path.home()}/scheduler.json')\n\ndef get_gpu_uuid():\n    import cupy as cp\n    gpu_id = cp.cuda.runtime.getDeviceProperties(0)['uuid'].hex()\n    return gpu_id\n\nworkers = list(client.scheduler_info()['workers'].values())\nnum_workers = len(workers)\nprint(f\"{num_workers} workers\")\n\nfutures = client.map(lambda x: get_gpu_uuid(), range(num_workers))\nresults = client.gather(futures)\nfor i, result in enumerate(results):\n    print(f\"Worker {workers[i]['name']} - GPU uuid: {result}\")\n\nclient.shutdown()\n</code></pre> <p>Example output: <pre><code>2 workers\nWorker sophia-gpu-11-1 - GPU uuid: 7aa25d84eb04a33caccb57993b5945ad\nWorker sophia-gpu-11-0 - GPU uuid: 4cc42dc4974265766c6d26ae48c05f85\n</code></pre></p>"},{"location":"sophia/data-science/fine-tune-LLM-with-Autotrain/","title":"Autotrain","text":"<p>Autotrain, developed by Hugging Face, is a platform designed to simplify training cutting-edge models in various fields: NLP, LLM, CV, etc. Read more.</p>"},{"location":"sophia/data-science/fine-tune-LLM-with-Autotrain/#create-python-virtual-environment-for-autotrain","title":"Create Python Virtual Environment for Autotrain","text":"<p>Let's first create a virtual environment for Autotrain, built on top of the minimal system Python installation located at <code>/usr/bin/python</code>:</p> <pre><code>mkdir -p venv_autotrain\npython -m venv venv_autotrain --system-site-packages\nsource venv_autotrain/bin/activate\npip3 install autotrain-advanced\n</code></pre> <p>Note: If Autotrain doesn't work properly, you may have to reinstall <code>nvidia-ml-py</code>.</p> <pre><code>pip3 uninstall nvidia-ml-py3 pynvml\npip3 install --force-reinstall nvidia-ml-py==11.450.51\n</code></pre>"},{"location":"sophia/data-science/fine-tune-LLM-with-Autotrain/#train-dataset-format","title":"Train Dataset Format","text":"<p>The dataset should have a column \"text\" containing the data to be trained on. Example</p>"},{"location":"sophia/data-science/fine-tune-LLM-with-Autotrain/#config-file-for-fine-tuning-local-llm","title":"Config File for Fine-Tuning Local LLM","text":"<p>Here is an example to create a config file for supervised fine-tuning purposes:</p> <pre><code>task: llm-sft\nbase_model: meta-llama/Meta-Llama-3.1-8B-Instruct\nproject_name: Llama-3-1-FT\nlog: wandb\nbackend: local\ndata:\n  path: Path/to/the/training/dataset/folder\n  train_split: train\n  valid_split: null\n  chat_template: null\n  column_mapping:\n    text_column: text\nparams:\n  block_size: 1024\n  model_max_length: 8192\n  epochs: 800\n  batch_size: 2\n  lr: 1e-5\n  peft: true\n  quantization: null\n  target_modules: all-linear\n  padding: right\n  optimizer: paged_adamw_8bit\n  scheduler: cosine\n  gradient_accumulation: 8\n  mixed_precision: bf16\nhub:\n  username: ***\n  token: hf_***\n  push_to_hub: true\n</code></pre> <p>More details</p>"},{"location":"sophia/data-science/fine-tune-LLM-with-Autotrain/#run-autotrain-to-fine-tune-using-the-config-file","title":"Run Autotrain to Fine-Tune Using the Config File","text":"<pre><code>cd Path/to/save/the/adapter\nautotrain --config path/to/config.yaml\n</code></pre>"},{"location":"sophia/data-science/fine-tune-LLM-with-Autotrain/#merge-adapters-with-base-model-to-create-new-model","title":"Merge Adapters with Base Model to Create New Model","text":"<p>Adapters need to be merged with the base model in order to run. You can use the code below:</p> <pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\nimport torch\nfrom peft import PeftModel\nimport os\n\nadapter = \"path/to/saved/adapters/\"\nmodel_name = \"project-name-from-config-file\"\nadapter_path = os.path.join(adapter, model_name)\nbase_model_path = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\ntarget_model_path = \"path/to/save/fine-tuned/models\" + model_name\n\nconfig = AutoConfig.from_pretrained(base_model_path)\nbase_model = AutoModelForCausalLM.from_pretrained(base_model_path)\n\nmerged_model = PeftModel.from_pretrained(base_model, adapter_path)\n\ntokenizer = AutoTokenizer.from_pretrained(adapter_path, trust_remote_code=True)\nmerged_model = merged_model.merge_and_unload()\n\nprint(\"Saving target model...\")\nmerged_model.save_pretrained(target_model_path)\ntokenizer.save_pretrained(target_model_path)\nconfig.save_pretrained(target_model_path)\n</code></pre>"},{"location":"sophia/data-science/python/","title":"Python","text":"<p>We provide prebuilt <code>conda</code> environments containing GPU-supported builds of <code>torch</code>, <code>tensorflow</code> (both with <code>horovod</code> support for multi-node calculations), <code>jax</code>, and many other commonly-used Python modules.</p> <p>Users can activate this environment by first loading the <code>conda</code> module, and then activating the base environment.</p> <p>Explicitly (either from an interactive job, or inside a job script):</p> <pre><code>module use /soft/modulefiles; module load conda; conda activate base\n</code></pre> <p>This will load and activate the base environment.</p>"},{"location":"sophia/data-science/python/#virtual-environments-via-venv","title":"Virtual environments via <code>venv</code>","text":"<p>To install additional packages that are missing from the <code>base</code> environment, we can build a <code>venv</code> on top of it.</p> <p>Conda <code>base</code> environment + <code>venv</code></p> <p>If you need a package that is not already installed in the <code>base</code> environment, this is generally the recommended approach.</p> <p>We can create a <code>venv</code> on top of the base Anaconda environment (with <code>--system-site-packages</code> to inherit the <code>base</code> packages):</p> <pre><code>module use /soft/modulefiles; module load conda; conda activate base\nCONDA_NAME=$(echo ${CONDA_PREFIX} | tr '\\/' '\\t' | sed -E 's/mconda3|\\/base//g' | awk '{print $NF}')\nVENV_DIR=\"$(pwd)/venvs/${CONDA_NAME}\"\nmkdir -p \"${VENV_DIR}\"\npython -m venv \"${VENV_DIR}\" --system-site-packages\nsource \"${VENV_DIR}/bin/activate\"\n</code></pre> <p>You can always retroactively change the <code>--system-site-packages</code> flag state for this virtual environment by editing <code>${VENV_DIR}/pyvenv.cfg</code> and changing the value of the line <code>include-system-site-packages=false</code>.</p> <p>To install a different version of a package that is already installed in the base environment, you can use:</p> <pre><code>python3 -m pip install --ignore-installed &lt;package&gt; # or -I\n</code></pre> <p>The shared base environment is not writable, so it is impossible to remove or uninstall packages from it. The packages installed with the above <code>pip</code> command should shadow those installed in the base environment.</p>"},{"location":"sophia/data-science/python/#cloning-the-base-anaconda-environment","title":"Cloning the base Anaconda environment","text":"<p>Warning</p> <p>This approach is generally not recommended as it can be quite slow and can use significant storage space.</p> <p>If you need more flexibility, you can clone the conda environment into a custom path, which would then allow for root-like installations via <code>conda install &lt;module&gt;</code> or <code>pip install &lt;module&gt;</code>.</p> <p>Unlike the <code>venv</code> approach, using a cloned Anaconda environment requires you to copy the entirety of the base environment, which can use significant storage space.</p> <p>To clone the <code>base</code> environment:</p> <pre><code>module load conda; conda activate base\nconda create --clone base --prefix /path/to/envs/base-clone\nconda activate /path/to/envs/base-clone\n</code></pre> <p>where <code>/path/to/envs/base-clone</code> should be replaced by a suitably chosen path.</p> <p>Note: The cloning process can be quite slow.</p>"},{"location":"sophia/data-science/python/#using-pip-install-user-not-recommended","title":"Using <code>pip install --user</code> (not recommended)","text":"<p>Danger</p> <p>This is typically not recommended.</p> <p>With the conda environment setup, one can install common Python modules using <code>python3 -m pip install --user '&lt;module-name&gt;'</code> which will install packages in <code>$PYTHONUSERBASE/lib/pythonX.Y/site-packages</code>.</p> <p>The <code>$PYTHONUSERBASE</code> environment variable is automatically set when you load the base conda module, and is equal to <code>/home/$USER/.local/polaris/conda/YYYY-MM-DD</code>.</p> <p>Note, Python modules installed this way that contain command line binaries will not have those binaries automatically added to the shell's <code>$PATH</code>. To manually add the path:</p> <pre><code>export PATH=\"$PYTHONUSERBASE/bin:$PATH\"\n</code></pre> <p>Be sure to remove this location from <code>$PATH</code> if you deactivate the base Anaconda environment or unload the module.</p> <p>Cloning the Anaconda environment, or using <code>venv</code> are both more flexible and transparent when compared to <code>--user</code> installs.</p>"},{"location":"sophia/data-science/python/#default-python-version","title":"Default Python Version","text":"<p>The default Python on Sophia is located at <code>/usr/bin/python</code> with version 3.9.18.</p>"},{"location":"sophia/data-science/python/#creating-a-jupyter-kernel","title":"Creating a Jupyter Kernel","text":"<p>If you would like to use your Python virtual environment on JupyterHub, you will need to create a Jupyter kernel for it.</p> <ol> <li> <p>Install <code>ipykernel</code>:     Ensure <code>ipykernel</code> is installed in your virtual environment:     <pre><code>pip install ipykernel\n</code></pre></p> </li> <li> <p>Create a Jupyter Kernel:     <pre><code>python -m ipykernel install --user --name=myenv --display-name \"Jupyter (myenv)\"\n</code></pre>     Replace <code>myenv</code> with the name of your virtual environment and <code>\"Jupyter (myenv)\"</code> with the display name you want for the kernel in JupyterHub.</p> </li> </ol>"},{"location":"sophia/queueing-and-running-jobs/running-jobs/","title":"Running Jobs on Sophia","text":""},{"location":"sophia/queueing-and-running-jobs/running-jobs/#nodes-vs-queue","title":"Nodes vs Queue","text":"<p>The Sophia nodes are NVIDIA DGX A100 nodes, and each node contains eight (8) A100 GPUs.  The majority of the nodes have the 40 GB A100 models, but two nodes contain the 80 GB A100 models (see below).  You may request resources by node (with 8 GPUs) or by individual GPUs based on your job needs.  What you will get is determined by the queue you submit to (see Queues section below).</p>"},{"location":"sophia/queueing-and-running-jobs/running-jobs/#queues","title":"Queues","text":"<p>There are three production queues you can target in your <code>qsub</code> command (<code>-q &lt;queue name&gt;</code>):</p> Queue Name Node/GPU Min Node/GPU Max Time Min Time Max <code>by-gpu</code> 1 GPU 8 GPUs (valid values are 1, 2, 4, and 8) 5 min 24 hr <code>by-node</code> 1 Node 8 Nodes 5 min 24 hr <code>bigmem</code> 1 Node 1 Node 5 min 12 hrs <p>Note</p> <p>For all Sophia queues, <code>MaxQueued</code> will be 20 queued or running jobs (per project) and <code>MaxRunning</code> will be 5 concurrent jobs (per project)</p> <p>The initial queue policy will be simple First-In-First-Out (FIFO) based on priority with EASY backfill.  The <code>by-queue</code> and <code>by-gpu</code> queues target non-bigmem nodes.  The old <code>single-node</code> queue is now a routing queue (redirect) to the <code>by-node</code>, and the old <code>single-gpu</code> queue is now a routing queue (redirect) to the <code>by-gpu</code> queue.</p>"},{"location":"sophia/queueing-and-running-jobs/running-jobs/#queue-descriptions","title":"Queue Descriptions","text":""},{"location":"sophia/queueing-and-running-jobs/running-jobs/#by-gpu","title":"<code>by-gpu</code>","text":"<p>This is the default production queue<sup>1</sup> and is targeted at jobs that can utilize 1-8 GPUs.  The number of \"chunks\" you specify in your <code>qsub</code> (i.e., <code>-l select=4</code>) will be the number of GPUs you are allocated, and they will all be on the same node.  Valid values are 1, 2, 4, or 8 in your select statement.  These restrictions ensure you get a sane set of resources (RAM is in the same NUMA node as the cores, the GPU has minimal hops to the GPU, etc.).  If you specify a different value, your <code>qsub</code> will issue an error and fail.</p>"},{"location":"sophia/queueing-and-running-jobs/running-jobs/#by-node","title":"<code>by-node</code>","text":"<p>This queue is targeted at jobs that can utilize more than 8 GPUs.  The number of \"chunks\" you specify in your <code>qsub</code> (i.e., <code>-l select=4</code>) will be the number of Sophia DGX nodes (with 8 GPUs each) you are allocated.</p>"},{"location":"sophia/queueing-and-running-jobs/running-jobs/#bigmem","title":"<code>bigmem</code>","text":"<p>Two of the nodes have 80GB of RAM per GPU, while the other 22 have 40GB of RAM per GPU (640 GB of aggregate GPU memory per node vs. 320 aggregate GPU memory per node).  Use this queue to access the 2 nodes with more memory by specifying <code>-q bigmem</code> in your <code>qsub</code>.  A max of 1 node (<code>-l select=1</code>) can be requested in this queue.</p> <ol> <li> <p>The default queue is where your job will be submitted if you don't have <code>-q &lt;queue name&gt;</code> in your <code>qsub</code>.\u00a0\u21a9</p> </li> </ol>"},{"location":"sophia/visualization/","title":"Visualization on Sophia","text":"<p>With its powerful NVIDIA GPUs, Sophia offers an excellent environment for visualization.</p> <p>Below is a list of available visualization tools with links to their respective documentation.</p> <p>ParaView: ParaView is an open-source visualization engine that seamlessly integrates with your existing tools and workflows. It allows you to construct visualization pipelines for quick data analysis. Whether interactively exploring large datasets in 3D or performing batch processing programmatically, ParaView provides versatile capabilities. For additional information, visit the Kitware website.</p>"},{"location":"sophia/visualization/paraview/","title":"ParaView on Sophia","text":"<p>The recommended way of running ParaView on Sophia is in client/server mode. This consists of running the ParaView client on your local resource and the ParaView server on the Sophia compute nodes. The ParaView client needs to first be installed on your local resource and needs to match the version that you run on Sophia.</p> <p>There may be multiple versions of ParaView installed on Sophia. To find the versions of ParaView currently available on Sophia, run the following command on a login node:  <pre><code>module use /soft/modulefiles\nmodule avail paraview\n</code></pre></p> <p>Binary and source packages of the ParaView client for Linux, macOS, and Windows are available from the ParaView Download Page.</p>"},{"location":"sophia/visualization/paraview/#connecting-to-the-paraview-server-on-sophia","title":"Connecting to the ParaView server on Sophia","text":"<p>This section describes how to launch the ParaView server on Sophia from a local ParaView client.</p>"},{"location":"sophia/visualization/paraview/#start-paraview-client","title":"Start ParaView Client","text":"<p>First, launch the ParaView client on your local resource. You will need to configure some server settings in the client. This initial setup should only need to be done once and can be reused each time you want to run ParaView on Sophia.</p>"},{"location":"sophia/visualization/paraview/#server-configuration","title":"Server Configuration","text":""},{"location":"sophia/visualization/paraview/#1-select-connect","title":"1. Select Connect","text":"<p>From the ParaView client, choose to connect to a server by either clicking on the \"Connect\" icon in the menu bar</p> <p></p> <p>or selecting File-&gt;Connect from the main menu.</p> <p></p>"},{"location":"sophia/visualization/paraview/#2-set-up-servers-first-time-only","title":"2. Set Up Servers (first time only)","text":"<p>The first time you want to run a server on Sophia and have it connect to your local ParaView client, you will need to set up a server. Once this server is set up, you can reuse it each time you run the ParaView client with the ParaView server on Sophia.</p> <p>Kitware, the developers of ParaView, maintain a database of server configurations which you can retrieve through the ParaView client.</p> <p>NOTE</p> <p>At this time, there are no specific files for Sophia available from Kitware. We will update this page when the files are available. In the meantime, you can download configuration files here and import them with the <code>Load Servers</code> option. Please use the <code>Save link as</code> option in your browser. Mac Windows</p>"},{"location":"sophia/visualization/paraview/#3-use-paraview","title":"3. Use ParaView","text":"<p>After the previous step, you can now select SOPHIA@ANL in the File-&gt;Connect menu and press Connect.</p> <p></p> <p>At this point, a new window will pop up.</p> <p></p> <p>There are a number of parameters that you must enter manually here:</p> <ul> <li>Xterm executable: The path of a terminal on your system. The figure shows the case of a Mac with XQuartz. You may need to change these values for Windows or Linux.</li> <li>SSH executable: The name of your ssh command. It may be different on Windows depending on the ssh client installed (e.g., PuTTY).</li> <li>Remote machine: Leave this value at sophia.alcf.anl.gov.</li> <li>Username: Your ALCF username.</li> <li>ParaView version: The version of ParaView that you want to use. Verify first that this version is installed on the system (as described at the top of this document). You will also need to add a <code>-EGL</code> suffix.</li> </ul> <p>Example: <pre><code>5.13.1-EGL\n</code></pre></p> <ul> <li>Client port: It is safe to use the default value.</li> <li>Server port: It is safe to use the default value.</li> <li>Number of nodes to reserve: Enter the number of Sophia compute nodes you want to use for your job.</li> <li>Number of ranks per node: Enter the number of ranks per node.</li> <li>Number of minutes to reserve: The duration of your job in minutes.</li> <li>Account: Enter here the name of your ALCF allocation.</li> <li>Queue: The name of the Sophia queue you would like to use (e.g., <code>by-gpu</code> or <code>by-node</code>). We recommend <code>by-gpu</code> for most jobs so that the nodes are used efficiently.</li> <li>File Systems: Enter here the file systems you need for your job, separated with colons, no spaces. Keep in mind that your job may not run if one of these file systems is not available at that time, so enter these values carefully.</li> <li>Job name: Safe to use the default value. The PBS scheduler will assign this name to your job.</li> </ul> <p>Now you can press OK to establish the connection with a ParaView server on Sophia.</p> <p>An SSH connection will be established with a Sophia login node, and a password will be requested in a terminal, similar to the process you normally use to connect and work on the system.</p> <p>After you enter your password, a job will be queued, and you will see a window like this:</p> <p></p> <p>When the job is launched on the compute nodes, the previous window will go away, and ParaView will show it is connected to Sophia in its Pipeline Browser:</p> <p></p> <p>At this point, you can open datasets stored on the ALCF file systems and use ParaView normally.</p>"},{"location":"sophia/visualization/paraview/#additional-information","title":"Additional Information","text":"<ul> <li>ParaView Documentation</li> <li>ParaView Community Support</li> </ul>"},{"location":"support/","title":"User Support","text":"<p>The ALCF Support team is available from 9 a.m. to 5 p.m. Central Time, Monday - Friday, except on holidays. </p> <p>Click on the links below for more information:</p> <ul> <li>Staying in Touch</li> <li>Mailing Lists</li> <li>Submit a Ticket</li> <li>Request Software</li> <li>ALCF Users Slack Workspace</li> <li>AskALCF AI Chatbot</li> <li>Contribute to User Guides</li> <li>Aurora Office Hours</li> </ul>"},{"location":"support/docs-issues/","title":"Questions/Issues on ALCF Docs","text":"<p>The ALCF documentation source code is hosted on GitHub to make it easier to contribute and collaborate.</p> <p>If you find any issues within these pages, please open an Issue at ALCF GitHub user guide webpage. Provide us with a brief description of the issue, page URL, section heading, and mark the appropriate label type on the right pane. </p>"},{"location":"support/ticket/","title":"Submitting a Ticket","text":"<p>ALCF manages user support issues through an email support ticketing system. To submit a trouble ticket, please email ALCF Support at support@alcf.anl.gov. You can also send questions, requests, and feedback to ALCF Support as well. </p> <p>Note</p> <p>Our ALCF Support team is available from 9 a.m. to 5 p.m. Central Time, Monday-Friday, except on holidays.</p>"},{"location":"support/ticket/#best-practices-for-submitting-tickets","title":"Best Practices for Submitting Tickets","text":"<p>Before contacting ALCF Support, be sure to check the Known Issues pages for the following systems:</p> <ul> <li>Polaris</li> <li>Aurora</li> </ul> <p>When emailing support, include:</p> <ul> <li>Your ALCF Username</li> <li>Your project shortname</li> <li>The system(s) you're having issues with (Polaris, Sophia, Aurora, etc.)</li> <li>Additional information to help us debug your issue. See Job Failures, Python Issues, Installation/compilation issues sections below for additional details to be included in your ticket</li> </ul> <p>Please note:</p> <ul> <li>Do not respond to closed tickets. Your response will NOT re-open the ticket.</li> <li>Do not use an existing ticket to ask for assistance on new topics. Instead, submit a new ticket by emailing Support.</li> <li>See \"Job Failures\", \"Python Issues\", \"Installation/compilation issues\" sections below for additional details to be included in your ticket</li> </ul>"},{"location":"support/ticket/#job-failures","title":"Job Failures","text":"<p>If you are having issues running your job, or your job is failing, please include the following in your email to support@alcf.anl.gov:</p> <ul> <li>All job IDs of the failures</li> <li>Your <code>qsub</code> submission script if you're submitting a batch job, or your full <code>qsub</code> command if you're submitting an interactive job</li> <li>A list of all modules loaded while running your job. Please provide the list via the <code>module list</code> command and NOT a list of your <code>module load &lt;module&gt;</code> commands</li> <li>The <code>*.e</code> (error) and <code>*.o</code> (output) files from at least one of your job failures</li> <li>Any errors displayed on the command line</li> </ul> <p>Info</p> <p>Support does not have access to your home directory or your project directory. Please do not include directory paths as a means for Support to access your submission script. It must be attached to the ticket.</p>"},{"location":"support/ticket/#python-issues","title":"Python Issues","text":"<p>If you need to open a ticket related to Python, please be sure to include the following in your email to support@alcf.anl.gov:</p> <ul> <li>Your <code>qsub</code> submission script</li> <li>Which base conda module and environment you are using</li> <li>The output from <code>module list</code></li> <li>Whether you have extended the base environment via <code>venv</code>, <code>conda clone</code>, etc.</li> <li>Have you installed any new packages, or removed existing ones? If so, please include your script and commands necessary to recreate the issue</li> <li>Whether you're attempting to run on a login node or a compute node</li> </ul> <p>By including the above information, this will help ALCF Support staff quickly route your ticket to the correct subject-matter expert (SME), resulting in a quicker resolution.</p> <p>Tip</p> <p>We encourage the use of the pre-installed <code>conda</code> environment. Any custom environments are supported on a best-effort basis only.</p>"},{"location":"support/ticket/#installation-compiling-issues","title":"Installation &amp; Compiling Issues","text":"<p>If you are having issues installing and/or compiling your app, please include the following in your email to support@alcf.anl.gov:</p> <ul> <li>The output from <code>module list</code></li> <li>If you are on a login node or a compute node</li> <li>A link to the app you are attempting to install (if possible)</li> <li>The full command you're using to compile</li> <li>Any other necessary steps Support will need to recreate the issue</li> </ul>"},{"location":"support/ticket/#mailing-lists","title":"Mailing lists","text":"<p>System outages and preventative maintenance schedules are sent to appropriate system Mailing Lists.</p>"},{"location":"support/get-help/","title":"Staying in Touch","text":"<p>ALCF uses several channels to share updates our facility and systems with users.</p>"},{"location":"support/get-help/#mailing-list-notifications","title":"Mailing List Notifications","text":"<p>As a facility user, you will be added to our system notification mailing list. The mailing list will keep you up-to-date on machine maintenance, outages, and opportunities. Users are auto-subscribed to the relevant system mailing list(s) when they first gain access to that resource. You can unsubscribe from these notifications, although we recommend against doing so. You can learn more about your subscriptions at Mailing Lists.</p> <p>We send users a weekly newsletter on Fridays at 10 a.m. CT and a monthly facility newsletter. </p>"},{"location":"support/get-help/#system-statuses","title":"System Statuses","text":"<p>You can check the current status of ALCF systems by logging in to MyALCF and checking the home screen dashboard. You can learn more about MyALCF here.</p> <p>All system-specific announcements will also be published on the <code>#announcements</code> channel in the ALCF Users Slack.</p>"},{"location":"support/get-help/#alcf-support","title":"ALCF Support","text":"<p>Our ALCF support team is available from 9 a.m. to 5 p.m. Monday - Friday, except on holidays. For technical assistance, you can reach the support team by submitting an email ticket to support@alcf.anl.gov. For account and access-related queries, you should submit a ticket to accounts@alcf.anl.gov. </p> <p>If you have a question or need help on your project, please see How to Submit a Ticket before emailing support@alcf.anl.gov. </p> <p>If you have an INCITE or ALCC allocation award, you can contact your Catalyst directly for project support.</p>"},{"location":"support/get-help/#training-events-and-videos","title":"Training Events and Videos","text":"<p>ALCF offers workshops and webinars on various tools, systems, and frameworks. These hands-on training programs are designed to help PIs, project team members, and future users take advantage of the leadership-class computers available at ALCF and enhance the performance and productivity of their research. </p> <p>ALCF also collaborates with peer institutions and vendor partners to offer training that strengthens community competencies and promotes best practices.</p> <p>Please check our website for upcoming events.</p> <p>Please tune into our YouTube channel for on-demand video content. </p>"},{"location":"support/get-help/alcf-users-slack/","title":"ALCF Users Slack Workspace","text":"<p>The ALCF Users Slack workspace is a platform intended for current, active ALCF users<sup>1</sup> where the user community can interact, collaborate, and help one another. This workspace is a pilot program valid for 1 year.  This workspace is a platform for the user community to interact and collaborate. ALCF staff may have a limited presence or not be present at all times to assist users with their queries. The official mechanism for requesting support is to email support@alcf.anl.gov for technical issues and accounts@alcf.anl.gov for account and access-related issues.</p>"},{"location":"support/get-help/alcf-users-slack/#getting-access","title":"Getting access","text":"<p>ALCF Users Slack access is automatically provided to members of INCITE, ALCC, and ESP projects. Certain (see footnote) DD projects<sup>1</sup> can request Slack access for their teams by submitting a support ticket to support@alcf.anl.gov. </p>"},{"location":"support/get-help/alcf-users-slack/#logging-into-slack","title":"Logging into Slack","text":"<p>ALCF Users Slack uses ALCF credentials for access. Active ALCF users who have been\u00a0granted access should log in here: https://alcf-users.slack.com.</p>"},{"location":"support/get-help/alcf-users-slack/#using-slack-channels","title":"Using Slack Channels","text":"<p>Once you are logged into the Slack workspace, your default channels will show up in the navigation pane. All system-specific announcements will be published on the <code>#announcements</code> channel. You can browse and join existing public channels or create private channels for your project. You can send direct messages to your collaborators. While you cannot create public channels, you can email support@alcf.anl.gov to request for one.</p> <p>The ALCF User Slack workspace should not be used to discuss, store, or operate any NDA/RSNDA, Official Use Only (OUO), or Business Sensitive information.</p> <p>Argonne's code of conduct governs the use of all ALCF resources. By joining and using the workspace, you agree to these terms. Users violating Argonne's code of conduct may be removed from the workspace.</p> <ol> <li> <p>ALCF users working on scientific or research campaigns across various allocation types are eligible for access to the ALCF Users Slack workspace. Users participating in training events, instructional courses, or lighthouse projects are not eligible for User slack access.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"support/get-help/askalcf/","title":"AskALCF: A RAG-empowered chatbot for User Support","text":"<p>Disclaimer</p> <p>AskALCF is an AI-assisted tool designed to help ALCF users quickly access information. Responses are generated using automated methods and may not always be accurate, complete, or current. Users should confirm critical information through official ALCF documentation or by contacting ALCF support.</p> <p>Feedback</p> <p>We value your input to improve AskALCF. If you encounter incorrect or unclear information, please share your feedback to help us enhance the service.</p> <p>AskALCF is an intelligent, Retrieval-Augmented Generation (RAG) powered chatbot system designed to enhance user support at the Argonne Leadership Computing Facility (ALCF). It provides fast, accurate, and context-aware responses to user queries by leveraging a curated HPC-specific knowledge base and state-of-the-art language models. </p> <p>Retrieval Augmented Generation (RAG) pipeline: LLM retrieves relevant external documents before generating an answer, grounding its output in factual, up-to-date information.</p>"},{"location":"support/get-help/askalcf/#knowledge-base","title":"Knowledge Base","text":"<p>Below are the documents curated in the vector database used by AskALCF chatbot.</p> Data Type / format ALCF User Guide Markdown OLCF User Guide RST LLNL User Guide Web PBS Documentation PDF Slurm Documentation Web CUDA C Programming Guide Web SYCL Documentation PDF AMD HIP Documentation Web Intel OneAPI Documentation Web"},{"location":"support/get-help/askalcf/#accessing-askalcf","title":"Accessing AskALCF","text":"<p>The chatbot is currently hosted on a CELS Virtual Machine accessible through https://ask.alcf.anl.gov</p> <p></p> <p>Example user interaction with AskALCF</p>"},{"location":"support/get-help/askalcf/#example-questions","title":"Example Questions","text":"<p>Please make your question as specific as possible. This helps the chatbot retrieve the most relevant information and provide a high-quality answer. Examples of high-quality questions include:</p> <ul> <li>On Aurora, what is the command to log in, and what is the default quota for user home directories?</li> <li>How do I request 8 Aurora nodes all within the same rack using PBS, using the following job parameters? Script:<code>pbs_submit_script.sh</code>, Project: <code>RackTest</code>, Queue: <code>prod</code>, Duration: <code>1 hr</code>, Filesystem: <code>grand</code>.</li> <li>Will my ALCF HPSS home directory remain accessible for my group members after my account termination?</li> <li>What is the best environment variable setting for oneCCL?</li> <li>How should I use copper to run a Python job at scale on Aurora?</li> <li>What is the optimal CPU binding on Aurora?</li> </ul>"},{"location":"support/get-help/askalcf/#providing-feedback","title":"Providing Feedback","text":"<ul> <li>If you have feedback on a specific query, you can directly rate and comment on the chatbot\u2019s response. We only track queries, responses, and ratings. No personal information is collected through this mechanism:<ul> <li>Click \u201cRate this assistant response\u201d</li> <li>Select a rating</li> <li>Optionally provide additional comments</li> <li>Click \u201cSubmit rating\u201d</li> </ul> </li> <li>For high-level comments or feedback, please contact: support@alcf.anl.gov</li> <li>All feedback is anonymous, by default. If you would like to receive follow-up communication, please provide your contact info. </li> </ul>"},{"location":"support/get-help/mailing-lists/","title":"Mailing Lists","text":"<p>All notifications regarding system outages and preventative maintenance schedules are sent to appropriate system mailing lists. </p> <p>Users are auto-subscribed to the relevant system mailing list(s) when they first gain access to that system. The user's primary email is subscribed to the list(s).</p> <p>You will need to re-subscribe if you either:</p> <ul> <li>Unsubscribed from the mailing list(s) and wish to rejoin, or</li> <li>Would like to subscribe a different email address instead</li> </ul>"},{"location":"support/get-help/mailing-lists/#manual-unsubscription","title":"Manual un/subscription","text":"<p>To manually subscribe or unsubscribe from an arbitrary <code>list-name</code>, go to: <pre><code>https://lists.alcf.anl.gov/mailman/listinfo/&lt;list-name&gt;-notify \n</code></pre> and follow the instructions. </p> <p>Warning</p> <p>You must replace <code>&lt;list-name&gt;</code> with an appropriate compute system you have access to (such as <code>polaris</code>, <code>crux</code>, <code>aurora</code>, <code>sophia</code>, etc.).</p>"},{"location":"support/get-help/office-hours/","title":"Aurora Center of Excellence (COE) Office Hours","text":"<p>Aurora Office Hours is a weekly discussion of questions, issues, and other topics from Aurora users.</p> <p>Aurora users are invited to join our Office Hours with the Intel Center of Excellence (COE) @ ALCF.</p> <ul> <li>When  : Tuesdays, 12 p.m. - 1 p.m. Central time</li> <li>Where : Online</li> </ul> <p>Aurora users are invited to our Office Hours with the Intel COE @ ALCF, The Intel COE @ ALCF is a small team of engineers and scientists from the Intel\u00ae Corporation focused on Scientific Computing and AI-in-Science.</p> <p>To be added to the Office Hours invite, please email support@alcf.anl.gov</p>"},{"location":"support/get-help/software-requests/","title":"Software Requests","text":"<p>Warning</p> <p>Software install requests can take several months to receive approval before testing and installation. Therefore, it is strongly encouraged to attempt to install the app yourself before contacting support for it to be installed system-wide.</p> <p>If you want to request a package be installed on Polaris or Aurora, please email support@alcf.anl.gov and include the following:</p> <ul> <li>A link to the package/app you want to be installed</li> <li>The reason you need the package installed</li> <li>Why the currently provided applications/modules will not work for your workflow (if applicable)</li> </ul>"}]}